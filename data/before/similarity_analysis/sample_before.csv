73827986,Copy data from host to container efficiently,"The idea is a docker container which aims to train machine learning models for computer vision.
The data which is trained needs to be uploaded to the container, consumed and deleted afterwards.
Is there any way to use a volume and transport data efficiently between the host and the container?
When I searched on the web, most sources mentioned manual transport via bash or something similar, while my application needs to do this in an automated an repeating way for different datasets.
The host machine is a windows and the container is linux.
EDIT: there is a main application running on the machine which is responsible for managing the process.

send data to container (somehow?)
trigger training process

the training process runs async to not block the rest api
Any ideas?
","docker, containers",2,73829547,"You can use bind mounts when building you docker container,
See https://docs.docker.com/storage/bind-mounts/
you specify a directory inside your container which will be mounted on a local directory on your host, this way all container write operations are mounted directly to your host directory.
I'd recommand doint it using docker-compose, for example below:
container directory /opt/Projects/01_MyProject will be mounted to host directory /Volumes/Partition_2/Docker-Volumes/Volume_1,
#docker-compose.yml
...
    volumes:
      - PERSIST_DATA:/opt/Projects/01_MyProject
volumes:
  PERSIST_DATA:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /Volumes/Partition_2/Docker-Volumes/Volume_1

This way, you can copy anything to /Volumes/Partition_2/Docker-Volumes/Volume_1, which will show up under /opt/Projects/01_MyProject
"
73368255,Rust can't borrow a newly declared variable?,"This code is suppose to be a simple while loop. Until I enter the word exit it should keep taking in a list of names and print out the vector. I am using this to test my understanding of borrowing.
use std::io;

fn main() { 

    let mut name = String::new();
    let mut vec = Vec::new();

    while name.ne(&quot;exit&quot;) {
        print!(&quot;Enter a name&quot;); 
        io::stdin().read_line(&amp;mut name).expect(&quot;failed to readline&quot;);
    
        print!(&quot;You entered {}&quot;, name); 

        vec.push(name); 
        println!(&quot;length of vector is {}&quot;, vec.len());

        for i in &amp;vec {
            println!(&quot;name in vector is {}&quot;, i);
        }  
    }

}


This code will not compile due to the following error:
~/rust/vectors/src$ cargo build
   Compiling vectors v0.1.0 (rust/vectors)
error[E0382]: borrow of moved value: `name`
  --&gt; src/main.rs:8:11
   |
5  |     let mut name = String::new();
   |         -------- move occurs because `name` has type `String`, which does not implement the `Copy` trait
...
8  |     while name.ne(&quot;exit&quot;) {
   |           ^^^^^^^^^^^^^^^ value borrowed here after move
...
14 |         vec.push(name); 
   |                  ---- value moved here, in previous iteration of loop

For more information about this error, try `rustc --explain E0382`.
error: could not compile `vectors` due to previous error


I thought it was a mutable reference that I have to borrow so I changed the while loop to this: while &amp;mut name.ne(&quot;exit&quot;) but that just gave me this error:
   Compiling vectors v0.1.0 (rust/vectors)
error[E0308]: mismatched types
 --&gt; src/main.rs:8:11
  |
8 |     while &amp;mut name.ne(&quot;exit&quot;) {
  |           ^^^^^^^^^^^^^^^^^^^^ expected `bool`, found `&amp;mut bool`
  |
help: consider removing the borrow
  |
8 -     while &amp;mut name.ne(&quot;exit&quot;) {
8 +     while name.ne(&quot;exit&quot;) {
  | 

For more information about this error, try `rustc --explain E0308`.
error: could not compile `vectors` due to previous error

",rust,1,73368502,"The move is not within ne(), and thus borrowing it there will not solve the problem (also, to borrow it you need to do (&amp;mut name).ne(&quot;exit&quot;); &amp;mut name.ne(&quot;exit&quot;) will borrow the result of ne() mutably). ne() borrows the value with a shared reference.
The move, as the compiler tells you, is within vec.push(name). Here we move name, and any further attempt to access it is an error. But in the next round of the loop we'll try to do exactly that to compare it with &quot;exit&quot;!
There are generally two solutions to that:

Clone the string and push the cloned string to the vector, leaving the original unmodified.

vec.push(name.clone());


Instead of checking name directly, check the last value in the vector. We need to be careful to not assume there is such value, because the vector is empty in the beginning of the first iteration:

let mut vec = Vec::&lt;String&gt;::new();

while vec.last().map(|v| &amp;**v) != Some(&quot;exit&quot;) {
    let mut name = String::new();

    print!(&quot;Enter a name&quot;);
    io::stdin()
        .read_line(&amp;mut name)
        .expect(&quot;failed to readline&quot;);

    print!(&quot;You entered {}&quot;, name);

    vec.push(name);
    println!(&quot;length of vector is {}&quot;, vec.len());

    for i in &amp;vec {
        println!(&quot;name in vector is {}&quot;, i);
    }
}

But in your case, it is more likely that you don't want to push &quot;exit&quot; into the Vec at all. So, it is better to use loop with break:
let mut vec = Vec::&lt;String&gt;::new();
loop {
    let mut name = String::new();
    print!(&quot;Enter a name&quot;);
    io::stdin()
        .read_line(&amp;mut name)
        .expect(&quot;failed to readline&quot;);

    if name == &quot;exit&quot; {
        break;
    }

    print!(&quot;You entered {}&quot;, name);

    vec.push(name);
    println!(&quot;length of vector is {}&quot;, vec.len());

    for i in &amp;vec {
        println!(&quot;name in vector is {}&quot;, i);
    }
}

"
72986123,how to detect a key press when a mouse click happened in tkinter canvas,"I have a canvas with a rectangle and I want to detect if someone pressed the rectangle together with a key (ie &quot;shift&quot;). In Matplotlib the mouse event can do that with the key property. Wondering if tkinter has somehting similar? I tried this solution
from tkinter import *

root = Tk()

def key(event):
    print(&quot;pressed&quot;, repr(event.char))

def callback(event):
    print(&quot;clicked at&quot;, event.x, event.y)

canvas= Canvas(root, width=100, height=100)
canvas.bind(&quot;&lt;Key&gt;&quot;, key)
canvas.bind(&quot;&lt;Button-1&gt;&quot;, callback)
canvas.pack()

root.mainloop()

but it doesn't detect key events, only the mouseclick events work.
","python, tkinter, tkinter-canvas",0,72986284,"Instead of detecting whether the shift key is pressed or not, you can bind to the &lt;Shift-Button-1&gt; event so that the callback is only called if the user shift-clicks on the object.
Here is an example that will display the color of an item when you shift-click on it.
import tkinter as tk

def handle_click(event):
    color = event.widget.itemcget(&quot;current&quot;, &quot;fill&quot;)
    label.configure(text=f&quot;item color: {color}&quot;)

root = tk.Tk()

canvas = tk.Canvas(root, background=&quot;bisque&quot;)
label = tk.Label(root)

label.pack(side=&quot;bottom&quot;, fill=&quot;x&quot;)
canvas.pack(fill=&quot;both&quot;, expand=True)

canvas.create_rectangle(10, 10, 110, 110, fill=&quot;red&quot;, tags=(&quot;rectangle&quot;,))
canvas.create_rectangle(150, 10, 200, 110, fill=&quot;green&quot;, tags=(&quot;rectangle&quot;,))

canvas.tag_bind(&quot;rectangle&quot;, &quot;&lt;Shift-Button-1&gt;&quot;, handle_click)

root.mainloop()


If you want to handle multiple combinations of modifier keys (alt, shift, control, meta, etc) you can bind to &lt;1&gt; and examine the state attribute of the event object. However, there are platform dependencies that make that problematic. I personally find making individual bindings easier and more straight-forward.
For more on how to use the event.state attribute, see check if modifier key is pressed in tkinter
"
74368270,Making a string inside a sentence bold - Apache POI,"How do I make a string bold while it's inside a sentence?
I've just started using Apache POI like 4 hours ago and wanted to:

Locate different strings inside a Word-Document (.docx/XWPF)
Replace the strings with the value of the map
Make the value appear bold, if the string has a special flag.

I tried to first approach this by iterating over the paragraph (not the Runs), but it didn't work. I've got my current solution from this post right here.
Everything is fine with the first two steps, now I want to make every value that contains a special flag (like ${key:bold} or ${score:bold}) bold. I've tried to create a new XWPFRun that writes the bold string, it just won't work with the code underneath...
ParagraphFieldReplacer.java (Currently working for step 1 and 2)
import java.util.List;
import java.util.Map;

import org.apache.poi.ooxml.POIXMLException;
import org.apache.poi.xwpf.usermodel.XWPFDocument;
import org.apache.poi.xwpf.usermodel.XWPFParagraph;
import org.apache.poi.xwpf.usermodel.XWPFRun;

public final class ParagraphFieldReplacer {
    
    public static void replace(final Student student, final XWPFDocument document, final Map&lt;String, FormatObject&gt; fields) {
        final List&lt;XWPFParagraph&gt; paragraphs = document.getParagraphs();
        for (final XWPFParagraph paragraph : paragraphs)
            replaceParagraph(student, paragraph, fields);
    }
    
    private static void replaceParagraph(final Student student, final XWPFParagraph paragraph, final Map&lt;String, FormatObject&gt; fields) throws POIXMLException {
        List&lt;XWPFRun&gt; runs;
        String paragraphtext;
        String runsText;
        XWPFRun nextRun;
        String target;
        XWPFRun run;
        for (final String key : fields.keySet()) {
            paragraphtext = paragraph.getText();
            if (!(paragraphtext.contains(&quot;${&quot;)))
                return;
            target = &quot;${&quot; + key + &quot;}&quot;;
            if (!(paragraphtext.contains(target)))
                continue;
            runs = paragraph.getRuns();
            for (int i = 0; i &lt; runs.size(); i++) {
                run = runs.get(i);
                runsText = run.getText(0);
                if (runsText.contains(&quot;${&quot;) || (runsText.contains(&quot;$&quot;) &amp;&amp; runs.get(i + 1).getText(0).substring(0, 1).equals(&quot;{&quot;))) {
                    while (!(openTagCountIsEqualCloseTagCount(runsText))) {
                        nextRun = runs.get(i + 1);
                        runsText = runsText + nextRun.getText(0);
                        paragraph.removeRun(i + 1);
                    }
                    if (!(runsText.contains(target)))
                        run.setText(runsText, 0);
                    else {
                        final FormatObject format = fields.get(key);
                        final String handle = format.handle(student);
                        run.setText(runsText.replace(target, handle), 0);
                    }
                }
            }
        }
    }
    
    private static boolean openTagCountIsEqualCloseTagCount(final String runText) {
        final int openTagCount = (runText.split(&quot;\\$\\{&quot;, -1).length - 1);
        final int closeTagCount = (runText.split(&quot;}&quot;, -1).length - 1);
        return (openTagCount == closeTagCount);
    }
    
}

FormatObject.java
public final class FormatObject {
    
    private boolean bold;
    private FormatHandler&lt;Student, String&gt; handler;
    
    public FormatObject(final FormatHandler&lt;Student, String&gt; handler, final boolean bold) {
        this.handler= handler;
        this.bold = bold;
    }
    
    public boolean isBold() {
        return bold;
    }
    
    public String handle(final ZertifikationsStudent student) {
        return handler.handle(student);
    }
    
}


FormatHandler.java
@FunctionalInterface
public interface FormatHandler&lt;P, R&gt; {
    
    public R handle(P p);
    
}

Thanks for reading/helping!
","java, ms-word, apache-poi",0,74420723,"I got this working the other day!
The best way to make it bold is to make the format-indicator bold in the document itself.
The other way is to create a new XWPFRun and set it to bold. The text should be the value of the key. After that, you can just add all the fixed XWPFRuns into an ArrayList and re-insert them, after removing every run in the selected paragraph. You can then just remove the old-normal XWPFRun that contains the format-indicator.
"
74511509,Start a bash session from python,"I want to drop into a shell for a ctf competition I am working on. I am not allowed to use pwntools for this. I want to achieve something like following from python:
import os
os.system(&quot;/bin/bash &amp;&quot;)
print(&quot;hello world&quot;)                 # assume I am writing to a file
os.system(&quot;fg&quot;)                      # does not work (but assume resuming shell /bin/bash)

I can't use subprocess since I need to drop into a shell. Not communicate back and forth with the bash process which would run in the background. Is there an easy way to approach this?
","python, python-3.x",0,74511576,"You want to use the subprocess module instead. fg is a shell built-in command that only works with job control in the shell itself.
import subprocess


p = subprocess.Popen([&quot;bash&quot;])
print('hello world')
p.wait()

"
73725448,How to make the loop update the range automatically in App Script for Google Sheets,"Background of this project
I am working on the database of employee evaluation. The database look something similar to the mock table below.




Row
KPI ID
Evaluation type
Owner(s)
Other data




1
SomeUniqueKey1
Type A
John
WhatEver1


2
SomeUniqueKey2
Type B
John, Jane, James
WhatEver2


3
...
...
...
...




So basically, I am trying to create the loop on this google sheet targeting 'Owner(s)' column that might contain a list-liked string that in this pattern ( a, b, c )(See row 2). My goal is to duplicate the row with multiple user and then modify the owner column to have only one user. So here is the end goal should look like:




Row
KPI ID
Evaluation type
Owner(s)
Other data




1
SomeUniqueKey1
Type A
John
WhatEver1


2
SomeUniqueKey2
Type B
John
WhatEver2


3
SomeUniqueKey2
Type B
Jane
WhatEver2


4
SomeUniqueKey2
Type B
James
WhatEver2


5
...
...
...
...




What I have done so far
By checking whether each cell in the owner column have a &quot;,&quot; or not (implying this is a list), if it contains &quot;,&quot;, I convert it into an array and duplicate the row to the amount of length of the array minus 1 and later modify each row of that column into the order of and array. (Please see the code).
function myFunction() {
  var ws = SpreadsheetApp.openById(&quot;SHEET ID&quot;);
  var ss = ws.getSheetByName('SHEET NAME');
  var r = ss.getRange(&quot;A1:E20000&quot;);
  r.activate;
  var v = r.getValues();
  for (var i=1;i&lt;=20000;i++){
    if(v[i-1][3].includes(&quot;,&quot;)){ 
      var temp = v[i-1][3].split(&quot;, &quot;);
      ss.insertRows(i,temp.length-1);
      for (var j = 0; j&lt;temp.length; j++ ){
        ss.getRange(i+temp.length-1,1,1,5).copyTo(ss.getRange(i+j,1,1,5));
        ss.getRange(i+j,3).setValue(temp[j]);
        }
        i = i+temp.length-1;
        }
    r.activate;
    v = r.getValues();
      }
      }

What being problematic
The loop stopped right after when they fix the first case of the issue. For instance, based on the mock table, the first case is on the row 2. After fixing the row 2, the later case after row 2 are not affected by the code anymore.
My assumption right now is that I insert the new row which change the referenced position. But I stuck here. Any kind of suggestions is appreciated.
","google-apps-script, google-sheets",0,73725748,"When I saw your script, getValue, setValue, and copyTo are used in a loop. In this case, the process cost becomes high. Ref In your situation, I would like to propose the following flow.

Retrieve values from Spreadsheet.
Process the retrieved values and create an array.
Put an array on Spreadsheet.

When this flow is reflected in a sample script, how about the following modified script?
Modified script:
function myFunction() {
  var ws = SpreadsheetApp.openById(&quot;SHEET ID&quot;);
  var ss = ws.getSheetByName('SHEET NAME');

  // I modified below script.
  var range = ss.getDataRange();
  var values = range.getValues().flatMap(r =&gt; {
    var idx = r.findIndex(c =&gt; c.includes(&quot;,&quot;));
    if (idx == -1) {
      return [r];
    }
    return r[idx].split(&quot;,&quot;).map(v =&gt; {
      var temp = r.slice();
      temp[idx] = v.trim();
      return temp;
    });
  });
  range.clearContent();
  ss.getRange(1, 1, values.length, values[0].length).setValues(values);
}

Or, if the column number is known, you might be able to be used.
function myFunction() {
  var ws = SpreadsheetApp.openById(&quot;SHEET ID&quot;);
  var ss = ws.getSheetByName('SHEET NAME');

  // I modified below script.
  var columnNumber = 3; // This is column &quot;C&quot;.
  var range = ss.getDataRange();
  var values = range.getValues().flatMap(r =&gt; {
    if (r[columnNumber - 1].includes(&quot;,&quot;)) {
      return r[columnNumber - 1].split(&quot;,&quot;).map(v =&gt; {
        var temp = r.slice();
        temp[columnNumber - 1] = v.trim();
        return temp;
      });
    }
    return [r];
  });
  range.clearContent();
  ss.getRange(1, 1, values.length, values[0].length).setValues(values);
}


When this script is run, the values are retrieved from Spreadsheet and put the converted values to the same sheet.

References:

getValues()
setValues(values)
map()

"
73465679,using load function with variables in MATLAB,"filterSize
sz = sprintf( '%dx%d', filterSize, filterSize );
I have some .mat files named

results_3x3.mat


results_5x5.mat

and so on..
I am importing that files with load function. But since that I have 20 files I need to do it in a for loop.  filterSize=3:2:41
I need to use the load function in MATLAB with variables.
I am now doing it manually as follows:
F1_score_3 = load('results_3x3.mat');
accuracy_3 = F1_score_3.accuracy;

F1_score_5 = load('results_5x5.mat');
accuracy_5 = F1_score_5.accuracy;

F1_score_7 = load('results_7x7.mat');
accuracy_7 = F1_score_7.accuracy;

F1_score_3 = load('results_&amp;s.mat',sz); doesn't work.
Can you help me with this? Also, can I define variables with another variable in them? Such as
F1_score_%d, filterSize

","matlab, variables, load",1,73465748,"Do not create dynamic variable names that contain numbers like this. They will be hard to work with downstream in your code. It would be better to store the results in an array or cell or struct. E.g., you could do something like this using a cell array:
F1_score = cell(41,1);
for filterSize=3:2:41
    fname = sprintf( 'results_%dx%d.mat', filterSize, filterSize );
    F1_score{filterSize} = load(fname);
end

Then when you want to get at accuracy, you can use indexing as usual. E.g.,
F1_score{3}.accuracy

"
74411450,R - how to extract a string between two delimiters when there are multiple instances of the same delimiter,"some previous questions have been asked on this topic, but they don't seem to include the case when a string contains multiple instances of the same delimiter.
How to extract substring between patterns &quot;_&quot; and &quot;.&quot; in R
Extracting a string between other two strings in R
Extract a string between patterns/delimiters in R
The problem I am facing is the following. Say we have a vector like this:
vec &lt;- c(&quot;Europe/Germany/Berlin/Mitte&quot;, 
         &quot;Europe/Germany/Berlin/Charlottenburg&quot;, 
         &quot;Europe/Croatia/Zagreb/Gornji Grad&quot;, 
         &quot;Europe/Croatia/Zagreb/Donji Grad&quot;)

Can you provide me with the following two functions:
The output of the first function should be:
c(&quot;Germany&quot;, &quot;Germany&quot;, &quot;Croatia&quot;, &quot;Croatia&quot;)

And the output of the second function should be:
c(&quot;Berlin&quot;, &quot;Berlin&quot;, &quot;Zagreb&quot;, &quot;Zagreb&quot;)

I don't understand how the answers from previous questions apply when the delimiter / appears more than once in the string and how can I specify which of the pieces I want.
",r,-1,74413195,"library(tidyverse)

get_name &lt;- function(position) {
  vec %&gt;%
    str_split(&quot;/&quot;) %&gt;%
    map_chr( ~ .x[position])
}

Get position 2
get_name(2)
[1] &quot;Germany&quot; &quot;Germany&quot; &quot;Croatia&quot; &quot;Croatia&quot;

Get position 3
get_name(3)
[1] &quot;Berlin&quot; &quot;Berlin&quot; &quot;Zagreb&quot; &quot;Zagreb&quot;

"
73956768,Integrating timeonsite.js on a basic ReactJS app and correct way to show live time counter for tracking user engagement,"I followed the public react app

simple-reactjs-app

by aditya-sridhar found on Github for setting up the web application. I cloned the repo and just added two blocks (timer init &amp; HTML timer update div) so that you can follow up if you wanted to reproduce the same. I also integrated the timeonsite.js tracker as given below:
&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
  &lt;head&gt;
    &lt;meta charset=&quot;utf-8&quot;&gt;
    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, shrink-to-fit=no&quot;&gt;
    &lt;meta name=&quot;theme-color&quot; content=&quot;#000000&quot;&gt;
    &lt;link rel=&quot;manifest&quot; href=&quot;%PUBLIC_URL%/manifest.json&quot;&gt;
    &lt;link rel=&quot;shortcut icon&quot; href=&quot;%PUBLIC_URL%/favicon.ico&quot;&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;styles.css&quot;&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css&quot; integrity=&quot;sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u&quot; crossorigin=&quot;anonymous&quot;&gt;
    
    &lt;!-- ADDED FOR Real-time time tracking --&gt;
    &lt;script type=&quot;text/javascript&quot;&gt;
      var Tos;
      (function(d, s, id, file) {
          var js, fjs = d.getElementsByTagName(s)[0];
          if (d.getElementById(id)) return;
          js = d.createElement(s);
          js.id = id;
          js.onload = function() {
              var config = {
                trackBy: 'seconds',
                developerMode: true,
                callback: function(data) {
                  console.log(data);
                  // give your endpoint URL/ server-side URL that is going to handle your TOS data which is of POST method. Eg. PHP, nodejs or python URL which saves this data to your DB
                  var endPointUrl = 'http://localhost/tos'; // replace with your endpoint URL
                  if (data &amp;&amp; data.trackingType &amp;&amp; data.trackingType == 'tos') {
                      if (Tos.verifyData(data) != 'valid') {
                        console.log('Data abolished!');
                        return;
                      }
                      if (navigator &amp;&amp; typeof navigator.sendBeacon === 'function') {
                        var blob = new Blob([JSON.stringify(data)], {type : 'application/json'});
                        navigator.sendBeacon(endPointUrl, blob);
                      }
                    }
                }
              };
              if(TimeOnSiteTracker) {
                  Tos = new TimeOnSiteTracker(config);
                  window.Tos = Tos;
              }
          };
          js.src = file;fjs.parentNode.insertBefore(js, fjs);
       } (document, 'script', 'TimeOnSiteTracker', '//cdn.jsdelivr.net/gh/saleemkce/timeonsite@1.2.1/timeonsitetracker.min.js'));
      &lt;/script&gt;
      &lt;!-- ADDED FOR Real-time time tracking --&gt;

    &lt;title&gt;React App&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;noscript&gt;
      You need to enable JavaScript to run this app.
    &lt;/noscript&gt;
    &lt;div id=&quot;root&quot;&gt;&lt;/div&gt;


    &lt;!-- ADDED FOR Real-time time tracking --&gt;
    &lt;div id=&quot;timeContainerStats&quot; style=&quot;border: 1px solid #bbb; border-radius: 10px; text-align: center; font-family: cursive;&quot;&gt;
      You spent : 
      &lt;span id=&quot;timeonsite&quot; style=&quot;color:#f55;&quot;&gt;
      &lt;/span&gt; Seconds
    &lt;/div&gt;

    &lt;script&gt;
      console.log(typeof window)
      if (typeof window !== 'undefined') {
        setInterval(function() {
          document.getElementById('timeonsite').innerHTML = (window.Tos).getTimeOnPage().timeOnPage;
        }, 1000)
      } 
    &lt;/script&gt;
    &lt;!-- ADDED FOR Real-time time tracking --&gt;

  &lt;/body&gt;
&lt;/html&gt;

Live Timer in React App
Sorry, my first post here. So, I'm not allowed to show image directly hence image is added as link.
Questions:
1, I'm not allowed to access Tos window object directly. Hence I accessed it like &quot;window.Tos&quot; in React root index.html  Is it the right approach to fetch third party object in React?
2, Is it proper way to include the HTML block,
&lt;span id=&quot;timeonsite&quot; style=&quot;color:#f55;&quot;&gt;
      &lt;/span&gt; Seconds

or the right way would be write it as React component?
3, I added the powerful
setInterval(function() {}, 1000);

JS Interval function. Is it fine or we can use React inbuilt timer function for updating TIMER &quot;div&quot; each second?
FYI, I will need this Tos JS object in every page in my React web app so that I show how much time the user spent in the app so far in web page. If it can be written as React component, could you show a sample component written for this live time-counter. I've seen one other question in SO raising the same question but that used JS date timer directly instead of full-fledged tracker like timeonsite.js. Thanks for your help.
","javascript, reactjs, time-tracking",0,74086439,"Let's try to give you some answers:

I'm not allowed to access Tos window object directly. Hence I accessed
it like &quot;window.Tos&quot; in React root index.html Is it the right approach
to fetch third party object in React?

As long as you declare Tos as a global variable you should be able to access it from all the scopes. But more importantly there are several ways of achieving what you want.
To add a third-party object in React you can:

add it as you did in the index.html file, the approach you took. The issue here is that then to have some communication between the third party library and your react code it can only happen through global variables which could be a bad pattern.
Using some kind of webpack plugin for your cdn. But this will present the same issue as the previous approach. It just looks cleaner.
Add onMount the script:

function App() {
  // Proof that we can use Tos object
  const click = () =&gt; {
    console.log('Click', Tos)
    Tos
  }
  useEffect(() =&gt; {
    // This is the same that your script does but in a &quot;React&quot; way
    const script = document.createElement('script')
    script.setAttribute('src', '//cdn.jsdelivr.net/gh/saleemkce/timeonsite@1.2.1/timeonsitetracker.min.js')
    script.id = 'TimeOnSiteTracker'
    script.addEventListener('load', () =&gt; {

        const config = {
          trackBy: 'seconds',
          developerMode: true,
          callback: function(data) {
            console.log(data);

          }
        };
        if(TimeOnSiteTracker) {
         // IF this was not a `var` it will not be a global scoped variable
          var Tos = new TimeOnSiteTracker(config);
          window.Tos = Tos;
        }

    })
    document.body.appendChild(script)
  }, [])
  return (
    &lt;div className=&quot;App&quot;&gt;
      &lt;header className=&quot;App-header&quot;&gt;
        &lt;button onClick={click}&gt;Click&lt;/button&gt;
      &lt;/header&gt;
    &lt;/div&gt;
  );
}

Using useEffect we can basically mount the 3rd-party library on the mount lifecycle. In this last approach, you have more control over the parameters that you pass to the library, they can even be more dynamic and easier to interact as you will see in the answer to your 3rd question.

Is it proper way to include the HTML block,
or the right way would be write it as React component?

To get the power of react (rendering, performance control over components) the best thing will be to move this code into the JSX of your app. This way this element will be dynamically added and not hard coded as in your approach.

I added the powerful setInterval(function() {}, 1000); JS Interval function. Is it fine or
we can use React inbuilt timer function for updating TIMER &quot;div&quot; each
second?

Actually given the API of Timeonsite.js, there is no better way of doing this (some may think that callback argument is called every time there is an update, but no, only on start and onload. Also, if we check what the developermode does, it basically calls Tos every second using the interval:
if (this.developerMode) {
        setInterval(function() {
            self.showProgress();
        }, (1 * 1000));
    }

To do this in a React friendly way:
 const [timer, setTimer] = useState(0)

  useEffect(() =&gt; {
    const interval = setInterval(() =&gt; {
        console.log(window.Tos.getTimeOnPage().timeOnPage)
        setTimer(window.Tos.getTimeOnPage().timeOnPage)
    }, 1000);
    return () =&gt; clearInterval(interval);
  }, []);

And then in the JSX:
 &lt;div&gt;You spent: &lt;span&gt; { timer }&lt;/span&gt; seconds&lt;/div&gt;

So if you declare it in your root component like this:
import './App.css';
import { useEffect, useState} from &quot;react&quot;;


function App() {
    const [timer, setTimer] = useState(0)

    useEffect(() =&gt; {
        const interval = setInterval(() =&gt; {
            setTimer(window.Tos.getTimeOnPage().timeOnPage)
        }, 1000);
        return () =&gt; clearInterval(interval);
    }, []);

    useEffect(() =&gt; {
        const script = document.createElement('script')
        script.setAttribute('src', '//cdn.jsdelivr.net/gh/saleemkce/timeonsite@1.2.1/timeonsitetracker.min.js')
        script.id = 'TimeOnSiteTracker'
        script.addEventListener('load', () =&gt; {
            const config = {
                trackBy: 'seconds',
            };

            if (TimeOnSiteTracker) {
                var Tos = new TimeOnSiteTracker(config);
                window.Tos = Tos;
            }

        })
        document.body.appendChild(script)
    }, [])
    
    return (
        &lt;div className=&quot;App&quot;&gt;
            &lt;header className=&quot;App-header&quot;&gt;
                &lt;div&gt;
                    You spent : &lt;span&gt;{timer} &lt;/span&gt; Seconds
                &lt;/div&gt;
            &lt;/header&gt;
        &lt;/div&gt;
    );
}


You can get a timer. Then it is a matter of playing in how you access the state in all your pages and properly configuring Tos to be tracked in all the pages you want.
"
73143311,standard deviation in TukeyHSD test in R?,"I have made an experiment where I measured the height of a plant with different genotypes (A,B or C). I ran a one-way ANOVA and I performed TukeyHSD as posthoc test. However, I would like to obtain the standard deviation of the difference in each comparison:
Here is my code:
#Create my dataset
genotype&lt;-c(&quot;A&quot;,&quot;A&quot;,&quot;A&quot;,&quot;B&quot;,&quot;B&quot;,&quot;B&quot;,&quot;C&quot;,&quot;C&quot;,&quot;C&quot;)
height&lt;-c(4,5,6,10,10,11,10,11,12)
data&lt;-data.frame(genotype,height)

#I run the ANOVA and TukeyHSD
model&lt;-aov(height~genotype,data=data)
TukeyHSD(model)
#It returns the difference of each comparison, but not the standard deviation. Although it can be obtain in SPSS, I would like to do it in R software.

Does anyone know if a specific R command exist? Or should I try to build my own formula creating a loop on my dataset?
Thank you in adavance.
King regard.
",r,1,73144263,"You can use the emmeans package to make the pairwise comparisons.
library(&quot;emmeans&quot;)

genotype &lt;- c(&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;)
height &lt;- c(4, 5, 6, 10, 10, 11, 10, 11, 12)
data &lt;- data.frame(genotype, height)

model &lt;- aov(height ~ genotype, data = data)

TukeyHSD(model)
#&gt;   Tukey multiple comparisons of means
#&gt;     95% family-wise confidence level
#&gt; 
#&gt; Fit: aov(formula = height ~ genotype, data = data)
#&gt; 
#&gt; $genotype
#&gt;          diff       lwr      upr     p adj
#&gt; B-A 5.3333333  3.123923 7.542743 0.0007609
#&gt; C-A 6.0000000  3.790590 8.209410 0.0003980
#&gt; C-B 0.6666667 -1.542743 2.876077 0.6453214

pairs(
  emmeans(model, ~genotype),
  adjust = &quot;tukey&quot;
)
#&gt;  contrast estimate   SE df t.ratio p.value
#&gt;  A - B      -5.333 0.72  6  -7.407  0.0008
#&gt;  A - C      -6.000 0.72  6  -8.332  0.0004
#&gt;  B - C      -0.667 0.72  6  -0.926  0.6453
#&gt; 
#&gt; P value adjustment: tukey method for comparing a family of 3 estimates

Created on 2022-07-27 by the reprex package (v2.0.1)
"
73551864,"Echarts Line chart , display line name","So I want to diplay my Linechart name at the end of each line and I'm not sure if this is possible with echarts
EXAMPLE :
On the image below there is a name at the end of each line

","javascript, reactjs, echarts, apache-echarts",1,73552737,"This is possible using series-line.endLabel, as they do in the example you gave.
To specifically display the name of the series, you'll have to use a formatter on endLabel :
endLabel: {
  show: true,
  formatter: function (params) {
    return params.seriesName;
  }
}

I also recommend you to increase grid.right so that the label won't be cropped.
Here is a simple example :


var myChart = echarts.init(document.getElementById('main'));

option = {
  tooltip: {
    trigger: 'axis'
  },
  grid: {
    left: '3%',
    right: '15%',
    bottom: '3%',
    containLabel: true
  },
  xAxis: {
    type: 'category',
    boundaryGap: false,
    data: ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
  },
  yAxis: {
    type: 'value'
  },
  series: [
    {
      name: 'Email',
      type: 'line',
      stack: 'Total',
      data: [120, 132, 101, 134, 90, 230, 210],
      endLabel: {
        show: true,
        formatter: function (params) {
          return params.seriesName;
        }
      }
    },
    {
      name: 'Union Ads',
      type: 'line',
      stack: 'Total',
      data: [220, 182, 191, 234, 290, 330, 310],
      endLabel: {
        show: true,
        formatter: function (params) {
          return params.seriesName;
        }
      }
    },
    {
      name: 'Video Ads',
      type: 'line',
      stack: 'Total',
      data: [150, 232, 201, 154, 190, 330, 410],
      endLabel: {
        show: true,
        formatter: function (params) {
          return params.seriesName;
        }
      }
    },
    {
      name: 'Direct',
      type: 'line',
      stack: 'Total',
      data: [320, 332, 301, 334, 390, 330, 320],
      endLabel: {
        show: true,
        formatter: function (params) {
          return params.seriesName;
        }
      }
    },
    {
      name: 'Search Engine',
      type: 'line',
      stack: 'Total',
      data: [820, 932, 901, 934, 1290, 1330, 1320],
      endLabel: {
        show: true,
        formatter: function (params) {
          return params.seriesName;
        }
      }
    }
  ]
};

myChart .setOption(option)
&lt;html&gt;
  &lt;body&gt;
    &lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/echarts/5.3.2/echarts.min.js""&gt;&lt;/script&gt;
    &lt;div id=""main"" style=""width: 600px; height:400px;""&gt;&lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;



"
74242518,Livesql Trigger IF statement,"This is what I have so far.
CREATE OR REPLACE TRIGGER OVERTIME_HOURS
AFTER INSERT OR UPDATE OF hoursWorked ON EMP_PROJ
declare 
hoursWorked number(22);
BEGIN
        IF(hoursWorked &gt; 100) 
        THEN
        INSERT INTO emp_proj_overtime(empNo, projNo, hourOt)
        SELECT empNo, projNo, hoursWorked - 100
        FROM EMP_PROJ;
        END IF;
END;

The problem with this trigger is it didn't send the hours over a 100 to the overtime table.
","sql, oracle, if-statement, triggers",0,74244453,"You don't select in a trigger; just use :new pseudorecord's values.
Sample tables:
SQL&gt; CREATE TABLE emp_proj (
  2      empno       NUMBER(4, 0) NOT NULL,
  3      projno      NUMBER(4, 0) NOT NULL,
  4      hoursworked NUMBER(6, 2) NOT NULL,  -- can't be NUMBER(4, 2) as you can't insert values =&gt; 100
  5      CONSTRAINT emp_proj_empno_projno_pk PRIMARY KEY ( empno,
  6                                                        projno )
  7  );

Table created.

SQL&gt; CREATE TABLE emp_proj_overtime (
  2      empno  NUMBER(4, 0) NOT NULL,
  3      projno NUMBER(4, 0) NOT NULL,
  4      hourot NUMBER(22) NOT NULL,
  5      CONSTRAINT emp_proj_overtime_empno_projno_pk PRIMARY KEY ( empno,
  6                                                                 projno )
  7  );

Table created.

Trigger: there can be only one row for each [empno, projno] combination due to primary key constraint which is defined as a composite key.
SQL&gt; CREATE OR REPLACE TRIGGER overtime_hours AFTER
  2      INSERT OR UPDATE OF hoursworked ON emp_proj
  3      FOR EACH ROW
  4      WHEN ( new.hoursworked &gt; 100 )
  5  BEGIN
  6      INSERT INTO emp_proj_overtime (
  7          empno,
  8          projno,
  9          hourot
 10      ) VALUES (
 11          :new.empno,
 12          :new.projno,
 13          :new.hoursworked - 100
 14      );
 15
 16  END;
 17  /

Trigger created.

Testing (overtime hours came during update of values in existing row):
SQL&gt; insert into emp_proj (empno, projno, hoursworked) values (1, 100, 75);

1 row created.

SQL&gt; select * From emp_proj;

     EMPNO     PROJNO HOURSWORKED
---------- ---------- -----------
         1        100          75

SQL&gt; select * From emp_proj_overtime;

no rows selected

SQL&gt; update emp_proj set hoursworked = 102 where empno = 1 and projno = 100;

1 row updated.

SQL&gt; select * From emp_proj;

     EMPNO     PROJNO HOURSWORKED
---------- ---------- -----------
         1        100         102

SQL&gt; select * From emp_proj_overtime;

     EMPNO     PROJNO     HOUROT
---------- ---------- ----------
         1        100          2

Some more testing (overtime hours inserted initially):
SQL&gt; insert into emp_proj (empno, projno, hoursworked) values (2, 995, 113);

1 row created.

SQL&gt; select * From emp_proj;

     EMPNO     PROJNO HOURSWORKED
---------- ---------- -----------
         1        100         102
         2        995         113

SQL&gt; select * From emp_proj_overtime;

     EMPNO     PROJNO     HOUROT
---------- ---------- ----------
         1        100          2
         2        995         13

SQL&gt;

"
74535758,"Borrow of moved value error, but the value shouldn't have moved, because it's borrowed","I'm trying to make sense of the error that comes up, it says that I can't borrow a moved value, but the value is the borrowed value nurse_list: &amp;mut Vec&lt;Nurse&gt;. So when I use it in the code for nurse in nurse_list { ... } it shouldn't move there, it should be borrowed.
fn assign_nurses_to_schedule(
    nurse_list: &amp;mut Vec&lt;Nurse&gt;,
    fte_budget: &amp;Vec&lt;NursesNeeded&gt;,
    cyclical_rosters: &amp;Vec&lt;Roster&gt;,
    total_incumbent_score: &amp;mut i32,
) -&gt; Vec&lt;Assignment&gt; {
    let mut assignments: Vec&lt;Assignment&gt; = vec![];
    let mut incumbent_score = 1000;
    //let mut total_incumbent_score = 0;
    let mut new_score: i32;
    for schedule in cyclical_rosters {
        let mut taken_nurse: Option&lt;i32&gt; = None;
        for nurse in nurse_list {
            new_score = calculate_score(&amp;schedule, nurse.get_pref_score().to_vec());
            if incumbent_score &lt; new_score {
                incumbent_score = new_score;
                assignments.push(new_assignment(schedule.get_nr(), nurse.get_nr()));
                taken_nurse = Some(nurse.get_nr());
            }
        }
        //add preference penalty to total score
        *total_incumbent_score += incumbent_score;
        //remove the nurse from the list, already assigned to a schedule
        let index = nurse_list
            .iter()
            .position(|x| x.get_nr() == taken_nurse.unwrap());
        nurse_list.remove(index.unwrap());
        // TODO: stop assigning nurses to schedules when fte budget is reached
        // ? do the schedules adhere to the fte budget?
    }
    assignments
}

error[E0382]: borrow of moved value: `nurse_list`
    --&gt; src\main.rs:75:21
     |
53   |       nurse_list: &amp;mut Vec&lt;Nurse&gt;,
     |       ---------- move occurs because `nurse_list` has type `&amp;mut Vec&lt;definitions::Nurse&gt;`, which does not implement the `Copy` trait
...
64   |           for nurse in nurse_list {
     |                        ---------- `nurse_list` moved due to this implicit call to `.into_iter()`
...
75   |           let index = nurse_list
     |  _____________________^
76   | |             .iter()
     | |___________________^ value borrowed here after move
     |
     = note: borrow occurs due to deref coercion to `[definitions::Nurse]`

I tried borrowing the nurse_list again in the for loop for nurse in &amp;nurse_list { ... } which then returns the following error:
src\main.rs:64:22
   |
64 |         for nurse in &amp;nurse_list {
   |                      ^^^^^^^^^^^ `&amp;&amp;mut Vec&lt;definitions::Nurse&gt;` is not an iterator
   |
   = help: the trait `Iterator` is not implemented for `&amp;&amp;mut Vec&lt;definitions::Nurse&gt;`

","rust, iterator, borrow-checker",0,74535844,"The type &amp;mut T which is a reference doesn't implement Copy thus the reference moved in the first loop and you can't access it anymore. To get around this you have to reborrow with this:
for nurse in &amp;mut *nurse_list {â€¦}

in every loop you do not want the nurse_list to move into.
"
73314559,Creating variant array from union of ranges,"I want to create a variant array when using a union to join ranges.
If I select one of the ranges the variant array will work.
When I union, I only receive the row dimensions and not the column dimensions.
For example,
Sub arrTest()
    
    'Declare varbs
    Dim ws As Worksheet
    Dim myArr() As Variant
    Dim lRow As Integer
    Dim myRng As Range
    
    'Assign varbs
    Set ws = ThisWorkbook.Worksheets(&quot;Sheet1&quot;)
    
    With ws
        
        lRow = .Cells(Rows.count, &quot;C&quot;).End(xlUp).row
       Set myRng = Application.Union(.Range(&quot;G3:G&quot; &amp; lRow), .Range(&quot;J3:O&quot; &amp; lRow), .Range(&quot;AD3:AE&quot; &amp; lRow), .Range(&quot;AI3:AI&quot; &amp; lRow))
        
        myArr = myRng.Value2
         
    End With

Will return a variant of
myArr(1, 1)
myArr(2, 1)
myArr(1, 3)
However if I were to select one of the ranges within the union for example:
Sub arrTest()
    
    'Declare varbs
    Dim ws As Worksheet
    Dim myArr() As Variant
    Dim lRow As Integer
    Dim myRng As Range
    
    'Assign varbs
    Set ws = ThisWorkbook.Worksheets(&quot;Sheet1&quot;)
    
    With ws
        
        lRow = .Cells(Rows.count, &quot;C&quot;).End(xlUp).row
       Set myRng = .Range(&quot;J3:O&quot; &amp; lRow)
        myArr = myRng.Value2
         
    End With

I properly get
myArr(1, 1)
myArr(1, 2)
myArr(1, 3)
etc.
How do I return the column dimensions as well, without looping through the sheet?
","excel, vba, multidimensional-array",0,73327989,"Like this:
Sub ArrayTest()
    
    Dim ws As Worksheet
    Dim arr, lrow As Long
    
    Set ws = ThisWorkbook.Worksheets(&quot;Sheet1&quot;)
    lrow = ws.Cells(Rows.Count, &quot;C&quot;).End(xlUp).Row
    
    arr = GetArray(ws.Range(&quot;G3:G&quot; &amp; lrow), ws.Range(&quot;J3:O&quot; &amp; lrow), _
                   ws.Range(&quot;AD3:AE&quot; &amp; lrow), ws.Range(&quot;AI3:AI&quot; &amp; lrow))
        
    With ThisWorkbook.Worksheets(&quot;Sheet2&quot;).Range(&quot;B2&quot;)
        .Resize(UBound(arr, 1), UBound(arr, 2)).Value = arr
    End With
         
End Sub

'Given a number of input ranges each consisting of one or more columns (assumed all input ranges have
'  the same # of rows), return a single 1-based 2D array with the data from each range
Function GetArray(ParamArray sourceCols() As Variant) As Variant
    Dim arr, rng, numCols As Long, numRows As Long, r As Long, c As Long, tmp, col As Long
    
    numRows = sourceCols(0).Rows.Count
    'loop over ranges and get the total number of columns
    For Each rng In sourceCols
        numCols = numCols + rng.Columns.Count
    Next rng
    
    ReDim arr(1 To numRows, 1 To numCols) 'size the output array
    c = 0
    For Each rng In sourceCols        'loop the input ranges
        tmp = As2DArray(rng)          'get range source data as array ####
        For col = 1 To UBound(tmp, 2) 'each column in `rng`
            c = c + 1                 'increment column position in `arr`
            For r = 1 To numRows      'fill the output column
                arr(r, c) = tmp(r, col)
            Next r
        Next col
    Next rng
    GetArray = arr
End Function

'Get a range's value, always as a 2D array, even if only a single cell
Function As2DArray(rng)
    If rng.Cells.Count &gt; 1 Then
        As2DArray = rng.Value
    Else
        Dim arr(1 To 1, 1 To 1)
        arr(1, 1) = rng.Value
        As2DArray = arr
    End If
End Function

"
73272894,How to add a separator character between each three numbers in an input field?,"How can I put a hyphen symbol (-) after the user types three numbers, then again after other three numbers. Like this:

719-646-636

It should be done automatically, in javascript.
","javascript, validation",0,73273476,"I think this is a good use case for the plugin jquery-inputmask.
Take a look at the documentation, there are plenty of options.
You can get your desired behavior in a one-liner javascript (plus workable copy/paste and disabling non-numeric characters).


$(""input[name=my-numeric-value]"").inputmask()
input {
  font-family: monospace;
}
&lt;script src=""https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js""&gt;&lt;/script&gt;
&lt;script src=""https://s3-us-west-2.amazonaws.com/s.cdpn.io/3/jquery.inputmask.bundle.js""&gt;&lt;/script&gt;

&lt;input type=""text"" name=""my-numeric-value"" placeholder=""xxx-xxx-xxx"" data-inputmask=""'mask': '999-999-999'""/&gt;



"
72966905,Compare two symbols that have almost 100% inverse correlation to identify the bars both tickers closed positive or negative,"I am trying to compare two symbols, that have almost 100% inverse correlation, to identify the days both tickers closed positive or negative (where they lose the inverse correlation).
",pine-script,-1,72967435,"We can get the close of both symbols and display bars wherever the close is in same direction. Example
//@version=5
indicator(title=&quot;Indicator Merge By Rohit&quot;,overlay=true)
symbol1 = input.symbol(&quot;ZN1!&quot;,&quot;Symbol1&quot;)
symbol2 = input.symbol(&quot;ED1!&quot;,&quot;Symbol2&quot;)
close1=request.security(symbol1, timeframe.period, close, barmerge.gaps_off, barmerge.lookahead_on)
close2=request.security(symbol2,timeframe.period, close, barmerge.gaps_off, barmerge.lookahead_on)
bgcolor(((close1&gt;close1[1] and close2&gt;close2[1]) or (close1&lt;close1[1] and close2&lt;close2[1]))?color.new(color.red,70):na)


"
72905471,Why is my console not showing up when my Dll is loaded?,"I have two files, the file which I'll use to load the Dll into the process is the following:
#include &lt;Windows.h&gt;

int main()
{
    // path to our dll
    LPCSTR DllPath = any_path;

    // Open a handle to target process
    HANDLE hProcess = OpenProcess(PROCESS_ALL_ACCESS, FALSE, 26188);

    // Allocate memory for the dllpath in the target process
    // length of the path string + null terminator
    LPVOID pDllPath = VirtualAllocEx(hProcess, 0, strlen(DllPath) + 1,
        MEM_COMMIT, PAGE_READWRITE);

    // Write the path to the address of the memory we just allocated
    // in the target process
    WriteProcessMemory(hProcess, pDllPath, (LPVOID)DllPath,
        strlen(DllPath) + 1, 0);

    // Create a Remote Thread in the target process which
    // calls LoadLibraryA as our dllpath as an argument -&gt; program loads our dll
    HANDLE hLoadThread = CreateRemoteThread(hProcess, 0, 0,
        (LPTHREAD_START_ROUTINE)GetProcAddress(GetModuleHandleA(&quot;Kernel32.dll&quot;),
            &quot;LoadLibraryA&quot;), pDllPath, 0, 0);

    // Wait for the execution of our loader thread to finish
    WaitForSingleObject(hLoadThread, INFINITE);

    // Free the memory allocated for our dll path
    VirtualFreeEx(hProcess, pDllPath, strlen(DllPath) + 1, MEM_RELEASE);

    return 0;
}

So far, it's working properly and loading the Dll into the file, however, the Dll doesn't seem to be working:
#include &quot;pch.h&quot;
#include &lt;iostream&gt;
#include &lt;windows.h&gt;
#include &lt;TlHelp32.h&gt;

DWORD WINAPI HackThread(HMODULE hModule)
{
    //Create Console
    AllocConsole();
    FILE* f;
    freopen_s(&amp;f, &quot;CONOUT$&quot;, &quot;w&quot;, stdout);

    std::cout &lt;&lt; &quot;ttt&quot; &lt;&lt; std::endl;
    std::cin.get();
    fclose(f);
    FreeConsole();
    FreeLibraryAndExitThread(hModule, 0);
    return 0;
}

BOOL APIENTRY DllMain(HMODULE hModule,
    DWORD  ul_reason_for_call,
    LPVOID lpReserved
)
{
    switch (ul_reason_for_call)
    {
    case DLL_PROCESS_ATTACH:
        CreateThread(nullptr, 0, (LPTHREAD_START_ROUTINE)HackThread, hModule, 0, nullptr);
    case DLL_THREAD_ATTACH:
    case DLL_THREAD_DETACH:
    case DLL_PROCESS_DETACH:
        break;
    }
    return TRUE;
}

I know the Dll is loading properly because the process is hitting the 'DLL_PROCESS_ATTACH' case and when I tested it with a message box instead of the CreateThread, it showed up, however, I can't seem to make the console show up. What would be the problem?
","c++, dll",2,72905654,"One issue I see is that your thread is re-mapping only stdout to the new console, but it is not re-mapping stdin as well.  So it is quite likely (use a debugger to verify this) that std::cin.get() is failing and thus not blocking the thread from closing the console immediately after creating it.
"
72826154,PCs cant find branches each other from gitlab,"I work from home, and from office( in two different computers ).
For instance, when i work from home in &quot;someBranch&quot;, and next go to office and try to get this &quot;someBranch&quot;, i cant see it.
Both computers work with two different ssh keys that connected to gitlab.
git fetch origin somebranch:somebranch
or
git fetch origin -a
dont help.
I think that i can just copy ssh key from one computer to another, and maybe it'll help.
But idk. It looks weird
","git, gitlab",0,73684860,"I just understood that is all works well. And I was doing everything properly, except one thing: Gitlab has a property that asks you when you merge in &quot;master&quot;: &quot;Do you want to delete source branch ?&quot;
And this box was checked by default.
"
73045806,How to exit the loop :while(cin>>n) in C++,"This is a program that counts how many letters and numbers a string has,but when I Press Enter to exit after entering,it has no response.
#include &lt;iostream&gt;
using namespace std;

int main()
{
    char c;
    int nums=0,chars=0;
    while(cin&gt;&gt;c){
        if(c&gt;='0'&amp;&amp;c&lt;='9'){
            nums++;
        }else if((c&gt;='A'&amp;&amp;c&lt;='Z')||(c&gt;='a'&amp;&amp;c&lt;='z')){
            chars++;
        }

    }
    printf(&quot;nums:%d\nchars:%d&quot;,nums,chars);
    return 0;
}

","c++, while-loop, cin",0,73045864,"Pressing enter does not end input from std::cin and std::cin stops when encountering a whitespace.
Better would be to use std::getline and std::isdigit as shown below:
int main()
{
    
    int nums=0,chars=0;
    std::string input;
    //take input from user 
    std::getline(std::cin, input);
    for(const char&amp;c: input){
        if(std::isdigit(static_cast&lt;unsigned char&gt;(c))){
            
            nums++;
        }
        else if(std::isalpha(static_cast&lt;unsigned char&gt;(c))){
            chars++;
            
        }

    }
    std::cout&lt;&lt;&quot;nums: &quot;&lt;&lt;nums&lt;&lt;&quot; chars: &quot;&lt;&lt;chars;
    return 0;
}

Demo
"
73891997,Share User Table between different websites for authorisation,"New to Backendless but have done a considerable amount of their lessons to get a good understanding. Having searched the forums I haven't quite got the info I need.

If I have one App/account in Backendless, does this mean I only ever have one 'Users' Table?

For the sake of economy and thus not having to buy multiple Apps/Accounts on Backendless is there anyway to create additional 'User' tables for other websites I would like to connect to for user authorisation?

If, no, is there a way to do this? For example is there a way to add a new Column to Backendless 'Users' to somehow categorise the 'Users' by website/app? So I could user the User Authorisation from both Site A and Site B?


Thanks in advance for any advice in relation to this.
Stephen
PS I only use Backendless for the Backend and hope to connect in from both Bubble and Webflow (depending on the project).
",backendless,0,73894508,"
Yes, you can have only one Users table in the application

You can create other tables, but you will not be able to use Backendless User API with the other tables

Sure, you can add a column like project and it can be a relation to the  Project table or something like that.


I do not recommend doing this, because such an economy may cause to the issues in the future.
Looks like you are trying to do a backendless inside the backendless.
"
73979650,How to lookup data across different sheets by given id and aggregate the results into single cell in O365 Excel?,"I have a spreadsheet with multiple sheets that each contain data I need to lookup and aggregate.
The current data structure and formats are as following:
SheetA (Master Sheet):




Id
(misc)
Components
...other non relevant columns




And the secondary sheets (SheetB, SheetC..., let's represent them as SheetX) with the same format:




RefId
Id
Component
...other non relevant columns




Where RefId represents a value of Id column from the master sheet.
The goal is to populate the Components column from the master sheet (SheetA) with the information from secondary sheets (SheetX). Considering the following rules:

The content of Components for a given Id value will the be the value of Component from any secondary sheet, where RefId column value is the same. If there is more than value, then it concatenates all the component information delimited by comma (,).
If the Components value in the master sheet is not empty, then the content of the search by Id will be appended delimited by comma (,).
The sheet names can be provided as a list or just refer in the formula to each sheet name.

Lets say if we have the following input information:
Master Sheet A:




Id
(misc)
Components
...other non relevant columns




A1

xxxx



A2





A3







Sheet B:




RefId
Id
Component
...other non relevant columns




A1
B1
B1Comp



A2
B1
B2Comp



A3
B3
B3Comp





and
Sheet C:




RefId
Id
Component
...other non relevant columns




A2
C1
C1Comp



A2
C2
C2Comp





The expected result will be in the Consolidated Sheet:




Id
(misc)
Components
...other non relevant columns




A1

xxxx,B1Comp



A2

B2Comp,C1Comp,C2Comp



A3

B3Comp





Note: Please don't consider any string pattern, they are just some string representation.
Currently I'm using the above mentioned VLOOKUP formulas, but they break when a sheet has multiple entries for a given Id.
","excel, excel-365",0,73994924,"Let's try with Power Query(PQ), your question is related to typical ETL operations and PQ is more suitable than using excel functions.
To easy differentiate the sheets, I am going to consider the Master Sheet, where we want the information consolidated and the secondary sheets, which are the input sheets to consolidate the information in the Master.
Since all the secondary sheets (SheetA, SheetB...) have the same structure, we can merge them.
This is the PQ command to generate AllSheets query as output:
=Table.Combine({TB_ShA, TB_ShB, TB_ShC})

When a connection is created from a range, PQ creates an Excel Table. I named them as: TB_ShA,...TB_ShC, for each corresponding sheet. On each table I have the following data for testing purpose (secondary sheets plus the Master Table). The Master table at the end will be updated with the consolidated components.
You can add as many sheets as you need in the previous formula to consolidate the component information. The rest of the process described here remains the same.

Now lets explain the main steps in PQ:
Load the Master table (TB_Master):

Next rename the Components column from the master table to Master Component:
= Table.RenameColumns(Source,{{&quot;Components&quot;, &quot;Master Component&quot;}})

Next we do a merge queries (Home-&gt; Merge Queries), with the Master table and AllSheets (all secondary tables), linking Id and RefId from each tables.
= Table.NestedJoin(#&quot;Renamed MasterComponent&quot;, {&quot;Id&quot;}, AllSheets, 
 {&quot;RefId&quot;}, &quot;AllSheets&quot;, JoinKind.LeftOuter)


and expand the Table information (just click on the top right icon of the table), here is the corresponding command:
= Table.ExpandTableColumn(#&quot;Merged Queries&quot;, &quot;AllSheets&quot;, 
  {&quot;Component&quot;}, {&quot;AllSheets.Component&quot;})


We need to change the type of Master Component column to text because later we are going to do some text operations and it is required:
= Table.TransformColumnTypes(#&quot;Expanded AllSheets&quot;,
  {{&quot;Master Component&quot;, type text}})

Now if we try to concatenate Master Component column with AllSheets.Component column, it works BUT, we are going to have duplication of Master Component values when we merge the information by unique values of the ID column. For example as it is now, if we merge the first two rows that belong to M1we will get the following:
xxxx,A1Comp,xxxx,BiComp

so we need to remove the repetition of Master Component column. In order to do that I used the solution from @RonRosenfeld from this question: Replace second or more instances of duplicates with null.
It requires two steps: dupsNull and add de-duped. The first one creates a temporary list with duplicated replaced with null, The second just adds the list created as a new column:

Note: I am assuming the pre-populated Components values from the input Master Sheet are unique, if that is not the case, it needs to be adjusted to avoid repetition only per Id value from this sheet.
Next we remove unnecessary columns:
= Table.RemoveColumns(#&quot;add de-duped&quot;,{&quot;Master Component&quot;})

and now  we are ready to concatenate both columns:
= Table.AddColumn(#&quot;Removed Columns&quot;, &quot;Components&quot;, 
  each Text.Combine({[Master Component.unique],
  Text.From([AllSheets.Component])},&quot;,&quot;))

Removing Master Component column:
= Table.RemoveColumns(#&quot;add de-duped&quot;,{&quot;Master Component&quot;})

and this is the result:

Finally we need to group the rows by Id. Home-&gt;Group By allows to group but it doesn't provide the function we need to concatenate the values. I took the idea from here: Combining Rows based on the ID of that table to change the script and replace the Max function for example by Text.Combine and here is the final result in PQ:

The rest is just  Close &amp; Load the result in an new Sheet that is named MasterUpdated:

Here is the entire PQ M script:
let
    Source = Excel.CurrentWorkbook(){[Name=&quot;TB_Master&quot;]}[Content],
    #&quot;Renamed MasterComponent&quot; = Table.RenameColumns(Source,{{&quot;Components&quot;, &quot;Master Component&quot;}}),
    #&quot;Merged Queries&quot; = Table.NestedJoin(#&quot;Renamed MasterComponent&quot;, {&quot;Id&quot;}, AllSheets, {&quot;RefId&quot;}, &quot;AllSheets&quot;, JoinKind.LeftOuter),
    #&quot;Expanded AllSheets&quot; = Table.ExpandTableColumn(#&quot;Merged Queries&quot;, &quot;AllSheets&quot;, {&quot;Component&quot;}, {&quot;AllSheets.Component&quot;}),
    #&quot;Changed Type&quot; = Table.TransformColumnTypes(#&quot;Expanded AllSheets&quot;,{{&quot;Master Component&quot;, type text}}),
    dupsNull = List.Generate(
        ()=&gt;[v=#&quot;Changed Type&quot;[Master Component]{0}, idx=0],
        each [idx]&lt;Table.RowCount(#&quot;Changed Type&quot;),
        each [v=if List.PositionOf(#&quot;Changed Type&quot;[Master Component],#&quot;Changed Type&quot;[Master Component]{[idx]+1},Occurrence.First) = [idx]+1
                    then #&quot;Changed Type&quot;[Master Component]{[idx]+1} else null, idx=[idx]+1],
        each [v]),
    #&quot;add de-duped&quot; = Table.FromColumns(
            Table.ToColumns(#&quot;Changed Type&quot;) &amp; {dupsNull},
            type table[Id=text, Master Component=text, AllSheets.Component=text,Master Component.unique=text]),
    #&quot;Removed Columns&quot; = Table.RemoveColumns(#&quot;add de-duped&quot;,{&quot;Master Component&quot;}),
    ConcatComponents = Table.AddColumn(#&quot;Removed Columns&quot;, &quot;Components&quot;, each Text.Combine({[Master Component.unique],Text.From([AllSheets.Component])},&quot;,&quot;)),
    RemovedComponents = Table.RemoveColumns(ConcatComponents,{&quot;AllSheets.Component&quot;, &quot;Master Component.unique&quot;}),
    #&quot;Grouped Rows&quot; = Table.Group(RemovedComponents, {&quot;Id&quot;}, {{&quot;Components&quot;, each Text.Combine([Components], &quot;,&quot;), type text}})
in
    #&quot;Grouped Rows&quot;

"
74422849,"In Flutter, I can't properly position in Stack","   Stack(
      children: [
        Container(
          height: MediaQuery.of(context).size.height * 0.5,
          decoration: BoxDecoration(
            borderRadius: BorderRadius.only(
                bottomLeft: Radius.circular(100.0),
                bottomRight: Radius.circular(100.0)),
            color: darkBlue,
          ),
        ),
        Positioned(
            bottom: 0,
            left: MediaQuery.of(context).size.width / 3,
            child: CircleAvatar(
                backgroundColor: white,
                radius: 70,
                child: Image.asset('assets/images/homepage.png'))),
      ],
    )


When I set the value as bottom : 0 in the code, since the image is inside the Stack, it sees it as a border and moves the image to the bottom of the Stack. But what I want is to place the image in the center of the Container, as shown by the black circle in the image.
","flutter, dart, flutter-layout",1,74422881,"You need to pass negative half of height to bottom value to get that, don't forget to set Stack's clipBehavior to none. Try this:
Stack(
    clipBehavior: Clip.none,// &lt;-- add this
    children: [
      Container(
        height: MediaQuery.of(context).size.height * 0.5,
        decoration: BoxDecoration(
          borderRadius: BorderRadius.only(
              bottomLeft: Radius.circular(100.0),
              bottomRight: Radius.circular(100.0)),
          color: darkBlue,
        ),
      ),
      Positioned(
          bottom: -100/2,// &lt;-- add this
          left: MediaQuery.of(context).size.width / 3,
          child: CircleAvatar(
              backgroundColor: white,
              radius: 70,
              child: Image.asset('assets/images/homepage.png'))),
    ],
  ),

"
73248689,Is there any reason I should include a header in the associated cpp file if the former only provides declarations the latter defines?,"Consider a foo.cpp file with the following content
#include &quot;foo.hpp&quot;
int foo() {
    return 7;
}

and its associated header
#pragma once
int foo();

The latter is obviously needed to make aware the following main function of the existence of foo:
#include &lt;iostream&gt;
#include &quot;foo.hpp&quot; // to make the name `foo` available

int main() {
    std::cout &lt;&lt; foo() &lt;&lt; std::endl;
}

However, the #include &quot;foo.hpp&quot; seems to be redundant. Is there any reason I should keep it?

I've seen this practice in the codebase where I work on, but I guess there's many examples available in open source. For instance, as an example picked at random, look at src/builtin_builtin.h and src/builtin_bultin.cpp from the fish-shell code base: the former, beside the include guard, has
just

one #include,
two class declarations,
and a function declaration.

One could put 2 in a fwd header, include it in the cpp file together with 1, and then the cpp file wouldn't need anymore to include its own header.
","c++, include, header-files, declaration, translation-unit",0,73258541,"Some reasons to include the header (fpp.hpp) from its implementation file (fpp.cpp):

If you include foo.hpp first in foo.cpp, then compilation of foo.cpp acts as a test that foo.hpp is self-contained, meaning it can be successfully compiled without including anything else first.  The Google C++ coding guidelines specifically recommend including the associated header first.

It is good practice for foo.hpp to declare everything that foo.cpp exports, and for everything else in foo.cpp to have internal linkage in order to not pollute the global namespace.  The GCC option -Wmissing-declarations will report deviations from that practice, but it only works if foo.cpp includes foo.hpp.

Sometimes (often, in fact), including foo.hpp is needed so foo.cpp will compile.  Most commonly, foo.hpp defines a type that foo.cpp needs, but it can also happen that function declarations are needed due to use before definition.  I recommend to just do so consistently rather than trying to deduce whether it's necessary in each case.

Occasionally, the compiler can diagnose mismatches between declarations and definitions.  A nasty case I've seen is a header declaring a global int x but the implementation file defining long x.  Waste a day debugging that mistake, and I predict you'll resolve to include the associated header every time thereafter!


Finally, there are no good reasons not to include the associated header.  In particular, omitting that include will almost never make a measurable difference to compile time.  There are ways of dramatically improving compile times by restructuring header dependencies (for example, use of forward headers), but this isn't one of them.
Acknowledgments: Point 1 was noted by BoP in a comment.  MSalters' answer notes points 3 and 4.
"
74437558,.NET 7.0 and React Native not working with Axios call,"My .NET api which was working perfectly well with .NET 6.x is not working with .NET 7. I can make http requests with Thunder Client and Swagger but it won't work with my React Native (expo) app. I tried it with Flutter as well and that didn't work. I get this error:
Possible Unhandled Promise Rejection (id: 1):

I'm using Axios to make the request. My appsettings.json looks like this:
...

&quot;Kestrel&quot;: {
    &quot;Endpoints&quot;: {
      &quot;Http&quot;:{
        &quot;Url&quot;: &quot;http://localhost:5000&quot;
      },
      &quot;Https&quot;:{
        &quot;Url&quot;: &quot;https://localhost:5001&quot;
      }
    }
  },

...

My API call looks like this:
const baseUrl = 'https://localhost:5001/api/users';
const headers = {
    &quot;Content-Type&quot;: &quot;application/json&quot;,
}


const [user, setUser] = useState(null);
    useEffect(() =&gt; {
        axios.get(baseUrl, {headers}).then((response) =&gt; {
            setUser(response.data);
            console.log(response.data);
        }).catch(function(error){
            console.log(error);
            console.log(error.response.data);
        });
    }, []);

I have enabled CORS in by Program.cs
...

builder.Services.AddCors(options =&gt;
{
    options.AddPolicy(name: CorsPolicy,
    policy =&gt;
    {
        policy.WithOrigins
        (
            &quot;exp://192.168.0.41:19000&quot;,
            &quot;http://localhost:19006&quot;,
            &quot;http://localhost:19000&quot;
        )
        .AllowAnyHeader()
        .AllowAnyMethod();
    });
});

...

app.UseCors(CorsPolicy);

...


Is this an issue with .NET 7.0 or is it just coincidence? How can I fix it?
","asp.net, react-native, asp.net-core, axios, expo",1,74439236,"react-native will not work with localhost calls use ngrok to handle this
"
74214892,React-Native pass useState to navigation Screen and updating FlatList,"I am trying to use react-navigation and pass useState between the screen, and having it render a flatlist.
It correctly updates the flatlist if i go back to the previous screen and then back to the commentscreen, meanwhile nothing happens when just pressing the button.
The setup is basically like this in my App.js file I have the following
....
 &lt;Stack.Screen
  name=&quot;CommentScreen&quot;
  component={CommentScreen}
  options={{ title: &quot;CommentScreen&quot; }}
  initialParams={{ comments: getComments, setComments: setComments }}
  /&gt;
....

Where the comments are from the following
...
var comments= [
    {
        comment_id: &quot;1&quot;,
        post_id: &quot;1&quot;,
        user: &quot;user&quot;,
        comment: &quot;comment1&quot;
    }
]
const [getComments, setComments] = useState((comments));
...

Then in my commentScreen.js file i have the following, which is basically just a flatlist, an input field with a button to update the state with a new comment. Where the getter / setter is passed from App.js
export default function CommentScreen({navigation, route}){

    const [currentComment, setCurrentComment] = useState(&quot;&quot;);
    const addComment = (message) =&gt; {
        route.params.setComments(
            [...route.params.comments,
                {
                    post_id: route.params.post_id,
                    comment_id: new_comment_id(),
                    user: &quot;user1&quot;,
                    comment: message
                }
            ]
        );
      }
    return(
        &lt;View style={styles.screenDefault}&gt;
            &lt;FlatList
                data={route.params.comments}
                renderItem={({item}) =&gt; Comment({item})} 
                keyExtractor={item =&gt; item.comment_id} 
                extraData={route.params.comments}
            /&gt;
            &lt;View style={styles.comment}&gt; 
                &lt;View style={styles.inputField}&gt;
                    &lt;TextInput
                        style={{flex: 1}}
                        onChangeText={setCurrentComment}
                        placeholder=&quot; Add comment &quot;
                    /&gt;
                    &lt;Button
                        style={{flex: 1}}
                        onPress={()=&gt;addComment(currentComment)}
                        title=&quot;Post&quot;
                        color=&quot;gray&quot;
                    /&gt;
                &lt;/View&gt;
            &lt;/View&gt;
        &lt;/View&gt;
    )
}

The renderItem function Comment is defined as follows in Comment.js
export default function Comment({item}){
    return(
    &lt;View style={styles.item}&gt;
      &lt;Text style={styles.title}&gt;
        {item.user}
      &lt;/Text&gt;
      &lt;Text style={styles.comment}&gt;
        {item.comment}
      &lt;/Text&gt;
    &lt;/View&gt;
    );
  }

So something does happen, since if I go back and forth after adding a comment it shows up, but simply pressing the button nothing happens.
Thanks for the help!
","javascript, node.js, react-native, react-hooks",0,74232609,"I recommend that you use Redux, as it centralize your application state.
React-redux
Here's how it works, imagine you have an app that contains two main screens, HomeScreen.js and OptionScreen.js.
1-Inside HomeScreen.js you have a View component
2-Inside OptionScreen.js you have a Button component
If we want to change the color of the View based on if Button is clicked or not, using useState, we will have to create a state for that color in the top parent component, which contains the two main screens, then pass it all the way down to the Button and View components, which is so messy and complicated.
Here's where Redux comes to play, we simply create a &quot;state file&quot; aside, and make the desired components listen to it.
Button clicked ---&gt; state in redux changed to dark
state in redux changed ---&gt; View will re-render and cause its color to change.
"
73903352,Error when passing URLs into a requests.get(),"I've been working on a program that takes URLs from a .csv and counts the word amount on the webpage. The URLs come from the rows under the &quot;Article&quot; column in a pandas dataframe. The URLs are inputted into a requests.get(url) set to a variable. In my investigation of the error, the problem arises when the URL is inputted into the requrests.get().
def file_input(file):
   #takes a .csv file from the user
   df = pd.read_csv(file, sep='[;,]', engine='python')
   for i in range(len(df)):
     df.at[i, &quot;Word Count&quot;] = word_counter(df.at[i, &quot;Article&quot;])

def word_counter(url):
  #keeps tracks of the page's word count
  count = 0
  #the requests.get(url) takes the string of url and gets the access of the webpage
  page = requests.get(url)

here are the error mesages:
Traceback (most recent call last):
  File &quot;/home/runner/Article-Word-counter/venv/lib/python3.8/site-packages/urllib3/response.py&quot;, line 406, in _decode
    data = self._decoder.decompress(data)
  File &quot;/home/runner/Article-Word-counter/venv/lib/python3.8/site-packages/urllib3/response.py&quot;, line 93, in decompress
    ret += self._obj.decompress(data)
zlib.error: Error -3 while decompressing data: incorrect header check

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;/home/runner/Article-Word-counter/venv/lib/python3.8/site-packages/requests/models.py&quot;, line 816, in generate
    yield from self.raw.stream(chunk_size, decode_content=True)
  File &quot;/home/runner/Article-Word-counter/venv/lib/python3.8/site-packages/urllib3/response.py&quot;, line 627, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File &quot;/home/runner/Article-Word-counter/venv/lib/python3.8/site-packages/urllib3/response.py&quot;, line 599, in read
    data = self._decode(data, decode_content, flush_decoder)
  File &quot;/home/runner/Article-Word-counter/venv/lib/python3.8/site-packages/urllib3/response.py&quot;, line 409, in _decode
    raise DecodeError(
urllib3.exceptions.DecodeError: ('Received response with content-encoding: gzip, but failed to decode it.', error('Error -3 while decompressing data: incorrect header check'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &quot;main.py&quot;, line 59, in &lt;module&gt;
    main()
  File &quot;main.py&quot;, line 44, in main
    file_input(file)
  File &quot;main.py&quot;, line 35, in file_input
    df.at[i, &quot;Word Count&quot;] = word_counter(df.at[i, &quot;Article&quot;])
  File &quot;main.py&quot;, line 13, in word_counter
    page = requests.get(anything)
  File &quot;/home/runner/Article-Word-counter/venv/lib/python3.8/site-packages/requests/api.py&quot;, line 73, in get
    return request(&quot;get&quot;, url, params=params, **kwargs)
  File &quot;/home/runner/Article-Word-counter/venv/lib/python3.8/site-packages/requests/api.py&quot;, line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File &quot;/home/runner/Article-Word-counter/venv/lib/python3.8/site-packages/requests/sessions.py&quot;, line 587, in request
    resp = self.send(prep, **send_kwargs)
  File &quot;/home/runner/Article-Word-counter/venv/lib/python3.8/site-packages/requests/sessions.py&quot;, line 745, in send
    r.content
  File &quot;/home/runner/Article-Word-counter/venv/lib/python3.8/site-packages/requests/models.py&quot;, line 899, in content
    self._content = b&quot;&quot;.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b&quot;&quot;
  File &quot;/home/runner/Article-Word-counter/venv/lib/python3.8/site-packages/requests/models.py&quot;, line 820, in generate
    raise ContentDecodingError(e)
requests.exceptions.ContentDecodingError: ('Received response with content-encoding: gzip, but failed to decode it.', error('Error -3 while decompressing data: incorrect header check'))

","python-3.x, pandas, python-requests",0,73904047,"
requests.exceptions.ContentDecodingError:
('Received response with content-encoding: gzip, but failed to decode it.',
error('Error -3 while decompressing data: incorrect header check'))

It seems the server's response states that it is gzip-encoded, but requests failed to decode it when it treated it as gzipped. This could be a server misconfiguration, or something more subtle. Try to request a non-compressed response by specifying the Accept-Encoding header (though it is possible the server will not respect your request):
headers = { 'Accept-Encoding': 'identity' }
page = requests.get(url, headers=headers)

You can also check whether you can access the URL using other tools, like curl, or your web browser. Additionally, you can explicitly check the raw response to see what the server is actually sending you. But it seems contacting the webmaster of the URL in question might be the real solution.
"
74393426,Why are NaN floats?,"Division by zero can lead to the apparition of objects, which, while being typed as numbers, are not valid numbers. This led to the creation of NaNs values for numeric data types, mostly used in floating point arithmetic (and hence in most programming float types).
Since division by zero could also occur when manipulating integers, why doesn't a 'NaN integer' exist?
I am looking for a documented answer on programmatic constraints explaining this pattern.
","floating-point, integer, nan",0,74393590,"Because all integers are consistent, have a value.
A 8 bit unsigned integers goes from 00000000 to 11111111, and all those values have a clear, defined, value, that is from 0 to 255.
Which one of those value would you sacrifice to code a 8 bit unsigned integer NaN? 255 maybe. But then, you sacrifice lot of possible applications. You can't use 8 bits unsigned integer to handle bytes (since they are in [0,256)). Nor use them to manipulate images (white (255,255,255) pixels would be (NaN, NaN, NaN)). Etc.
Not even mentionning all the optimization that becomes impossible if 11111111 unsigned 8bits int means NaN, but 11111111 signed bits int means -1 (which it has to do)
Sure, you could use 16 bits integer instead. But that would be to need twice as much memory for all those applications (and those happen to be the kind of applicative usage that makes sometimes even 64Gb memory insufficient. I am currently working on a such an application, where my buffer images use all of my 64 Gb. It would be to much cost to half my buffer capacity, just because of a remote possibility that I might need to encode an integer NaN).
Because, that is another reason why it is not so: why would someone need that? I mean, NaN means &quot;Not a number&quot;. That is it means that the bits stored in a memory place where a number should be, do not, in reality, represent a number.
It is different for floats. Because classical IEEE encoding of floats makes some combination of bits meaningless (or special). Not much. It is not like it was 1 unused bit, or anything remotely similar. Just a few impossible values among billions of possible ones. But still, some combination of bits are not valid. Or, more precisely, we gave them some special meaning, including NaN.
For int, it is up to you to decide that, for your application, you can sacrifice a value. For example, if you are storing dice outputs, you have more than enough choice to decide that one value (-1, 0, 7, 99, ... anything but 1,2,3,4,5 or 6)  will have a special meaning for you (such as &quot;the dice was not rolled&quot;). The system can't take the responsibility to sacrifice some combination of bits, that is some possible values, to make same special, even for those who don't need any such special value.
For float, well, since there are already a few impossible/redundant combination of bits it cost nothing to give them special names.
"
73810638,How to track changes to Content WebView2,"It is necessary to track the link change in WebView 2. I have the following code in the VM:
VM
private Uri _myHtml;

public Uri MyHtml
{
    get { return _myHtml; }
    set
    {
        _myHtml = value;
        CheckUri(MyHtml);
        OnPropertyChanged();
        OnPropertyChanged(nameof(MyHtml));
    }
}

VMBASE
public event PropertyChangedEventHandler PropertyChanged;

protected void OnPropertyChanged([CallerMemberName] string propertyName = &quot;&quot;)
{
    PropertyChangedEventHandler handler = this.PropertyChanged;
    if (handler != null)
    {
        var e = new PropertyChangedEventArgs(propertyName);
        handler(this, e);
    }
}

VIEW XAML
&lt;Wpf:WebView2 Name=&quot;webView&quot;
                  Source=&quot;{Binding MyHtml, UpdateSourceTrigger=Explicit}&quot; Grid.RowSpan=&quot;2&quot;  Grid.ColumnSpan=&quot;3&quot; HorizontalAlignment=&quot;Stretch&quot; VerticalAlignment=&quot;Stretch&quot;  /&gt;

Alas, the breakpoint on &quot;set&quot; is triggered only when the &quot;MyHTML&quot; variable is directly assigned a value. But when you change the URL in WebView2, nothing changes
","c#, wpf, mvvm, webview",0,73811372,"You have two options

Set the Mode to TwoWay, and remove the UpdateSourceTrigger=Explicit

Source=&quot;{Binding MyHtml, Mode=TwoWay}&quot;


If you want to keep Explicit mode, you have to call UpdateSource() to update the bound property (i.e.MyHtml). This can be done by handling NavigationCompleted event like so..

In .xaml
&lt;Wpf:WebView2 
    Source=&quot;{Binding MyHtml, UpdateSourceTrigger=Explicit, Mode=TwoWay}&quot;
    NavigationCompleted=&quot;WebView_OnNavigationCompleted&quot; ..

In .xaml.cs
private void WebView_OnNavigationCompleted(object sender, CoreWebView2NavigationCompletedEventArgs args)
{
    if (args.IsSuccess)
    {
        var bindingExpression =  
            webView.GetBindingExpression(WebView2.SourceProperty);
        bindingExpression?.UpdateSource();
    }
}

Note that in both options you need Mode=TwoWay.
"
73184914,Razor pages - Change page name depending on the culture,"I'm building a Razor web application using .NET6 and I have 3 different cultures.
For SEO purpose, I'm trying to have a page name who's different depending from the culture.
Like for example:
en: https://www.website.com/en/contact-us
fr: https://www.website.com/fr/contactez-nous
I found a cool article about friendly routes but it has to be done via .AddPageRoute in the Pipeline and I don't see how could I make it match depending on the culture (like one for each culture).
I tried this but it looks like it only take care of the last one:
options.Conventions.AddPageRoute(&quot;/Contact&quot;, &quot;/contact-us&quot;);
options.Conventions.AddPageRoute(&quot;/Contact&quot;, &quot;/contactez-nous&quot;);

This is my Program.cs
var builder = WebApplication.CreateBuilder(args);


builder.Services.AddRazorPages()
    .AddRazorPagesOptions(options =&gt;
    {
        options.Conventions.AddFolderRouteModelConvention(&quot;/&quot;, model =&gt;
        {
            foreach (var selector in model.Selectors)
            {
                selector.AttributeRouteModel.Template = AttributeRouteModel.CombineTemplates(&quot;{culture?}&quot;, selector.AttributeRouteModel.Template);
            }
        });
    });
builder.Services.AddMvc().AddViewLocalization(LanguageViewLocationExpanderFormat.Suffix).AddDataAnnotationsLocalization();
builder.Services.Configure&lt;RequestLocalizationOptions&gt;(opt =&gt;
{
    var supportedCultures = new List&lt;CultureInfo&gt;
    {
        new CultureInfo(&quot;en&quot;),
        new CultureInfo(&quot;fr&quot;),
        new CultureInfo(&quot;nl&quot;)
    };
    opt.DefaultRequestCulture = new RequestCulture(&quot;en&quot;);
    opt.SupportedCultures = supportedCultures;
    opt.SupportedUICultures = supportedCultures;
    opt.RequestCultureProviders.Insert(0, new RouteDataRequestCultureProvider()
    {
        RouteDataStringKey = &quot;culture&quot;,
        UIRouteDataStringKey = &quot;culture&quot;,
        Options = opt
    });
});

builder.Services.Configure&lt;RouteOptions&gt;(opt =&gt;
{
    opt.LowercaseUrls = true;
    opt.AppendTrailingSlash = true;
});

builder.Services.AddHttpContextAccessor();

builder.Services.AddLocalization(opt =&gt; { opt.ResourcesPath = &quot;Resources&quot;; });

var app = builder.Build();

// Configure the HTTP request pipeline.
if (!app.Environment.IsDevelopment())
{
    app.UseExceptionHandler(&quot;/Error&quot;);
    // The default HSTS value is 30 days. You may want to change this for production scenarios, see https://aka.ms/aspnetcore-hsts.
    app.UseHsts();
}

var options = ((IApplicationBuilder)app).ApplicationServices.GetRequiredService&lt;IOptions&lt;RequestLocalizationOptions&gt;&gt;();
app.UseRequestLocalization(options.Value);

app.UseHttpsRedirection();
app.UseStaticFiles();

app.UseRouting();

app.UseAuthorization();

app.MapRazorPages();

app.Run();

Contact.cshtml
@page &quot;/Contact&quot;
@model client.Pages.Contact
@{
    ViewData[&quot;Title&quot;] = &quot;Contact&quot;;
}

&lt;h1&gt;@ViewData[&quot;Title&quot;]&lt;/h1&gt;

&lt;div&gt;
    &lt;form method=&quot;post&quot;&gt;
        &lt;div&gt;
            &lt;label&gt;Name&lt;/label&gt;
            &lt;input type=&quot;text&quot; asp-for=&quot;ContactModel.FullName&quot; placeholder=&quot;Full name&quot;&gt;
            &lt;span asp-validation-for=&quot;ContactModel.FullName&quot; class=&quot;text-danger&quot;&gt;&lt;/span&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;label&gt;Email&lt;/label&gt;
            &lt;input type=&quot;email&quot; asp-for=&quot;ContactModel.Email&quot; placeholder=&quot;info@developify.be&quot;&gt;
            &lt;span asp-validation-for=&quot;ContactModel.Email&quot; class=&quot;text-danger&quot;&gt;&lt;/span&gt;
        &lt;/div&gt;
        &lt;div&gt;
            &lt;label&gt;Message&lt;/label&gt;
            &lt;textarea asp-for=&quot;ContactModel.Message&quot; cols=&quot;30&quot; rows=&quot;10&quot;&gt;&lt;/textarea&gt;
            &lt;span asp-validation-for=&quot;ContactModel.Message&quot; class=&quot;text-danger&quot;&gt;&lt;/span&gt;
        &lt;/div&gt;
        &lt;button type=&quot;submit&quot;&gt;Submit&lt;/button&gt;
    &lt;/form&gt;
&lt;/div&gt;

Anchor from _Layout.cshtml
&lt;a class=&quot;&quot; asp-area=&quot;&quot; asp-page=&quot;/Contact&quot;
                        asp-route-culture=&quot;@CultureInfo.CurrentCulture.Name&quot;&gt;Contact&lt;/a&gt;

How can I achieve this? Do I have to do something with the selector.AttributeRouteModel.Template?
","c#, asp.net, asp.net-mvc, asp.net-core, razor",1,73219493,"I recommend to use url rewrite as described in https://learn.microsoft.com/en-us/aspnet/core/fundamentals/url-rewriting?view=aspnetcore-6.0#extension-and-options
That way, every page is mapped to its english spelled route. Translations are rewritten to the english version by the specified rewrite options.
"
74595002,What is the difference between SingletonScope. Function & Host in Azure WebJob,"What is the difference between SingletonScope? Function &amp; Host in Azure WebJob?
I have Time trigger hosted in two regions in AKS. I want to ensure that only one instance runs every time.
All my instances are sharing the same storage account. Can I use one of the above settings to configure my scenario?
","azure, azure-functions, azure-webjobs",0,74613125,"
Difference between WebJob host and Azure function:

The host is a runtime container for functions. The Host listens for triggers and calls functions.
In version 3.x, the host is an implementation of IHost.
In version 2.x, you use the JobHost object.
You create a host instance in your code and write code to customize its behavior.
This is a key difference between using the WebJobs SDK directly and using it indirectly through Azure Functions.
In Azure Functions, the service controls the host, and you can't customize the host by writing code.
Azure Functions lets you customize host behavior through settings in the host.json file.
For more information, see Compare the WebJobs SDK and Azure Functions

What is Singleton?

The Singleton attribute ensures that only one instance of a function runs, even when there are multiple instances of the host web app. The Singleton attribute uses distributed locking to ensure that one instance runs.
As in below example, only a single instance of the ProcessImage function runs at any given time:
[Singleton]
public static async Task ProcessImage([BlobTrigger(&quot;images&quot;)] Stream image)
{
     // Process the image.

To learn more about how the SingletonMode.Function works see: https://github.com/Azure/azure-webjobs-sdk/blob/master/src/Microsoft.Azure.WebJobs/SingletonMode.cs
Further you can specify a scope expression/value on a singleton. The expression/value ensures that all executions of the function at a specific scope will be serialized.
Check this link for example: https://learn.microsoft.com/en-us/azure/app-service/webjobs-sdk-how-to#scope-values
"
73534241,useState define an empty array with new Array method,"I am getting data which is an array of objects from the store. In useState I want to set an array of data.length size all set to false initially. But when I set the value it returns an empty array [] for each of the state variable I set. I also tried updating the state in the useeffect but nothing works. I am unable to figure out what is the issue here.
function Datatable() {
       let data = useSelector((state) =&gt; state.dish);
      console.log(data.length)
      const [clicked1, setClicked1] = useState(new Array(data.length).fill(false));
      const [clicked2, setClicked2] = useState(new Array(data.length).fill(false));
      const [clicked3, setClicked3] = useState(new Array(data.length).fill(false));
      const dispatch = useDispatch();
      function setAllStates() {
        setClicked1(new Array(data.length).fill(false));
        setClicked2(new Array(data.length).fill(false));
        setClicked3(new Array(data.length).fill(false));
      }
      useEffect(() =&gt; {
        setAllStates();
      }, []);

image of console the data
Here is my jsx where i am creating the table
&lt;TableBody&gt;
            {data.map((row, index) =&gt; (
              &lt;TableRow
                key={row.id}
                sx={{ &quot;&amp;:last-child td, &amp;:last-child th&quot;: { border: 0 } }}
              &gt;
                &lt;TableCell component=&quot;th&quot; scope=&quot;row&quot;&gt;
                  &lt;img width={150} height={100} src={row.image} /&gt;
                &lt;/TableCell&gt;
                &lt;TableCell align=&quot;right&quot;&gt;{row.dishName}&lt;/TableCell&gt;
                &lt;TableCell align=&quot;right&quot;&gt;
                  {clicked1[index] == false ? (
                    &lt;&gt;
                      &lt;Button
                        onClick={() =&gt; handleOnclick(&quot;Rank 1&quot;, index, row)}
                      &gt;
                        Rank 1
                      &lt;/Button&gt;
                    &lt;/&gt;
                  ) : (
                    &lt;Typography&gt;Selected&lt;/Typography&gt;
                  )}
                &lt;/TableCell&gt;

Here is the image of the table
in console data.length is showing 0 two times and then 30. I am populating the data in the reducers in its parent component. But still all the arrays are undefined. And in the table all i am showing in the data table are undefined. (Note: I am creating a table of length data.length. data.image, data.description are showing in the table only the buttons that are showing only when clicked1[index] == false are not defined.
","javascript, reactjs, arrays",0,73534525,"Unless data.length is 0, this gotta work.
    function Datatable() {
          const data = useSelector((state) =&gt; state.dish);

          const [clicked1, setClicked1] = useState();
          const [clicked2, setClicked2] = useState();
          const [clicked3, setClicked3] = useState();

          const dispatch = useDispatch();

          function setAllStates(size) {
            const newArray = new Array(size).fill(false);
            setClicked1(newArray);
            setClicked2(newArray);
            setClicked3(newArray);
          }

          useEffect(() =&gt; {
            if(data) setAllStates(data.length);
          }, [data]);
     }

"
73144075,How do you get a single table column to continue onto next column of page instead of one column on every page in ASP.NET MVC C#?,"I am trying to design a pdf view page for product labels in asp.net mvc c#. Basically, I want there to be two columns on the page with 5 rows (so 10 total labels per page). Based on a form where certain products are selected, the form pulls up the pdf view of the labels (which I use Rotativa for) and it inserts the products selected from form into the labels to print. I have it working perfectly as far as getting the data to the labels, but its only displaying as a single column per page. I'd like after the column on each page reaches the end of the page, instead continuing onto the next page, it flows over to the next column on page. I tried doing another  section and copied the same fields to it from column one but it just shows the same duplicate record per row. I've tried alot of different things I've read online and none of it is working such as display: block or block-inline, I've tried in css setting column-count: 2;. Everything I'm finding online they have multiple fields or columns. I have just one . It's weird that it repeats all the way down the page on the left half of the page but won't continue onto the right half. Here's a basic example of what I want:
[ label from record 1 ]   [ label from record 6 ]
[ label from record 2 ]   [ label from record 7 ]
[ label from record 3 ]   [ label from record 8 ]
[ label from record 4 ]   [ label from record 9 ]
[ label from record 5 ]   [ label from record 10]
(end of page 1)
I've been stuck on this for a couple days now, any help would be greatly appreciated. Here is my code so far:
   &lt;table&gt;
     @foreach (var item in Model)
     {
       &lt;tr&gt;
         &lt;td class=&quot;left-col&quot;&gt;
           &lt;img src=&quot;@Server.MapPath(&quot;~/Images/&quot; + item.Logo)&quot; class=&quot;comp-logo&quot;&gt;&lt;br /&gt;
           &lt;label class=&quot;item-lbl&quot;&gt;Item #&lt;/label&gt;&lt;br /&gt;
           &lt;label class=&quot;code&quot;&gt;@Html.DisplayFor(modelitem =&gt; item.Product_Code)&lt;/label&gt;&lt;br /&gt;
           &lt;label class=&quot;descript&quot;&gt;@Html.DisplayFor(modelitem =&gt; item.Description)&lt;/label&gt;
         &lt;/td&gt;
       &lt;/tr&gt;
     }
   &lt;/table&gt;

","c#, html, css, asp.net, asp.net-mvc",0,73144379,"since you said it doesnt need to be a html table tag in the comment, you can do something like this, where you wrap all the elements in a div and set the div to display grid. grid template columns says how many columns you want and there widths. In this case i set them to 1fr 1fr which will make 2 columns with equal widths. If you want something different you can specify the width in pixels or percentages. This is the same with grid-template-rows.


&lt;style&gt;
.grid{
display:grid;
grid-template-columns: 1fr 1fr;
grid-template-rows:1fr 1fr 1fr 1fr 1fr;
justify-content:start;
width:max-content;
}
&lt;/style&gt; 
&lt;div class=""grid""&gt;
@foreach (var item in Model)
     {
         &lt;span class=""left-col""&gt;
           &lt;img src=""@Server.MapPath(""~/Images/"" + item.Logo)"" class=""comp-logo""&gt;&lt;br /&gt;
           &lt;label class=""item-lbl""&gt;Item #&lt;/label&gt;&lt;br /&gt;
           &lt;label class=""code""&gt;@Html.DisplayFor(modelitem =&gt; item.Product_Code)&lt;/label&gt;&lt;br /&gt;
           &lt;label class=""descript""&gt;@Html.DisplayFor(modelitem =&gt; item.Description)&lt;/label&gt;
         &lt;/span&gt;
}
   &lt;/div&gt;



"
74543810,Im making a PropHunt game in roblox but the whenever i morph the player character into a new form the UI keeps on being called,"I have this project, im creating a prophunt game, however im in a little road block that i can't understand.
Here is how my code works, I have a local script which tells me which team the player is in, since the player does not have a team yet they are always assumed as neutral, then the local script is called whenever the players are added, which a GUI appears, allowing for them to pick the team.
Heres what i did for the Local script GUI, I'm just learning this for now so not really the best way i could have coded it right now, but it does simulate what i want to happen.
Player.PlayerAdded:Connect(function(player)
    if player.Team == TeamService.Blue then
        Frame.Visible = false
    else
        Frame.Visible = true
    end
end)

Hiders.MouseButton1Click:Connect(function(player)
    
    
    local result = ReplicatedStorage.RemoteFunction:InvokeServer(TeamHiders)
    print(result)
    if result == true then
        Frame.Visible = false
    else
        Frame.Visible = false
    end
end)

Here's what i did for the server script to assign the players a team, I'm sorry I'm still fairly new to roblox so i don't know if my approach is correct im just going with what closely gets me to the output.
game.ReplicatedStorage.RemoteFunction.OnServerInvoke = function (player, Team)
    

    
    if Team == teamService.Blue then
        player.Team = Team
        
        print(ChoosenTeam)
        return &quot;player Team is blue&quot;
    end
    
    if Team == teamService.Red then
        player.Team = Team
        
        print(player.Team)
        return &quot;player Team is red&quot;
    end

end

And here is my script for the Morph, so i got this click detector which should tell the game that whenever its clicked transform the player into whatever form this is scripted on.
local model = script.Parent.Parent
script.Parent.MouseClick:Connect(function(player)
    
    if player.Team == teamservice.Blue then
        
        local oldCharacter = player.Character
        local newCharacter = model:Clone()

        newCharacter.HumanoidRootPart.Anchored = false
        newCharacter:SetPrimaryPartCFrame(oldCharacter.PrimaryPart.CFrame)

        player.Character = newCharacter
        newCharacter.Parent = workspace 
    end 
end)


The players under blue side should only encounter this once since the UI should only appear when they do not have a team or are loaded in the game, but what happens is the blue players whenever they morph into a block they encounter the GUI prompt again.
I was expecting by limiting the player teams to nil it would only show the UI, and if the player has a team already then the UI would not show itself, the same goes to when the player decides to morph the player UI should not be visible.
",roblox,0,74697841,
73556146,How to run multiple tags at once in Cucumber / Cypress JS project?,"In my Cypress JS / Cucumber project, I am trying to run multiple test scenario's with different tags.
Feature: First feature

    @tagOne
    Scenario: #1 Navigation

Another feature:
Feature: Secondfeature

    @tagTwo
    Scenario: #1 Visibility

I'm able to run the tags seperately using the below commands:
npx cypress run -e TAGS=\&quot;@tagOne\&quot;
npx cypress run -e TAGS=\&quot;@tagTwo\&quot;

However, I now need to run them together at the same time.
When I run the below command, only tagOne scenario's run, &amp; the tagTwo scenario is Pending.
npx cypress run -e TAGS=\&quot;@tagOne or @tagTwo\&quot;
Can someone please tell me how I can run these tags at the same time?
","cucumber, cypress",1,74715519,
74089173,Updating list in memory doesn't change UI in Flutter,"I am currently modifying my app to support large devices. In this app I want to have a list of categories at the left and when I tap the list tile I want to show the list of the items which the category holds on the left. By the approach I am using the list updates in memory but doesnt change the UI. This is my current approach -&gt;
class _OrderCategoryScreenState extends State&lt;OrderCategoryScreen&gt; {

  List&lt;FoodItem&gt; filteredLists = [];

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      body: SafeArea(
          child: Row(
        children: [
          ValueListenableBuilder&lt;Box&lt;FoodCategory&gt;&gt;(
            valueListenable: Boxes.getFoodCategories().listenable(),
            builder: (context, box, child) {
              final categories = box.values.toList().cast&lt;FoodCategory&gt;();
              return categories.length == 0
                  ? Container(
                      color: Color(0xFFFCF9F9),
                      height: double.infinity,
                      width: MediaQuery.of(context).size.height * 0.30,
                      child: Center(
                        child: Text(&quot;No Categories&quot;),
                      ))
                  : Container(
                      height: double.infinity,
                      width: MediaQuery.of(context).size.height * 0.35,
                      child: Drawer(
                        backgroundColor: Color(0xFFFCF9F9),
                        elevation: 0,
                        child: ListView(
                          children: &lt;Widget&gt;[
                            DrawerHeader(
                              child: ListView(
                                children: [
                                  Container(
                                    height: MediaQuery.of(context).size.height,
                                    child: ValueListenableBuilder&lt;
                                        Box&lt;FoodCategory&gt;&gt;(
                                      builder: (context, value, child) {
                                        final foodCategories = box.values
                                            .toList()
                                            .cast&lt;FoodCategory&gt;();
                                        return ListView.builder(
                                          itemCount: foodCategories.length,
                                          itemBuilder: (context, index) {
                                            return ListTile(
                                              tileColor: Colors.green,
                                              
                                              onTap: () {
                                                filteredLists = Boxes
                                                        .getFoodItems()
                                                    .values
                                                    .where((element) =&gt;
                                                        element.categoryName ==
                                                        foodCategories[index]
                                                            .name)
                                                    .toList();
                                                print(filteredLists.length);
                                                print(&quot;object&quot;);
                                              },
                                              title: Text(
                                                  foodCategories[index].name),
                                            );
                                          },
                                        );
                                      },
                                      valueListenable: Boxes.getFoodCategories()
                                          .listenable(),
                                    ),
                                  )
                                ],
                              ),
                            ),
                          ],
                        ),
                      ));
            },
          ),
          Container(
            width: MediaQuery.of(context).size.width * 0.5,
            height: MediaQuery.of(context).size.height * 0.5,
            color: Colors.amberAccent,
            child: filteredLists.isEmpty
                ? Center(
                    child: Text(&quot;Choose A Category&quot;),
                  )
                : ListView.builder(itemCount: filteredLists.length,
                    itemBuilder: (context, index) {
                      return ListTile(
                        title: Text(filteredLists[index].itemName),
                      );
                    },
                  ),
          ),
        ],
      )
      
      
      ),
    );
  }
}

When I hot reload using this approach it works on the UI as well.
Please Help.
","flutter, dart, flutter-layout",0,74089267,"Try calling setState to update the UI.
onTap: () {
    filteredLists = Boxes
            .getFoodItems()
        .values
        .where((element) =&gt;
            element.categoryName ==
            foodCategories[index]
                .name)
        .toList();
    print(filteredLists.length);
    print(&quot;object&quot;);
    setState((){}); //this
  },

"
72847591,Add SwipeToRefresh to RecyclerView Android,"Have activity page with following code:
&lt;androidx.swiperefreshlayout.widget.SwipeRefreshLayout
        android:id=&quot;@+id/swipeRefreshLayout&quot;
        android:layout_width=&quot;match_parent&quot;
        android:layout_height=&quot;wrap_content&quot;
        android:background=&quot;#00FFFFFF&quot;
        app:layout_constraintEnd_toEndOf=&quot;parent&quot;
        app:layout_constraintTop_toBottomOf=&quot;@+id/view&quot;
        app:layout_constraintHorizontal_bias=&quot;0.0&quot;
&gt;

        &lt;androidx.recyclerview.widget.RecyclerView
            android:id=&quot;@+id/mainList&quot;
            android:layout_width=&quot;match_parent&quot;
            android:layout_height=&quot;wrap_content&quot;
            android:background=&quot;#F0F2F5&quot;
            app:layout_constraintBottom_toBottomOf=&quot;parent&quot;
            app:layout_constraintTop_toBottomOf=&quot;@+id/view&quot;
            app:layout_constraintVertical_bias=&quot;0&quot;
            tools:layout_editor_absoluteX=&quot;0dp&quot; /&gt;

    &lt;/androidx.swiperefreshlayout.widget.SwipeRefreshLayout&gt;

On my main activity.kt file, I have the following code but I am unsure where i need to put listenings etc. as I didn't write this part of the code;
package com.example.what2do_v2

import android.content.Intent
import android.os.Bundle
import android.util.Log
import android.widget.ImageButton
import androidx.appcompat.app.AppCompatActivity
import androidx.recyclerview.widget.LinearLayoutManager
import androidx.recyclerview.widget.RecyclerView
import androidx.swiperefreshlayout.widget.SwipeRefreshLayout
import com.example.what2do_v2.Adapter.TaskAdapter
import com.example.what2do_v2.Model.TaskResponse
import com.example.what2do_v2.Service.ApiClient
import retrofit2.Call
import retrofit2.Callback
import retrofit2.Response


class MainActivity : AppCompatActivity() {
    private val apiService by lazy {
        ApiClient.create()
    }


    private var taskData : ArrayList&lt;TaskResponse&gt; = arrayListOf();

    override fun onCreate(savedInstanceState: Bundle?) {

        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)

        val searchbutton:ImageButton=findViewById(R.id.searchbutton)
        searchbutton.setOnClickListener{
            startActivity(Intent(this, ActivitySearch::class.java))
        }

        val saves:ImageButton=findViewById(R.id.saves)
        saves.setOnClickListener{
            startActivity(Intent(this, ActivitySaves::class.java))
        }

        val settings:ImageButton=findViewById(R.id.settings)
        settings.setOnClickListener{
            startActivity(Intent(this, ActivitySettings::class.java))
        }
        loadData();
    }

    private fun loadData(){
        var data = apiService.getMainData();

        data.enqueue(object : Callback&lt;ArrayList&lt;TaskResponse&gt;&gt; {

            override fun onResponse(
                call: Call&lt;ArrayList&lt;TaskResponse&gt;&gt;,
                response: Response&lt;ArrayList&lt;TaskResponse&gt;&gt;
            ) {

                if (response.code() == 200) {
                    taskData = response.body()!!;
                    displaydata();
                }

            }

            override fun onFailure(call: Call&lt;ArrayList&lt;TaskResponse&gt;&gt;, t: Throwable) {
                Log.d(&quot;-----------------&quot;, t.toString())
            }
        })
    }

    private fun displaydata(){
        var recyclerView = findViewById&lt;RecyclerView&gt;(R.id.mainList);
        var adapter = TaskAdapter(this, taskData);
        recyclerView.layoutManager = LinearLayoutManager(this)
        recyclerView.adapter = adapter

    }
}

I'm really struggling where to add additional &quot;SwipeRefreshLayout&quot; code into the above. I have tried to follow each example on stackflow, but can't seem to understand where the appropriate places to add.
","android, kotlin, android-recyclerview",1,72847627,"Initialize the SwipeRefreshLayout &amp; assign a refresh listener in your onCreate() like this:
val swipeRefreshLayout: SwipeRefreshLayout = findViewById(R.id.swipeRefreshLayout)

// load data on swipe refresh.
swipeRefreshLayout.setOnRefreshListener { loadData() }

// Disable the refreshing after data load
swipeRefreshLayout.isRefreshing = false

"
73903603,Is it possible to have race condition with golang chan?,"My goal is to create a simple websocket server. I use chan to distribute the message e.g by invoking &lt;-messageChan. the messageChan have many writers and readers.
However, this StackOverflow question scares me of causing an unintentionally deadlock.
What I've did:

Create a test that essentially do:

populate a chan int with 0 to 1000.
create 100 goroutine to invoke &lt;-chan and add it to a map[int]bool.
invoke t.Fatal if len(map[int]bool) is not 1000. In other words, race condition.



However, the test did not fail. I am afraid, I did something wrong, and chan can have deadlock.
The code
main_test.go
package main

import (
    &quot;log&quot;
    &quot;sync&quot;
    &quot;testing&quot;
)

type MapMux struct {
    sync.RWMutex
    m map[int]bool
    sync.WaitGroup
}

func (mux *MapMux) AddInt(i int) {
    mux.RLock()
    if _, isExist := mux.m[i]; isExist {
        log.Fatal(&quot;race condition&quot;)
    }
    mux.RUnlock()
    mux.Lock()
    mux.m[i] = true
    mux.Unlock()
    mux.Done()
}

func TestChanRaceCondition(t *testing.T) {
    l := 1000
    c := make(chan int, l)
    defer close(c)
    for i := 0; i &lt; l; i++ {
        c &lt;- i
    }

    mux := MapMux{sync.RWMutex{}, map[int]bool{}, sync.WaitGroup{}}

    mux.Add(l)

    for i := 0; i &lt; 100; i++ {
        go func(key int) {
            for {
                payload := &lt;-c
                log.Printf(&quot;go%d: %d&quot;, key, payload)
                mux.AddInt(payload)
            }
        }(i)
    }

    mux.Wait()

    if len(mux.m) != l {
        t.Fatal(&quot;expected len:&quot;, l, &quot;, actual len:&quot;, len(mux.m))
    }
}

Edit:

The code finds duplicates in the map[int]bool field. Edit: This is because defer close(c). I should have check is the channel was open for every operation.

Anyway, this is what I learn. Hope this help new Golangers.
Lesson learnt:

it is okay to have many writers and many readers for one channel.
always check val, isOpen := &lt;-chan. If isOpen == false, then stop using the channel.
sync.RWMutex.RLock() does not guarantee other goroutine from making changes to the map. So, becareful. This is how it should be done.
 func (mux *MapMux) AddInt(i int) {
     mux.RLock()
     if _, isExist := mux.m[i]; isExist {
         log.Fatal(&quot;race condition&quot;)
     }
     mux.RUnlock()
     mux.Lock()
     if _, isExist := mux.m[i]; isExist {
         log.Fatal(&quot;race condition&quot;)
     }
     mux.m[i] = true
     mux.Unlock()
     mux.Done()
 }



",go,0,73903664,"A data race happens if you share memory between goroutines. If you do not share memory between goroutines, the kind of data races you are afraid of will not happen. There can be other race conditions, such as the one you have in your AddInt method. The correct version should be:
func (mux *MapMux) AddInt(i int) {
    mux.RLock()
    if _, isExist := mux.m[i]; isExist {
        log.Fatal(&quot;race condition&quot;)
    }
    mux.RUnlock()
    mux.Lock()
    if _, isExist := mux.m[i]; isExist {
        log.Fatal(&quot;race condition&quot;)
    }
    mux.m[i] = true
    mux.Unlock()
    mux.Done()
}

This is because there is no guarantee that another goroutine changes the map between RUnlock and Lock.
In your example, you are sharing a map between goroutines. That means you have to protect all access to it using a mutex. If you do that, there will be no data races around the use of that map.
However, in general, if you can avoid sharing memory, your program will not have such data races.
"
74448709,"bizday() not flagging June 20, 2022 (Juneteenth) as NYSE market holiday R","How can I add a missing date when a market was closed to a loaded calendar so I can use the date difference function bizdays() from library(bizdays)?
From NYSE's website:

Juneteenth National Independence Day  Monday, June 20, 2022 (Juneteenth
holiday observed)

But bizday() doesn't recognize 2022-06-20 as a NYSE market holiday
&gt; library(bizdays)
&gt; load_rmetrics_calendars(2000:2022)
Calendar Rmetrics/NYSE loaded

&gt; bizdays.options$set(default.calendar = &quot;Rmetrics/NYSE&quot;)
&gt; is.bizday(&quot;2022-06-20&quot;)
[1] TRUE


","r, bizdays",1,74449877,"The current version 4021.106 of the package timeDate with publication date 2022-9-29 resolved the issue and now recognizes 2022-06-20 as a market holiday for the NYSE:
&gt; library(timeDate)
&gt; library(bizdays)
&gt; load_rmetrics_calendars(2000:2023)
Calendar Rmetrics/NYSE loaded
&gt; bizdays.options$set(default.calendar = &quot;Rmetrics/NYSE&quot;)
&gt; is.bizday(&quot;2022-06-20&quot;)
[1] FALSE

For background, I previously encountered the issue with not flagging Juneteenth as a market holiday, because I was using the package timeDate dated 2018-02-21, and Juneteenth was not established as a US national holiday until 2021-06-18.
"
74284478,Is it possible you can get the actual value of a string resource by calling it from a sealed class?,"I want to add a string resource to my app in the topbar but when I call it a number appears and because it is a sealed class it does not let me implement stringResource or getString.
&lt;resources&gt;
    &lt;string name=&quot;app_name&quot;&gt;AppEsquema&lt;/string&gt;
    &lt;string name=&quot;app&quot;&gt;&lt;b&gt;&quot;Translator&lt;/b&gt;&quot;&lt;/string&gt;
&lt;/resources&gt;

sealed class Destinations(
    val route: String,
    val title: String,
    val icon: ImageVector
){
    //Bottom bar windows
    object Translate: Destinations(R.string.app.toString(), &quot;Translate&quot;, Icons.Default.Translate)
    object Words: Destinations(&quot;Words&quot;, &quot;Words&quot;, Icons.Default.Assignment)
    object Numbers: Destinations(&quot;Numbers&quot;, &quot;Numbers&quot;, Icons.Default.FormatListNumbered)
}


I don't enter the string directly because the topbar changes the name when navigating the windows and I want it to be personalized.
this is the code for the change of title by window, if it works but it gets the name of the path of the window and the only solution I saw is to assign a string resource to the path to customize it.

","android, kotlin, resources, android-jetpack-compose, jetpack-compose-navigation",4,74285798,"You can capture the return value from backStackEntry and used it to check against your Destination's route parameter via when and have it return an explicit String
var title by remember {
    mutableStateOf(&quot;&quot;)
}

LaunchedEffect(Unit){
     navController.currentBackStackEntryFlow.collect {
        title = it.destination.route.let { route -&gt;
            when (route) {
                Destinations.Translate.route -&gt; {
                     &quot;Translate&quot;
                }
                Destinations.Words.route -&gt; {
                     &quot;Words&quot;
                }
                Destinations.Numbers.route -&gt; {
                    &quot;Numbers&quot;
                } else -&gt; {
                    &quot;&quot; // empty or your default title bar
                }
            }
        }
    }
}

TopAppBar(
    title = {
        Text(text = title)
    }
)

or you can add an additional parameter to your Destination sealed class
sealed class Destinations(
    @StringRes val stringRes: Int,
    val route: String,
    val title: String,
    val icon: ImageVector
) {
    object Translate: Destinations(R.string.translate_title, ...)
    object Words: Destinations(R.string.words_title, ...)
    object Numbers: Destinations(R.string.numbers_title, ...)
}

and in your LaunchEffect call
...

val context = LocalContext.current

LaunchedEffect(Unit){
    navController.currentBackStackEntryFlow.collect {
        title = context.getString(it.destination.route.let { route -&gt;
            when (route) {
                Destinations.Translate.route -&gt; {
                    Destinations.Translate.stringRes
                }
                Destinations.Words.route -&gt; {
                    Destinations.Words.stringRes
                }
                Destinations.Numbers.route -&gt; {
                    Destinations.Numbers.stringRes
                }
                else -&gt; {
                    // empty or your default/initial title
                    Destinations.Translate.stringRes
                }
            }
        })
    }
}

...
    

"
74405746,How to Get Apps to Show Full Screen on Chromebook?,"I've been making Android apps for a long time and can get them to open in full screen mode on every device except Chromebook. No matter what I do, they only open about half screen and a user has to click the &quot;maximize&quot; button to get them to open further.
Here is the code I use to try to get the apps full screen:
&lt;item name=&quot;android:windowFullscreen&quot;&gt;true&lt;/item&gt;

in the relevant style in themes.xml
as well as
getWindow().setFlags(WindowManager.LayoutParams.FLAG_FULLSCREEN, WindowManager.LayoutParams.FLAG_FULLSCREEN);

in MainActivity's onCreate() method.
I've also tried putting
android:theme=&quot;@android:style/Theme.NoTitleBar.Fullscreen&quot;

in the application block of AndroidManifest.xml.
Is there something else I can do to get the apps to open full screen on Chromebook?
(I'm using HP Chromebook x360, if that helps)
","android, fullscreen, chromebook",0,74671349,
73407546,Zend Framework - More than one record matches the supplied identity,"Here is the problem. I have an eshop with users, they do not need to create account when ordering something, but they have a chance for it. I have a user that he first time refuse registering (I also save his data into User table with his email for order porpouses) but now he confirm and register account with new order he made. So what happens.. now he has two accounts in my db with same emails..(dont know why yet, it shouldnt). I have column in my db called active, if user is registered then active is 1. How can i tell ZendAuth to only choose this type of account?
Zend Error message now: More than one record matches the supplied identity.
My code:
     $db = Zend_Registry::get('db');
     $authAdapter = new Zend_Auth_Adapter_DbTable($db);
     $authAdapter-&gt;setTableName('user');
     $authAdapter-&gt;setCredentialColumn('password');
     $authAdapter-&gt;setIdentityColumn('email');
     $authAdapter-&gt;setCredential($password);
     $authAdapter-&gt;setIdentity($email);

IÂ´am looking for something like $authAdapter-&gt;setContition('active = 1'); any suggestion?
","php, zend-framework, zend-db",0,73409090,"You can use the getDbSelect method of Zend_Auth_Adapter_DbTable to access the adapter's Zend_Db_Select instance and set your additional criteria on it. The docs show exactly your case in the last example.
// get the select object and set your additional where clause
$select = $authAdapter-&gt;getDbSelect();
$select-&gt;where('active = 1');

If possible you should consider adding a unique index for the email column.
"
74339986,I don't understand why am I getting this output in this C program,"#include &lt;stdio.h&gt;
#include &lt;string.h&gt;


int main(void) {

    char s1[6] = &quot;Hello&quot;;
    char s2[3];

    strcpy(s2, s1);

    printf(&quot;%s\n&quot;, s2);
    
    return 0;
}

I have written this code in C and expected the output to be either an error
or maybe s2 will be {'H', 'e', '\0'} but the actual output was a &quot;Hello&quot; (without &quot;&quot;) just like s1
so why did this happen considering that s2 should only hold up to 3 chars which is smaller than s1 size.
","arrays, c, string, strcpy",0,74340126,"Having placed your code in question.c, let's do a little debugging to figure out what is happening.
$ gcc -Wall -fstack-protector-strong -g -o question question.c
$ ./question 
Hello

So far none of the warnings you get with -Wall or -fstack-protector-strong have helped us to catch this issue. So let's try valgrind:
$ valgrind -q ./question 
==1313263== Source and destination overlap in strcpy(0x1ffefff73f, 0x1ffefff742)
==1313263==    at 0x484EF00: strcpy (in /usr/libexec/valgrind/vgpreload_memcheck-amd64-linux.so)
==1313263==    by 0x1091C3: main (question.c:10)
==1313263== 
Hello

Looks like valgrind has provided a clue that something is wrong here. Let's try debugging it.
$ gdb ./question 
(gdb) b main
Breakpoint 1 at 0x1195: file question.c, line 5.

(gdb) r
Breakpoint 1, main () at question.c:5
5   int main(void) {

(gdb) n
7       char s1[6] = &quot;Hello&quot;;
(gdb) n
10      strcpy(s2, s1);
(gdb) n
12      printf(&quot;%s\n&quot;, s2);
(gdb) p s1
$1 = &quot;lo\000lo&quot;
(gdb) p s2
$2 = &quot;Hel&quot;
(gdb) p (char*) s2
$3 = 0x7fffffffd7cf &quot;Hello&quot;

From the above debug session you can kind of see what is really going on:

Because gdb knows that s2 is only a three-byte array, printing it out dislays Hel.
You can see by printing out s1 that the remainder of the string has overflowed into s1.

Why did it do this? It's due how how the variables were laid out on the stack when you ran the program. You can check for yourself by dumping the stack in gdb:
(gdb) p $sp
$4 = (void *) 0x7fffffffd7c0
(gdb) p &amp;s1
$5 = (char (*)[6]) 0x7fffffffd7d2
(gdb) p &amp;s2
$6 = (char (*)[3]) 0x7fffffffd7cf

This shows the in-memory addresses of the stack, and the addresses of s1 and s2. By printing out a hex dump of the stack, you can also visualize this:
(gdb) dump binary memory stackdump $sp $sp+32
(gdb) shell xxd stackdump
00000000: e9dc ffff ff7f 0000 6400 0000 0000 0048  ........d......H
00000010: 656c 6c6f 006c 6f00 0002 9cd6 42c9 4be5  ello.lo.....B.K.

You can see from the above that 15 bytes into the stack is where s2 was, and confirm that as follows:
(gdb) p (char*) $sp+15
$7 = 0x7fffffffd7cf &quot;Hello&quot;
(gdb) p (char*) s2
$8 = 0x7fffffffd7cf &quot;Hello&quot;

... and similarly, you can see that s1 was 18 bytes into the stack and has been overwritten by the write to s2:
(gdb) p (char*) $sp+18
$10 = 0x7fffffffd7d2 &quot;lo&quot;
(gdb) p (char*) s1
$11 = 0x7fffffffd7d2 &quot;lo&quot;

"
73547364,"Create a BaseComponent for web components, and refer to component name once","I have noticed there are a few common/repeated methods I keep reusing in some web components I am working on. When I change the method in one, if I want the improvement in the others, I have to open each one and make the changes to all the other components, which is tedious and error prone. So I am trying to create a BaseComponent which the other components inherit from.
The issue is I would like to define the component name, e.g. wc-thingy in one place, keep it DRY. However this name is requried in two places:

To find the template of the component (I name the id of the template TEMPLATE_&lt;component_name&gt;, e.g. TEMPLATE_wc-thingy
To customElements.define it.

Below is my attempt to try accomplish it, but I think the issue is this.constructor is not refering to the subclass class instance:


window.BaseComponent = class extends HTMLElement {
    static componentName;

    static define(componentName) {
        this.constructor.componentName = componentName;
        window.customElements.define(this.constructor.componentName, this);
    }

    constructor() {
        super();
        this.attachShadow({ mode: ""open"" });
        const template = document.getElementById(""TEMPLATE_"" + this.constructor.componentName);
        this.shadowRoot.appendChild(template.content.cloneNode(true));
        console.log(""Contructed"", this.constructor.componentName)
    }

    sayHello() {
        console.log(""Hello"");
    }
};

(class extends window.BaseComponent {
    sayBi() {
        console.log(""K Bi, thxns!"");
    }
}).define('wc-thingy')
&lt;wc-thingy&gt;thingy here&lt;/wc-thingy&gt;



","javascript, web-component, native-web-component",0,73547578,"+1 for creating your own BaseComponent
-392.176.112 if you now think you are great, and sell it to the world like the other 60+ BaseClasses
The Web Component name is in this.nodeName (uppercase) or this.localName (lowercase)


&lt;template id=""WC-FOO""&gt;foo:&lt;slot&gt;&lt;/slot&gt;&lt;/template&gt;
&lt;template id=""WC-BAR""&gt;bar:&lt;slot&gt;&lt;/slot&gt;&lt;/template&gt;

&lt;wc-foo&gt;FOO&lt;/wc-foo&gt;
&lt;wc-bar&gt;BAR&lt;/wc-bar&gt;

&lt;script&gt;
  class BaseComponent extends HTMLElement {
    constructor() {
      const template = () =&gt; document.getElementById(this.nodeName).content;
      super().attachShadow({mode:""open""})
             .append(template().cloneNode(true));
      console.log(""Contructed"", this.nodeName , this.localName)
    }
  };
  customElements.define(""wc-foo"", class extends BaseComponent {});
  customElements.define(""wc-bar"", class extends BaseComponent {});
&lt;/script&gt;



"
74095245,AnalysisException: need struct type but got string,"I have created a table in Databricks
create table TabA (latitude float, longitude float, col1 string,col2 string)

utils.executequery( &quot;&quot;&quot; update TabA set col1 = ST_Envelope(col2)&quot;&quot;&quot; ) I tried converting this output as string but getting error as _tostring() not supported
utils.executequery(&quot;&quot;&quot; optimize TabA &quot;&quot;&quot;)

utils.executequery( &quot;&quot;&quot; update TabA set latitude = col1.Lat&quot;&quot;&quot; )
utils.executequery(&quot;&quot;&quot; optimize TabA &quot;&quot;&quot;)

utils.executequery( &quot;&quot;&quot; update TabA set longitude= col1.Long&quot;&quot;&quot; )
utils.executequery(&quot;&quot;&quot; optimize TabA &quot;&quot;&quot;)

I am getting the error

col1#22613: need struct type but got string

I tried casting the &quot;col1&quot; as string, but I was not able to solve this exception. How do I solve it?
","apache-spark, pyspark, struct, databricks, apache-sedona",1,74099851,"Your error must be coming from col1.Lat and col1.Long. Since your col1 is string, you cannot use dot . notation such as col1.Lat, because this notation is for struct data type, not for string.
Consider this example:
df = spark.createDataFrame([('x', (1.0, 2.0))], 'string_col:string, struct_col:struct&lt;lat:double,lon:double&gt;')
df.createOrReplaceTempView('TabA')

df.printSchema()
# root
#  |-- string_col: string (nullable = true)
#  |-- struct_col: struct (nullable = true)
#  |    |-- lat: double (nullable = true)
#  |    |-- lon: double (nullable = true)

df.show()
# +----------+----------+
# |string_col|struct_col|
# +----------+----------+
# |         x|{1.0, 2.0}|
# +----------+----------+

The following SQL query works, because I address the struct type column and successfully extract the field lon:
spark.sql('select struct_col.lon from TabA').show()
# +---+
# |lon|
# +---+
# |2.0|
# +---+

But the following SQL query fails, because I try to do the same on the string tyoe column.
spark.sql('select string_col.lon from TabA').show()


AnalysisException: Can't extract value from string_col#617: need struct type but got string; line 1 pos 7

"
73515766,New card not rendering in react,"I added a feature whereby the user can add cards to the app with the following code:
export default function Filter({
   onChangeHogListAdd
   }) {

const [textInput, setTextInput] = useState('')

function handleAdd() {
    onChangeHogListAdd(textInput)
}

return(
   &lt;div&gt;
        &lt;div className ='ui item'&gt;
            &lt;label&gt;Add a hog!&lt;/label&gt;
        &lt;/div&gt;
        &lt;div className='ui item'&gt;
            &lt;input
                className='ui input focus'
                type='text'
                placeholder='Add hog...'
                onChange={(e) =&gt; setTextInput(e.target.value)}
            /&gt;
        &lt;/div&gt;
        &lt;div className='ui item'&gt;
            &lt;button className='ui button' onClick={handleAdd}&gt;Add&lt;/button&gt;
        &lt;/div&gt;
   &lt;/div&gt;
)

The callback prop in the parent component is the following
function hogListAdd(newName) {
    hogList.push({ name : newName })
}

Whereby hogList is an array of objects which is rendered as cards on the UI. Weirdly enough, when a user adds a new hog through the text input box, the array hogList updates with the newly added object, but the page doesn't render it in. This is the part that I am stuck on, any help would be appreciated. Thank you.
","javascript, reactjs, arrays, render",0,73515860,"You are pushing to hogList, which doesn't tell React about state change. In the parent component use useState hook and call the setter
const [hogList, setHogList] = useState([]);
function hogListAdd(newName) {
  setHogList((old) =&gt; [...old, { name : newName }]);
}

"
73004413,Nginx Redirect Chaining,"This is What I have
http://example.com ---&gt; https://www.example.com ---&gt; https://example.com

This is what I am trying to Achieve
http://example.com ---&gt; https://example.com

My current nginx config has the below mentioned line
if ($real_scheme = 'http') { return 301 https://$host$request_uri; }

Where real_scheme is a variable derived from a Map block
I am trying to Achieve the same using a Map, can anyone lemme know the mistake I am making, Below is the updated Config
map $host $nonwwwhost {
~*^www\.(.*)   $1;   
default     $host;
}

if ($real_scheme = 'http') { return 301 https://$nonwwwhost$request_uri; }

",nginx,1,73046908,"Finally figured out a way to Achieve this using regex expression
map $host $nonwwwhost {
~*^www\.(?&lt;domain3&gt;\S+)*  $domain3;
default     $host;
}

"
73380316,Beautifulsoup scrape financial data,"I am an absolute beginner, trying to extract financial data from a website. The data I'm looking for is hidden in unordered lists and spans with no name. Does anybody know how to deal with this using beautifulsoup? I'd like to add the data in a dataframe in pandas.
&lt;div class=&quot;finance__details__right&quot;&gt;
        &lt;ul&gt;
            &lt;li&gt;
                &lt;i&gt;Î†Î½Î¿Î¹Î³Î¼Î±&lt;/i&gt;
                &lt;span data-bind=&quot;text: o.extend({priceNumeric: { dependOn: l, precision: 4 }})&quot;&gt;15,8100&lt;/span&gt;
            &lt;/li&gt;
            &lt;li&gt;
                &lt;i&gt;Î¥ÏˆÎ·Î»ÏŒ&lt;/i&gt;
                &lt;span data-bind=&quot;text: hp.extend({priceNumeric: { dependOn: l, precision: 4 }})&quot;&gt;16,2400&lt;/span&gt;
            &lt;/li&gt;
            &lt;li&gt;
                &lt;i&gt;Î§Î±Î¼Î·Î»ÏŒ&lt;/i&gt;
                &lt;span data-bind=&quot;text: lp.extend({priceNumeric: { dependOn: l, precision: 4 }})&quot;&gt;15,8100&lt;/span&gt;
            &lt;/li&gt;
        &lt;/ul&gt;
        &lt;ul&gt;
            &lt;li&gt;
                &lt;i&gt;ÎŒÎ³ÎºÎ¿Ï‚&lt;/i&gt;
                &lt;span data-bind=&quot;text: tv() &gt; 0? tv.extend({numeric: { precision: 0}})(): '', flashBackground: tv&quot;&gt;301.286&lt;/span&gt;
            &lt;/li&gt;
            &lt;li&gt;
                &lt;i&gt;Î¤Î¶Î¯ÏÎ¿Ï‚&lt;/i&gt;
                &lt;span data-bind=&quot;text: to() &gt; 0? to.extend({numeric: { precision: 0 }})() + ' â‚¬': '', flashBackground: to&quot;&gt;
4.843.588 â‚¬                &lt;/span&gt;
            &lt;/li&gt;
            &lt;li&gt;
                &lt;i&gt;Î ÏÎ¬Î¾ÎµÎ¹Ï‚&lt;/i&gt;
                &lt;span data-bind=&quot;text: t() &gt; 0? t.extend({numeric: { precision: 0}})(): '', flashBackground: t&quot;&gt;1.890&lt;/span&gt;
            &lt;/li&gt;
        &lt;/ul&gt;
            &lt;ul&gt;
                &lt;li&gt;
                    &lt;i&gt;Î‘Î³Î¿ÏÎ±ÏƒÏ„Î­Ï‚&lt;/i&gt;
                    &lt;span data-bind=&quot;text: bs() &gt; 0? b.extend({priceNumeric: l})() + ' x ' + bs.extend({numeric: { precision: 0}})(): '', flashBackground: b&quot;&gt;
                    &lt;/span&gt;
                &lt;/li&gt;
                &lt;li&gt;
                    &lt;i&gt;Î Ï‰Î»Î·Ï„Î­Ï‚&lt;/i&gt;
                    &lt;span data-bind=&quot;text: as() &gt; 0? a.extend({priceNumeric: l})() + ' x ' + as.extend({numeric: { precision: 0}})(): '', flashBackground: a&quot;&gt;
16,2400 x 6.884
                    &lt;/span&gt;
                &lt;/li&gt;
                &lt;li&gt;
                    &lt;i&gt;ÎšÎµÏ†Î±Î»Î±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ·&lt;/i&gt;
                    &lt;span data-bind=&quot;text: cp.extend({numeric: { precision: 0}})() + ' â‚¬', flashBackground: cp&quot;&gt;2.320.552.455 &amp;euro;&lt;/span&gt;
                &lt;/li&gt;

this is the code (that doesnt work)
SCRIP = 'ÎœÎ¥Î¤Î™Î›'
link = f'https://www.capital.gr/finance/quote/{SCRIP}'
hdr = {'User-Agent':'Mozilla/5.0'}
req = Request(link,headers=hdr)
 
try:
    page=urlopen(req)
    soup = BeautifulSoup(page)
    
    div_html = soup.find('div',{'class': 'finance_details_right'})
    ul_html = div_html.find('ul')
    ÎšÎµÏ†Î±Î»Î±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· = 0.0
        
    for li in ul_html.find_all(&quot;li&quot;):
        name_span = li.find('')
        if 'ÎšÎµÏ†Î±Î»Î±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ·' in name_span.text: 
            num_span = li.find('span',{'class':''})
            
            ÎšÎµÏ†Î±Î»Î±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· = float(num_span) if (num_span != '') else 0.0
            break
    
    print(f'ÎšÎµÏ†Î±Î»Î±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· - {SCRIP}: {ÎšÎµÏ†Î±Î»Î±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ·} Cr')

except:
    print(f'EXCEPTION THROWN: UNABLE TO FETCH DATA FOR {SCRIP}')

I am looking for ÎšÎµÏ†Î±Î»Î±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· and 2.320.552.455 without the euro sign
any help is greatly appreciated.
Thank you in advance
","python, beautifulsoup, finance",1,73380498,"The following code will get you that number (if I understood your question) for a number of tickers:
import requests
from bs4 import BeautifulSoup

tickers = ['ÎœÎ¥Î¤Î™Î›','Î›Î‘ÎœÎ”Î‘'] 
for t in tickers:
    url = f'https://www.capital.gr/finance/quote/{t}'
    r = requests.get(url)
    soup = BeautifulSoup(r.text, 'lxml')

    el = soup.find('i', string = 'ÎšÎµÏ†Î±Î»Î±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ·').parent.find('span').text.split(' ')[0]
    print(t, 'ÎšÎµÏ†Î±Î»Î±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ·', el)

Result:
ÎœÎ¥Î¤Î™Î› ÎšÎµÏ†Î±Î»Î±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· 2.320.552.455
Î›Î‘ÎœÎ”Î‘ ÎšÎµÏ†Î±Î»Î±Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· 1.126.696.558

"
73114255,"In Python, rearrange order of words in a dataframe when condition is met?","I have this dataframe df:
        Addressee          Title   FirstName   LastName  SpTitle  SpFirstName  SpLastName
0  John Doe and Jane Doe    Mr.      John        Doe       Mrs.     Jane         Doe
1  Jane Doe and John Doe    Mrs.     Jane        Doe       Mr.      John         Doe

My data is over 50k rows, with unknown names. Addressee has different variations to consider.
     Addressee        Title   FirstName   LastName  SpTitle  SpFirstName  SpLastName
0  John and Jane       Mr.      John        Doe       Mrs.     Jane         Doe
1  Jane and John       Mrs.     Jane        Doe       Mr.      John         Doe
2  Mrs. Jane E. Doe    Mrs.     Jane        Doe       NaN       NaN         NaN
3  Jane Doe            Mrs.     Jane        Doe       NaN       NaN         NaN
4  John Michael Doe    Mr.      John        Doe       NaN       NaN         NaN

When Addressee has Mrs. first in Addressee, I want to swap John and Jane around, then mark the row as changed by adding a 1 at the end of the row.
        Addressee          Title   FirstName   LastName  SpTitle  SpFirstName  SpLastName Rearrange
0  John Doe and Jane Doe    Mr.      John        Doe       Mrs.     Jane         Doe
1  John Doe and Jane Doe    Mrs.     Jane        Doe       Mr.      John         Doe           1
2  Mrs. Jane E. Doe         Mrs.     Jane        Doe       NaN       NaN         NaN
3  Jane Doe                 Mrs.     Jane        Doe       NaN       NaN         NaN
4  John Michael Doe         Mr.      John        Doe       NaN       NaN         NaN

Here is what I have so far:
import pandas as pd 
import numpy as np

# Read csv
df= pd.read_csv(csv_file, encoding='latin-1')

# Add column to keep track of what was changed. 
df['Rearrange']= ''
df= df.replace(np.nan,'')
df.insert(0, 'ID', range(0, len(df)))

# Code I cannot figure out
####################### Pseudo code ##########################
#
# data_1 = If title == [(Mrs.|Ms.|Miss) &amp; (FirstName comes first in Addressee)]:
#            df['Addressee'] == SpFirstName + SpLastName + 'and' + FirstName + LastName
#
####################### Pseudo code ##########################

# If the row is rearranged, keep track and add it to the list. 
    ids = df.index.tolist()
    for i in ids:
      df.at[i,'Rearrange']+=', 1'

    # Total rows changed
    changed = df[(df['Rearrange'] != '')]
    unchanged = df[(df['Rearrange'] == '')]
    changed['Rearrange'] = changed['Rearrange'].str[1:]
    changed = changed[(changed['Rearrange'] != '')]

    # Clean up
    del changed[&quot;ID&quot;]
    del unchanged[&quot;ID&quot;]

    # Print results 
    changed['Rearrange'].value_counts()
    print(&quot;There was a total of&quot;,data.shape[0], &quot;rows.&quot;, &quot;There were&quot; ,data.shape[0] - changed.shape[0], &quot; rows unchanged&quot; ,changed.shape[0], &quot;rows rearranged&quot;)

I have attempted to add something like the following, but it's not working quite right, and I cannot figure out how to do this, only if a condition is met:
df['Rearrange '] = [' '.join(s.split()[::-1]) for s in df['Addressee']]
How can I rearrange words to a specific order when a condition is met?
","python, pandas, dataframe, split",2,73114550,"Try:
mask = df[&quot;Title&quot;].eq(&quot;Mrs.&quot;)

df.loc[mask, &quot;Addressee&quot;] = df[mask].apply(
    lambda x: f&quot;{x['SpFirstName']} {x['SpLastName']} and {x['FirstName']} {x['LastName']}&quot;,
    axis=1,
)
df.loc[mask, &quot;Rearrange&quot;] = 1

print(df)

Prints:
               Addressee Title FirstName LastName SpTitle SpFirstName SpLastName  Rearrange
0  John Doe and Jane Doe   Mr.      John      Doe    Mrs.        Jane        Doe        NaN
1  John Doe and Jane Doe  Mrs.      Jane      Doe     Mr.        John        Doe        1.0


EDIT: Updated answer with new input:
mask = df[&quot;Title&quot;].eq(&quot;Mrs.&quot;) &amp; df.notna().all(axis=1)

df.loc[mask, &quot;Addressee&quot;] = df[mask].apply(
    lambda x: f&quot;{x['SpFirstName']} {x['SpLastName']} and {x['FirstName']} {x['LastName']}&quot;,
    axis=1,
)
df.loc[mask, &quot;Rearrange&quot;] = 1

print(df)

Prints:
               Addressee Title FirstName LastName SpTitle SpFirstName SpLastName  Rearrange
0          John and Jane   Mr.      John      Doe    Mrs.        Jane        Doe        NaN
1  John Doe and Jane Doe  Mrs.      Jane      Doe     Mr.        John        Doe        1.0
2       Mrs. Jane E. Doe  Mrs.      Jane      Doe     NaN         NaN        NaN        NaN
3               Jane Doe  Mrs.      Jane      Doe     NaN         NaN        NaN        NaN
4       John Michael Doe   Mr.      John      Doe     NaN         NaN        NaN        NaN

"
74310780,Is there anyway to remove/Replace a Column from a list of lists in Java?,"I have a List of Lists filled with strings and I'm trying to sort a column of the list So i could then use binary search on it to find an element within that column. I also want to get all the information on the Row after finding the element in the column and print it out.
I'm trying to replace a column in a list of lists with a sorted version of the column.
Example: I'm looking for &quot;345&quot; in the 3rd column using binary search and want to print the entire row after finding &quot;345&quot; in the column.
before sorting 3rd column:

&quot;Test0&quot; &quot;ABC&quot; &quot;123&quot; &quot;A1&quot;
&quot;Test3&quot; &quot;JKL&quot; &quot;901&quot; &quot;A4&quot;
&quot;Test1&quot; &quot;DEF&quot; &quot;345&quot; &quot;A2&quot;        
&quot;Test4&quot; &quot;MNO&quot; &quot;234&quot; &quot;A5&quot;
&quot;Test2&quot; &quot;GHI&quot; &quot;678&quot; &quot;A3&quot;

after sorting 3rd column: 

&quot;Test0&quot; &quot;ABC&quot; &quot;123&quot; &quot;A1&quot;
&quot;Test4&quot; &quot;MNO&quot; &quot;234&quot; &quot;A5&quot;
&quot;Test1&quot; &quot;DEF&quot; &quot;345&quot; &quot;A2&quot;   
&quot;Test2&quot; &quot;GHI&quot; &quot;678&quot; &quot;A3&quot;
&quot;Test3&quot; &quot;JKL&quot; &quot;901&quot; &quot;A4&quot;

Output: 

&quot;Test1&quot; &quot;DEF&quot; &quot;345&quot; &quot;A2&quot;  

I already have a method that can get any column from the list and sort it, I just need to find a way to replace that sorted column back into the list if possible. Then I could run Binary search and print the row(s).
Edit:
I've tried making this method that attempts loop through and add the updated column to the original 2d string array then i convert it to a lists of lists. It just ends up returning the original list.
public static List &lt;List&lt;String&gt;&gt; replaceCol (String [][] dataArray, List &lt;String&gt; col, int valType){
        List&lt;List&lt;String&gt;&gt; updatedList = new ArrayList&lt;&gt;();

        for (int i = 0; i &lt; dataArray.length; i++) {
            for (int j = 0; j &lt; dataArray.length; j++) {

            }
            if (dataArray[i][valType].equalsIgnoreCase(col.get(i))) {
                dataArray[i][valType] = col.get(i);
            }
        }
        updatedList = TwoDArrayToList(dataArray);

        return updatedList;
    }

","java, list, sorting",-2,74311061,"For this, I created a method that returns the index of the matching element. If no matching element is found, it simply returns -1.
I also created a comparator that compares lists based on the value of the string at the found index. If the index is less than zero, it simply skips the comparator to avoid an exception being thrown. Since the list is of String objects and this class already implements the Comparator interface, the rest is easy: simply return the result of comparison of the compared strings.
public class GridSort {
    public static void main (String[] args) {
        List&lt;List&lt;String&gt;&gt; grid = new ArrayList&lt;&gt;();
        grid.add(List.of(&quot;Test0&quot;, &quot;ABC&quot;, &quot;123&quot;, &quot;A1&quot;));
        grid.add(List.of(&quot;Test3&quot;, &quot;JKL&quot;, &quot;901&quot;, &quot;A4&quot;));
        grid.add(List.of(&quot;Test1&quot;, &quot;DEF&quot;, &quot;345&quot;, &quot;A2&quot;));
        grid.add(List.of(&quot;Test4&quot;, &quot;MNO&quot;, &quot;234&quot;, &quot;A5&quot;));
        grid.add(List.of(&quot;Test2&quot;, &quot;GHI&quot;, &quot;678&quot;, &quot;A3&quot;));
        
        String key = &quot;345&quot;;
        int pivotPoint = findPivotPoint(grid, key); // returns index 2
        
        // sorting
        Comparator&lt;List&lt;String&gt;&gt; rowComparator = new Comparator&lt;List&lt;String&gt;&gt;() {
            
            @Override
            public int compare (List&lt;String&gt; o1, List&lt;String&gt; o2) {
                String s1 = o1.get(pivotPoint);
                String s2 = o2.get(pivotPoint);
                return s1.compareTo(s2);
            }       
        };
        
        if (pivotPoint &gt;= 0) {
            Collections.sort(grid, rowComparator);
        }
        
        System.out.println(&quot;Pivot Point: &quot; + pivotPoint);
        grid.stream().forEach(System.out::println);
    }
    
    private static int findPivotPoint(List&lt;List&lt;String&gt;&gt; grid, String key) {
        for (List&lt;String&gt; list : grid) {
            OptionalInt indexOpt = IntStream.range(0, list.size())
             .filter(i -&gt; key.equals(list.get(i)))
             .findFirst();
            if (indexOpt.isPresent()) {
                return indexOpt.getAsInt();
            }
        }
        return -1;
    }
}

This prints out
Pivot Point: 2
[Test0, ABC, 123, A1]
[Test4, MNO, 234, A5]
[Test1, DEF, 345, A2]
[Test2, GHI, 678, A3]
[Test3, JKL, 901, A4]

If instead you pass &quot;foo&quot; as the key, the original list is printed out:
Pivot Point: -1
[Test0, ABC, 123, A1]
[Test3, JKL, 901, A4]
[Test1, DEF, 345, A2]
[Test4, MNO, 234, A5]
[Test2, GHI, 678, A3]

Just a clarifying note, the List&lt;List&lt;String&gt;&gt; has to be mutable since the contents of the list needs to be changed for sorting. However, since I did not intended to change any of the List&lt;String&gt;, I created those using List.of() to make them immutable. If you attempt to mutate these lists, an exception will be thrown.
"
73553976,Is it logical to get Wordpress article id with PHP API,"I have a custom wordpress php rest api. The API has 2 functions. The first function is returning all posts from the wordpress website. Second function is returning posts by slug.
I have developing mobile app for the website(blog website). I am getting datas for the app.
And I have some anxiety here. I am getting a lot of datas about articles and one of these is article Id.
The question: Is it logical to get wordpress article id with php api. I am asking for security.
1-The api is my custom api for get datas about article.
2-If I don't use the custom php api, I will use the mysql database for save the article informations. And I will get the article datas with php api. But I will set my own id for article(I won't use the wordpress article id).
Which one is the best way to use. Please think for security.
This is my custom PHP API function.
function api_posts()
{
    $args = [
        'numberposts' =&gt; 99999,
        'post_type' =&gt; 'post',
    ];

    $posts = get_posts($args);

    $data = [];
    $i = 0;

    foreach ($posts as $post) {
        $category = get_the_category( $post-&gt;ID )[0]-&gt;name;
        $data[$i]['category'] = $category;
        $data[$i]['id'] = $post-&gt;ID;
        $data[$i]['title'] = $post-&gt;post_title;
        $data[$i]['excerpt'] = $post-&gt;post_excerpt;
        $data[$i]['content'] = $post-&gt;post_content;
        $data[$i]['slug'] = $post-&gt;post_name;
       // $data[$i]['featured_image']['thumbnail'] = get_the_post_thumbnail_url($post-&gt;ID, 'thumbnail');
        $data[$i]['thumbnailImage'] = get_the_post_thumbnail_url($post-&gt;ID, 'thumbnail');
        $data[$i]['mediumImage'] = get_the_post_thumbnail_url($post-&gt;ID, 'medium');
        $data[$i]['largeImage'] = get_the_post_thumbnail_url($post-&gt;ID, 'large');
        setlocale(LC_TIME, array('tr_TR.UTF-8','tr_TR.UTF-8','tr_TR.UTF-8','tr_TR.UTF-8'));//tarihi esas alan locali seÃ§er
        $gelen_date = $post-&gt;post_date;
        $data[$i]['date'] = strftime(&quot;%e %B %Y&quot;,strtotime($gelen_date));
        $data[$i]['post_url'] = get_permalink($post-&gt;ID);
        $i++;
    }

    return $data;
}

add_action('rest_api_init', function () {
    register_rest_route('api/v1', 'posts', [
        'methods' =&gt; 'GET',
        'callback' =&gt; 'api_posts',

    ]);

    register_rest_route('api/v1', 'posts/(?P&lt;slug&gt;[a-zA-Z0-9-]+)', array(
        'methods' =&gt; 'GET',
        'callback' =&gt; 'api_post',
    ));
});

Footnote: The website is not ready to publish. I am using free wordpress blog theme for the test. But I will use the jannah theme when I publish my website.
","php, wordpress, api",1,73554224,"Post ID values are visible to visitors to a WordPress site. (They show up in places like HTML element classes. Do View Source on a page showing posts and you'll see this.)
So if your reason for using an alternative ID is to avoid disclosing post ID values (maybe for security reasons) don't bother. They are already available.
Plus, if you use an alternative ID you'll probably need to store it as a post attribute in wp_postmeta in your database. That is, putting it mildly, not the best-performing part of WordPress.
"
74612337,MongoDB sum returning always 0,"I am new in Mongodb and IÂ´m trying to create a query which print all the combinations of points that were assigned to the accommodations and sort them by the number of accommodations that received these points. However when I execute this query, the $sum is always returning 0 despite the 3 fields are numeric values:
db.test.aggregate([
  {$addFields: {sumPoints: **{$sum: [&quot;$lodging.reviews.cleanliness&quot;, &quot;lodging.reviews.location&quot;, &quot;lodging.reviews.food&quot;]}**}},
  {$group: {
    _id: &quot;$sumPoints&quot;,
    count: {$sum: 1}
  }},
  {$sort: {count: 1}},
  {$project: {_id: 0, count: 1, sumPoints: &quot;$_id&quot;}}
  ])

In the photo I show a document example.
Document example
Does anyone know what can be the problem?
I tried with that query and the result is just:
{ count: 5984, sumPoints: 0 }
because sumPoints is always returning 0.
","mongodb, nosql, document",0,74614149,"I think there are two problems. The first is that you are missing the dollar sign (to indicate that you want to access the fields) for the second and third items. But on top of that, it seems that $sum might not be able to add from different values in the array by itself? Summing sums seems to have worked:
  {
    &quot;$addFields&quot;: {
      &quot;sumPoints&quot;: {
        $sum: [
          {
            $sum: [
              &quot;$lodging.reviews.cleanliness&quot;
            ]
          },
          {
            $sum: [
              &quot;$lodging.reviews.location&quot;
            ]
          },
          {
            $sum: [
              &quot;$lodging.reviews.food&quot;
            ]
          }
        ]
      }
    }
  }

Playground example here
Alternatively, you can use the $reduce operator here:
  {
    &quot;$addFields&quot;: {
      &quot;sumPoints&quot;: {
        &quot;$reduce&quot;: {
          &quot;input&quot;: &quot;$lodging.reviews&quot;,
          &quot;initialValue&quot;: 0,
          &quot;in&quot;: {
            $sum: [
              &quot;$$value&quot;,
              &quot;$$this.cleanliness&quot;,
              &quot;$$this.location&quot;,
              &quot;$$this.food&quot;
            ]
          }
        }
      }
    }
  }

Playground example here
In the future please also provide the text for your sample documents (or, better yet, a playground example directly) so that it is easier to assist.
"
73196092,Can't upload image to firebase storage VueJs,"I am creating a site for my store and learning Vue js simultaneously. I'm stuck in the part regarding uploading a product image to firebase. I get that storageRef.put is not a function. I'm using Vue js 3 and firebase 9.
uploadImage(e) {
      const file = e.target.files[0];
      const storage = getStorage();
      const storageRef = storageReference(storage, 'products/' + file.name);
      storageRef.put(file);
    }

","javascript, firebase, vue.js",1,73196258,"This syntax you provide is for firebase version 8.
For version 9
import { getStorage, ref, uploadBytes } from &quot;firebase/storage&quot;;


uploadImage(e) {
  const file = e.target.files[0];
  const storage = getStorage();

  // Create a reference to 'mountains.jpg'
  const storageRef = ref(storage, 'products/' + file.name);

  uploadBytes(storageRef, file).then((snapshot) =&gt; {
    console.log('Uploaded!');
  });
}

For more resources.
https://firebase.google.com/docs/storage/web/upload-files#web-version-9
"
74227793,ImageSharp RecolorBrush not available anymore?,"I'm using ImageSharp version 2.1.3 in a .NET 6 project. Now the API which I can use seems to be different from what is shown in the official documentation. For instance the docs are pointing to a namespace SixLabors.ImageSharp.Drawing which is not part of the NuGet package I received.
One thing I cannot find is the RecolorBrush documented here. It allows me to replace a color with another one like this:
using SixLabors.ImageSharp;
using SixLabors.ImageSharp.Drawing;
using SixLabors.ImageSharp.Drawing.Processing;

using (var image = Image.Load('file.png'))
{
    var brush = new RecolorBrush(Color.White, Color.Transparent, 0.2F);
    image.Mutate(ctx =&gt; ctx.Fill(brush));
    image.Save('transparent.png');
}

Several things are now not working:

RecolorBrush is not a thing in my Nuget.
ctx.Fill seems to be no longer available.

So am I missing a package, is this a breaking change and if yes what is the new way to do it and where can I find some official info on this?
","c#, .net-6.0, imagesharp",0,74960231,
74076957,Is there a way to check a radius around a random point in order for random points to be separate from each other,"I'm currently creating a drawing project, where I use random to create random star points in the sky. I currently have the ability for two points to not be the same, but I would like to find a way to make it so they wouldn't land in a x radius circle. Is there any way in python to complete this
import turtle as t, random as r
screen=t.Screen()
screen.bgcolor(&quot;#3A3B3C&quot;)
t.speed(1)


def randomStars(y, num):
  t.penup()
  t.pensize(2)
  t.color(&quot;white&quot;)
  locations = []
  
  for x in range(num):
    repeat = True
    t.penup()
    t.seth(90)
    y_pos = starLocationY(y)
    x = starLocationX()
    while repeat == True:
      if [x,y_pos] in locations:
          y_pos = starLocationY(y)
          x = starLocationX()
      else:
        locations.append([x,y_pos])
        repeat = False
    t.goto(x,y_pos)
    t.pendown()
    t.seth(60)
    t.fd(2)
    t.fd(-2)
    t.seth(-60)
    t.fd(2)
    t.fd(-2)
    t.seth(240)
    t.fd(2)
    t.fd(-2)
    t.seth(120)
    t.fd(2)
    t.fd(-2)

randomStars(85,30)

p.s: I'm using trinket for the project, as required by the class, so the modules are limited
link to trinket:https://trinket.io/python/9776ba1b8a
","python, random, turtle-graphics, python-turtle",1,74082456,"We can use any on a generator invoking turtle's distance() method on the elements of your locations list.  Easier than it sounds:
from turtle import Screen, Turtle
from random import randint

EXCLUSION_RADIUS = 35 # in pixels

def starLocationY(y):
    return randint(y, 190)

def starLocationX():
    return randint(-190, 190)

def randomStars(y, number):
    turtle.penup()
    turtle.pensize(2)
    turtle.color('white')
    locations = []

    for _ in range(number):
        y_pos = starLocationY(y)
        x = starLocationX()

        while True:
            turtle.goto(x, y_pos)

            if any(turtle.distance(location) &lt; EXCLUSION_RADIUS for location in locations):
                y_pos = starLocationY(y)
                x = starLocationX()
            else:
                locations.append((x, y_pos))
                break

        turtle.pendown()

        for heading in range(0, 360, 120):
            turtle.setheading(heading)
            turtle.forward(2)
            turtle.backward(4)
            turtle.forward(2)

        turtle.penup()

screen = Screen()
screen.bgcolor('#3A3B3C')

turtle = Turtle()
turtle.hideturtle()
turtle.speed('fastest')  # because I have no patience

randomStars(85, 20)

screen.exitonclick()

"
73682305,How to debug missing functions in vtable of base class,"By using objects of the following structure(some bits simplified):
  class RafkoAgent{
    virtual std::vector&lt;double&gt; solve(std::vector&lt;double&gt;&amp; in) = 0;
    void solve(std::vector&lt;double&gt;&amp; in, std::vector&lt;double&gt;&amp; out){
      out = solve(in);
    }
  };

  class SolutionSolver : public RafkoAgent {
    std::vector&lt;double&gt; solve(std::vector&lt;double&gt;&amp; in){ /* ... */}
  };

In some cases a segfault is being thrown.
In my understanding, this structure should be adequate, but in the example I tried it in(here), it throws a segfault and I can't seem to get to the bottom of it.
In the code, when I check the vtable of the 2 symbols I find the following difference:
150   solver-&gt;solve({1.0, 2.0});
(gdb) info vtbl solver
This object does not have a virtual function table
(gdb) info vtbl *solver
vtable for 'rafko_net::SolutionSolver' @ 0x555555692bf0 (subobject @ 0x5555556ad710):
[0]: 0x55555559ff42 &lt;rafko_gym::RafkoAgent::get_step_sources[abi:cxx11]() const&gt;
[1]: 0x5555555a016c &lt;rafko_gym::RafkoAgent::[abi:cxx11]() const&gt;
[2]: 0x5555555a030a &lt;rafko_gym::RafkoAgent::get_input_shapes() const&gt;
[3]: 0x5555555a0502 &lt;rafko_gym::RafkoAgent::get_output_shapes() const&gt;
[4]: 0x5555555a074a &lt;rafko_gym::RafkoAgent::get_solution_space() const&gt;
[5]: 0x5555555a4c8e &lt;rafko_net::SolutionSolver::~SolutionSolver()&gt;
[6]: 0x5555555a4cdc &lt;rafko_net::SolutionSolver::~SolutionSolver()&gt;
[7]: 0x5555555a0a80 &lt;rafko_net::SolutionSolver::set_eval_mode(bool)&gt;
[8]: 0x55555559e42a &lt;rafko_net::SolutionSolver::solve(std::vector&lt;double, std::allocator&lt;double&gt; &gt; const&amp;, rafko_utilities::DataRingbuffer&lt;std::vector&lt;double, std::allocator&lt;double&gt; &gt; &gt;&amp;, std::vector&lt;std::reference_wrapper&lt;std::vector&lt;double, std::allocator&lt;double&gt; &gt; &gt;, std::allocator&lt;std::reference_wrapper&lt;std::vector&lt;double, std::allocator&lt;double&gt; &gt; &gt; &gt; &gt; const&amp;, unsigned int, unsigned int) const&gt;
(gdb) info vtbl *(rafko_gym::RafkoAgent*)solver
vtable for 'rafko_gym::RafkoAgent' @ 0x555555692bf0 (subobject @ 0x5555556ad710):
[0]: 0x55555559ff42 &lt;rafko_gym::RafkoAgent::get_step_sources[abi:cxx11]() const&gt;
[1]: 0x5555555a016c &lt;rafko_gym::RafkoAgent::get_step_names[abi:cxx11]() const&gt;


Which suggest to me that something is not quite right with the vtable for RafkoAgent. The actual segfault is thrown when it tries to access its virtual function, and instead of solve, gdb seem to step into get_step_names, which is at the end of RafkoAgent's displayed vtable.
An additional detail is that the whole project is a static library + tests. When I run the same code inside the CMake project of the library ( i.e.: where RafkoAgent and SolutionSolver is) the segfault does not occur. It does occur however in the linked example file, where I link the classes from a generated static library file (librafko.a)
The focus of the question is:
Is it by design for a base class to not contain its defined virtual functions in its own vtable, only the derived class? even if the derived class does not introduce additional virtual functions?
If what I'm seeing is faulty how might I be able to debug the root cause of this error?
","c++, c++17, static-libraries, virtual-functions, vtable",0,73814247,"The root cause of the problem was that there were compilation macros used in the exported header files.
The main hint for this was that in the same repository it worked flawlessly, but it failed by the exported library.
The faulty structure was as follows:
class A {};

class B 
#if(compile_time_macro)
: public A
#endif
{};

So essentially the library object was built as if the inheritance was included, but since the exported headers did not contain the macro definition, the inheritance was not present there.
This resulted in a very hardly traceable problem.
Whenever you use macros BEWARE.
"
74136704,Replace value in DataFrame when value not empty,"I want to replace the values from a DataFrame column with values from a List.
How do I replace them only when the value in the list is not an empty string ?
Both are ordered the same way :
    Dataframe                  List

ID     Date                  UpdatedDate
1      19/04/2022            20/10/2022
2      12/07/2022                  
3      27/09/2022            03/10/2022
4      11/05/2022            14/10/2022
5      04/10/2022                  
6      02/08/2022            19/10/2022

I want this to become a single dataframe with the updated dates.
ID     Date
1      20/10/2022
2      12/07/2022                  
3      03/10/2022
4      14/10/2022
5      04/10/2022                  
6      19/10/2022

Any suggestions? Much appreciated.
","python, pandas, dataframe",0,74136785,"Assuming you list is a list that looks like this:
lst = ['20/10/2022', '', '03/10/2022', '14/10/2022', '', '19/10/2022']
You can add that to your df as a new column like this:
df['lst'] = lst

         Date         lst
0  19/04/2022  20/10/2022
1  12/07/2022            
2  27/09/2022  03/10/2022
3  11/05/2022  14/10/2022
4  04/10/2022            
5  02/08/2022  19/10/2022

you can then use .replace() on the lst column to replace the empty strings with np.nan (may need to add import numpy as np for this). Then use .fillna() to fill in the gaps in lst with Date:
df['Date'] = df['lst'].replace('', np.nan).fillna(df['Date'])

         Date         lst
0  20/10/2022  20/10/2022
1  12/07/2022            
2  03/10/2022  03/10/2022
3  14/10/2022  14/10/2022
4  04/10/2022            
5  19/10/2022  19/10/2022

Then drop the 'lst' column to get the final df:
df = df.drop('lst', axis=1)

         Date
0  20/10/2022
1  12/07/2022
2  03/10/2022
3  14/10/2022
4  04/10/2022
5  19/10/2022

"
73867414,Correct way to get a gRPC client to communicate with one of many ECS instances of the gRPC service?,"I have a gRPC client, not dockerised, and server application, which I want to dockerise.
What I don't understand is that gRPC first creates a connection with a server, which involves a handshake. So, if I want to deploy the dockerised server on ECS with multiple instances, then how will the client switch from one to the other (e.g., if one gRPC server falls over).
I know AWS loadbalancer now works with HTTP 2, but I can't find information on how to handle the fact that the server might change after the client has already opened a connection to another one.
What is involved?
","grpc, amazon-ecs",0,73953968,"You don't necessarily need an in-line load balancer for this. By using a Round Robin client-side load balancing policy along with a DNS record that points to multiple backend instances, you should be able to get some level of redundancy.
"
72971634,How to add background to image in react native?,"I added a picture and I want to add a background to the image in a fixed size.
import React, {useState} from 'react';

import { Alert, View, Image, StyleSheet , Text , Button, ImageBackground} from 'react-native'

function Test1(props) {

    return (
        &lt;View style={styles.container}&gt;
            &lt;View style={styles.container2}&gt;
            &lt;ImageBackground source={require('../assets/plus.jpeg')} resizeMode=&quot;cover&quot; style={styles.image4}&gt;
               
            &lt;/ImageBackground&gt;  
            &lt;/View&gt;
        &lt;/View&gt;
        
    );
}

export default Test1;

const styles = StyleSheet.create({
    image4:{
        //  flex: 1,
          justifyContent: &quot;center&quot;,
          width: 100,
          height: 100,
  },
    text4: {
        color: &quot;white&quot;,
        fontSize: 42,
        lineHeight: 84,
        fontWeight: &quot;bold&quot;,
        textAlign: &quot;center&quot;,
        backgroundColor: &quot;#000000c0&quot;
      },
    container2: {
        flex: 1,
    },
  
    container: {
        flex: 1,
        backgroundColor: '#a9a9a9',
        flexDirection:'column',
        alignItems:'center',
        paddingTop: 100,
      }
    

})

This is the result that I want ( +- )

I want to add another black square to the image ( the default background is gray )
In my case the default image is with white background( and not green but it is not matter )  I want to add another black square to the image

",react-native,0,72972450,"If you want something like Create New, you can do like this.
You need to add height and width in ImageBackground. You cannot use flex:1 as it wont work.
    &lt;TouchableOpacity&gt;
     &lt;ImageBackground source={YOUR SOURCE} style={{width:100,height:100,alignItems:'center', justifyContent:'center', flexDirection:'column'}}&gt;
     &lt;Image source={YOUR OTHER SOURCE} style={{width:30,height:30}} /&gt;
     &lt;Text&gt;Send&lt;/Text&gt;
    &lt;/ImageBackground&gt;
    &lt;/TouchableOpacity&gt;

"
73165456,ClojureDart: How to pass data to parent state widget?,"I have a Scaffold parent widget where I defined a variable transforms that contains a vector of Offset.
The child widget is supposed to display those points with CustomPainter.
For now, I just passed my variable transforms as an argument to the child widget.
The problem is, I want to add an element to my vector each time we pressed the floatingActionButton, which is written in my parent widget ; and when I click on it, it does not appear on the screen (the child doesn't get the information).
So how to make widgets communicate?
","flutter, clojure",2,73165457,"The answer is pretty simple.
The way for a widget to inherit informations from another, is to used the f/widget function and the :inherit keyword. Example:
(f/widget
:inherit [m/Theme]
)

In order to inherit from the Theme widget and its internal state data.
But that is not it, in the parent widget you want to make your data available/sharable, you have to define your data in the :bind map.
Example:
(def child
  (f/widget
    :inherit [:transforms]
;; don't forget to dereference it when you want to use it
;; (dart:core/print @transforms)
...))

(def parent
  (f/widget
    :bind {:transforms [(m/Offset 0 0) (m/Offset 1 0)]}
...))


"
72988901,AddEventListener is not working for one element,"AddEventListener is working fine for the first function but not triggering the second one, not even showing in the console.log. Please see where I'm going wrong?
    &lt;ul id=&quot;nv&quot;&gt;
      &lt;li class=&quot;nvItem&quot;&gt;&lt;a href=&quot;#&quot;&gt;Home&lt;/a&gt;&lt;/li&gt;
      &lt;li class=&quot;nvItem&quot;&gt;&lt;a href=&quot;#the-story&quot;&gt;Story&lt;/a&gt;&lt;/li&gt;
      &lt;li class=&quot;nvItem&quot;&gt;&lt;a href=&quot;#comic-book&quot;&gt;Comic&lt;/a&gt;&lt;/li&gt;
      &lt;li class=&quot;nvItem&quot;&gt;&lt;a href=&quot;#creatures&quot;&gt;Creatures&lt;/a&gt;&lt;/li&gt;
      &lt;li class=&quot;nvItem&quot;&gt;&lt;a href=&quot;#the-path&quot;&gt;Path&lt;/a&gt;&lt;/li&gt;
      &lt;li class=&quot;nvItem&quot;&gt;&lt;a href=&quot;#artists&quot;&gt;Nikal&lt;/a&gt;&lt;/li&gt;                      
    &lt;/ul&gt;

Please ignore the id mn
const navigation = document.getElementById(&quot;nv&quot;);
const menu = document.getElementById(&quot;mn&quot;);
const navItems = document.getElementsByClassName(&quot;nvItem&quot;)

menu.addEventListener(&quot;click&quot;, () =&gt; {
  navigation.style.setProperty(&quot;--childenNumber&quot;, navigation.children.length);

  navigation.classList.toggle(&quot;active&quot;);
  menu.classList.toggle(&quot;active&quot;);
  console.log(&quot;---Active---&quot;);
});

navItems.addEventListener(&quot;click&quot;, () =&gt; {
    navigation.classList.toggle(&quot;nonActive&quot;);
    menu.classList.toggle(&quot;nonActive&quot;);
    console.log(&quot;---Deactive---&quot;);
  });
  

","javascript, addeventlistener",-2,72988962,"You should take some time and read this about event listeners:
https://developer.mozilla.org/en-US/docs/Web/API/EventTarget/addEventListener
They can not be attached to NodeLists
https://developer.mozilla.org/en-US/docs/Web/API/NodeList
We can get around this by looping through the Nodes and applying an EventListener to each node.
Because you have  tags you may have some side effects. I would recommend pointer-events: none or some other kind of prevention on the  to stop default behavior.


const navigation = document.getElementById(""nv"");
const menu = document.getElementById(""mn"");
const navItems = document.getElementsByClassName(""nvItem"")

menu.addEventListener(""click"", () =&gt; {
  navigation.style.setProperty(""--childenNumber"", navigation.children.length);

  navigation.classList.toggle(""active"");
  menu.classList.toggle(""active"");
  console.log(""---Active---"");
});

Array.from(navItems).forEach(item =&gt; {
  item.addEventListener(""click"", e =&gt; {
    navigation.classList.toggle(""nonActive"");
    menu.classList.toggle(""nonActive"");
    console.log(""---Deactive---"");
  });
});
&lt;div id=""mn""&gt;
  menu
&lt;/div&gt;
&lt;ul id=""nv""&gt;
  &lt;li class=""nvItem""&gt;&lt;a href=""#""&gt;Home&lt;/a&gt;&lt;/li&gt;
  &lt;li class=""nvItem""&gt;&lt;a href=""#the-story""&gt;Story&lt;/a&gt;&lt;/li&gt;
  &lt;li class=""nvItem""&gt;&lt;a href=""#comic-book""&gt;Comic&lt;/a&gt;&lt;/li&gt;
  &lt;li class=""nvItem""&gt;&lt;a href=""#creatures""&gt;Creatures&lt;/a&gt;&lt;/li&gt;
  &lt;li class=""nvItem""&gt;&lt;a href=""#the-path""&gt;Path&lt;/a&gt;&lt;/li&gt;
  &lt;li class=""nvItem""&gt;&lt;a href=""#artists""&gt;Jozef&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;



"
73635965,How do I return a value from a function triggered by Timer,"I have created a timer to trigger the function timerFire, every 5 seconds accepting the Double howHungry from another swift file.
The timer takes the value of howHungry and reduces it by 1 every time the timer fires and returns the new value.
Once the new value of howHungry is returned how can i retrieve the new value of howHungry to file1.swift?
As the original value is not being reduced the same value is sent each time
Console is currently showing:
Hunger value is 14.0
Hunger value is 14.0
Hunger value is 14.0

file1.swift
    let hungerTimer = myTimer()

    hungerTimer.startTimer(timerInitialValue: howHungry)

file2.swift
    func startTimer(timerInitialValue:Double){
    
        if timer == nil{ //Create a new timer for hunger if one doesn't exist
            timer = Timer.scheduledTimer(timeInterval: 2, target: self, selector: #selector(timerFire(sender:)), userInfo: timerInitialValue/*how hungry*/, repeats: true)
            print(&quot;New Timer Started&quot;)

        }else{ //If a timer does exist, end it and start a new one.

            timer!.invalidate()
            timer = nil
            print(&quot;Old Timer Stopped&quot;)
            timer = Timer.scheduledTimer(timeInterval: 2, target: self, selector: #selector(timerFire(sender:)), userInfo: timerInitialValue, repeats: true)
            print (&quot;Now New Timer Started&quot;)
            print(timer)
        }
}

   @objc func timerFire(sender: Timer) -&gt; Double{
        //get hungryDouble value from Timer       
        var hungryDouble = sender.userInfo as! Double
        //Reduce it by 1
        hungryDouble -= 1.0
        print(&quot;Hunger value is \(hungryDouble)&quot;)
        return(hungryDouble)
}

",swift,0,73636018,"You can add a callback inside file2.swift
var callback:((Double)-&gt;())?

@objc func timerFire(sender: Timer){
   //get hungryDouble value from Timer       
   var hungryDouble = sender.userInfo as! Double
   //Reduce it by 1
   hungryDouble -= 1.0
   print(&quot;Hunger value is \(hungryDouble)&quot;)
   callback?(hungryDouble)
} 

And inside file1.swift
let hungerTimer = myTimer()
hungerTimer.startTimer(timerInitialValue: howHungry)
hungerTimer.callback = { [weak self] res in
   print(res)
} 

"
73738035,Break array into childs from the same key using explode,"this is my array now but I don't want like this
array:36 [â–¼
  &quot;pentrose_50_rafhan_c_kgs&quot; =&gt; 100
  &quot;pentrose_50_rafhan_c_issued_kgs&quot; =&gt; 300
  &quot;pentrose_50_rafhan_c_rskg&quot; =&gt; 99.1
  &quot;pentrose_50_rafhan_c_amount&quot; =&gt; 29730
  
]

This is my code:
foreach (array_combine($result, $filterred_chemical_keys) as $key =&gt; $chemical) {
    $arr = explode('_c_', $key);
    // dd($arr);
    $result[array_shift($arr)] = $arr;            
}

dd($result);

Please help to make array like this
array:36 [â–¼
    &quot;pentrose_50_rafhan&quot; =&gt; [
        &quot;kgs&quot; =&gt; 100
        &quot;issued_kgs&quot; =&gt; 300
        &quot;rskg&quot; =&gt; 99.1
        &quot;amount&quot; =&gt; 29730
    ]
]

I just explode via _c_ and make key parent and other keys as a child. I have tried many things like array_shift but nothing works for me.
Any help, please?
","php, arrays, laravel",0,73738215,"A method using collections instead of array_functions
Inspired by https://laravel.com/docs/9.x/helpers#method-array-prependkeyswith
$data = [
     &quot;pentrose_50_rafhan_c_kgs&quot; =&gt; 100,
     &quot;pentrose_50_rafhan_c_issued_kgs&quot; =&gt; 300,
     &quot;pentrose_50_rafhan_c_rskg&quot; =&gt; 99.1,
     &quot;pentrose_50_rafhan_c_amount&quot; =&gt; 29730,
];

collect($data)
    -&gt;groupBy(function($item, $key) {
        return Str::before($key, '_c_');
    }, preserveKeys: true)
    -&gt;map
    -&gt;mapWithKeys(function ($item, $key) {
        return [Str::after($key, '_c_')  =&gt; $item];
    })
    -&gt;toArray();

[
    &quot;pentrose_50_rafhan&quot; =&gt; [
        &quot;kgs&quot; =&gt; 100,
        &quot;issued_kgs&quot; =&gt; 300,
        &quot;rskg&quot; =&gt; 99.1,
        &quot;amount&quot; =&gt; 29730,
    ],
]

"
73032148,kubernetes: error: Unexpected args: [create],"Follow guide at https://operatorhub.io/operator/postgresql-operator-dev4devs-com (press button Install), on Windows 10 pro x64 . Error
Microsoft Windows [Version 10.0.19044.1826]
(c) Microsoft Corporation. All rights reserved.

C:\Users\Administrator&gt;curl -sL https://github.com/operator-framework/operator-lifecycle-manager/releases/download/v0.21.2/install.sh | bash -s v0.21.2
customresourcedefinition.apiextensions.k8s.io/catalogsources.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/clusterserviceversions.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/installplans.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/olmconfigs.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/operatorconditions.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/operatorgroups.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/operators.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/subscriptions.operators.coreos.com created
customresourcedefinition.apiextensions.k8s.io/catalogsources.operators.coreos.com condition met
customresourcedefinition.apiextensions.k8s.io/clusterserviceversions.operators.coreos.com condition met
customresourcedefinition.apiextensions.k8s.io/installplans.operators.coreos.com condition met
customresourcedefinition.apiextensions.k8s.io/olmconfigs.operators.coreos.com condition met
customresourcedefinition.apiextensions.k8s.io/operatorconditions.operators.coreos.com condition met
customresourcedefinition.apiextensions.k8s.io/operatorgroups.operators.coreos.com condition met
customresourcedefinition.apiextensions.k8s.io/operators.operators.coreos.com condition met
customresourcedefinition.apiextensions.k8s.io/subscriptions.operators.coreos.com condition met
namespace/olm created
namespace/operators created
serviceaccount/olm-operator-serviceaccount created
clusterrole.rbac.authorization.k8s.io/system:controller:operator-lifecycle-manager created
clusterrolebinding.rbac.authorization.k8s.io/olm-operator-binding-olm created
olmconfig.operators.coreos.com/cluster created
deployment.apps/olm-operator created
deployment.apps/catalog-operator created
clusterrole.rbac.authorization.k8s.io/aggregate-olm-edit created
clusterrole.rbac.authorization.k8s.io/aggregate-olm-view created
operatorgroup.operators.coreos.com/global-operators created
operatorgroup.operators.coreos.com/olm-operators created
clusterserviceversion.operators.coreos.com/packageserver created
catalogsource.operators.coreos.com/operatorhubio-catalog created
Waiting for deployment &quot;olm-operator&quot; rollout to finish: 0 of 1 updated replicas are available...
deployment &quot;olm-operator&quot; successfully rolled out
Waiting for deployment &quot;catalog-operator&quot; rollout to finish: 0 of 1 updated replicas are available...
deployment &quot;catalog-operator&quot; successfully rolled out
Package server phase: Installing
Package server phase: Succeeded
deployment &quot;packageserver&quot; successfully rolled out

C:\Users\Administrator&gt;kubectl create -f https://operatorhub.io/install/postgresql-operator-dev4devs-com.yamlkubectl create -f https://operatorhub.io/install/postgresql-operator-dev4devs-com.yaml
error: Unexpected args: [create]
See 'kubectl create -h' for help and examples

C:\Users\Administrator&gt;

error: Unexpected args: [create]

How to fix it?
","kubernetes, kubectl, docker-for-windows, docker-desktop",-2,73032236,"kubectl create -f 
https://operatorhub.io/install/postgresql-operator-dev4devs-com.yamlkubectl 
create -f 
https://operatorhub.io/install/postgresql-operator-dev4devs-com.yaml

duplicate create -f,
so you need use only create -f as:
kubectl create -f 
https://operatorhub.io/install/postgresql-operator-dev4devs-com.yaml 
https://operatorhub.io/install/postgresql-operator-dev4devs-com.yaml

"
73687017,How to get all keys whose values are null in Java 8 using Map,"I was going through How to remove a key from HashMap while iterating over it?, but my requirement is bit different.
class Main {
    public static void main(String[] args) {
        Map&lt;String, String&gt; hashMap = new HashMap&lt;&gt;();

        hashMap.put(&quot;RED&quot;, &quot;#FF0000&quot;);
        hashMap.put(&quot;BLACK&quot;, null);
        hashMap.put(&quot;BLUE&quot;, &quot;#0000FF&quot;);
        hashMap.put(&quot;GREEN&quot;, &quot;#008000&quot;);
        hashMap.put(&quot;WHITE&quot;, null);

        // I wan't result like below - get All keys whose value is null
        List&lt;String&gt; collect = hashMap.values()
                .stream()
                .filter(e -&gt; e == null)
                .collect(Collectors.toList());
        System.out.println(collect);
        
        // Result - BLACK, WHITE in list
    }
}

",java-8,1,73687178,"Try this:
import java.util.*;
import java.util.stream.*;
class Main {
    public static void main(String[] args) {
        Map&lt;String, String&gt; hashMap = new HashMap&lt;&gt;();

        hashMap.put(&quot;RED&quot;, &quot;#FF0000&quot;);
        hashMap.put(&quot;BLACK&quot;, null);
        hashMap.put(&quot;BLUE&quot;, &quot;#0000FF&quot;);
        hashMap.put(&quot;GREEN&quot;, &quot;#008000&quot;);
        hashMap.put(&quot;WHITE&quot;, null);

        // I wan't result like below - get All keys whose value is null
        List&lt;String&gt; collect = hashMap.keySet()
                .stream()
                .filter(e -&gt; Objects.isNull(hashMap.get(e)))
                .collect(Collectors.toList());
        System.out.println(collect);
        
        // Result - BLACK, WHITE in list
    }
}

As pointed out in the comments, you can try this as well:
import java.util.*;
import java.util.stream.*;
class Main {
    public static void main(String[] args) {
        Map&lt;String, String&gt; hashMap = new HashMap&lt;&gt;();

        hashMap.put(&quot;RED&quot;, &quot;#FF0000&quot;);
        hashMap.put(&quot;BLACK&quot;, null);
        hashMap.put(&quot;BLUE&quot;, &quot;#0000FF&quot;);
        hashMap.put(&quot;GREEN&quot;, &quot;#008000&quot;);
        hashMap.put(&quot;WHITE&quot;, null);

        // I wan't result like below - get All keys whose value is null
        List&lt;String&gt; collect = hashMap.entrySet()
                .stream()
                .filter(e -&gt; Objects.isNull(e.getValue()))
                .map(e -&gt; e.getKey())
                .collect(Collectors.toList());
        System.out.println(collect);
        
        // Result - BLACK, WHITE in list
    }
}

This is more optimized, as compared to the first solution.
"
73531936,Using svelte actions to manipulate an html element with d3,"this is somewhat related to my previous post where I learned a bit more about actions.
I have been trying to figure out how to work with this nifty feature but I seem to be a bit stuck in the past few hours.
In my Component I create an SVG viewbox like so:
&lt;svg id=&quot;pitch&quot; viewBox={`0 0 ${width} ${height}`} use:foo&gt;

    &lt;/svg&gt;

then drawPitch is this function:
function foo(node) {
        // the node has been mounted in the DOM
        let g = node.append('h1');
        g.text(&quot;This is the text I'd like to render to check that it works&quot;);
        return {
            destroy() {
                // the node has been removed from the DOM
            }
        };
    }

From what I've understood in the docs, the use:foo will pass the calling node to foo, so I thought directly appending svg elements to it should work.
Do I need to update it somehow?
Here is a repl with reproducible code.
I get the following error:

Missing &quot;./types/runtime/internal/keyed_each.js&quot; export in &quot;svelte&quot; package

Thank you!
","d3.js, svelte, sveltekit",0,73531996,"I would expect the code in foo to start with d3.select(node), and everything to work based off that. Otherwise the DOM tree generated by d3 will not be connected to your document at all. Alternatively the resulting element (selection.node()) has to be appended to node at some point.
The error sounds highly unrelated and probably would require more context.
Note: You cannot add HTML directly to SVGs, SVGs are for canvas-like vector graphics, not document layouts. If you want to insert text, use the &lt;text&gt; element.
"
73158541,infinite value while using cumulative constraint,"I am stuck with a cumulative constraint I seem not to use properly, I seek for help ! :)
I have tasks with precedence and, for some of them, required &amp; forbidden resources.
I need to decide when to start a task &amp; who to assign to it.
To do so, I'm using an array of decision variable resource_allocation:
array[Tasks, Resources] of var 0..1: resource_allocation; %Selection of resources per task.

To manage the required/forbidden resources, I used the following:
% Mandatory &amp; Forbidden constraint allocation
constraint forall(t in Tasks, r in resource_required[t])(resource_allocation[t,r]=1);
constraint forall(t in Tasks, r in resource_forbidden[t])(resource_allocation[t,r]=0);

resource_required being set of int storing the resources number that are required/forbidden.
Each resource represents 1 worker, and each worker can only perform one task at a time, so I am trying to state that, for every resources, the cumsum of allocation can at max be 1.
It might be important to note that start is also a decision variable.
 % Constraint allocated to only one task at a time
    constraint forall(t in Resources)(
        cumulative(start, duration, [resource_allocation[t, r] | t in Tasks], 1)
    );

Doing so, I always end up with the following error
JC:70.12-82
  in call 'cumulative'
cumulative:21-3.49-7
  in binary '/\' operator expression
cumulative:25-3.49-7
  in if-then-else expression
cumulative:26-5.48-9
  in binary '/\' operator expression
cumulative:30-5.48-9
  in if-then-else expression
cumulative:47.7-32
  in call 'fzn_cumulative'
fzn_cumulative:4-9.20-17
  in let expression
fzn_cumulative:8-13.20-17
  in if-then-else expression
fzn_cumulative:10-17.19-17
  in let expression
fzn_cumulative:12.21-74
  in variable declaration for 'late'
  in call 'max'
    with i = &lt;expression&gt;
MiniZinc: evaluation error: arithmetic operation on infinite value
Process finished with non-zero exit code 1.

I need a little guidance, I looked in the source code of fzn_cumulative, but I don't get what is going on.
Thanks !
",minizinc,0,73159013,"You might consider to limit the domains of your decisions variables.
int is unlimited (disregarding the limited number of bits per int) and may lead to overflow situations or complaints about infinite values.
include &quot;globals.mzn&quot;;
set of int: Tasks = 1..3;
set of int: Resources = 1..3;
set of int: Durations = 1..10;
set of int: Times = 1..1000;

% Use this editor as a MiniZinc scratch book
array[Tasks, Resources] of var 0..1: resource_allocation; %Selection of resources per task.
array [Tasks] of var Times: start;
array [Tasks] of var Durations: duration;
array [Tasks] of set of Resources: resource_required = [{1,2},{2,3},{3}];
array [Tasks] of set of Resources: resource_forbidden = [{},{1},{1}];

% Mandatory &amp; Forbidden constraint allocation
constraint forall(t in Tasks, r in resource_required[t])(resource_allocation[t,r]=1);
constraint forall(t in Tasks, r in resource_forbidden[t])(resource_allocation[t,r]=0);

% Constraint allocated to only one task at a time
% Changed &quot;t in Resources&quot; to &quot;r in Resources&quot;
    constraint forall(r in Resources)( 
        cumulative(start, duration, [resource_allocation[t, r] | t in Tasks], 1)
    );
    

"
74588596,ETL / ELT pipelines - Metainformation about the pipeline,"how do you add metainformation about the used ETL / ELT code (and version of this ELT code) to the produced sink files / tables?
Do u consider it as required to have information like &quot;PipelineID&quot; or &quot;DataProductionTime&quot; in the targetfolder?
","azure, azure-data-factory, etl, data-warehouse, data-lakehouse",0,74597157,"
how do you add metainformation about the used ETL / ELT code (and version of this ELT code) to the produced sink files / tables?

You can do it using the pipeline dynamic content and additional column in copy activity.
This is my source file:

In source of copy activity use additional column.

In ADF you can find meta information about the pipeline in System variables of dynamic content.

Target file in sink folder:


Do u consider it as required to have information like &quot;PipelineID&quot; or &quot;DataProductionTime&quot; in the targetfolder?

All this depends on your requirement like if you want to know by which pipeline you are getting data you can use this.
"
73538666,"Print a placeholder in bold within a sentence, using tags. AttributeError: 'str' object has no attribute 'tag_config'","If I select City in the combobox, I would like to print London placeholder in bold. London only in bold, the rest of the sentence not in bold. I've never used tags, so I'm having a hard time, sorry for my difficulty. I would like to obtain:
LONDON Phrase1, Phrase2, Phrase3.
I get the error: AttributeError: 'str' object has no attribute 'tag_config'
How to solve? I would like to try to maintain this code structure, or at least a similar structure.
from tkinter import ttk
import tkinter as tk
from tkinter import *

root = tk.Tk()
root.geometry(&quot;300x200&quot;)

combobox=ttk.Combobox(root, width = 16)
combobox.place(x=15, y=10)
combobox['value'] = [&quot;City&quot;, &quot;Other&quot;]


textbox = tk.Text(root,width=20,height=4)
textbox.place(x=15, y=50)

def function1():
    if combobox.get() == &quot;City&quot;:
        city = &quot;London&quot; #city = diz[sel_city][&quot;City&quot;]
        city_start = city.upper()
        city_start.tag_config(font=(&quot;Verdana&quot;, 14, 'bold'))


    def function2():
        text =  f&quot;{city_start} Phrase1, Phrase2, Phrase3&quot;
                
        textbox.delete(1.0,END)     
        textbox.insert(tk.END, text) #.format(allenat_random=allenat_random, variable_random=variable_random))

    function2()


Button = Button(root, text=&quot;Print&quot;, command=function1)
Button.pack()
Button.place(x=15, y=130)
 
root.mainloop()

","python, python-3.x, string, tkinter",-2,73550724,"Note that .tag_config() should be called on instance of Text widget, i.e. textbox in your case.  Also the first argument of .tag_config() should be a tag name.
Then .tag_add() should be used to apply the configured effect on the text.
Below is the modified function1():
def function1():
    if combobox.get() == &quot;City&quot;:
        city = &quot;London&quot; #city = diz[sel_city][&quot;City&quot;]
        city_start = city.upper()
        textbox.tag_config('city', font=(&quot;Verdana&quot;, 14, 'bold')) ### added tag argument


    def function2():
        text =  f&quot;{city_start} Phrase1, Phrase2, Phrase3&quot;

        textbox.delete(1.0,END)
        textbox.insert(tk.END, text) #.format(allenat_random=allenat_random, variable_random=variable_random))

        ### search city_start
        idx = textbox.search(city_start, 1.0)
        ### apply effect on city_start
        textbox.tag_add('city', idx, f'{idx}+{len(city_start)}c')

    function2()

And the result:

"
72828351,"Not able to perform operations on resulting dataframe after ""join"" operation in PySpark","df=spark.read.csv('data.csv',header=True,inferSchema=True)
rule_df=spark.read.csv('job_rules.csv',header=True)
query_df=spark.read.csv('rules.csv',header=True)

join_df=rule_df.join(query_df,rule_df.Rule==query_df.Rule,&quot;inner&quot;).drop(rule_df.Rule).show()
print(join_df.collect().columns)

Here I have created three dataframes: df,rule_df and query_df. I've performed inner join on rule_df and query_df, and stored the resulting dataframe in join_df. However, when I try to simply print the columns of the join_df dataframe, I get the following error-
AttributeError: 'NoneType' object has no attribute 'columns' 

The resultant dataframe is not behaving as one, I'm not able to perform any dataframe operations on it.
I'm guessing this error occurs when you're trying to call an object that doesn't exist, but it shouldn't be the case here as I'm able to view the resultant join_df.
Do I need to perform a different join in order to avoid this error? Might be a silly mistake, but I'm stumped trying to figure out what it is. Please help!
","python, dataframe, pyspark, apache-spark-sql, data-profiling",1,72828419,"You are doing several mistakes.
First of all you try to assign the return value of .show() to join_df which returns None.
Then you are calling the .collect() function which returns a list that contains all of the elements in this RDD. You need to call .columns directly on the DataFrame.
This should work:
join_df = rule_df.join(query_df,rule_df.Rule==query_df.Rule,&quot;inner&quot;).drop(rule_df.Rule)
print(join_df.columns)

"
73657033,Does Mapbox geocoding API support intersections outside US?,"According to the Mapbox geocoding API docs, it supports searching for intersections of two roads through the following API call:
https://api.mapbox.com/geocoding/v5/{endpoint}/{street_1}%20and%20{street_2}.json

The example listed in the docs (Market Street / Fremont Street, San Francisco) works:
$ curl &quot;https://api.mapbox.com/geocoding/v5/mapbox.places/Market%20Street%20and%20Fremont%20Street.json?types=address&amp;proximity=-122.39738575285674,37.7925147111369453&amp;access_token=[TOKEN]&quot;

{
  &quot;type&quot;: &quot;FeatureCollection&quot;,
  &quot;query&quot;: [
    &quot;market&quot;,
    &quot;street&quot;,
    &quot;and&quot;,
    &quot;fremont&quot;,
    &quot;street&quot;
  ],
  &quot;features&quot;: [
    {
      &quot;id&quot;: &quot;address.826558382307746&quot;,
      &quot;type&quot;: &quot;Feature&quot;,
      &quot;place_type&quot;: [
        &quot;address&quot;
      ],
      &quot;relevance&quot;: 1,
      &quot;properties&quot;: {
        &quot;accuracy&quot;: &quot;intersection&quot;
      },
      &quot;text&quot;: &quot;Fremont Street&quot;,
      &quot;place_name&quot;: &quot;Market Street and Fremont Street, San Francisco, California, United States&quot;,
      &quot;center&quot;: [
        -122.3982976,
        37.791734
      ],
      &quot;geometry&quot;: {
        &quot;type&quot;: &quot;Point&quot;,
        &quot;coordinates&quot;: [
          -122.3982976,
          37.791734
        ]
      },
      ...
    },
    ...
  ]
}

but when I search for somewhere outside the US (e.g. King Street / Collins Street, Melbourne), it never returns an intersection:
$ curl &quot;https://api.mapbox.com/geocoding/v5/mapbox.places/William%20Street%20and%20Collins%20Street.json?access_token=[TOKEN]&amp;country=au&amp;types=address&amp;proximity=144.95979,-37.81638&quot;

{
  &quot;type&quot;: &quot;FeatureCollection&quot;,
  &quot;query&quot;: [
    &quot;william&quot;,
    &quot;street&quot;,
    &quot;and&quot;,
    &quot;collins&quot;,
    &quot;street&quot;
  ],
  &quot;features&quot;: [
    {
      &quot;id&quot;: &quot;address.6899530118768598&quot;,
      &quot;type&quot;: &quot;Feature&quot;,
      &quot;place_type&quot;: [
        &quot;address&quot;
      ],
      &quot;relevance&quot;: 0.716667,
      &quot;properties&quot;: {
        &quot;accuracy&quot;: &quot;street&quot;
      },
      &quot;text&quot;: &quot;Williams Street&quot;,
      &quot;place_name&quot;: &quot;Williams Street, St Arnaud Victoria 3478, Australia&quot;,
      &quot;center&quot;: [
        143.25317765,
        -36.62076935
      ],
      &quot;geometry&quot;: {
        &quot;type&quot;: &quot;Point&quot;,
        &quot;coordinates&quot;: [
          143.25317765,
          -36.62076935
        ]
      },
      ...
    },
    ...
  ]
}

As far as I can tell, the geocoding intersection search only works for US-based addresses. I've tried different combinations of the country, proximity and bbox parameters to no success.
US-based addresses work:

&quot;Market Street and Fremont Street, San Francisco&quot; (used in the docs example)
&quot;Broadway and Columbus Avenue, New York&quot;

Non US-based addresses don't work at all:

&quot;Collins Street and William Street, Melbourne&quot;
&quot;Eagle Street and Queen Street, Brisbane&quot;
&quot;George Street and Grosvenor Street, Sydney&quot;
&quot;Oxford Street and Tottenham Court Road, London&quot;
&quot;Avenue Des Champs-Ã‰lysÃ©es and Place Charles de Gaulle, Paris&quot;

How do I get Mapbox geocoding intersection search to work for non-US addresses?
If this is not possible, is it documented anywhere? Nothing in the docs indicates that this is not available world-wide, and I can't think of any reason why it wouldn't be.
","mapbox, geojson, geocoding, mapbox-gl-js, mapbox-api-geocoding",0,73659373,"You can use Mapbox's geocoding API playground to try various queries. Based on my testing, it seems clear that intersection queries always resolve to the US, or to something other than an intersection.
So:

How do I get Mapbox geocoding intersection search to work for non-US addresses?

I doubt it is possible.

If this is not possible, is it documented anywhere?

Not that I can see.

Nothing in the docs indicates that this is not available world-wide, and I can't think of any reason why it wouldn't be.

Geocoders are built from lots of different data sources in different regions, with lots of different rules.
It's hard to imagine why Mapbox would deliberately introduce this limitation, but easy to imagine how it could unintentionally come to be. You may wish to contact them directly.
"
73925755,"Pinescript v5 error with function request.security argument with expr type ""float series""","I'm going crazy trying to avoid an error in Pinescript v5:
MA = nz(AMA[1]) + 0.5*(hlc3 - nz(MA[1]))    
signal = request.security(syminfo.tickerid, timeframe.period, MA)

It returns undeclared identifier, but not if I type:
MA = hlc3    
signal = request.security(syminfo.tickerid, timeframe.period, MA)

Also gives an error if I type:
MA = 0    
MA = nz(AMA[1]) + 0.5*(hlc3 - nz(MA[1]))    
signal = request.security(syminfo.tickerid, timeframe.period, MA)

It returns &quot;series int&quot; declared when type &quot;series float&quot;.
",pine-script,0,73927555,"MA = nz(AMA[1]) + 0.5*(hlc3 - nz(MA[1]))    
signal = request.security(syminfo.tickerid, timeframe.period, MA)

Self referencing is not allowed.
You should write this as:
MA = 0.0
MA := nz(AMA[1]) + 0.5*(hlc3 - nz(MA[1]))    
signal = request.security(syminfo.tickerid, timeframe.period, MA)

Below statement makes MA an int.
MA = 0    
MA = nz(AMA[1]) + 0.5*(hlc3 - nz(MA[1]))

If you want to declare it as a float either do MA = 0.0 or flaot MA = 0.
Also, please note that, you should use the := assignment operator when you are assigning a value to an already declared variable.
"
73452611,Ensure sidebar sticky goes to the bottom of the viewport when scrolled down,"https://jsfiddle.net/fw8ozvqh/
When the page is not scrolled, the sidebar meets the bottom of the page properly and content in the sidebar can still be scrolled all the way to the bottom.

However, once the page scrolls, the sidebar is off the bottom of the page by the size of the navbar + margin. This is expected, however, is there a way to ensure the sidebar sticks to the bottom of the viewport as well after scrolling the body?

Solutions that involve absolute or fixed positioning are not sufficient for me, as I'd like to keep the sidebar in the flow of the document.
html, body {
  height: 1200px;
  background: red;
  margin: 0;
}

header {
  height: 50px;
  background: blue;
}

.sidebar {
  background: green;
  height: calc(100vh - 50px - 32px);
  position: sticky;
  top: 32px;
  margin-top: 32px;
  width: 200px;
  overflow-y: scroll;
}

&lt;header&gt;
   header
&lt;/header&gt;

&lt;div class=&quot;sidebar&quot;&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
  &lt;div&gt;sidebar content&lt;/div&gt;
&lt;/div&gt;

","html, css, position, sticky",0,73464688,"I solved it using interaction observer to detect when sticky is triggered and then removed the header height from the calc. Not a perfect solution, but gets the job done in my use case. A better solution would be nice.
"
74271731,"""dd/MM/yyyy"" format not validating YEAR in Spring boot","I tried to validate the date using custom validation in spring boot. But the only yyyy is not validating the year although dd and MM is working fine.
For Example,
if in RequestBody I passed the date format as
02/1k/2022, is validated properly and also k2/12/2022 is validated properly but
when I passed a date like 02/12/2k22 is not validated.
I couldn't figure out it.
SpringBoot version: 2.3.0.RELEASE
Dependency:
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt;
&lt;/dependency&gt;

Code:
public class IsValidDateFormatValidator implements ConstraintValidator&lt;IsValidDateFormat, String&gt; {

    @Override
    public void initialize(IsValidDateFormat arg0) {
        // TODO Auto-generated method stub

    }

    @Override
    public boolean isValid(String arg0, ConstraintValidatorContext arg1) {

        if (arg0 != null) {
            if (arg0.trim().length() &gt; 10) {
                return false;
            }
            if (!arg0.isEmpty()) {
                SimpleDateFormat sdf = new SimpleDateFormat(&quot;dd/MM/yyyy&quot;);
                sdf.setLenient(false);
                try {
                    sdf.parse(arg0);
                } catch (ParseException e) {
                    return false;
                }
            }
        }
        return true;

    }
}

@Target({ METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE })
@Retention(RetentionPolicy.RUNTIME)
@Constraint(validatedBy = {IsValidDateFormatValidator.class})
@Documented
public @interface IsValidDateFormat {

    String message() default &quot;&quot;;

    Class&lt;?&gt;[] groups() default {};

    Class&lt;? extends Payload&gt;[] payload() default {};

}

Model:
@NotEmpty(message = &quot;dob {emptyDateValidationMsg}&quot;)
@IsValidDateFormat(message = &quot;dob {dateFormatValidationMsg}&quot;)
@JsonProperty(&quot;dob&quot;)
private String dob;

Please suggest what mistake I made...
The same code was validating the year properly if I passed dateformat yyyy-MM-dd instead of dd/MM/yyyy
","java, spring-boot, customvalidator",0,74272384,"There is some flaws if you use SimpleDateFormat.parse, that &quot;The method may not use the entire text of the given string&quot;. You can find that in javadoc DateFormat
I suggest you can use DateTimeFormatter &amp; LocalDate.parse instead.
    try {
        DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;dd/MM/yyyy&quot;);
        LocalDate.parse(arg0, formatter);
    } catch (DateTimeParseException e) {
        return false;
    }

"
73985472,Flutter: perfectly align Icons to the edge,"I am trying to align the icon to the very left edge of the blue container.
The red container is just there for reference (I am using ScreenUtil).
How can I align the icon perfectly to the left edge of the blue container? So that there is no gap, not even one pixel?  In this snippet I used FaIcons, however I have the same problem with the standard material icons.

 Widget build(BuildContext context) {
return Scaffold(
  body: SafeArea(
    left: false,
    child: Column(
      crossAxisAlignment: CrossAxisAlignment.start,
      children: [
        Container(
          width: 50.w,
          color: Colors.blue,
          margin: EdgeInsets.only(left: 35.w),
          child: IconButton(
            iconSize: 25.w,
            onPressed: () {},
            icon: const FaIcon(FontAwesomeIcons.bars),
          ),
        ),
        Container(
          margin: EdgeInsets.only(left: 35.w),
          color: Colors.red,
          width: 20.w,
          height: 20.w,
        )
      ],
    ),
  ),
);}}

","flutter, dart, flutter-layout",0,73985590,"remove the padding from iconbutton and set constraints.
Widget build(BuildContext context) {
    return Scaffold(
  body: SafeArea(
    left: false,
    child: Column(
      crossAxisAlignment: CrossAxisAlignment.start,
      children: [
        Container(
          width: 50,
          color: Colors.blue,
          margin: EdgeInsets.only(left: 35),
          padding: EdgeInsets.zero,
          alignment: Alignment.centerLeft,
          child: IconButton(
            iconSize: 25,
            padding: EdgeInsets.zero,
            constraints: BoxConstraints(),
            onPressed: () {},
            icon: const Icon(Icons.person,),
          ),
        ),
        Container(
          margin: EdgeInsets.only(left: 35),
          color: Colors.red,
          width: 20,
          height: 20,
        )
      ],
    ),
  ),
);
}


"
72954104,Copy multiple cells in excel once - paste into another app for each field,"I need to copy a row of 10 fields in excel.  I can use Ctrl+C for this.
When I paste the fields - I would like to only paste 1 field at a time into different fields in a different app.
Is it possible to copy the row fields once and when I paste into the other app - I can use Ctrl+V but only paste the 1st field, so I can move to the 2nd field and paste the 2nd copied field from excel?
","excel, vba",0,72954366,"Windows 10 and Windows 11 have a â€œClipboard Historyâ€ tool that allows the Clipboard to store multiple items that can be pasted at any time. If you copy each item you want to transfer individually, you can use this to approximate your desired functionality.
Microsoft turns this new â€œClipboard Historyâ€ feature off by default.
Follow these steps to turn the â€œClipboard Historyâ€ feature on:

Open Settings.

Search for &quot;Clipboard&quot;.

Select &quot;Save Multiple Clipboard Items&quot;.

Toggle the â€œClipboard historyâ€ setting to On.


The Clipboard History feature should now be active.
Now, when you copy (or cut) items to the Clipboard all of those items will be stored (until restart) instead of being over-written when you copy or cut something new.
However, you canâ€™t access the stored Clipboard items simply by clicking Paste or pressing Ctrl+V. If you want to paste one of the previously stored items, press the Windows+V key combination. Pressing Windows+V will bring up the entire list of previously stored Clipboard items. Select one from this list to paste it in.
"
74400294,MUI DateTimePicker set custom InputFormat,"I want to set a custom InputFormat as follows
2018-01-05 13:08:00
Here is the sample code
&lt;LocalizationProvider dateAdapter={AdapterDayjs}&gt;
    &lt;DateTimePicker
        renderInput={(props) =&gt; &lt;TextField {...props} size=&quot;small&quot; /&gt;}
        value={dayjs(myDate)}
        onChange={(value) =&gt; setDate(value)}
        minDate={dayjs(startDate)}
        maxDate={dayjs(endDate)}
    /&gt;
&lt;/LocalizationProvider&gt;

How can I do that?
","reactjs, material-ui, datetimepicker",-1,74401197,"Try this it might works, Use inputFormat props.
inputFormat=&quot;YYYY-DD-MM HH:mm:ss
&lt;DateTimePicker
   renderInput={(props) =&gt; &lt;TextField {...props} size=&quot;small&quot; /&gt;}
   value={dayjs(myDate)}
   onChange={(value) =&gt; setDate(value)}
   minDate={dayjs(startDate)}
   maxDate={dayjs(endDate)}
   inputFormat=&quot;YYYY-DD-MM HH:mm:ss&quot;
/&gt;

"
74481905,SAS to create a GROUP ID,"I have the following data
data have;
  input id seq value;
datalines;
1 1 4
1 2 4
1 3 0
1 4 0
1 5 0
1 6 4
1 7 4
2 1 1
2 2 1
2 3 5
2 4 5
2 5 5
2 6 8
;
run;

I need to create a groupid variable, which depends on the id and value, so that the output looks like this,
id seq value grpid
1   1    4     1
1   2    4     1
1   3    0     2
1   4    0     2
1   5    0     2
1   6    4     3
1   7    4     3
2   1    1     1
2   2    1     1
2   3    5     2
2   4    5     2
2   5    5     2
2   6    8     3

I have no idea how to achieve this, the error that I run into is this,

ERROR: BY variables are not properly sorted on data set

But I cannot change the sorting, the dataset needs to be sorted by id and seq variables first before generating the grpid.
","sas, sas-macro",0,74481966,"Try this
data have;
  input id seq value;
datalines;
1 1 4
1 2 4
1 3 0
1 4 0
1 5 0
1 6 4
1 7 4
2 1 1
2 2 1
2 3 5
2 4 5
2 5 5
2 6 8
;
run;

data want;
   set have;
   by id value notsorted;
   if first.id then grpid = 0;
   if first.value then grpid + 1;
run;

"
73125825,Is it correct to define a global static const std::string in a header file,"Is it correct to define a global std::string in a header file like this :
namespace Colors
{
    static const std::string s_blue = &quot;Blue&quot;;
}

",c++,1,73126069,"Correct?
Yes. static here means that each translation unit (TU) that includes this header will have a unique object. So there isn't 1 s_blue object for the whole project, but one for each TU.
However since it's const all objects will be equal, so for the user it doesn't make a difference.
Recommended?
Maybe, depends.
The big downside is that you create multiple objects and all of them are initialized at program startup.
Another possible downside is the access pattern. If the program assesses s_blue from multiple TUs in quick succession it could trash the cache.
However for certain programs and scenarios this could be the best option or at least &quot;good enough&quot;. For instance (spoiler for next paragraph) in a header only library or before C++17.
Are there better alternatives?
Yes, but they cannot always be used.
extern
Make it an extern declaration in the header and in just 1 TU have the definition.
// constants.hpp
extern const std::string k_blue;

// constants.cpp
#include &quot;constants.hpp&quot;
const std::string k_blue = &quot;Blue&quot;;

This is clearly superior in terms of performance over OP. However you can't use it in a header only lib.
Even in a normal program static could be preferred as the ease of declaring and defining the constants in just one place could be seen as outweighing the performance downsides in specific projects.
constexpr inline string_view C++17
A clearly better alternative if it's available (since C++17) is string_view. It's very light weight but has all the amenities of a modern container (unlike raw const char[]). And since you already are in C++17 you should make it constexpr inline:
constexpr inline std::string_view k_blue = &quot;Blue&quot;;

inline const std::string c++17
If for whatever reason you need std::string over std::string_view you can inline the variable for better optimization:
inline const std::string k_blue = &quot;Blue&quot;;

"
73475744,Terraform - 'Objects have changed outside of Terraform' for a new Azure resource group,"I have been experimenting with terraform with the following basic configuration file for creating a resource group...
resource &quot;azurerm_resource_group&quot; &quot;myrg&quot; {
  name = &quot;MyResourceGroup&quot;
  location = &quot;westeurope&quot;
}

output resource_group_details {
  value = azurerm_resource_group.myrg
}


First terraform plan - 1 resource will be created
First terraform apply - 1 resource created
Second terraform plan (with no changes made to the configuration file) - Objects have changed outside of Terraform (See below)
Second terraform apply - Objects have changed outside of Terraform, 0 added/changed/detroyed
Third terraform plan (with no changes made to the configuration file) - No changes. Your infrastructure matches the configuration.

Note: Objects have changed outside of Terraform

Terraform detected the following changes made outside of Terraform since the last &quot;terraform apply&quot; which may have
affected this plan:

  # azurerm_resource_group.myrg has changed
  ~ resource &quot;azurerm_resource_group&quot; &quot;myrg&quot; {
        id       = &quot;/subscriptions/176f2ee3-d0a2-476d-9106-43cad1f63f16/resourceGroups/MyResourceGroup&quot;
        name     = &quot;MyResourceGroup&quot;
      + tags     = {}
        # (1 unchanged attribute hidden)
    }

Based on what I've tried to find about this online, it looks like this warning is because Azure adds an empty tag array to a resource group during creation. Then when terraform compares the now existing resource with the configuration file and state, it's now warning you there is a difference. I'm not quite sure how terraform reconciles this on the third terraform plan though....
What should be the workflow here? Particularly when thinking about CI?
It appears to just be noise to be informed of the existence of an empty, optional attribute that I haven't defined.
I've looked at -refresh=false but it looks like this could suppress a genuine change that has occurred on your infrastructure that you may want to be notified about. When using -refresh-only on the second terraform plan and apply it just outputs the same noise as above.
","azure, azure-devops, terraform, terraform-provider-azure",1,73475981,"Indeed, what you have observed here is a small bug in the Azure provider where it is being inconsistent between the object it returns during apply and the object it returns during refresh.
It is typically okay for a provider to insert a default value for an argument that wasn't set, which is what seems to be happening here, but a provider ought to be consistent in doing so in all of its results: in the initial plan, in the new state created after apply, and in the refreshed state created on the next plan. Terraform produces this message in particular if the refreshed state created on the next plan is different than the new state that was created by the previous apply.

One way to hide the bug would be to explicitly set the tags argument to the default value that the provider's refresh step is inserting:
resource &quot;azurerm_resource_group&quot; &quot;myrg&quot; {
  name     = &quot;MyResourceGroup&quot;
  location = &quot;westeurope&quot;

  tags = {}
}

As long as the provider logic doesn't treat an empty map as special during plan and apply (which I'm not sure about), this should hopefully cause the initial result to agree with the refreshed result and thus avoid showing an incorrect &quot;changed outside of Terraform&quot; note.

Another separate answer is to change your output value to return more specific attributes of the resource group, so that Terraform can see that the end result doesn't depend on the tags attribute.
Terraform shows this message in an attempt to explain why the resource_group_details output value is also planned to change, and so Terraform shouldn't show the message if it can be sure that your output value won't be affected by the change to the tags. For example:
output &quot;resource_group_details&quot; {
  value = {
    name     = azurerm_resource_group.myrg.name
    location = azurerm_resource_group.myrg.location
    # (...and any other attributes you want to export,
    # as long as you don't refer to &quot;tags&quot;.)
  }
}

Note that this rule generally applies to anything in your configuration that may directly or indirectly refer to the tags attribute, so if there's more to your configuration that you didn't show here then you should also make sure that nothing else refers to tags.
Terraform's analysis of this is not fully precise, so if it isn't sure that there aren't any references to tags then it will still show the note just in case. Therefore you would need to stick to relatively simple expressions that refer directly to individual attributes of azurerm_resource_group.myrg, and avoid using expressions which do dynamic work with the entire resource object which would prevent Terraform's analysis from proving that the tags attribute is unused.
"
73188739,Rotate Camera around a cube in real time using Preview Render Utility in uitoolkit,"I'm trying to rotate the camera in Preview Render Utility around a cube. The following code does seem to be able to do this, but it never seems to be able to update the image while the user is in a mouse drag.
Is there any way to have the image update in real-time? Rather than delayed after a mouse drag.
This example is completely self-contained so if you create a MyEditor file in an Editor folder it should be possible to reproduce the problem I'm having.
using UnityEditor;
using UnityEngine;
using UnityEngine.UIElements;

namespace Editor
{
    public class MyEditor : EditorWindow
    {

    private const int ImageSize = 256;
    private const float CameraDistance = 10f;

    private static readonly Rect ImageDimension = new(0, 0, ImageSize, ImageSize);
   
    private static readonly Vector3 DefaultCameraPosition = new(0, CameraDistance, 0);

    private static Vector3 RotateAroundPivot(Vector3 point, Vector3 pivot, Vector3 angles)
    {
        return Quaternion.Euler(angles.y, -angles.x, 0) * (point -pivot) + pivot;
    }
   
    [MenuItem(&quot;Custom/My Editor&quot;)]
    public static void Popup()
    {
        MyEditor editor = GetWindow&lt;MyEditor&gt;();
        editor.titleContent = new GUIContent(&quot;My Custom Editor&quot;);
    }

    private PreviewRenderUtility _previewUtility;

    private Image _image;

    private bool _mouseIsDown;

    private Vector3 _previousMousePosition;

    private Vector3 _totalRotation;
   
    public void OnEnable()
    {
        // setup basic Preview Render Utility
        _previewUtility ??= new PreviewRenderUtility();
        _previewUtility.camera.farClipPlane *= 2;
        Transform transform = _previewUtility.camera.transform;
        transform.position = DefaultCameraPosition;
        transform.LookAt(Vector3.zero);
       
        // Add the cube to the scene
        GameObject obj = GameObject.CreatePrimitive(PrimitiveType.Cube);
        obj.transform.localScale = new Vector3(0.1f,0.1f,0.1f);
        _previewUtility.AddSingleGO(obj);
    }

    public void OnDisable()
    {
        if (_previewUtility is not null)
        {
            _previewUtility.Cleanup();
            _previewUtility = null;
        }
    }

    private void CreateGUI()
    {
        // Create Image
        _image = new Image();
        rootVisualElement.Add(_image);

        // Setup Mouse Handlers for image
        // note image should be focusable for image to receive all event types
        _image.RegisterCallback&lt;PointerDownEvent&gt;(OnPointerDownHandler);
        _image.RegisterCallback&lt;PointerMoveEvent&gt;(OnPointerMoveHandler);
        _image.RegisterCallback&lt;PointerUpEvent&gt;(OnPointerUpHandler);

        // create and assign Render Texture to Image
        _previewUtility.BeginPreview(ImageDimension, GUIStyle.none);
        _previewUtility.camera.Render();
        _image.image = _previewUtility.EndPreview();
    }

    private void OnPointerDownHandler(PointerDownEvent evt)
    {
        // start dragging
        _mouseIsDown = true;
        _previousMousePosition = evt.position;
    }

    private void OnPointerMoveHandler(PointerMoveEvent evt)
    {
        // If the mouse is not down do nothing
        if (!_mouseIsDown)
        {
            return;
        }

        // Calculate delta and add it to the total rotation
        Vector3 delta = evt.position - _previousMousePosition;
        _previousMousePosition = evt.position;
        _totalRotation += delta;

        // pivot camera around (0, 0, 0)
        _previewUtility.camera.transform.position = RotateAroundPivot(DefaultCameraPosition, Vector3.zero, _totalRotation);
        _previewUtility.camera.transform.LookAt(Vector3.zero);
       
        // Render new camera location - seems to lag
        _previewUtility.BeginPreview(ImageDimension, GUIStyle.none);
        _previewUtility.camera.Render();
        _previewUtility.EndAndDrawPreview(ImageDimension);
    }

    private void OnPointerUpHandler(PointerUpEvent evt)
    {
        _mouseIsDown = false;
    }
   
}

}
","c#, unity3d",2,73278023,"Simply call Repaint() after rendering the camera to force the EditorWindow to redraw its contents:
            //beginning of OnPointerMoveHandler...


            // Render new camera location - seems to lag
            _previewUtility.BeginPreview(ImageDimension, GUIStyle.none);
            _previewUtility.camera.Render();
            _previewUtility.EndAndDrawPreview(ImageDimension);

            Repaint(); //added here
        }

"
74365692,error when using time in rolling function pandas,"I am trying to calculate mean i.e moving average every 10sec of data; lets say 1 to 10sec, and 11sec to 20sec etc.
Is below right for this? I am getting error when using &quot;60sec&quot; in rolling function, I think it may be due to the &quot;ltt&quot; column which is of type string, I am converting it to datetime, but still the error is coming.
How to resolve this error? Also how to do the averaging for samples collected every 10sec. This is streaming data coming in, but for testing purpose, I am using the static data in record1.
import pandas as pd
import numpy as np

records1 = [
{'ltt': 'Mon Nov  7 12:12:05 2022', 'last': 258},
{'ltt': 'Mon Nov  7 12:12:05 2022', 'last': 259},
{'ltt': 'Mon Nov  7 12:12:07 2022', 'last': 259},
{'ltt': 'Mon Nov  7 12:12:08 2022', 'last': 260},
{'ltt': 'Mon Nov  7 12:12:09 2022', 'last': 259},
{'ltt': 'Mon Nov  7 12:12:10 2022', 'last': 259},
{'ltt': 'Mon Nov  7 12:12:11 2022', 'last': 261},
{'ltt': 'Mon Nov  7 12:12:12 2022', 'last': 262},
{'ltt': 'Mon Nov  7 12:12:12 2022', 'last': 260},
{'ltt': 'Mon Nov  7 12:12:14 2022', 'last': 258},
{'ltt': 'Mon Nov  7 12:12:15 2022', 'last': 259},
{'ltt': 'Mon Nov  7 12:12:16 2022', 'last': 259},
{'ltt': 'Mon Nov  7 12:12:17 2022', 'last': 260},
{'ltt': 'Mon Nov  7 12:12:18 2022', 'last': 258},
{'ltt': 'Mon Nov  7 12:12:19 2022', 'last': 259},
{'ltt': 'Mon Nov  7 12:12:20 2022', 'last': 260},
{'ltt': 'Mon Nov  7 12:12:21 2022', 'last': 260},
{'ltt': 'Mon Nov  7 12:12:22 2022', 'last': 258},
{'ltt': 'Mon Nov  7 12:12:23 2022', 'last': 259},
{'ltt': 'Mon Nov  7 12:12:24 2022', 'last': 260}
]

datalist = []

def strategy1(record):
    global datalist

    datalist.append(record)
    pandas_df = pd.DataFrame(datalist)
    pandas_df['ltt'] = pd.to_datetime(pandas_df['ltt'], format=&quot;%a %b %d %H:%M:%S %Y&quot;)

    pandas_df['hour'] = pandas_df['ltt'].dt.hour
    pandas_df['minute'] = pandas_df['ltt'].dt.minute
    pandas_df['second'] = pandas_df['ltt'].dt.second

    pandas_df['max'] = pandas_df.groupby('second')['last'].transform(&quot;max&quot;)

    pandas_df[&quot;ma_1min&quot;] = (
        pandas_df.sort_values(&quot;ltt&quot;)
            .groupby([&quot;hour&quot;, &quot;minute&quot;])[&quot;last&quot;]
            .transform(lambda x: x.rolling('10sec', min_periods=1).mean())
    )

    print(pandas_df)

","python, pandas",-1,74365917,"i don't know how to exactly implement this in your code but i had a kind of similar problem where i had to group each day into 4 hour timeslots. so an approach might be something like this:
pandas_df.groupby([pandas_df['ltt'].dt.hour, pandas_df['ltt'].dt.minute, (pandas_df['ltt'].dt.second / 10).astype(int)]).last.agg('mean')

this should basically give you 6 groups ([0s-9s -&gt; 0], [10s-19s -&gt; 1], etc. for the 3rd groupby index) for every minute of data.
"
74041416,How to isolate handleSubmit() functions in React Hooks Form when the forms are nested such that they don't trigger each other?,"I am using React Hook Form for forms in my Next JS App. I have two forms FormA &amp; FormB components. But the issue is whenever I execute the handleSubmit() function for child FormB, the handleSubmit() function for parent FormA also gets executed.
&lt;FormA onSubmit(handleSubmit(submitFunctionA)&gt;
   ............
  &lt;FormB onSubmit(handleSubmit(submitFunctionB))&gt;
  &lt;/FormB&gt;
   ............
&lt;/FormA&gt;

After applying suggestions from comments. My issue is fixed as shown below.
                &lt;form
                    onSubmit={(event) =&gt; {
                 //Child Form's onSubmit function here//
                      handleSubmit(onSubmit)(event);

                      if (event) {
                        if (typeof event.preventDefault === &quot;function&quot;) {
                          event.preventDefault();
                        }
                        if (typeof event.stopPropagation === &quot;function&quot;) {
                          event.stopPropagation();
                        }

                      }
                    }}
                  &gt;

","reactjs, forms, next.js, react-hook-form",1,74041453,"Events get propagated up the tree to their parents, so this behaviour is normal. In order to stop the propagation, try adding this to your child handleSubmit:
    if (event) {
      if (typeof event.preventDefault === 'function') {
        event.preventDefault();
      }
      if (typeof event.stopPropagation === 'function') {
        event.stopPropagation();
      }
    }

"
73671051,Svelte script for parsing only key filtered from json,"I have a very strange issue, and I'm not able to fix it.
I have this Json response from an API:
{
 &quot;type::new&quot;:&quot;#000000&quot;,
 &quot;type::closed&quot;:&quot;#000011&quot;,
 &quot;priority::low&quot;:&quot;#FFFFFF&quot;,
 &quot;priority::normal&quot;:&quot;#FF0000&quot;,
 &quot;priority::high&quot;:&quot;#FFFF00&quot;,
 &quot;type::bug&quot;:&quot;#001100&quot;
}

I need to get, for example, only key that start with &quot;type&quot;, so:
&quot;type::new&quot;, &quot;type::closed&quot;, &quot;type::bug&quot;

and assign each element to an array object with these values:
items: [
{
    id: 'type::new',
    value: 'type::new',
    title: 'type::new'
},
{
    id: 'type::closed',
    value: 'type::closed',
    title: 'type::closed'
},
{
    id: 'type::bug',
    value: 'type::bug',
    title: 'type::bug'
}
]

I'm in a Svelte script, I tryed this but it not works (and I'm stopping only on get without filter them) [response is a result of fetch API):
const data = await response.json();
return data.map((item: any) =&gt; ({ id: item.key(), value: item.key(), title: item.key()}));

Thank you so much :)
","javascript, json, fetch, mapping, svelte",0,73671146,"As stated in my comment, you can't map() objects properties, but you can loop them over using Object.keys() or for...in.


const data = {
  ""type::new"": ""#000000"",
  ""type::closed"": ""#000011"",
  ""priority::low"": ""#FFFFFF"",
  ""priority::normal"": ""#FF0000"",
  ""priority::high"": ""#FFFF00"",
  ""type::bug"": ""#001100""
}


//
// USING for...in
//
const results = []

for (let key in data) {
  if (key.includes('type::')) {
    results.push({ id: key, value: key, title: key })
  }
}

console.log(results)



//
// USING Object.keys(), filter() AND map()
//
const results2 = Object.keys(data).filter(item =&gt; item.includes('type::')).map(key =&gt; {
  return { id: key, value: key, title: key }
})

console.log(results2)



"
74556446,Swift: How to convert vertical UIScrollView to a horizontal one,"Usually, I would use SwiftUI's ScrollView, but in my edge case scenario, I need to use it as a UIScrollView in SwiftUI's UIViewRepresentable
struct CALayerScrollView: UIViewRepresentable {
func makeUIView(context: Context) -&gt; some UIView {
    var view = UIView(frame: CGRect(x: 0, y: 0, width: UIScreen.main.bounds.width / 2, height: UIScreen.main.bounds.height / 2))
    let scrollView: UIScrollView = {
        let scrollView = UIScrollView()
        scrollView.translatesAutoresizingMaskIntoConstraints = false
        return scrollView
    }()

    let scrollViewContainer: UIStackView = {
        let view = UIStackView()

        view.axis = .vertical
        view.spacing = 10

        view.translatesAutoresizingMaskIntoConstraints = false
        return view
    }()

    let redView: UIView = {
        let view = UIView()
        view.heightAnchor.constraint(equalToConstant: 500).isActive = true
        view.backgroundColor = .red
        return view
    }()

    let blueView: UIView = {
        let view = UIView()
        view.heightAnchor.constraint(equalToConstant: 200).isActive = true
        view.backgroundColor = .blue
        return view
    }()

    let greenView: UIView = {
        let view = UIView()
        view.heightAnchor.constraint(equalToConstant: 1200).isActive = true
        view.backgroundColor = .green
        return view
    }()
    
    view.addSubview(scrollView)
            scrollView.addSubview(scrollViewContainer)
            scrollViewContainer.addArrangedSubview(redView)
            scrollViewContainer.addArrangedSubview(blueView)
            scrollViewContainer.addArrangedSubview(greenView)

            scrollView.leadingAnchor.constraint(equalTo: view.leadingAnchor).isActive = true
            scrollView.trailingAnchor.constraint(equalTo: view.trailingAnchor).isActive = true
            scrollView.topAnchor.constraint(equalTo: view.topAnchor).isActive = true
            scrollView.bottomAnchor.constraint(equalTo: view.bottomAnchor).isActive = true

            scrollViewContainer.leadingAnchor.constraint(equalTo: scrollView.leadingAnchor).isActive = true
            scrollViewContainer.trailingAnchor.constraint(equalTo: scrollView.trailingAnchor).isActive = true
            scrollViewContainer.topAnchor.constraint(equalTo: scrollView.topAnchor).isActive = true
            scrollViewContainer.bottomAnchor.constraint(equalTo: scrollView.bottomAnchor).isActive = true
            // this is important for scrolling
            scrollViewContainer.widthAnchor.constraint(equalTo: scrollView.widthAnchor).isActive = true
        

    return view
       
}
func updateUIView(_ uiView: UIViewType, context: Context) { }
}

I've tried setting the viewAxis to .horizontal, but I still does not scroll laterally.
Any advices is appreciated. Thanks
","swift, uiscrollview, uikit",0,74563806,"You are setting the stack view axis to Vertical -- but you want Horizontal scrolling... so set it to .horizontal.
You are setting Height for each arranged subview, but you haven't set the Widths... so give them Widths.
You should constrain the scroll view's content to the scroll view's Content Layout Guide.
Because you're setting varying Heights, it's not quite clear if you want only horizontal scrolling... so this example ends up scrolling both directions:
struct TestView: View {
    
    var body: some View {
        
        VStack {
            CALayerScrollView()
        }
        .frame(width: 240, height: 400)
        .background(Color.yellow)

    }
}

struct CALayerScrollView: UIViewRepresentable {
    func makeUIView(context: Context) -&gt; some UIView {
        let view = UIView(frame: CGRect(x: 0, y: 0, width: UIScreen.main.bounds.width / 2, height: UIScreen.main.bounds.height / 2))
        
        let scrollView: UIScrollView = {
            let scrollView = UIScrollView()
            scrollView.translatesAutoresizingMaskIntoConstraints = false
            return scrollView
        }()
        
        let scrollViewContainer: UIStackView = {
            let view = UIStackView()
            
            // Horizontal Stack View
            view.axis = .horizontal
            view.spacing = 10
            
            // .top Alignment, because we're setting different heights for the subviews
            view.alignment = .top
            
            view.translatesAutoresizingMaskIntoConstraints = false
            return view
        }()
        
        let redView: UIView = {
            let view = UIView()
            view.heightAnchor.constraint(equalToConstant: 500).isActive = true
            // also needs a width
            view.widthAnchor.constraint(equalToConstant: 200).isActive = true
            view.backgroundColor = .red
            return view
        }()
        
        let blueView: UIView = {
            let view = UIView()
            view.heightAnchor.constraint(equalToConstant: 200).isActive = true
            // also needs a width
            view.widthAnchor.constraint(equalToConstant: 400).isActive = true
            view.backgroundColor = .blue
            return view
        }()
        
        let greenView: UIView = {
            let view = UIView()
            view.heightAnchor.constraint(equalToConstant: 1200).isActive = true
            // also needs a width
            view.widthAnchor.constraint(equalToConstant: 800).isActive = true
            view.backgroundColor = .green
            return view
        }()
        
        view.addSubview(scrollView)
        scrollView.addSubview(scrollViewContainer)
        scrollViewContainer.addArrangedSubview(redView)
        scrollViewContainer.addArrangedSubview(blueView)
        scrollViewContainer.addArrangedSubview(greenView)
        
        scrollView.leadingAnchor.constraint(equalTo: view.leadingAnchor).isActive = true
        scrollView.trailingAnchor.constraint(equalTo: view.trailingAnchor).isActive = true
        scrollView.topAnchor.constraint(equalTo: view.topAnchor).isActive = true
        scrollView.bottomAnchor.constraint(equalTo: view.bottomAnchor).isActive = true
        
        // we want to constrain the scroll view *content* to the Content Layout Guide
        let cg = scrollView.contentLayoutGuide
        
        scrollViewContainer.leadingAnchor.constraint(equalTo: cg.leadingAnchor).isActive = true
        scrollViewContainer.trailingAnchor.constraint(equalTo: cg.trailingAnchor).isActive = true
        scrollViewContainer.topAnchor.constraint(equalTo: cg.topAnchor).isActive = true
        scrollViewContainer.bottomAnchor.constraint(equalTo: cg.bottomAnchor).isActive = true
        
        return view
        
    }
    func updateUIView(_ uiView: UIViewType, context: Context) { }
}

Should get you on your way...
"
74127525,Assembly boot sector working on VirtualBox but not on real hardware,"I am trying to write a simple bootloader in assembly. What I am trying to do is print a few strings, then wait for a keypress. This is my code:
[org 0x7c00]
mov al, 0
mov ah, 0
mov ax, 0
mov bx, 0
mov bp , 0x8000 ; Set the base of the stack a little above where BIOS
mov sp , bp ; loads our boot sector - so it won â€™t overwrite us.
jmp main
message:
    db 0x0a,0x0d,'Enderbyte Programs',0x0a,0x0d,0
bmessage:
    db 0x0a,0x0d,'Booting...',0x0a,0x0d,0
cmessage:
    db 0x0a,0x0d,'Just kidding this does nothing ',0
kmessage:
    db 'Or does it?',0
print_string:
    mov al, [bx]
    inc bx
    cmp al, 0 
    jne print_char
    mov bx, 0
    ret
print_char: 
    int 0x10; Print AL register
    jmp print_string
main:
    mov ah, 0x0e ; int 10/ ah = 0 eh -&gt; scrolling teletype BIOS routine
    mov bx, message
    call print_string
    mov bx, bmessage
    call print_string
    mov bx, cmessage,
    call print_string
    mov ah, 00h
    int 16h; Wait for keypress?
    mov ah, 0x0e
    mov bx, kmessage
    call print_string
    ;jmp $

This code works perfectly on VirtualBox, but when I try to run it on my PC (by copying it into a flash drive and booting from it), something very strange happens. The cursor is moved to the bottom-right area of the screen and prints off a strange character (An O but with an arrow coming off at the NE corner). Pressing a key causes it to clear the screen, the cursor jumps around before printing off another one of these characters. What is going on?
I have tried to follow the advice in Assembly boot loader working on virtual PC, not on real PC (setting all registers to zero, validating the stack) but it still did not work on the real hardware. (Still works fine on Virtualbox).
B0 00 B4 00 B8 00 00 BB 00 00 BD 00 80 89 EC EB
63 0A 0D 45 6E 64 65 72 62 79 74 65 20 50 72 6F
67 72 61 6D 73 0A 0D 00 0A 0D 42 6F 6F 74 69 6E
67 2E 2E 2E 0A 0D 00 0A 0D 4A 75 73 74 20 6B 69
64 64 69 6E 67 20 74 68 69 73 20 64 6F 65 73 20
6E 6F 74 68 69 6E 67 20 00 4F 72 20 64 6F 65 73
20 69 74 3F 00 8A 07 43 3C 00 75 04 BB 00 00 C3
CD 10 EB F1 B4 0E BB 11 7C E8 E9 FF BB 28 7C E8
E3 FF BB 37 7C E8 DD FF B4 00 CD 16 B4 0E BB 59
7C E8 D1 FF 25 00 00 00 00 00 00 00 00 00 00 00
*
00 00 00 00 00 00 00 00 00 00 00 00 00 00 55 AA

","assembly, x86, nasm, bootloader, usb-drive",1,74128252,"You should do a better setup and probably a somehow valid MBR. You cannot assume that BIOS set up the segments and registers for you. You have to initialize the most important things from the beginning. Maybe try something like:
This code assumes that your print_string is properly functional.
[ORG 0x7c00]
[BITS 16]

global boot

boot:
    jmp _start
    nop

    ; Here is a example BPB
    OEMname:           db    &quot;mkfs.fat&quot;  
    bytesPerSector:    dw    512
    sectPerCluster:    db    0
    reservedSectors:   dw    0
    numFAT:            db    0
    numRootDirEntries: dw    0
    numSectors:        dw    0
    mediaType:         db    0
    numFATsectors:     dw    0
    sectorsPerTrack:   dw    0
    numHeads:          dw    0
    numHiddenSectors:  dd    0
    numSectorsHuge:    dd    0
    driveNum:          db    0
    reserved:          db    0
    signature:         db    0
    volumeID:          dd    0
    volumeLabel:       db    &quot;NO NAME    &quot;
    fileSysType:       db    &quot;FAT12   &quot;

_start:
    cli
    xor ax, ax ; clear your segments
    mov es, ax
    mov ds, ax

    jmp 0x00:main ; clear code segment

main:
    sti
    mov bp , 0x8000 ; Set the base of the stack a little above where BIOS
    mov ss,  ax ; Setup Stack SS (AX=0) followed immediately by SP
    mov sp , bp 

    mov ah, 0x0e ; int 10/ ah = 0 eh -&gt; scrolling teletype BIOS routine
    mov bx, message
    call print_string
    mov bx, bmessage
    call print_string
    mov bx, cmessage,
    call print_string
    mov ah, 00h
    int 16h; Wait for keypress?
    mov ah, 0x0e

    jmp $

print_string:
    mov al, [bx]
    inc bx
    cmp al, 0 
    jne print_char
    mov bx, 0
    ret
print_char: 
    int 0x10; Print AL register
    jmp print_string

message:
    db 0x0a,0x0d,&quot;Enderbyte Programs&quot;,0x0a,0x0d,0
bmessage:
    db 0x0a,0x0d,&quot;Booting...&quot;,0x0a,0x0d,0
cmessage:
    db 0x0a,0x0d,&quot;Just kidding this does nothing &quot;,0
kmessage:
    db &quot;Or does it?&quot;,0

times 446 - ($ - $$) db 0x00 ; Padding to 512 bytes

; Partitions table for a MBR

partition_table_1:
    db 0x80 ; Status, 0x80 means active
    db 0x00 ; First Absolute Sector CHS
    db 0x00 ; 
    db 0x00 ;  
    db 0x00 ; Partition Type
    db 0x00 ; Last Absolute Sector CHS
    db 0x00 ; 
    db 0x00 ; 
    dd 0x00000001 ; First Absolute Sector LBA
    dd 0x00000200 ; Number of Sectors
    
partition_table_2:
    db 0x00 ; Status, 0x80 means active
    db 0x00 ; First Absolute Sector CHS
    db 0x00 ; 
    db 0x00 ;  
    db 0x00 ; Partition Type
    db 0x00 ; Last Absolute Sector CHS
    db 0x00 ; 
    db 0x00 ; 
    dd 0x00000000 ; First Absolute Sector LBA
    dd 0x00000000 ; Number of Sectors
    
partition_table_3:
    db 0x00 ; Status, 0x80 means active
    db 0x00 ; First Absolute Sector CHS
    db 0x00 ; 
    db 0x00 ;  
    db 0x00 ; Partition Type
    db 0x00 ; Last Absolute Sector CHS
    db 0x00 ; 
    db 0x00 ; 
    dd 0x00000000 ; First Absolute Sector LBA
    dd 0x00000000 ; Number of Sectors
    
partition_table_4:
    db 0x00 ; Status, 0x80 means active
    db 0x00 ; First Absolute Sector CHS
    db 0x00 ; 
    db 0x00 ;  
    db 0x00 ; Partition Type
    db 0x00 ; Last Absolute Sector CHS
    db 0x00 ; 
    db 0x00 ; 
    dd 0x00000000 ; First Absolute Sector LBA
    dd 0x00000000 ; Number of Sectors

dw 0xAA55 ; Boot signature required to boot


First, we cleared the segments to ensure that BIOS didn't give us junk values that will cause trouble later. We also cleared the code segments to make sure that we are in address 0x0000:0x7c00 instead of its equivalents such as 0x07c0:0x0000. I formatted the code, and move the data down so you can manipulate them easier. Your code also lacked padding and signature which were added. I also added some MBR partition tables in case you are booting from harddrive or equivalent system. You could also add a BPB, you can find the structure to that here:
https://wiki.osdev.org/FAT#BPB_.28BIOS_Parameter_Block.29
The above code can be compiled with
nasm -fbin bootloader.asm -o bootloader.bin

Write this to the first sector of a harddrive/USB/CD or equivalent.
Also check these out:
https://wiki.osdev.org/Bootloader
https://wiki.osdev.org/Rolling_Your_Own_Bootloader
https://wiki.osdev.org/MBR_(x86)
Edit:
The above code is compiled without errors and runs on QEMU.
Edit:
Also added a BPB
"
73168099,Invert Vector{Vector{}} grouping in Julia,"Given:
julia&gt; x = [[0,1,2], [3,4,5]]
2-element Vector{Vector{Int64}}:
 [0, 1, 2]
 [3, 4, 5]

How can I flip the groupings so each index is collected into a vector?
julia&gt; y = f(x)
3-element Vector{Vector{Int64}}:
 [0, 3]
 [1, 4]
 [2, 5]

(For context, I then want to compute minimum.(y).)
",julia,0,73169476,"You can vertically combine elements:
julia&gt; y = vcat.(x...)
3-element Vector{Vector{Int64}}:
 [0, 3]
 [1, 4]
 [2, 5]

"
74321568,Iterate over win_disk_facts result appended with empty dict along with result,"I am trying to iterate over available disks and fetch few details. I use win_disk_facts to get all the disks present on the host, then I manage to loop and append the results to mdisk dict variable.
I am getting the intended Json output from debug but the result is also getting appended with empty dict {} at the beginning of my json result.
I am sure the problem is with the syntax but I don't get how to append only the json dict excluding empty dict {}, first occurrence is empty dict as in output shown here .
Code:
- name: get disk
  win_disk_fact:

- name:
  set_fact:
    mdisk: &quot;{{mdisk|d({})}},
           {
           'name': '{{ item | json_query('friendly_name') }}',
           'Firmware_version': '{{ item | json_query('firmware_version') }}'
            }&quot;
  loop: &quot;{{ ansible_disks }}&quot;

Output:
&quot;ansible_facts&quot;: {
        &quot;diskfact&quot;: [
            [
                {},
                {
                    &quot; friendly_name&quot;: &quot;abcde&quot;,
                    &quot;firmware_version&quot;: &quot;x1y2z3&quot;
                }
            ],
            {
                &quot; friendly_name &quot;: &quot;xyze&quot;,
                &quot;'firmware_version'&quot;: &quot;2341&quot;
            }
        ]
    },

",ansible,1,74329392,"Thats IMO a lot of complexity for something that can get as simple as:
- name: print out the needed information
  ansible.builtin.debug:
    msg:
      - disk name is {{ item.friendly_name }}
      - firmware version is {{ item.firmware_version }}
  loop: &quot;{{ ansible_disks }}&quot;
  loop_control:
    label: &quot;{{ item.friendly_name }}&quot;

I used debug in the above example but you can use that loop in any other task.
If for some reason (that we cannot guess from your question and that I really have a hard time to understand...) you really need to transform the variable name, some of the key names and the number of keys inside each item, you can still keep the KISS principle (although it makes by itself things too complex compared to using the original var directly IMO).
- name: make a var out of an other var
  vars:
    query: '[].{&quot;name&quot;: &quot;friendly_name&quot;, &quot;firmware_version&quot;: &quot;firmware_version&quot;}'
  ansible.builtin.set_fact:
    mdisk: &quot;{{ ansible_disks | json_query(query) }}&quot;


Now to answer your direct question if you still want to do the above transformation and construct the variable through an iteration, you can. But this is in all respect the least efficient scenario.
- name: make a var out of an other var
  vars:
    current_disk:
      name: &quot;{{ item.friendly_name }}&quot;
      firmware_version: &quot;{{ item.firmware_version }}&quot;
  ansible.builtin.set_fact:
    mdisk: &quot;{{ mdisk | d([]) + [current_disk] }}&quot;
  loop: &quot;{{ ansible_disks }}&quot;
  loop_control:
    label: &quot;{{ item.friendly_name }}&quot;

Meanwhile, note that ansible_disks and mdisk are lists (of dict elements) and not dicts.
"
73573040,Installed Anaconda on an M1 MacBook Pro but I can't find the Navigator in applications - why is this happening?,"I installed Anaconda 3 via the graphical user interface and after the download was completed, I can't find the Anaconda Navigator app anywhere on the computer. I tried uninstalling and reinstalling and met the same issue.
","python, macos, anaconda, anaconda3",0,73574629,"Anaconda distribution supports MacBook Pro M1, but does not support Qt yet â€“ Anaconda Navigator and Spyder will not be available.
Check the following link Please!
https://www.anaconda.com/blog/new-release-anaconda-distribution-now-supporting-m1
"
73419719,"Merge nested objects in JavaScript, and append matching properties in array","I have an object like this, with nested objects:
obj1 = { 
  1: { a:5,b:6,c:7,d:8 },
  2: { a:6,b:9,c:10,d:12,e:1 },
  3: { a:3,b:4,c:9 },
}

I want to merge all its nested objects, while grouping in a list the values of properties with the same key.
Desired output:
{ 
  a: [5,6,3],  
  b: [6,9,4],  
  c: [7,10,9],  
  d: [8,12],  
  e: [1]
}

","javascript, arrays, object, merge, grouping",1,73420289,"This is a good opportunity to show off the neat javascript spread syntax, Array and Object prototype functions, and destructuring patterns.
Object.values(obj1).flatMap(Object.entries).reduce(
  (acc, [k, v]) =&gt; ({ ...acc, [k]: [...acc[k]||[], v] }), {})

As simple as this!

Extended answer

Object.values takes the values of all properties of an object and makes a list out of them. The rules of iteration are same as for...in
For example:
Object.values(obj1)
// The result will be:
[{a:5,b:6,c:7,d:8}, {a:6,b:9,c:10,d:12,e:1}, {a:3,b:4,c:9}]


Object.entries is similar to Object.values above, but it generates a list of [key, val] pairs instead, one for each property.
For example:
Object.entries({a:5,b:6,c:7,d:8})
// The result will be:
[['a',5], ['b',6], ['c',7], ['d',8]]


Array.flatMap applies the passed function on all elements of an array (just like map), but in the end, it flattens the result. That means, if the result is a list of lists, it returns only one big array with all inner elements.
For example:
Object.values(obj1).flatMap(Object.entries)
// By passing Object.entries as function,
// it will extract all the key-value pairs in one big list
[['a',5],['b',6],['c',7],['d',8], ['a',6],['b',9],['c',10],['d',12],['e',1], ['a',3],['b',4],['c',9]]


The spread syntax (...) is a neat feature of javascript, that is used to semantically refer to the enumeration of something.

When used in array literals, you can merge and append values together to form a bigger array.
Like this:
 o = {a: [5, 6]}

 o.a = [...o.a, 3]     // all elements from o.a, appending 3
 { a:[5, 6, 3] }

 o.d = [...o.d, 8]     // TypeError: o.d is undefined
 o.d = [...o.d||[], 8] // if o.d is undefined, use [], then append 8
 { a:[5, 6, 3], d:[8] }

 // This is useful as a semantic: &quot;append to list or create a new one&quot;

[Note 1]: o.d||[] works because undefined is falsy and the logical OR operator || short circuits.

When the spread syntax is used in object literals, you can merge objects together or append new properties.
Like this:
o = { 
  ...o,                       // all properties of o
  ...{b:[6,9,4], c:[7,10,9]}, // all properties of the literal
  d: [...o.d||[], 12],        // overriding property d
  ['e']: [1]                  // new property with computed name
}
// Result will be:      
{ a:[5,6,3], b:[6,9,4], c:[7,10,9], d:[8,12], e:[1] }




Array.reduce iterates over a list, applying the passed function and accumulating the results. In the end, it returns the accumulated value. The returned value depends on the operation performed by the passed function.
For example, you can use reduce to sum over all elements of an array.
[1, 2, 3, 4, 5].reduce((acc, curr) =&gt; curr + acc, 0)
// It is the same as (((((0 + 1) + 2) + 3) + 4) + 5)
15

However, you can also use reduce to take [key, val] pairs from a list and make them properties into an object (like Object.fromEntries, but more flexible).
This snippet below uses a destructuring pattern to unpack the [k, v] pairs passed as function parameter, and uses [k] as computed property name.
See:
[['a',5], ['b',6], ['c',7], ['d',8]].reduce(
  (acc, [k, v]) =&gt; ({ ...acc, [k]:v }), {})
// The result will be:
{ a:5, b:6, c:7, d:8 }

[['a',5], ['b',6], ['a',6]].reduce(
  (acc, [k, v]) =&gt; ({ ...acc, [k]:v }), {})
// Property a is repeated, so it will honor only the last value
{ a:6, b:6 }

// But if we use the semantic &quot;append or create&quot; mentioned above,
[['a',5], ['b',6], ['a',6]].reduce(
  (acc, [k, v]) =&gt; ({ ...acc, [k]: [...acc[k]||[], v] }), {})
// The result will be:
{ a:[5,6], b:[6] }



Now just bring it all together:
Object.values(obj1).flatMap(Object.entries).reduce(
  (acc, [k, v]) =&gt; ({ ...acc, [k]: [...acc[k]||[], v] }), {})

// You can read it as:
// From all entries of the inner-lists of obj1, 
// create one big flat array of [k, v] out of them
// and go adding each one as a property into a new object acc
// grouping the value in lists.

// Final result will be:
{ a:[5,6,3], b:[6,9,4], c:[7,10,9], d:[8,12], e:[1] }    

"
73106769,WebStorm/IntelliJ does not associate TypeScript file type,"I cannot get IntelliJ/WebStorm to associate a &quot;.ts&quot; file as TypeScript file.
I have created a file named confirmationRequiredRenderer. Initially I created this file by just creating a text file and then adding a .ts at the end of the file name.

Now, no matter what I do, I cannot associated this file as a TypeScript file type. It thinks it is a text file.
These are the actions I have gone through to fix this problem and nothing has worked:

rebuild project
restart IDE
Invalidate caches
creating a TS file through the wizard, and then renaming it
npm build

Any advice on why my IDE is so confused with this file?
","typescript, intellij-idea, webstorm",0,73108311,"
I have created a file named confirmationRequiredRenderer. Initially I created this file by just creating a text file and then adding a .ts at the end of the file name.

That is the source of the problem: the confirmationRequiredRenderer file name is now associated with the Text file type. And it has a &quot;priority&quot; because it's longer/more specific than just default *.ts.
You need to go into the IDE Settings/Preferences and remove such a association for more broad *.ts to be used instead.

Go to Settings/Preferences | Editor | File Types
Locate Text file type there
Locate and remove the offending entry -- should be confirmationRequiredRenderer or very similar to that.
Save the settings, let IDE reindex that file and see how it goes.

If still nothing (pretty unlikely but still possible): it may still have an association in another file type, so may need to check other files types for the same.


P.S. Another alternative is to hard-override the file type for that specific file. Just right click on the file in the Project View panel and choose the right action (Override File Type).
It will work for that specific file but will still be an issue for the file with the same name in another project/another folder. So it's much better to fix the original source of the issue.
"
73179160,Type '()' cannot conform to 'View' on SWIFT,"I'm getting this error when I try to validate password field under a SecureTextField field.
any thoughts?  I did similar with an TextField for Email validation and works just fine! my issue is with the password validation &quot;If&quot;
                HStack {
                
                    TextField(&quot;Email Address&quot;, text: $loginVM.credentials.email) { isEditing in
                        self.isEditing = isEditing
                        
                        errorMessage = &quot;&quot;
                        ////// == getting  email validation boolean after losing  the focus
                        if  isEditing  == false  {
                            if validateEmail(emailAddressString: loginVM.credentials.email) ==  true {
                                errorMessage = &quot;YES, Email is Good&quot;
                                print(errorMessage)
                                } else {
                                errorMessage = &quot;*-Oops,Something is wrong with your email !!!&quot;
                                print(errorMessage)

                            }
                        }
                       
                    }
                   
                    } .textFieldStyle(MyTextFieldStyle(focused: $isEditing))
                    
                        
                HStack {
                    
                    SecureTextField(text: $loginVM.credentials.password)

                            .padding(10)
                            .focused($isInFocus)
                            .background(
                            RoundedRectangle(cornerRadius: 10, style: .continuous)
                            .stroke(isInFocus ? Color.orange : Color.gray, lineWidth: 1))
                    
                               
                            }.disableAutocorrection(true)
                // Here is where I'm getting this Type '()' cannot conform to 'View'
                            if validatePassword(passwordString: loginVM.credentials.password) ==  true {
                                errorMessage = &quot;YES, Password  OK&quot;
                                print(errorMessage)
                                } else {
                                errorMessage = &quot;*-Oops,Something is wrong with your Password !!!&quot;
                                print(errorMessage)

                            }

","ios, swift, validation, view, securefield",0,73181170,"you can wrap your logic inside onSubmit.
the compiler expects some View inside the ViewBuilder
SecureTextField(text: $name)
    .padding(10)
    .focused($isInFocus)
    .disableAutocorrection(true)
    .background(
        RoundedRectangle(
            cornerRadius: 10,
            style: .continuous
        )
        .stroke(isInFocus ? Color.orange : Color.gray, lineWidth: 1)
    )
    .onSubmit {
        if validatePassword(passwordString: loginVM.credentials.password) {
            errorMessage = &quot;YES, Password  OK&quot;
            print(errorMessage)
        } else {
            errorMessage = &quot;*-Oops,Something is wrong with your Password !!!&quot;
            print(errorMessage)
        }
    }

the .onSubmit block will execute when the user presses submit button on the keyboard though i would recommend handling this logic inside a view model and execute the logic once everything is set up
"
73920596,pandas: pivot on two columns,"I have the following data:
import pandas as pd, numpy as np
dates = pd.date_range('01/01/2022', '01/11/2022', freq = 'D')
values = [0,0,1,1,0,0,1,1,1,0,1]
df = pd.DataFrame({'date': dates, 'value': values})
df

    date    value
0   2022-01-01  0
1   2022-01-02  0
2   2022-01-03  1
3   2022-01-04  1
4   2022-01-05  0
5   2022-01-06  0
6   2022-01-07  1
7   2022-01-08  1
8   2022-01-09  1
9   2022-01-10  0
10  2022-01-11  1

I would like to transform this such that i end up with a 'start' and 'end' column such that start is the first occurrence of 1, and end is the last consecutive occurrence of 1.  Basically i should end up with this:
start      end
2022-01-03 2022-01-04  
2022-01-07 2022-01-09
2022-01-11

So what i have done so far is the following:
conditions = [
    (df.value == 1) &amp; (df.value.shift(1) == 0),
    (df.value == 1) &amp; (df.value.shift(-1) == 0)]
choices = ['start', 'end']
df['value'] =  np.select(conditions, choices, default=pd.NA)
df = df.dropna()
df.pivot(columns='value')

    date
value   end         start
2       NaT         2022-01-03
3       2022-01-04  NaT
6       NaT         2022-01-07
8       2022-01-09  NaT
10      NaT         2022-01-11

As you can see it is almost there..and i could do some addition fiddling to get what i want at this point - but i feel maybe im approaching this the wrong way.
Is there a better, more efficient way to solve this problem?
","python, pandas, numpy",1,73920781,"I would use a groupby.agg here:
# which rows have value 1?
m = df['value'].eq(1)

(df[m] # keep only value==1
 .groupby(m.ne(m.shift()).cumsum()) # group by consecutive values
 ['date'].agg(['first', 'last'])    # get first and last date
 .reset_index(drop=True)
)

output:
       first       last
0 2022-01-03 2022-01-04
1 2022-01-07 2022-01-09
2 2022-01-11 2022-01-11

"
74386488,How can I ask for user input in Python?,"So to start coding I have to ask for a user input. They have to place 4 cards like so
A-S,A-H,A-C,A-D

Then I would create a list from their input. It should take the 2nd element then the 4th element from their input
4cards = input()
List1 = []
List1.append(4cards[1], 4cards[3])
List1pair = ', '.join(P2)
print 'List1 cards: {0}.format(List1pair)'

This should or I hope it prints this (I haven't check yet)
List1 cards: A-H,A-D

But my code returns with a syntax error &quot;SyntaxError: invalid syntax&quot;
4cards = input()

How do I resolve this?
","python, python-3.x",-1,74386677,"&quot;SyntaxError: invalid syntax&quot; shows because variable name can not start with numbers. you can use four_cards instead of 4cards.
four_cards = input()

"
72857296,Why my code is not working for problem (Marathon) Code forces,"You are given four distinct integers a, b, c, d.
Timur and three other people are running a marathon. The value a is the distance that Timur has run and b, c, d correspond to the distances the other three participants ran.
Output the number of participants in front of Timur.
Input
The first line contains a single integer t (1â‰¤tâ‰¤104) â€” the number of test cases.
The description of each test case consists of four distinct integers a, b, c, d (0â‰¤a,b,c,dâ‰¤104).
Output
For each test case, output a single integer â€” the number of participants in front of Timur.
#include &lt;iostream&gt;

using namespace std;

int main()
{
    int t, p(0);
    cin &gt;&gt; t;
    while (t--) {
        int a, b, c, d, x;
        cin &gt;&gt; a &gt;&gt; b &gt;&gt; c &gt;&gt; d;
        if (b &gt; a) {
            p++;
        } else if (c &gt; a) {
            p++;
        } else if (d &gt; a) {
            p++;
        }
        cout &lt;&lt; p &lt;&lt; endl;
    }
}

","c++, c++17",-3,72857671,"Try changing the else ifs to ifs and declaring the variable p inside the loop:
#include &lt;iostream&gt;

using namespace std;

int main() {
  ios::sync_with_stdio(false);
  cin.tie(0);
  int t;
  cin &gt;&gt; t;
  while (t--) {
    int p = 0;
    int a, b, c, d;
    cin &gt;&gt; a &gt;&gt; b &gt;&gt; c &gt;&gt; d;
    if (b &gt; a) {
      p++;
    }
    if (c &gt; a) {
      p++;
    }
    if (d &gt; a) {
      p++;
    }
    cout &lt;&lt; p &lt;&lt; '\n';
  }
  return 0;
}

Example Usage:
4
2 3 4 1
10000 0 1 2
500 600 400 300
0 9999 10000 9998
2
0
1
3

"
74407560,Mismatch in expected results of convolution using Conv2d from Pytorch?,"I am experimenting with the conv2d function implemented in PyTorch. I wrote a code sample below where we have a 3x3 matrix of 1 batch, 2 input channels. I implement my convolution layer to have a kernel the exact size of the matrix (so the stride doesn't matter) and an output channel of 1. I fix the weights at 1.
Basically this should just sum up input tensor. Why are the last two printed values slightly differing? Is this the result of some sort of floating point calculation error?
import torch.nn as nn
import torch
m = nn.Conv2d(2, 1, 3, stride=2) 
input = torch.randn(1, 2, 3, 3)
m.weight = torch.nn.Parameter(torch.ones_like(m.weight))

output = m(input)
print(input)
print(torch.sum(input))
print(output)

","machine-learning, deep-learning, pytorch, conv-neural-network, precision",0,74409913,"The bias of Conv2d is not initialized as zeros.
Try this
import torch.nn as nn
import torch
m = nn.Conv2d(2, 1, 3, stride=2) 
input = torch.randn(1, 2, 3, 3)
m.weight = torch.nn.Parameter(torch.ones_like(m.weight))
nn.init.zeros_(m.bias)

output = m(input)
print(input)
print(torch.sum(input))
print(output)

"
73633189,Grouping age in Pandas (Python),"I have a DataFrame with column &quot;ages&quot; and column &quot;professional qualification&quot;, like this:




ages
professional qualification




45
labourer


49
labourer


29
labourer


61
labourer


45
labourer


37
labourer


17
office worker


56
labourer


47
office worker




I want to group the ages like this ( ,17), (17,29), (30,40), (40,50), (50, )
and, with these ages grouped I would to create a frequency table indicating on each age group what professional qualification appears more often.
Example:




ages
professional qualification




(,17)
office worker


(17,29)
labourer


(30,40)
labourer


(40,50)
labourer




etc, etc, etc.
The people who have an age between 40 and 50 (excluding 40) are mostly labourers
All solutions will be appreciated.
","python, pandas, dataframe, grouping, frequency",1,73633224,"Use cut with aggregate by GroupBy.agg custom function by Series.mode with select first element:
bins = [0,17,29,40,50,70,100]

f = lambda x: x.mode().iat[0]
df1 = (df.groupby(pd.cut(df['ages'], bins=bins))['professional qualification']
         .agg(f)
         .reset_index())
print (df1)
        ages professional qualification
0    (0, 17]              office worker
1   (17, 29]                   labourer
2   (29, 40]                   labourer
3   (40, 50]                   labourer
4   (50, 70]                   labourer
5  (70, 100]                       None

"
73985713,How to find and extract parts of a string in a Pandas column and encode it into new columns,"I have a Pandas dataframe with a column like this:




Id
language




01
Spanish - C1


02
No


03
Spanish - B2


04
Spanish - C1 / German - C1 / Portuguese - C1


05
No


06
German C2


07
No


08
Spanish - B2 / Portuguese - C1




Each id can have no language ('No'), it can have a single language followed by its level (eg 'Spanish - B2') or it can have several languages with their level separated by the &quot;/&quot; symbol (eg. &quot;Italian-B1 / Portuguese-C2&quot;).
The idea is to encode in new columns with the information from the 'language' column. For example, something like this:




id
no_lang
Spanish - B2
Spanish - C1
German - C1
German - C2
Portuguese - C1




01
0
0
1
0
0
0


02
1
0
0
0
0
0


03
0
1
0
0
0
0


04
0
0
1
1
0
1


05
1
0
0
0
0
0


06
0
0
0
0
1
0


07
1
0
0
0
0
0


08
0
1
0
0
0
1




If there are multiple languages, they always appear in alphabetical order.
I imagine this is complex and I don't know where to start.
Thanks in advance! Any help is appreciated!
","python, pandas, dataframe",2,73985845,"A possible solution, based on pandas.crosstab:
df['language'] = df['language'].str.split(' / ')
df = df.explode('language')
pd.crosstab(index=df['Id'], columns=df['language'])

Output:
language  German - C1  German C2  No  Portuguese - C1  Spanish - B2  \
Id                                                                    
1                   0          0   0                0             0   
2                   0          0   1                0             0   
3                   0          0   0                0             1   
4                   1          0   0                1             0   
5                   0          0   1                0             0   
6                   0          1   0                0             0   
7                   0          0   1                0             0   
8                   0          0   0                1             1   

language  Spanish - C1  
Id                      
1                    1  
2                    0  
3                    0  
4                    1  
5                    0  
6                    0  
7                    0  
8                    0  

"
74306195,CSS animations cycle doesn't work as it should,"I have created two classes for two animations that pressing a button should turn fullscreen on and off using one animation first and another one after a second press of the button.
CSS
Animate enable fullscreen, animatereverse disable it
    #mv {
        width: 100%;
        height: 57%;
    }

    .animate {
        animation: fullscreen 0.5s;
        animation-fill-mode: forwards;
    }

    @keyframes fullscreen {
        from {
            height: 57%;
        }

        to {
            height: 100%;
        }
    }


    .animatereverse {
        animation: fullscreenreverse 0.5s;
        animation-fill-mode: forwards;
    }

    @keyframes fullscreenreverse {
        from {
            height: 100%;
        }

        to {
            height: 57%;
        }
    }

TS/JS
I used a flag to make the function know if the interface is in fullscreen or not
      var fullscreen = false;
      //console.log(&quot; fullscreen now false &quot;);
        document.getElementById('fllbtn').addEventListener(&quot;click&quot;, function () {          
          if(fullscreen == false){     
            //console.log(&quot; fullscreen is false &quot;);
            fullscreen = true;
            //console.log(&quot; fullscreen now true &quot;);
            document.getElementById(&quot;mv&quot;).classList.toggle(&quot;animate&quot;);
          }else{
            //console.log(&quot; fullscreen is true &quot;);
            fullscreen = false;
            //console.log(&quot; fullscreen now false &quot;);
            document.getElementById(&quot;mv&quot;).classList.toggle(&quot;animatereverse&quot;);
          }
        })

The problem is as follows:
BEGIN
*non-fullscreen interface
*I press fullscreen button
*animation works, interface becomes fullscreen
*I press fullscreen button
*animation works, interface returns to initial non-fullscreen state
*I press fullscreen button
*animation does not work, does not go fullscreen
*I press the fullscreen button
*animation does not work, does not go to fullscreen
END
Think of it as a loop, it basically runs twice, jumps twice and repeats like this.
","javascript, css, typescript, css-animations, keyframe",1,74326904,"I found a better way, I simply use a transition:
CSS
#mv {
    width: 100%;
    height: 57%;
    transition: height 0.5s ease;
}

#mv.fullscreen {
    height: 100%;
}

TS/JS
  document.getElementById('fllbtn').addEventListener(&quot;click&quot;, function () {
    document.getElementById(&quot;mv&quot;).classList.toggle(&quot;fullscreen&quot;);
  })

"
74191220,How to disable B frames in FFmpeg for H.264 encoding?,"I'm encoding video with h264_nvenc, and I would like to disable B-Frames. I'm trying to use -bframes 0 parameter, but I'm not sure if it works, and where exactly put the command.
For now, this is my code:
-probesize 10MB -s 1920x1080 -framerate 30 -i video.h264 -c:v h264_nvenc -preset p7 -tune 4 -rc:v vbr -cq:v 1 -profile:v high -pix_fmt yuv420p -s 1920x1080 -r:v 30 video.h264


Furthermore, should I need to use bframes 0 when I'm already using tune 4 (lossless)?
The original video doesn't have any B-frame.
","ffmpeg, h.264, nvenc",0,74192212,"The FFmpeg option is:

bf integer (encoding,video)
Set max number of B frames between non-B-frames.
Must be an integer between -1 and 16. 0 means that B-frames are disabled. If a &gt; value of -1 is used, it will choose an automatic value depending on the encoder.
Default value is 0.

In libavcodec/nvenc.c it sets frameIntervalP (0 - intra-only, 1 - IPP, 2 - IBP, 3 - IBBP etc.):
if (avctx-&gt;gop_size &gt; 0) {
    if (avctx-&gt;max_b_frames &gt;= 0) {
        /* 0 is intra-only, 1 is I/P only, 2 is one B-Frame, 3 two B-frames, and so on. */
        ctx-&gt;encode_config.frameIntervalP = avctx-&gt;max_b_frames + 1;
    }

    ctx-&gt;encode_config.gopLength = avctx-&gt;gop_size;
} else if (avctx-&gt;gop_size == 0) {
    ctx-&gt;encode_config.frameIntervalP = 0;
    ctx-&gt;encode_config.gopLength = 1;
}

For the older LosslessHP preset the frameIntervalP is 1 (IPP).
If you use the new presets as recommended you should set it manually.
See the NVENC Preset Migration Guide.
"
73968425,GraphQL - How to get child's argument in parent using Java,"I have a schema like this:
type Query {
    shows: [Show]
}

type Show {
    id: Int
    title: String
    audiences(userId: [Int]): [User]
}

type User {
    id: Int
    name: String
}

I think the userId will only appear in User resolver layer, and if there a way to get the userId in Show layer(User's parent layer)?
I've already read this post Get child args in parent in GraphQL, but I have no idea how to achieve it by using Java.
I'm using graphql-java this library.
","java, graphql",1,74167840,"You can get child arguments through the selectionSet:
In your particular case:
environment.getSelectionSet.getImmediateFields.get(2).getArguments will give you the arguments for audience field in shows data fetcher.
This functionality was added some years ago within this PR:
https://github.com/graphql-java/graphql-java/pull/835/files
"
72925947,React: How to select all text in each div,"When I pressed Ctrl + A (Command + A), it's select all text in the page. how can I select only the letters inside the selected div when I pressed Ctrl + A (Command + A)?
Below is my full code.
import React, { useState } from 'react';

const Test = () =&gt; {
  const [chatList, setChatList] = useState([]);
  const onSubmit = (e) =&gt; {
    e.preventDefault();
    const value = e.target[0].value;
    setChatList([...chatList, { value }]);
  };
  return (
    &lt;div&gt;
      &lt;form onSubmit={onSubmit}&gt;
        &lt;textarea placeholder=&quot;Enter text&quot;&gt;&lt;/textarea&gt;
        &lt;button type=&quot;submit&quot;&gt;submit&lt;/button&gt;
      &lt;/form&gt;
      {chatList.map((chat, index) =&gt; (
        &lt;div key={index} style={{ whiteSpace: 'pre-wrap' }}&gt;
          {chat.value}
        &lt;/div&gt;
      ))}
    &lt;/div&gt;
  );
};

export default Test;


",reactjs,0,72926035,"Browsers are not able to selectively highlight using Ctrl+A. Selecting all truly selects all text on the page. There may be browser plugins you can use to select different lines at once but you won't be able to reliably provide others with that experience.
While I don't know the exact use case, I'm going to assume it's to copy/paste the content.
I'd recommend grabbing the values of the different content areas you want and putting those into a textarea (you'll almost certainly want the textarea hidden with style=&quot;display:none&quot;).
Then, once the content is all in the textarea, you can copy it to the clipboard programatically.
Then instead of having users hit Ctrl+A, you can provide an easy &quot;Copy&quot; button which is more instructive to people not familiar with the select all shortcut.
Here's a basic example showing the copy function in vanilla JS.
&lt;textarea&gt;&lt;/textarea&gt;

&lt;script&gt;

    // fetch the textarea
    var textarea = document.querySelector('textarea');

    // add content to the textarea
    textarea.value = '' // clear it
    textarea.value += 'First Content Area' // this represents content from different parts of your site
    textarea.value += 'Second Content Area' // this represents content from different parts of your site
    textarea.value += 'Third Content Area' // this represents content from different parts of your site

    // copy it to the clipboard
    textarea.focus();
    textarea.select();
    document.execCommand('copy');

&lt;/script&gt;

This is a very basic example of copying data. For more details, view this answer: How do I copy to the clipboard in JavaScript?
"
74357958,HTML & CSS - I'm having trouble trying to create a square shape from rounds,"I'm trying to make the following shape with HTML and CSS:

I tried to do this with HTML and CSS but with the code I wrote, I got the following image:

This is my homework and I can't get the round shapes down that should be below. How can I do that? Thanks in advance for your help.


* {
  margin: 0;
  padding: 0;
}

.container {
  margin: 0 auto;
  height: 250px;
  width: 250px;
  background-color: grey;
}

.box {
  background-color: red;
  width: 50px;
  height: 50px;
  border-radius: 50px;
}

.left-flex {
  display: flex;
  flex-direction: column;
  float: left;
}

.right-flex {
  display: flex;
  flex-direction: column;
  float: right;
}

.top-flex {
  display: flex;
  flex-direction: row;
  justify-items: start;
}

.bottom-flex {
  display: flex;
  flex-direction: row;
  justify-items: end;
}
&lt;div class=""container""&gt;
  &lt;div class=""left-flex""&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=""right-flex""&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=""top-flex""&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=""bottom-flex""&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;



","html, css",1,74358035,"Simplify your code and think in rows. The 3 center rows have only 2 boxes. Then space them apart with justify-content: space-between


* {
  margin: 0;
  padding: 0;
}

.container {
  margin: 0 auto;
  height: 300px;
  width: 300px;
  background-color: grey;
  flex-direction: column;
}

.container,
.row {
  display: flex;
  justify-content: space-between;
}

.box {
  background-color: red;
  width: 50px;
  height: 50px;
  border-radius: 50px;
}
&lt;div class=""container""&gt;
  &lt;div class=""row""&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=""row""&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=""row""&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=""row""&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=""row""&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
    &lt;div class=""box""&gt;&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;



EDIT: If you want to do the spacings, add the same flexbox and justify-content: space-between to the container. Just change the flex-direction to column. If you make the container then wider and taller, you create equal gaps by default.
"
73072459,How can use filter and contains with multi-ArrayList in Kotlin so I only have elements which match the condition?,"I have a class called Person
data class Person(
    val id: Int,
    val name: String
)

data class IDs(
    val id : Int,
    val active : Boolean )

and an array list that has numbers of ids and another list of Persons
val myStu = listOf&lt;Person&gt;(Person(1, &quot;Name_1&quot;), Person(2, &quot;Name_2&quot;), Person(3, &quot;Name_3&quot;))
var ids = listOf&lt;IDs&gt;(IDs(1,false),IDs(2,true),IDs(3,true))
var newIds = listOf&lt;Int&gt;(2,3,4,6)

First I want to apply two actions to the myStu, first is to have a list that include all the items from myStu that his id matches the id in the IDS and only if the active is true
myStu or the new list will have the values
Person(2, &quot;Name_2&quot;), Person(3, &quot;Name_3&quot;))

Then do action two , I need to add a new item to the new list that their id does not exist in the newIds , in another word we will add a new person Person(4,&quot;None&quot;) and (6,&quot;None) , 4 and 6 values come from newIds list
the final output will be :
   id= 2 name = &quot;Name_2&quot;, id= 3 name = &quot;Name_3&quot;, id= 4 name = &quot;None&quot; , id =6 name=&quot;None&quot;

I want to write the code with filter , I failed with first step because I don't know how to use contains() with the list inside the filter
val newArr = myStu.filter {
    ids.contains(it.id)
}

","kotlin, filter",0,73072827,"The &quot;easiest&quot; way of doing that would be to use filter directly, there's no need for contains. If we were to use contains, then we would need to also search for which element contained the id, in order to get the status. We can just do a .any() to do both at the same time.
V1
val activeStu = myStu.filter { person -&gt; ids.any { it.id == person.id &amp;&amp; it.active } }

val result = newIds.map { newId -&gt;
    activeStu.find { it.id == newId } ?: Person(id = newId, name = &quot;None&quot;)
}

Another method, that might work a bit better if we have big lists, would be to first transform the IDs list into a map. That way the second part of our code is a bit more efficient, since there is no search involved.
V2
val idsMap = ids.associate { it.id to it.active }
val activeStu = myStu.filter { idsMap[it.id] ?: false }

//the creation of the result list is the same


Version without creating 2 new lists. This works, but it might be quite ineficient processing wise, and also harder to understand what is going on IMO.
V3
val result = newIds.map { newId -&gt;
    //try to find an IDs with the current newId and status as true
    when (ids.find { it.id == newId }?.active) {
        //if found, then find the corresponding Person  
        true -&gt; myStu.find { it.id == newId } ?: Person(newId, &quot;None&quot;) // if this happens, it means that an IDs with status true existed and no Person had that id. Not sure what you want in this scenario, this version creates one of the &quot;none&quot; persons.
        //if not found, then create a new one
        else -&gt; Person(newId, &quot;None&quot;)
    }
}

Note: depending on what version of kotlin you have, you might have to change the when statement to this:
when (ids.find { it.id == newId }?.active == true)

Since I think I remember that null didn't used to be treated as false in old versions (I've run this with version 1.4.20).
Btw, you can also use this version with the idsMap from V2, just replace the when(...) with when(idsMap[newId] or when(idsMap[newId] == true) depending on the kotlin version.
"
73354989,Remove array duplicates (the old way),"What's up guys, I was just messing arround LeetCode, and different ways to solving this problem (I know the Set way and the for of with array.includes + push, and the filter, but all of them create a new array), and with this method I'm getting this output, can someone explain me why?
P.S. You can't create a new array, just modify the first one.


let nums = [0, 0, 1, 1, 1, 2, 2, 3, 3, 4];

var removeDuplicates = (nums) =&gt; {
  for (let i = 0; i &lt; nums.length; i++) {
    if (nums[i] === nums[i + 1]) {
      nums.splice(i, i + 1);
    }
  }
};

removeDuplicates(nums);

console.log(nums);
// [0, 1, 3, 4]



",javascript,1,73355071,"The first problem is here: nums.splice(i, i + 1);
Array splice method takes 2 arguments, the first one is the index of element, and the second one is a number of elements to replace/remove (it seems you confused the second argument with the end index). Source: Array.prototype.splice()
Another problem is changing the original array, while iterating over it (be very careful with such in-place manipulations, they very often result in some kind of errors). Look at what is happening in your loop:

You have some array [0, 0, 0, 1, 1, 2, 2];
You want to remove the first element, since it is a duplicate: [0, 0, 0, 1, 1, 2, 2];
After removing, you have [0, 0, 1, 1, 2, 2];
You increment your i, so now it is equal to 1;
You look at the element with index 1, and find no duplicates [0, 0, 1, 1, 2, 2], since you just skipped the element, that moved into the first index in place of the removed element.

The solution is to decrement the i after removing the element:


let nums = [0, 0, 1, 1, 1, 2, 2, 3, 3, 4];

var removeDuplicates = (nums) =&gt; {
  for (let i = 0; i &lt; nums.length; i++) {
    if (nums[i] === nums[i + 1]) {
      nums.splice(i, 1);
      i--;
    }
  }
};

removeDuplicates(nums);

console.log(nums);
// [0, 1, 2, 3, 4]



"
74512813,No output when looping over numerous files using an awk script,"I have 50 text files that looks like this. All the file names begin with ENSG00000...
&quot;number&quot;    &quot;variant_id&quot;    &quot;gene_id&quot;   &quot;tss_distance&quot;  &quot;ma_samples&quot;    &quot;ma_count&quot;  &quot;maf&quot;   &quot;pval_nominal&quot;&quot;slope&quot;   &quot;slope_se&quot;  &quot;hg38_chr&quot;  &quot;hg38_pos&quot;  &quot;ref_allele&quot;    &quot;alt_allele&quot;    &quot;hg19_chr&quot;  &quot;hg19_pos&quot;  &quot;ID&quot;    &quot;new_MAF&quot;   &quot;CHROM&quot; &quot;POS&quot;   &quot;REF&quot;   &quot;ALT&quot;   &quot;A1&quot;    &quot;OBS_CT&quot;    &quot;BETA&quot;  &quot;SE&quot;    &quot;P&quot; &quot;SD&quot;    &quot;Variance&quot;
&quot;14&quot;    6253456 &quot;chr1_17726150_G_A_b38&quot; &quot;ENSG00000186715.10&quot;    955913  68  78  0.0644628   0.895156    0.0139683   0.105945    &quot;chr1&quot;  17726150    &quot;G&quot; &quot;A&quot; &quot;chr1&quot;  18052645    &quot;rs260514:18052645:G:A0.058155  1   18052645    &quot;G&quot; &quot;A&quot; &quot;G&quot; 1597    0.0147047   0.0656528   0.822804    2.62364886486368    6.88353336610048

I want to get rid of the speech marks surrounding every value in the file, so it looks like this below. I am using the script below which works for when I try with one file.
number  variant_id  gene_id  tss_distance   ma_samples  ma_count    maf pval_nominal slope  slope_se    hg38_chr    hg38_pos    ref_allele  alt_allele  hg19_chr    hg19_pos    ID  new_MAF CHROM   POS REF ALT A1  OBS_CT  BETA    SE P    SD Variance
14  6253456 chr1_17726150_G_A_b38   ENSG00000186715.10  955913  68  78  0.0644628   0.895156    0.0139683   0.105945    chr1    17726150    G   A   chr1    18052645    rs260514:18052645:G:A0.058155   1   18052645    G   A   G   1597    0.0147047   0.0656528   0.822804    2.62364886486368    6.88353336610048

However, I want to apply the awk script to all 50 files via a loop. However, when I use the script below I get no output.
#!/bin/bash
#PBS -N Edit
#PBS -l walltime=01:00:00
#PBS -l nodes=1:ppn=8
#PBS -l vmem=10gb
#PBS -m bea

for i in ENSG00000*; do
    awk '{ gsub(/&quot;/, &quot;&quot;); print }' &gt; $i.out
done

","bash, loops, awk",0,74512881,"You forgot to specify the input file for awk to scan. Try:
for i in ENSG00000*; do
    awk '{ gsub(/&quot;/, &quot;&quot;); print }' $i &gt; $i.out
done

"
74345581,How to use regexp with linux expect?,"I want to use Duplicity to backup my files from shell, but it requires the password to be passed twice before run. I thought of expect to solve the problem, but I cannot make it work.
What I tried:
expect &quot;Local and Remote metadata are synchronized, no sync needed.\nLast full backup date: none\nLast full backup is too old, forcing full backup\nGnuPG passphrase for decryption: &quot; {send &quot;$pass\r&quot;}
expect &quot;Retype passphrase for decryption to confirm: &quot; {send &quot;$pass\r&quot;}

There is a multi line message from Duplicity. I tried expect -re to use regexp, but it did not recognize the r option.
I use Alpine in a docker container.
","shell, expect, alpine-linux, duplicity-backup",0,74347856,"The first pattern is not matching because Expect uses \r\n for all newlines.
Run your code with expect -f script.exp for verbose output to see how expect is attempting to match.
You could write
expect &quot;Local and Remote metadata*GnuPG passphrase for decryption: &quot; {send &quot;$pass\r&quot;}

By default, the expect command uses glob-matching like the tcl string match commabnd
"
74382338,IConfiguration - how to bind dynamic values from configuration to object,"I am having configuration.ini file which contain following content -&gt;
[Objects]
obj1={7CE7ECE0-B70D-4622-8F4B-D999E5F06AAD}
obj2={5964945B-C31B-4805-9408-D56A4A5457CF}
obj3={5964945B-C31B-4805-9408-D56A4A5457CF}

Those keys - objN can be dynamically added.
With help of ConfigurationBuilder I am creating the config -&gt;
IConfigurationRoot configuration = new ConfigurationBuilder()
     .AddIniFile(Path.Combine(configFolderPath, @&quot;Configuration.ini&quot;))
     .Build();

Now when it come to the topic of Binding to object I get stuck and cant find any solution.

services.AddOptions&lt;SomeObject&gt;()
                .Bind(_configuration.GetSection(&quot;Object&quot;))

P.S

As temporary solution I found is to get configuration section as enumerable which is dictionary&lt;string,string&gt; and then map it manually. This is just look quite dirty.
configuration.GetSection(&quot;Objects&quot;).AsEnumerable()

","c#, .net",-1,74382629,"I would say Guru Stron gave you the answer.
services.Configure&lt;Dictionary&lt;string, Guid&gt;&gt;(_configuration.GetSection(&quot;Objects&quot;));

Then, consume with DI:
public class SomeService
{
    private Dictionary&lt;string, Guid&gt; Objects { get; }
    public SomeService(IOptions&lt;Dictionary&lt;string,Guid&gt;&gt; objects)
    {
        Objects = objects.Value;
    }
}

If you feel that Dictionary&lt;string,Guid&gt; is not a specific-enough data type, simply create a derived class:
public class MyObjectDictionary : Dictionary&lt;string, Guid&gt;
{ }

Then use MyObjectDictionary as the type in the call to services.Configure&lt;&gt;().
"
74237043,Importing methods from built-in class for use in custom class - Python,"I created a class with extended methods for the built-in 'str' class, but I want the user to be able to use those normal built-in methods for strings as well as my extra methods. How would I do this without having to manually code each method already in the 'str' class?
class StringMethods:
    &quot;&quot;&quot;
    StringMethods class:
    
    A class similar to the built in python str class
    but with extended methods for string analysis, password checking etc.
    &quot;&quot;&quot;
    
    def __init__(self, string: str) -&gt; None:
        
        self.string = string
    
    
    def contains(self, char: str) -&gt; bool:
        
        if char in self.string:
            return True
        return False
    
    
    def containsany(self, chars: str | list | tuple | set) -&gt; bool:
        
        for char in chars:
            if char in self.string:
                return True
        return False
    
    
    def hasdigit(self) -&gt; bool: return self.containsany(&quot;0123456789&quot;)
    def haslower(self) -&gt; bool: return self.containsany(&quot;abcdefghijklmnopqrstuvwxyz&quot;)
    def hasupper(self) -&gt; bool: return self.containsany(&quot;ABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;)
    def haswhitespace(self) -&gt; bool: return self.contains(&quot; &quot;)


# I want the user to be able to do the following:
my_string = StringMethods(&quot;string123&quot;)
print(my_string.hasdigit()) # custom method
print(my_string.upper())    # built-in str method

","python, string, class, methods",0,74237665,"Here is a class that inherits from str() and is extended with your functions.
class StringMethod(str):
&quot;&quot;&quot;
StringMethods class:

A class inheriting from the built in python str class
but with extended methods for string analysis, password checking etc.
&quot;&quot;&quot;

def contains(self, char: str) -&gt; bool:
    
    return self.__contains__(char)


def containsany(self, chars: str | list | tuple | set) -&gt; bool:
    
    for char in chars:
        if char in self.__str__():
            return True
    return False


def hasdigit(self) -&gt; bool: return self.containsany(&quot;0123456789&quot;)
def haslower(self) -&gt; bool: return self.containsany(&quot;abcdefghijklmnopqrstuvwxyz&quot;)
def hasupper(self) -&gt; bool: return self.containsany(&quot;ABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;)
def haswhitespace(self) -&gt; bool: return self.contains(&quot; &quot;)

Notice that I dropped the __init__() method as str() provides that already. With this class you can use any builtin string methods plus your own special methods.
"
74594144,Check if column data exists in column and return value of the another column in R,"I want to check if values from column B exist in column A, and if yes and equal with the value in that row, create another column D, getting the value from column C (for the A on that row).




A
B
C
D




a
f
12
55


b
a
23
12


c
b
33
23


d
c
1
33


e
e
11
11


f
d
55
1




This is what I have, but it's not working as it should as it is setting the value of D by just checking if the value exists in column A and not comparing them.
  ifelse(df$B %in% df$A, df$C , NA)

","r, dplyr",0,74594226,"You could also do:
transform(df1, D = setNames(C,A)[B])

  A B  C  D
1 a f 12 55
2 b a 23 12
3 c b 33 23
4 d c  1 33
5 e e 11 11
6 f d 55  1

"
74168837,How do I combine a nested list of multiple data frames? Getting the following error,"I have eight data frames with various number of columns in each. I went through the process of data cleansing and combined all the common columns between them.
This is the code I used to combine the commons columns.What I want to do now is combine all the columns in the nested lists as one then convert it to a data frame.
However, I get the following error:
Can't join on `x$Corruption` x `y$Corruption` because of
  incompatible types.
i `x$Corruption` is of type &lt;double&gt;&gt;.
i `y$Corruption` is of type &lt;character&gt;&gt;.

My code:
# Code used to combine common columns:
common_cols &lt;- Reduce(intersect, list(colnames(df_2015), colnames(df_2016),colnames(df_2017),
                                 colnames(df_2018),colnames(df_2019),colnames(df_2020),
                                 colnames(df_2021),colnames(df_2022)))

files &lt;- list(df_2015[common_cols],df_2016[common_cols], df_2017[common_cols], df_2018[common_cols],
            df_2019[common_cols],df_2020[common_cols],df_2021[common_cols],df_2022[common_cols])

files &lt;- Reduce(full_join,files) # Trying to use this code to combine all the nested lists columns as one.

","r, list, dataframe, nested",1,74168970,"Here is a way.

Start by putting the data.frames in a list;
loop through the list with lapply and if column Corruption is of class &quot;character&quot; coerce it to class &quot;numeric&quot;.

The instructions that follow those two steps should output the same as the posted code but are much simpler. They show one of the reasons why it's better to have the data in one object, in this case a list.
(The other reason is not to clutter the .GlobalEnv.)
df_list &lt;- list(df_2015, df_2016, df_2017, df_2018, 
                df_2019, df_2020, df_2021, df_2022)
df_list &lt;- lapply(df_list, \(x) {
  if(is.character(x$Corruption)) x$Corruption &lt;- as.numeric(x$Corruption)
  x
})

col_names &lt;- lapply(df_list, names)
common_cols &lt;- Reduce(intersect, col_names)

files &lt;- lapply(df_list, `[`, common_cols)
files &lt;- Reduce(dplyr::full_join, files)

"
73784320,How to set up the 1Password SSH agent for Gitkraken?,"Although Gitkraken is compatible with 1Password, this is not working out of the box even with Use local SSH agent option checked in Preferences.
https://developer.1password.com/docs/ssh/agent/compatibility/#gitkraken

","ssh, 1password",1,73784321,"Short answer:
Prepend the following line to desktop entry of Gitkraken and replace the USER:
Exec=env SSH_AUTH_SOCK=/home/USER/.1password/agent.sock 


To fix this (fix is required after each upgrade of Gitkraken) you edit desktop entries with correct env variable.
Make sure your entry path matches one used for your distribution in this case Ubuntu.
vim /usr/share/applications/gitkraken-url-handler.desktop
# /usr/share/applications/gitkraken-url-handler.desktop
[Desktop Entry]
Name=GitKraken
Comment=Unleash your repo
GenericName=Git Client
Exec=/usr/bin/gitkraken --uri=%U
Icon=/usr/share/pixmaps/gitkraken.png
Type=Application
NoDisplay=true
StartupNotify=true
Categories=GNOME;GTK;Development;RevisionControl;
MimeType=x-scheme-handler/gitkraken;
StartupWMClass=gitkraken

And extend the line with Exec to:
Exec=env SSH_AUTH_SOCK=/home/USER/.1password/agent.sock /usr/bin/gitkraken --uri=%U

You should also do the same for this entry as well:
#/usr/share/applications/gitkraken.desktop
[Desktop Entry]
Name=GitKraken
Comment=Unleash your repo
GenericName=Git Client
Exec=/usr/share/gitkraken/gitkraken %U
Icon=/usr/share/pixmaps/gitkraken.png
Type=Application
StartupNotify=true
Categories=GNOME;GTK;Development;RevisionControl;
MimeType=text/plain;
StartupWMClass=gitkraken

Modified line:
Exec=env SSH_AUTH_SOCK=/home/USER/.1password/agent.sock /usr/share/gitkraken/gitkraken %U

Make sure to replace USER with actual USER wise step would be to have those in your home directory as desktop entries.
"
73377019,Gitlab commit author is different than pipeline author (triggerer),"I think there was a previous git account on my computer, I tried to uninstall Git and re-install it and did the following commands to configure it :
git config --global user.name &quot;myusername&quot;
git config --global user.email myemail
But I always get a wrong user as pipeline triggerer :

What can I do ?
Thanks
Update 1 : I get the correct user name as commit author, the problem is only on pipelines.
","git, gitlab, gitlab-ci, commit, git-commit",0,73380360,"Your credentials used to push determine the pipeline user, not the commit author. Otherwise, you could arbitrarily impersonate users for pipelines just by changing the commit author. The commit author has no bearing on the pipeline &quot;triggered by&quot; user.
You are probably still using the SSH key or username/password to your other &quot;wrong&quot; account when pushing to GitLab or otherwise triggering the pipeline. You will need to update your git ssh or https authentication to use the intended account.
"
73210611,Why is it necessary to establish a tnsnames.ora file prior to running a python-oracledb query?,"When using cx_Oracle (8.3.0), it is simple to connect to an Oracle DB with just this line of code:
con = cx_Oracle.connect(user = myname, password = mypw, dsn = &quot;myDBprod&quot;)

When I swap out for oracledb module (1.0.2), I get an error:
con = oracledb.connect(user = myname, password = mypw, dsn = &quot;myDBprod&quot;)

DatabaseError: DPY-4026: cannot connect to database. File tnsnames.ora not found in C:\Oracle\InstantAdmin

While researching this, I found this post: With python-oracledb what does &#39;DPY-4027: no configuration directory to search for tnsnames.ora&#39; mean But I have no clue why all these extra steps are necessary.
","python, python-oracledb",0,73211052,"I can explain why this is necessary. With cx_Oracle, an Instant Client (or Oracle Database) installation is required. These installations have a default location for tnsnames.ora: &lt;install_dir&gt;/network/admin/tnsnames.ora. So if you put the file in that location you don't need to specify its location. The thin driver doesn't require an Oracle Client (or Database) installation, so there is no default location. So you have to do one of the following:

set the environment variable TNS_ADMIN to point to the location where your tnsnames.ora file is found
pass the location where your tnsnames.ora file is found in your code, as in:

con = oracledb.connect(user=myname, password=mypw, dsn=&quot;myDBprod&quot;,
                       config_dir=&quot;/the/directory/of/tnsnames.ora&quot;)

If you have an Oracle Client installation already (since you were using cx_Oracle), you can also enable thick mode which behaves the same way as cx_Oracle. You can do that by doing this:
oracledb.init_oracle_client()

"
74548191,How to identify what currency is in cell?,"I need function what will return currency type of cell property. Is it possible?

I found only =TYPE(cell) method what return only data type (number, string etc)
","regex, google-sheets, match, locale, vlookup",1,74548291,"there isn't such a function. you will need to try something like:
 =INDEX(IFNA(VLOOKUP(REGEXREPLACE(TO_TEXT(A1:A3), &quot;[0-9, ]&quot;, ), 
  {&quot;$&quot;, &quot;USD&quot;; &quot;â‚¬&quot;, &quot;EUR&quot;; &quot;zÅ‚&quot;, &quot;PLN&quot;}, 2, 0)))

also, you may want to see: https://stackoverflow.com/questions/73767719/locale-differences-in-google-sheets-documentation-missing-pages

"
73502432,How Can I Handle State In Jetpack Compose?,"I try to change the value of a card with a slider, but it won't work. The slider is not movable and the value in the card don't change. Do you have an idea what I'm doing wrong?
View Model:
class CardSelectionViewModel: ViewModel() {
private var _state by mutableStateOf(
    CardState()
)
val state: CardState
    get() = _state

fun setCardValue(value: Float){
    CardState().value = (Math.round(value * 2) / 2.0).toFloat()
}
}
data class CardState(
var value: Float = 0f
)

View:
   @Composable
   fun CardSelectionScreen(state: CardState) {
    val viewModel = CardSelectionViewModel()
    CardSelectionScreenTheme {
        Column(
            verticalArrangement = Arrangement.Center,
            horizontalAlignment = Alignment.CenterHorizontally,
            modifier = Modifier.fillMaxSize()
        ) {
            CardContent(remember{viewModel.state.value})
            Slider(
                value = viewModel.state.value,
                onValueChange = {
                    viewModel.setCardValue(it)
                },
                valueRange = 0f..7f,
                modifier = Modifier.width(300.dp)
            )
            Button(onClick = {
                state.value ++
                println(state.value) }) {
                Text(text = stringResource(R.string.Continue))
            }

        }

    }
}

","android, android-jetpack-compose, viewmodel",0,73502503,"You are creating new instance of CardState() inside setCardValue instead of setting _state =  CardState((Math.round(value * 2) / 2.0).toFloat())
"
73515934,Ansible variable 'null' vs. 'None',"From what I understood reading about the topic, null and &quot;{{ None }}&quot; are basically the same thing in Ansible. The difference is that the former is language agnostic YAML syntax and the latter is Python specific (I do not speak that language so I do not know how correct that is). However, as the following Ansible playbook shows, they are different.
- hosts: localhost
  vars:
    a: null
    b: &quot;{{ None }}&quot;
  tasks:
  - name: a always
    debug:
      var: a
  - name: a if none
    debug:
      var: a
    when: a==None
  - name: a if not none
    debug:
      var: a
    when: a!=None
  - name: b always
    debug:
      var: b
  - name: b if none
    debug:
      var: b
    when: b==None
  - name: b if not none
    debug:
      var: b
    when: b!=None

The output from the above is this:
PLAY [localhost] *******************************************************************************************************************************************************************************

TASK [Gathering Facts] *************************************************************************************************************************************************************************
ok: [localhost]

TASK [a always] ********************************************************************************************************************************************************************************
ok: [localhost] =&gt; {
    &quot;a&quot;: null
}

TASK [a if none] *******************************************************************************************************************************************************************************
ok: [localhost] =&gt; {
    &quot;a&quot;: null
}

TASK [a if not none] ***************************************************************************************************************************************************************************
skipping: [localhost]

TASK [b always] ********************************************************************************************************************************************************************************
ok: [localhost] =&gt; {
    &quot;b&quot;: &quot;&quot;
}

TASK [b if none] *******************************************************************************************************************************************************************************
skipping: [localhost]

TASK [b if not none] ***************************************************************************************************************************************************************************
ok: [localhost] =&gt; {
    &quot;b&quot;: &quot;&quot;
}

PLAY RECAP *************************************************************************************************************************************************************************************
localhost                  : ok=5    changed=0    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   

I am not so much concerned about the output null vs. &quot;&quot;, but what really bothers me is the different test results a==None compared to b==None.
Can somebody please help me understand what I am missing here?
",ansible,2,73516259,"Regarding

From what I understood reading about the topic, null and &quot;{{ None }}&quot; are basically the same thing in Ansible.

there was a longer conversation under Ansible Issue #7984 &quot;Ansible substitutes YAML null value with &quot;None&quot; in templates&quot;.

The difference is that the former is language agnostic YAML syntax and the latter is Python specific

Right, such is discussed under the above mentioned issue.
From the discussion there I understand also that such test is meant for testing defined. And since

To check if it is defined and truthy ...  The string &quot;None&quot; evaluates as truthy and defined, the actual python None evaluates as &quot;falsey&quot; and defined.

a test might look like
---
- hosts: localhost
  become: false
  gather_facts: false

  vars:

    a: null
    b: &quot;{{ None }}&quot;

  tasks:

  - name: a if none
    debug:
      var: a
    when: a == None

  - name: b if none
    debug:
      var: b
    when: b is defined and not b

Further Discussions and Documentation

Ansible Issue #37441 &quot;Ansible incorrectly evaluates 'null' as a variable name in when statements&quot;
Ansible: How to check if a variable is not null?
How to create a null default in Ansible?
Making variables optional


If you are interested more in they types of the variables you may have a look into
---
- hosts: localhost
  become: false
  gather_facts: false

  vars:

    a: null
    b: &quot;{{ None }}&quot;
    c: !!null

  tasks:

  - name: a if none
    debug:
      msg: 'a: &quot;{{ a }}&quot; is of {{ a | type_debug }}'
    when: a == None

  - name: b if none
    debug:
      msg: 'b: &quot;{{ b }}&quot; is of {{ b | type_debug }}'
    when: b is defined and not b

  - name: c if none
    debug:
      msg: &quot;{{ c }}&quot;
    when: c ==  None

resulting into an output of
TASK [a if none] ************
ok: [localhost] =&gt;
  msg: 'a: &quot;&quot; is of NoneType'

TASK [b if none] ************
ok: [localhost] =&gt;
  msg: 'b: &quot;&quot; is of unicode'

TASK [c if none] ************
ok: [localhost] =&gt;
  msg: null

"
72936313,Python mockito - how to verify method's fields,"I'm working with python mockito in my unit test. I'm familiar with the abilities of mockito, such as verify, mock, capture, etc., but I wonder how to verify the value of the method's fileds.
My production code.
class Dog(BaseModel):
    type: str
    age: int

    def bark(self, times: int) -&gt; None:
        print(f&quot;{self.type} {self.age}  {'ruf' * times}&quot;)


class FlowManager:

    def __init__(self, barks: int, dog_type: str, age: int):
        self.barks = barks
        self.dog_type = dog_type
        self.age = age

    def foo(self):
        # Some code....
        dog = Dog(type=self.dog_type, age=self.age)
        dog.bark(self.barks)
        # More some code...

And this is the unit test that covers the &quot;foo&quot; method of the &quot;FlowManager&quot; class.
from mockito import verify, when
class TestFlowManager(unittest.TestCase):

    def test_foo_happy_flow(self):
        # Arrange
        when(Dog).bark(...).thenReturn(None)

        # Act
        num_of_barks = 5
        dog_type = &quot;bulldog&quot;
        dog_age = 3
        FlowManager(num_of_barks, dog_type, dog_age).foo()

        # Assert
        verify(Dog).bark(num_of_barks)

My question is: How could I assert the properties of the Dog object. In other words: how could I assert the Dog class created with dog_type==&quot;bulldog&quot; and dog_age==3?
Thanks!
","python, unit-testing, mockito",0,72987412,"It looks like you don't inject Dog into FlowManager or its methods.  Within foo you call a modules global Dog so you probably have to intercept that:
when(module_under_test).Dog(type=&quot;bulldog&quot;, age=3).thenReturn(mock())

Since the when configuration is really specific you maybe don't need to verify anything.  (foo has the type None -&gt; None; it's just a side-effect out of the blue :grin:)
"
74110774,R dplyr: replace Inf values by 0?,"I wonder how to replace the Inf values by 0 across all columns in the dataframe? I have tried several examples, but most answers work only for the vectors, not for the whole dataframe, eg. here or replace NA but not Inf. I am sure there has to be some more ellegant way directly in dplyr!
Dummy example:
df &lt;- data.frame(vals &lt;- c(1, Inf, NA, NaN))

Not working conversions:
df[!is.finite(df)] &lt;- 0

df %&gt;% mutate(across(everything(), !is.finite(), -99))

Errors:
Error in is.finite(df) : default method not implemented for type 'list'

or
Error in `mutate()`:
! Problem while computing `..1 =
  across(everything(), !is.finite(), -99)`.
Caused by error in `is.finite()`:
! 0 arguments passed to 'is.finite' which requires 1

","r, dplyr",0,74110921,"df[as.matrix(df) == Inf]  &lt;- 0

"
73113554,How can i write this as a while loop? PHP,"&lt;?php
for ($i=0; $i&lt;10; $i++) {
    $number = mt_rand(1, 100);
    if ($number %2== 0) {
        $result = 'even';
    } else {
        $result = 'odd';
    }
    echo $number.' '.'('.$result.')'.'&lt;br&gt;';
}?&gt;

I want to write it in a while loop form
this is as far as i have gotten. It just prints one random number and nothing else. I am using phpStorm and edge browser on PHP8.1.
&lt;?php

$i=0;
while ($i&lt;10) {
  if ($number=mt_rand(1,100)) {
    $result = 'even';
  } else {
    $result = 'odd';
  }
  $i++;
  echo $number.' '.'('.$result.')'.'&lt;br&gt;';
}
    
?&gt;

",php,0,73113682,"The main reason that the code is not working is that you are assigning the $number = mt_rand(1,100) inside the if() condition.
So everytime you execute if then it will not compare but it'll keep assigning the $number variable. I have separated the assignment and comparison logic.
Try This:
&lt;?php

    $i=0;
    while ($i&lt;10) {
        $number = mt_rand(1,100);
        if ($number % 2 == 0) {
            $result = 'even';
        } else {
            $result = 'odd';
        }
        $i++;
        echo $number.' '.'('.$result.')'.'&lt;br&gt;';
    }

"
73960832,"""RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!"" in Azure DevOps - Azure IoT Edge Task - build","One of my deployment pipelines on Azure DevOps fails when executing the build module images action of Azure IoT Edge task. I am trying to deploy a custom module developed using the Azure IoT SDK for C# (.NET 6).
Error message:
##[error]/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!  
I tried to include this solution as CmdLine task before the build task. It worked a few runs and then failed again.
The pipeline already had a &quot;Temporary fix&quot; installing iotedgedev separately as a workaround for this bug
The deployment logs don't tell much about where to focus. I wonder what could be the cause of this issue? and if there is a quick fix or something to avoid while developing the application (i.e. warning messages while building or something like that)
","azure, azure-devops, azure-iot-edge",1,74096068,"Short answer -&gt; force pyOpenSSL to version 22.0.0
(Edited 09.01.20223)

pip install -U iotedgedev pyOpenSSL==22.0.0 urllib3 requests

The cause seems to be a reported bug related to a dependency issue connected to a new pyOpenSSL release: github.com/Azure/iotedgedev/issues/589
pyOpenSSL&gt;=20.0.1 on iotedgedev requirements resolves pyOpenSSL-22.1.0 creating some conflict with urlib or chardet
In this case, a temporary fix needed a &quot;quick&quot; temporary fix :D
"
74387517,Use request to translate file by google.translate.com,"I added file translation function for google-trans-new library. All is working fine but the request returns the file I posted. I need help....

https://gist.github.com/thuanpham582002/a84130c89bc7a91fb200dfd49a07764a
Here is the code: Line 115 - 190
",python-requests,0,74396721,"I already know where my problem is, in google request there is an element which is 'x-goog-batchexecute-bgr'. value of 'x-goog-batchexecute-bgr' is generated with different files. If incorrect code is generated, it will return the original file. Thank for all!
"
73634127,How to find the number of bytes that Garbage Collector has freed up till now?,"Can anyone tell me How to find out the amount of memory that GC has freed up in an application until now?
",java,2,73634220,"The GarbageCollectorMXBean exposes garbage collector information, but only the number of collection runs and total time, and no information of the number of objects collected or memory freed.
So from the standard API, there's no way to get this information.
I assume that this would actually be quite an overhead for any garbage collector implementation to compute the actually freed size, so I doubt that this information can be obtained even from the actual GC implementations.
"
73316739,Flutter How can i clip half of my circle on border?,"I have a bordered container. I want to add a half circle and make it looks like clipped as a coupon. But i cant clip my circle as i wanted. I want my circle will be on border so it will look like coupon. But i cant figure out how can i do it.
Its what i wanted :

Its what i did for now :

If I can clip that circles it will be like how i want but i dont know how can i do it. Its my code for that widget :
Container(
      height: 168,
      width: double.infinity,
      decoration: BoxDecoration(
        border: Border.all(
          color: ColorService.purple,
        ),
        borderRadius: BorderRadius.circular(8),
      ),
      child: Row(
        children: [
          Expanded(
            flex: 5,
            child: Container(
              decoration: BoxDecoration(
                borderRadius: BorderRadius.only(
                  topLeft: Radius.circular(8),
                  bottomLeft: Radius.circular(8),
                ),
                color: Colors.amberAccent,
              ),
            ),
          ),
          Container(
            width: 20,
            child: Column(
              children: [
                Container(
                  transform: Matrix4.translationValues(0, -10, 0),
                  width: 20,
                  height: 20,
                  decoration: BoxDecoration(
                    color: Colors.white,
                    border: Border.all(
                      color: ColorService.purple,
                    ),
                    shape: BoxShape.circle,
                  ),
                ),
                Spacer(),
                Container(
                  transform: Matrix4.translationValues(0, 10, 0),
                  width: 20,
                  height: 20,
                  decoration: BoxDecoration(
                    color: Colors.white,
                    border: Border.all(
                      color: ColorService.purple,
                    ),
                    shape: BoxShape.circle,
                  ),
                ),
              ],
            ),
          ),
          Expanded(
            flex: 3,
            child: Container(
              color: Colors.blueAccent,
            ),
          )
        ],
      ),
    );

Thanks for all helps!
","android, ios, flutter, mobile",1,73317072,"You can include clipBehavior on top Container, default is Clip.none
Container(
  height: 168,
  width: double.infinity,
  clipBehavior: Clip.hardEdge, //this
  decoration: BoxDecoration(
    border: Border.all(
      color: Colors.purple,

"
73683516,"""error: too many arguments to function"" when trying to access vector elements in a function call","I'm writing a program to populate a vector from a list of numbers in a file, and then check the list to see how many numbers appear more than once. The program works when I hard code the array size based on the number of lines in the file. But I want to use a vector to automate the sizing of the array for each file since there are many files to process and each is unique in length.
I'm confused by this error message because I'm pretty certain I have 3 args in the function declaration and definition. The error is attached to line 63, and g++ highlights the closing brace of (i) and (j).
  4 #include &lt;iostream&gt;
  5 #include &lt;fstream&gt;
  6 #include &lt;string&gt;
  7 #include &lt;iomanip&gt;
  8 #include &lt;vector&gt;
  9 using namespace std;
 10
 11
 12 void duplicateSort(vector&lt;int&gt; &amp;list, int length, int&amp; fpy);
 13 void printToScreen(int size, int fpy);
 14 void printToFile(int size, int fpy, ofstream &amp;outFile);
 15
 16
 17 int main() {
 18     //declare vars
 19     ifstream inFile;
 20     ofstream outFile;
 21     string serNumber;
 22     //const int size = 8995;
 23     vector&lt;int&gt; list;
 24     int fpy = 0;
 25     string path;
 26
 27     cout &lt;&lt; &quot;Enter a file path: &quot; &lt;&lt; endl;
 28     cin &gt;&gt; path;
 29
 30     inFile.open(path);
 31     //outFile.open(&quot;exubt_2022_fpy.txt&quot;);
 32     if (!inFile.is_open()) {
 33         cout &lt;&lt; &quot;Bad file path!&quot; &lt;&lt; endl;
 34         return 1;
 35     }
 36     list[0] = 0;
 37
 38     //read source file and populate array
 39     while(!inFile.eof())    {
 40         inFile.ignore(200, '_');
 41         inFile.ignore(20, '_');
 42         getline(inFile, serNumber, '.');    //fetch a line of data
 43         int num = stoi(serNumber);          //convert string data to int
 44         inFile.ignore(3);
 45
 46         list.push_back(num);            // add the next number to the back of the vector
 47     }
 48
 49     duplicateSort(list, list.size(), fpy);
 50     printToScreen(list.size(), fpy);
 51     //printToFile(list.size(), fpy, outFile);
 52
 53     inFile.close();
 54     //outFile.close();
 55
 56         return 0;
 57 }
 58
 59 void duplicateSort(vector&lt;int&gt; &amp;list(), int length, int&amp; fpy) {     //sort the list for fpy
 60     int match = 0;
 61     for (int i = 0; i &lt; length; i++) {
 62         for (int j = 0; j &lt; length; j++) {
 63             if(list(i) == list(j))
 64                 match++;
 65             if (match == 1) {
 66                 fpy++;
 67                 match = 0;
 68             }
 69         }
 70     }
 71 }
 72 void printToScreen(int size, int fpy) {
 73     cout &lt;&lt; &quot;Total number of units tested = &quot; &lt;&lt; size &lt;&lt; endl;
 74     cout &lt;&lt; &quot;Total number of passed on first try = &quot; &lt;&lt; fpy &lt;&lt; endl;
 75     cout &lt;&lt; &quot;FPY = &quot; &lt;&lt; static_cast&lt;double&gt;(fpy) * 100 / size &lt;&lt; &quot;%&quot; &lt;&lt; endl;
 76 }
 77
 78 void printToFile(int size, int fpy, ofstream &amp;outFile) {
 79     outFile &lt;&lt; &quot;Total number of units tested = &quot; &lt;&lt; size &lt;&lt; endl;
 80     outFile &lt;&lt; &quot;Total number of passed on first try = &quot; &lt;&lt; fpy &lt;&lt; endl;
 81     outFile &lt;&lt; &quot;FPY = &quot; &lt;&lt; static_cast&lt;double&gt;(fpy) * 100 / size &lt;&lt; &quot;%&quot; &lt;&lt; endl;
 82 }
 83

","c++, c++14",-1,73683846,"In C++, () is a function call operator and is used to call the function. For example, when you write main(), you are calling the function main which in turn causes the main function to start executing.
To access an element of a vector, you should use subscript operator [] not function call operator ().
I've highlighted the mistakes in your duplicateSort sort function below:
//           function argument should just list the name without `()` operator          
//                             vvvvvvv
void duplicateSort(vector&lt;int&gt; &amp;list(), int length, int&amp; fpy) {     
      //sort the list for fpy
      int match = 0;
      for (int i = 0; i &lt; length; i++) {
          for (int j = 0; j &lt; length; j++) {
//               vvvvvvv    vvvvvvv   to access element of a vector use [] operator
              if(list(i) == list(j))
                  match++;
              if (match == 1) {
                  fpy++;
                  match = 0;
              }
          }
      }
  }

To make your program work, change the function as follows:
 void duplicateSort(vector&lt;int&gt; &amp;list, int length, int&amp; fpy) {     //sort the list for fpy
      int match = 0;
      for (int i = 0; i &lt; length; i++) {
          for (int j = 0; j &lt; length; j++) {
              if(list[i] == list[j])
                  match++;
              if (match == 1) {
                  fpy++;
                  match = 0;
              }
          }
      }
  }

"
73253228,Blazor API Post Not Getting Called,"I am fairly new to Blazor, I am trying to call a Post action in a HandleValidSubmit method of a form.
EditForm Model=&quot;@date&quot; OnValidSubmit=&quot;@HandleValidSubmit&quot;
private DateGenerator.Shared.Date date = new Date();

[Parameter]
public EventCallback OnSubmitCallback { get; set; }

public async void HandleValidSubmit()
{
    var connectedUser = DateGenerator.Shared.ConnectedUser.Get();
    if (connectedUser == null || connectedUser.UserId == 0)
    {
        string? email = AuthProvider?.GetAuthenticationStateAsync()?.Result?.User?.Identity?.Name;
        if (email == null)
            StateHasChanged();

        var users = await Http.GetFromJsonAsync&lt;DateGenerator.Shared.User[]&gt;(&quot;api/Users&quot;);
        if (users != null &amp;&amp; users.Any(u =&gt; u.Email == email))
            DateGenerator.Shared.ConnectedUser.Set(users.First(u =&gt; u.Email == email));

        connectedUser = DateGenerator.Shared.ConnectedUser.Get();
    }

    if (connectedUser == null)
        return;

    var newDate = new Date(date, connectedUser);

    await Http.PostAsJsonAsync&lt;DateGenerator.Shared.Date&gt;(&quot;api/Dates&quot;, newDate);
    await OnSubmitCallback.InvokeAsync();

    date.Clear();
}

The post in the api controller is not getting called
[Route(&quot;api/[controller]&quot;)]
[ApiController]
public class DatesController : ControllerBase
{
    private readonly DateGeneratorContext _context;

    public DatesController(DateGeneratorContext context)
    {
        _context = context;
    }

    [HttpGet]
    public IEnumerable&lt;DateGenerator.Shared.Date&gt; Get()
    {
        return _context.Dates.ToList();
    }

    [HttpPost]
    public void Post(Shared.Date date)
    {
        _context.Dates.Add(date);
        _context.SaveChanges();
    }
}

I can call the &quot;Get&quot; function from the same codeblock and it works, and I can't see any difference between this call and ones for other api controllers that work. Any help would be appreciated.
","blazor, blazor-server-side, blazor-webassembly",1,73280725,"A null property in the object that was being posted caused the post to fail. Make sure all properties that are not nullable have a value.
"
73555284,Remove popup when clicked outside of area,"I have a button that I want to be able to close if it's clicked outside the area of the popout. I tried adding a toggle class but I am not sure if I am doing it right. I used the example from geekforgeeks.
https://www.geeksforgeeks.org/how-to-toggle-an-element-class-in-javascript/
But I am getting the following error message:

Uncaught InvalidCharacterError: Failed to execute 'add' on 'DOMTokenList': The token provided ('function openPopOut() {popOut.classList.add(&quot;open&quot;);setTimeout(closePopOut, 8000);
}') contains HTML space characters, which are not valid in tokens.

Any pointers on how to proceed?
This is my code:
const activateBtn = document.querySelector(&quot;.activate-btn&quot;);
const html = document.querySelector(&quot;html&quot;);
const popOut = document.querySelector(&quot;.pop-out&quot;);
const popOutCloseBtn = popOut.querySelector(&quot;.pop-out__close-btn&quot;);

function openPopOut() {
  popOut.classList.add(&quot;open&quot;);
  setTimeout(closePopOut, 8000);
}

function closePopOut() {
  popOut.classList.remove(&quot;open&quot;);
}

// activateBtn.addEventListener(&quot;click&quot;, openPopOut);
activateBtn.addEventListener(&quot;click&quot;, function (e){
  activateBtn.classList.add(openPopOut);
});

popOutCloseBtn.addEventListener(&quot;click&quot;, closePopOut);

html.addEventListener(&quot;click&quot;, function (e) {
  if (e.target !== popOut) popOut.classList.remove(&quot;pop-out&quot;);
});

body {
  display: flex;
  width: 100%;
  height: 100%;
}

button {
  cursor: pointer;
}

.activate-btn {
  margin: auto;
}

.pop-out {
  position: absolute;
  bottom: 32px;
  right: 32px;
  display: flex;
  width: 175px;
  height: 100px;
  background-color: cornflowerblue;
  border: 1px solid;
  border-radius: 4px;
  transform: translateX(210px);
  transition: transform 333ms ease-out;
}

.pop-out__close-btn {
  position: absolute;
  top: 8px;
  right: 8px;
  background-color: transparent;
  font-weight: bold;
  border: none;
}

.pop-out__msg {
  margin: auto;
}

.pop-out.open {
  transform: translateX(0);
}

&lt;html&gt;
&lt;button class=&quot;activate-btn&quot;&gt;Activate&lt;/button&gt;

&lt;div class=&quot;pop-out&quot;&gt;
  &lt;button class=&quot;pop-out__close-btn&quot;&gt;X&lt;/button&gt;
  &lt;h3 class=&quot;pop-out__msg&quot;&gt;Hello!&lt;/h3&gt;
&lt;/div&gt;
&lt;/html&gt;


","javascript, html, css",1,73555626,"Fixed your code.
The popup shows when you click the button, when you click outside the popup, it disappears.


const activateBtn = document.querySelector("".activate-btn"");
const html = document.querySelector(""html"");
const popOut = document.querySelector("".pop-out"");
const popOutCloseBtn = popOut.querySelector("".pop-out__close-btn"");

function openPopOut() {
  popOut.classList.add(""open"");
  setTimeout(closePopOut, 8000);
}

function closePopOut() {
  popOut.classList.remove(""open"");
}

// activateBtn.addEventListener(""click"", openPopOut);
activateBtn.addEventListener(""click"", function (e){
  openPopOut();
});

popOutCloseBtn.addEventListener(""click"", closePopOut);

document.addEventListener(""click"", function (e) {
  if (e.target !== popOut &amp;&amp; e.target !== activateBtn) closePopOut();
});
body {
  display: flex;
  width: 100%;
  height: 100%;
  overflow-x: hidden;
}

button {
  cursor: pointer;
}

.activate-btn {
  margin: auto;
}

.pop-out {
  position: absolute;
  bottom: 32px;
  right: 32px;
  display: flex;
  width: 175px;
  height: 100px;
  background-color: cornflowerblue;
  border: 1px solid;
  border-radius: 4px;
  transform: translateX(210px);
  transition: transform 333ms ease-out;
}

.pop-out__close-btn {
  position: absolute;
  top: 8px;
  right: 8px;
  background-color: transparent;
  font-weight: bold;
  border: none;
}

.pop-out__msg {
  margin: auto;
}

.pop-out.open {
  transform: translateX(0);
  display: flex;
}
&lt;html&gt;
&lt;button class=""activate-btn""&gt;Activate&lt;/button&gt;

&lt;div class=""pop-out""&gt;
  &lt;button class=""pop-out__close-btn""&gt;X&lt;/button&gt;
  &lt;h3 class=""pop-out__msg""&gt;Hello!&lt;/h3&gt;
&lt;/div&gt;
&lt;/html&gt;



"
73809448,How do I get Ansible's json_query to return a value from this JSON document,"After several hours of beating my head against this (not to mention leaving it for a day) I'm pretty much stumped on trying to figure out why I can't JMESPath to return a value in Ansible.
I have a task which runs a shell command and returns the following output:
[
    {
        &quot;ansible_loop_var&quot;: &quot;item&quot;,
        &quot;changed&quot;: false,
        &quot;cmd&quot;: [
            &quot;pvesh&quot;,
            &quot;create&quot;,
            &quot;/access/users/user@pve/token/pve-apikey&quot;,
            &quot;-privsep=0&quot;,
            &quot;--output=json&quot;
        ],
        &quot;delta&quot;: &quot;0:00:00.707130&quot;,
        &quot;end&quot;: &quot;2022-09-22 12:28:43.746253&quot;,
        &quot;failed&quot;: false,
        &quot;invocation&quot;: {
            &quot;module_args&quot;: {
                &quot;_raw_params&quot;: &quot;pvesh create /access/users/\&quot;user@pve\&quot;/token/\&quot;pve-apikey\&quot; -privsep=0 --output=json&quot;,
                &quot;_uses_shell&quot;: false,
                &quot;argv&quot;: null,
                &quot;chdir&quot;: null,
                &quot;creates&quot;: null,
                &quot;executable&quot;: null,
                &quot;removes&quot;: null,
                &quot;stdin&quot;: null,
                &quot;stdin_add_newline&quot;: true,
                &quot;strip_empty_ends&quot;: true,
                &quot;warn&quot;: false
            }
        },
        &quot;item&quot;: {
            &quot;token&quot;: &quot;pve-apikey&quot;,
            &quot;user&quot;: &quot;user@pve&quot;
        },
        &quot;msg&quot;: &quot;&quot;,
        &quot;rc&quot;: 0,
        &quot;start&quot;: &quot;2022-09-22 12:28:43.039123&quot;,
        &quot;stderr&quot;: &quot;&quot;,
        &quot;stderr_lines&quot;: [],
        &quot;stdout&quot;: &quot;{\&quot;full-tokenid\&quot;:\&quot;user@pve!pve-apikey\&quot;,\&quot;info\&quot;:{\&quot;privsep\&quot;:\&quot;0\&quot;},\&quot;value\&quot;:\&quot;dc2aa48f-daf6-4efe-b95e-83774a588988\&quot;}&quot;,
        &quot;stdout_lines&quot;: [
            &quot;{\&quot;full-tokenid\&quot;:\&quot;user@pve!pve-apikey\&quot;,\&quot;info\&quot;:{\&quot;privsep\&quot;:\&quot;0\&quot;},\&quot;value\&quot;:\&quot;dc2aa48f-daf6-4efe-b95e-83774a588988\&quot;}&quot;
        ]
    }
]

I'm now trying to obtain the UUID returned as value in the stdout_line using json_query and this is far as I can get:
    - debug:
        msg: &quot;{{ token | community.general.json_query(query) }}&quot;
      vars:
        query: '[].stdout'

This json_query returns the following output:
&quot;msg&quot;: [
        &quot;{\&quot;full-tokenid\&quot;:\&quot;tfuser@pve!tfe-pve-apikey\&quot;,\&quot;info\&quot;:{\&quot;privsep\&quot;:\&quot;0\&quot;},\&quot;value\&quot;:\&quot;e47e82d4-6798-47ea-9592-c7cf55cc8b61\&quot;}&quot;
    ]

I believe that this is a list, so I've tried extending the json_query as [].stdout[].value but that returns null. I've tried various permutations but so far nothing seems to work.
Any advice on how to proceed would be very welcome!
","ansible, jmespath",2,73809696,"The items of the list stdout_lines are strings. You can test it. For example,
    - debug:
        var: output.0.stdout_lines.0|type_debug

gives
  output.0.stdout_lines.0|type_debug: AnsibleUnsafeText

Convert the items to dictionaries. For example
    - debug:
        var: output.0.stdout_lines.0|from_yaml

gives
  output.0.stdout_lines.0|from_yaml:
    full-tokenid: user@pve!pve-apikey
    info:
      privsep: '0'
    value: dc2aa48f-daf6-4efe-b95e-83774a588988

To get the UUID, declare the variable
    UUID: &quot;{{ output|map(attribute='stdout_lines')|
                     map('map', 'from_yaml')|list|
                     json_query('[].value') }}&quot;

This gives the list of the values
  UUID:
  - dc2aa48f-daf6-4efe-b95e-83774a588988



Example of a complete playbook for testing
- hosts: localhost

  vars:

    output: &quot;{{ lookup('file', 'output.json') }}&quot;
    UUID: &quot;{{ output|map(attribute='stdout_lines')|
                     map('map', 'from_yaml')|list|
                     json_query('[].value') }}&quot;

  tasks:

    - debug:
        var: output.0.stdout_lines.0|type_debug
    - debug:
        var: output.0.stdout_lines.0|from_yaml
    - debug:
        var: UUID


"
72887432,Regenerate XCFramework if there is a code change,"I have a Demo project and Framework which can be integrated with multiple ways(Cocoapods, SPM - using generated XCFramework, directly integrate with XCFramework)
For distributing Demo app to external users we integrate the Framework with SPM.
Problem with this approch is during development its makes really hard to regenerate XCFramework after each change, so I have decided to drag and drop the Framework's project to Demo app, but cant understand how to recompile XCFramework if there is a change.
Could you please help me with understading how to handle this scenario.
","xcode, swift-package-manager, xcframework",0,72887961,"Create an .xcworkspace that contains the framework project and the demo app project side by side, then inside the demo app target General settings (see screenshot), add the .framework file from the framework project within the workspace instead of depending on the .xcframework binary file directly.

After that, add a &quot;Copy File&quot; build phase that embeds the framework file.

"
74217317,Get list of numbers in python without using numpy,"Is there a way to get list of numbers in python without using numpy.
Example,
asd = ['926', '927', '928', '929', '930', '931']

I have a list above which are typed manually.. but can not put a range like (926 to 931) and get the list?
Any help?
",python,1,74217361,"You can do with range + map,
In [1]: list(map(str,range(926, 932)))
Out[1]: ['926', '927', '928', '929', '930', '931']

"
74016253,"Clickhouse not working after losing zookeeper cluster, how to force it to generate new metadata","I am setting up Posthog which includes Clickhouse and connects to Zookeeper. It was set up and working, but the Zookeeper cluster was destroyed by accident.
Now a new one is set up, but Clickhouse logs that it has issues with the metadata and can't use the new zookeeper, tables are being put in READ_ONLY mode. Because of this no new PostHog events are being saved.
How can I make Clickhouse generate new metadata on this new Zookeeper cluster?
","apache-zookeeper, clickhouse, posthog",0,74018087,"system restore replica 'your_table';

https://clickhouse.com/docs/en/sql-reference/statements/system/#restore-replica
"
73299474,Powershell - extract specific items from zip then send a message (loop with message box),"I'm trying to achieve the following with this powershell script.

Copy any .zip file from folder dropfilehere to folder IN.
For each .zip file in folder &quot;IN&quot; open the zip file, find only the .csv file.
When .csv file is found, extract it to $dst under name DB.csv (overwrite old file).
Empty contents of folders &quot;dropfilehere&quot; and &quot;IN&quot;
Finally, when all the above is done, create a popup box with a message to the user using wscriptshell -
This is the issue. When the message is sent, the user gets 10+ popup boxes or an endless loop of them.

In the background i see cmd.exe and conhost.exe processes appearing as each popup box gets created.
I use a batch file to call the powershell script.
Powershell.exe -ExecutionPolicy Bypass -File C:\pathtoscript\call.ps1
exit

The script is:
  $dst = &quot;C:\Testing\DB&quot;
Copy-item -Path &quot;C:\Users\user\dropfilehere\*.zip&quot; -destination &quot;C:\Testing\Other\In&quot; -Force
Foreach ($zipfile in (Get-ChildItem &quot;C:\Testing\Other\In\*.zip&quot; -Recurse)) {
Add-Type -Assembly System.IO.Compression.FileSystem
$zipFile = [IO.Compression.ZipFile]::OpenRead($zipfile)
$zipFile.Entries | where {$_.Name -like '*.csv'} | foreach {$FileName = $_.Name
[System.IO.Compression.ZipFileExtensions]::ExtractToFile($_, &quot;$dst\DB.csv&quot;, $true)}
$zipFile.Dispose()
Remove-Item &quot;C:\Testing\Other\In\*&quot; -Recurse -Force
Remove-Item &quot;C:\Users\user\dropfilehere\*&quot; -Recurse -Force
$org=&quot;Name of Org&quot;
$timeout = 60 # in seconds
$ws = New-Object -ComObject &quot;Wscript.Shell&quot;
$intButton = $ws.Popup(&quot;A new update message here`n
Another message here.&quot;,$timeout,$org, 0)
}
exit

","windows, powershell, batch-file, command, powershell-4.0",0,73309652,"
There is code inside your foreach loop that should be placed after it, as shown below (properly indenting your code would have made that more obvious):
Add-Type -Assembly System.IO.Compression.FileSystem

$dst = &quot;C:\Testing\DB&quot;
Copy-item -Path &quot;C:\Users\user\dropfilehere\*.zip&quot; -destination &quot;C:\Testing\Other\In&quot; -Force

# Process all files.
foreach ($zipfile in (Get-ChildItem &quot;C:\Testing\Other\In\*.zip&quot; -Recurse)) {
  $zipFile = [IO.Compression.ZipFile]::OpenRead($zipfile)
  $zipFile.Entries | 
    Where-Object { $_.Name -like '*.csv' } |
    ForEach-Object { 
      [System.IO.Compression.ZipFileExtensions]::ExtractToFile($_, &quot;$dst\DB.csv&quot;, $true) 
    }
  $zipFile.Dispose()
}

# Remove the folders containing the original *.zip files.
Remove-Item &quot;C:\Testing\Other\In\*&quot; -Recurse -Force
Remove-Item &quot;C:\Users\user\dropfilehere\*&quot; -Recurse -Force

# Show a message box.
$org = &quot;Name of Org&quot;
$timeout = 60 # in seconds
$ws = New-Object -ComObject &quot;Wscript.Shell&quot;
$intButton = $ws.Popup(&quot;A new update message here`nAnother message here.&quot;, $timeout, $org, 0)

"
74490549,Optimize a for loop in matlab,"This is my code:
variables=1000;
t=20;
x=zeros(t,t,3);
y=rand(variables,3);
z=rand(t,t,variables);
e=rand(variables,1);
for c=1:variables
            x(:,:,1)=x(:,:,1)+y(c,1).*((z(:,:,c)-e(c)).^2);
            x(:,:,2)=x(:,:,2)+y(c,2).*((z(:,:,c)-e(c)).^2);
            x(:,:,3)=x(:,:,3)+y(c,3).*((z(:,:,c)-e(c)).^2);
end  

How can I improve calculation speed on this loop? I think that the problem is the for loop with a large c.
","matlab, for-loop, optimization",0,74490954,"It's a myth, but alas a persistent one, that loops are slow in MATLAB.  As you've written your for loop, it goes sequentially through the last dimension of your variables. That pretty much translates to a FORTRAN loop directly, leaving little room for improvement using vectorisation. The below does vectorise your output as much as possible, but doesn't improve performance much, even though reshape() is almost free, and severely degrades readability.
In each iteration, all you're doing is calculating y(c,1).*((z(:,:,c)-e(c)).^2), which is added to the total. If we are able to vectorise that expression, we can sum over the dimension of c to get rid of the loop.
z(:,:,c)-e(c) can be vectorised by adding two singleton dimensions to e: reshape(e, [1 1 numel(e)]), then subtract and power by 2 as usual.
Multiplication by  y(c,1) also works, if we add two singleton dimensions to y(:,1):, reshape(y(:,1), [1 1 numel(e)]), then multiply again as usual.
Finally, we just need to sum over our 3rd dimension and we end up with our t -by- t result: sum(tmp2, 3).
All that's left are the hardcoded three dimensions in x, which I've left be in a loop.
The working code on R2007b:
variables=10;
t=2;
x=zeros(t,t,3);
y=rand(variables,3);
z=rand(t,t,variables);
e=rand(variables,1);

for ii = 1:size(x, 3)
    x(:, :, ii) = sum(bsxfun(@times, reshape(y(:,1), [1 1 numel(e)]), bsxfun(@minus, z, reshape(e, [1 1 numel(e)])).^2), 3);
end

I wasn't sure what to do with the hardcoded dimension of 3, so I just left a loop over that. The rest is vectorised away, thanks to a few reshape() calls to arrange the dimensions for the bsxfun() expansion.
Code for &gt;R2016b with implicit expansion:
for ii = 1:size(x, 3)
    x(:, :, ii) = sum(reshape(y(:,ii), [1 1 numel(e)]) .* (z -  reshape(e, [1 1 numel(e)])).^2, 3)
end

A quick timing comparison shows that this is roughly 2x faster than your original loop:
Elapsed time is 0.780516 seconds. Original code
Elapsed time is 0.397369 seconds. My bsxfun() solution
Elapsed time is 0.305160 seconds. My implicit expansion

Note that in the above a 100 loops were ran for each code version, i.e. timings are 8ms, 4ms and 3ms per version.

For an introduction to reshape() you can refer to this answer of mine.
The documentation article on implicit broadcasting is rather good, as is this blog.
"
73134275,Is there a clean way to make declvals for types with no default constructors?,"consider this example:
template&lt;typename T&gt;
concept Iteratable = requires(T n) {
    n.begin();
    n.end();
};

namespace detail {
    template&lt;Iteratable T&gt;
    using subtype = std::decay_t&lt;decltype(*(std::declval&lt;T&gt;().begin()))&gt;;

    template&lt;Iteratable T&gt;
    constexpr auto deepest_subtype_recursive() {

        if constexpr (Iteratable&lt;subtype&lt;T&gt;&gt;) {
            return detail::deepest_subtype_recursive&lt;subtype&lt;T&gt;&gt;();
        }
        else {
            return subtype&lt;T&gt;{};
        }
    }
}

template&lt;Iteratable T&gt;
using deepest_subtype = decltype(detail::deepest_subtype_recursive&lt;T&gt;());

A recursive function that calls itself with the subtype, until the type in question is no longer iteratable, then that type is returned. What this enables, is to find the deepest container type at compile time. So e.g. vector&lt;list&lt;deque&lt;int&gt;&gt;&gt; becomes int:
int main() {

    using container_type = std::vector&lt;std::list&lt;std::deque&lt;int&gt;&gt;&gt;;
    using deepest = deepest_subtype&lt;container_type&gt;;

    static_assert(std::is_same_v&lt;deepest, int&gt;);
}

using this way of return the value, and finding out the type with decltype is something I do very often, as I can write code that has more room to breathe and doesn't rely on insanley nested std::conditional_ts.

this example breaks, once I apply it on a class that doesn't have a default constructor:
struct foo {
    foo(int) {}
};

int main() {

    using container_type = std::vector&lt;std::list&lt;std::deque&lt;foo&gt;&gt;&gt;;
    using deepest = deepest_subtype&lt;container_type&gt;;

    static_assert(std::is_same_v&lt;deepest, foo&gt;);
}


error C2512: 'foo': no appropriate default constructor available

on the line where it says return subtype&lt;T&gt;{};.
I also can't say return std::declval&lt;subtype&lt;T&gt;&gt;(); as that will give the error error C2338: static_assert failed: 'Calling declval is ill-formed, see N4892 [declval]/2.'

To fix this I had the following idea: Skip the constructor by declaring a pointer, and immediately derefence it. So basically making my own declval:
template&lt;typename T&gt;
constexpr auto declval() {
    using pointer = T*;
    return *(pointer{});
}

namespace detail {
    template&lt;Iteratable T&gt;
    using subtype = std::decay_t&lt;decltype(*(std::declval&lt;T&gt;().begin()))&gt;;

    template&lt;Iteratable T&gt;
    constexpr auto deepest_subtype_recursive() {

        if constexpr (Iteratable&lt;subtype&lt;T&gt;&gt;) {
            return detail::deepest_subtype_recursive&lt;subtype&lt;T&gt;&gt;();
        }
        else {
            return declval&lt;subtype&lt;T&gt;&gt;();
        }
    }
}

this works, but it doesn't seem like a very clean solution to me.

Is there a clean way to declval? like maybe there is a utility like that already, or a utility that fully constructs a passed object.
Or am I supposed to abandon returning values and rather make the logic with only types, therefore using statements?
","c++, c++20, constexpr, typetraits",1,73134425,"You can return std::type_identity&lt;T&gt;{} (which is always default-constructible) and use decltype()::type to get the wrapped type.
namespace detail {
    template&lt;Iteratable T&gt;
    using subtype = std::decay_t&lt;decltype(*(std::declval&lt;T&gt;().begin()))&gt;;

    template&lt;Iteratable T&gt;
    constexpr auto deepest_subtype_recursive() {
        if constexpr (Iteratable&lt;subtype&lt;T&gt;&gt;) {
            return detail::deepest_subtype_recursive&lt;subtype&lt;T&gt;&gt;();
        }
        else {
            return std::type_identity&lt;subtype&lt;T&gt;&gt;{}; // here
        } 
    }
}

template&lt;Iteratable T&gt;
using deepest_subtype = typename decltype(
                            detail::deepest_subtype_recursive&lt;T&gt;())::type;

It's worth noting that you don't have to make your own wheels, the standard already provides something like Iteratable and subtypes, namely ranges::range and ranges::range_value_t.
"
74257296,Tag-like (/x=y/yellow=flower) Pattern-Matching Regex Python,"I need to match the information associated with each tag with a regex pattern. The tags here are not HTML but follow the format of: /x=y or
tags = &quot;/yellow=flower/blue=sky&quot;

What would be the regex pattern to yield this information?
I have tried:
linein = &quot;/yellow=flower/blue=sky&quot;
pattern = &quot;^[A-Za-z0-9]{1}^[A-Za-z0-9]{1}&quot;
p2 = re.findall(pattern, linein)

The expected output is:
yellow flower
blue sky

","python, python-3.x, regex, data-structures, pattern-matching",-1,74261837,"Your attempt has several issues:

It doesn't attempt to match /, nor =
^ will (by default) match the start of the input, so having it in the middle of your regex pattern is a guarantee of having no matches. Moreover, you want to match pairs that are not at the start of your input, so there really shouldn't be a ^ in your pattern.
{1} tells the regex engine that the preceding pattern should be matched exactly once. This is never necessary to include, since that is the default. Secondly, it doesn't do what you want: you don't want to say that an identifier like &quot;yellow&quot; can consist of only one character. On the contrary, you want to allow multiple characters, and the way to indicate that is with a +.
Less of an issue, but [A-Za-z0-9] is almost the same as the much shorter \w. The only difference is that the latter also allows for an underscore character, which I think would be fine. In most contexts identifiers are allowed to include underscores. So use \w instead. To make sure backslashes are passed on as-is to the regex engine, prefix your string literal with r
The desired output seems a multiline string. But that is not very handy to work with. You'd want to get a list of pairs, or possibly a dictionary with key/value pairs.

With the above points taken into account, your code would become:
import re

linein = &quot;/yellow=flower/blue=sky&quot;
pattern = r&quot;/(\w+)=(\w+)&quot;
lst = re.findall(pattern, linein)
print(lst)  # [('yellow', 'flower'), ('blue', 'sky')]
print(dict(lst))  # {'yellow': 'flower', 'blue': 'sky'}

"
72966759,how to implement or after group in regex pattern,"I want to get the thread-id from my urls in one pattern. The pattern should hat just one group (on level 1). My test Strings are:
https://www.mypage.com/thread-3306-page-32.html
https://www.mypage.com/thread-3306.html
https://www.mypage.com/Thread-String-Thread-Id

So I want a Pattern, that gives me for line 1 and 2 the number 3306 and for the last line &quot;String-Thread-Id&quot;
My current state is .*[t|T]hread-(.*)[\-page.*|.html]. But it fails at the end after the id. How to do it well? I also solved it like .*Thread-(.*)|.*thread-(\\w+).*, but this is with two groups not applicable for my java code.
","regex, nsregularexpression",1,72966969,"Not knowing if this fits for all situations, but I would try this:
^.*?thread-((?:(?!-page|\.html).)*)

In Java, that could look something like
List&lt;String&gt; matchList = new ArrayList&lt;String&gt;();
Pattern regex = Pattern.compile(&quot;^.*?thread-((?:(?!-page|\\.html).)*)&quot;, Pattern.CASE_INSENSITIVE | Pattern.UNICODE_CASE | Pattern.MULTILINE);
Matcher regexMatcher = regex.matcher(subjectString);
while (regexMatcher.find()) {
    matchList.add(regexMatcher.group(1));
} 

Explanation:
^                  # Match start of line
.*?                # Match any number of characters, as few as possible
thread-            # until &quot;thread-&quot; is matched.
(                  # Then start a capturing group (number 1) to match:
 (?:               # (start of non-capturing group)
  (?!-page|\.html) # assert that neither &quot;page-&quot; nor &quot;.html&quot; follow
 .                 # then match any character
 )*                # repeat as often as possible
)                  # end of capturingn group

"
74606136,Inserting data using PyMongo based on a defined data model,"I have a dataset consisting of 250 rows that looks like to following:

In MongoDB Compass, I inserted the first row as follows:
db.employees.insertOne([{&quot;employee_id&quot;: 412153, 
                        &quot;first_name&quot;: &quot;Carrol&quot;, 
                        &quot;last_name&quot;: &quot;Dhin&quot;, 
                        &quot;email&quot;: &quot;carrol.dhin@company.com&quot;, 
                        &quot;managing&quot;: [{&quot;manager_id&quot;: 412153, &quot;employee_id&quot;: 174543}], 
                        &quot;department&quot;: [{&quot;department_name&quot;: &quot;Accounting&quot;, &quot;department_budget&quot;: 500000}], 
                        &quot;laptop&quot;: [{&quot;serial_number&quot;: &quot;CSS49745&quot;, 
                                    &quot;manufacturer&quot;: &quot;Lenovo&quot;, 
                                    &quot;model&quot;: &quot;X1 Gen 10&quot;, 
                                    &quot;date_assigned&quot;: {$date: 01-15-2022}, 
                                    &quot;installed_software&quot;: [&quot;MS Office&quot;, &quot;Adobe Acrobat&quot;, &quot;Slack&quot;]}]})

If I wanted to insert all 250 rows into the database using PyMongo in Python, how would I ensure that every row is entered following the format that I used when I inserted it manually in the Mongo shell?
","python, mongodb, pymongo",0,74632037,
73292446,How can I do horizontal scrolling animations?,"Some websites have some elements that slide horizontally while you are scroll(vertically). Have an example about it in http://www.timeslot.com/. How can I do that with javascript and css? Or do you have any codepen etc. instance about it?
","javascript, css, user-interface, scroll, ui-design",-3,73292570,"This website probably works with different kind of techniques, for example, playing certain animations on scroll. I can recommend &quot;gsap scrolltriger&quot; or &quot;locomotive-scroll&quot;, which has an effect to scroll horizontally. Hope this helps.
"
73725267,Pandas lookup to update value by refereeing col and row with 2 data frames,"I've a df 1 and df2 like below and need to lookup the part and week column value from df2 and update the qty value in df1 .. Initially I've tried using melt function to change weeks as col and used merge function to join them but when i do pivot to get back to same as df1 with updated value it says grouper is not 1 dimensional since part and weeks are repeated -- is there any other better approach pls help. ( Need to update DF1 weeks value based on DF2 by referring .. Not to group the DF2 value )


{'Part': {0: 'Part1', 1: 'part2', 2: 'Part3'},
 'Week26': {0: nan, 1: nan, 2: nan},
 'Week27': {0: nan, 1: nan, 2: nan},
 'Week28': {0: nan, 1: nan, 2: nan},
 'Week29': {0: nan, 1: nan, 2: nan},
 'Week30': {0: nan, 1: nan, 2: nan},
 'Week31': {0: nan, 1: nan, 2: nan},
 'Week32': {0: nan, 1: nan, 2: nan},
 'Week33': {0: nan, 1: nan, 2: nan},
 'Week34': {0: nan, 1: nan, 2: nan}}
 
 
 {'ITM_NO': {0: 'Part1',
  1: 'Part1',
  2: 'Part1',
  3: 'part2',
  4: 'part2',
  5: 'part2',
  6: 'part2',
  7: 'Part3',
  8: 'Part3',
  9: 'Part3',
  10: 'Part3'},
 'WEEK': {0: 'Week26',
  1: 'Week27',
  2: 'Week28',
  3: 'Week26',
  4: 'Week27',
  5: 'Week28',
  6: 'Week29',
  7: 'Week29',
  8: 'Week30',
  9: 'Week31',
  10: 'Week32'},
 'QTY': {0: 12,
  1: 10,
  2: 30,
  3: 20,
  4: 40,
  5: 60,
  6: 70,
  7: 20,
  8: 10,
  9: 30,
  10: 20}}

Expected output

","python, pandas, dataframe",0,73725315,"Pivot the 2nd dataframe, then concatenate with the first dataframe, and finally get the sum by grouping the Part column. You can reset_index() at last if you want to
(pd.concat([
    df2
    .pivot('ITM_NO', 'WEEK', 'QTY')
    .reset_index()
    .rename(columns={'ITM_NO': 'Part'}),
    df1])
 .groupby('Part').sum())

       Week26  Week27  Week28  Week29  Week30  Week31  Week32  Week33  Week34
Part                                                                         
Part1    12.0    10.0    30.0     0.0     0.0     0.0     0.0     0.0     0.0
Part3     0.0     0.0     0.0    20.0    10.0    30.0    20.0     0.0     0.0
part2    20.0    40.0    60.0    70.0     0.0     0.0     0.0     0.0     0.0

"
72856097,Test a map inside a pipe in Angular (Isolated Test),"I have a method that has a pipe with a map inside of it. When I run the test I can't find a way to get into that map.
This is my component code
public getParents(): void {
    Eif (this.filter.siteId !== null) {
      this.parents$ = this.parentsM().pipe(
        map(items =&gt; items.data),
        catchError(error =&gt; {
        this.messageService.errorHandler(error);
        return Array&lt;any&gt;();
      }));
    }
  }

This is my Spec.ts code
it(&quot;getParents with siteId&quot;, async(() =&gt; {
      const mockItems:Response = {
      codError: &quot;&quot;,
      msgError: &quot;&quot;,
      data: &quot;test&quot;}
      let spy = spyOn&lt;any&gt;(component, &quot;parentsM&quot;).and.returnValue(scheduled([mockItems], asyncScheduler));
    component.getParents();
    component.parentsM().subscribe(items =&gt; {
      expect(items).toEqual(mockItems);
    });
    spy.calls.reset();
  }));

This is my code coverage

","angular, dictionary, testing, jasmine, pipe",1,72856252,"Multiple issues here. You actually have to subscribe to this.parents$ to execute the map, which makes your test async. In your test, you're subscribing on the result of parentsM(), which I guess doesn't return exactly this.parents$, so you're not subscribing to the pipe you wrote. You may also use waitForAsync instead of async.
Please try this:
it(&quot;getParents with siteId&quot;, waitForAsync(() =&gt; { // &lt;== waitForAsync
      const mockItems:Response = {
      codError: &quot;&quot;,
      msgError: &quot;&quot;,
      data: &quot;test&quot;}
      let spy = spyOn&lt;any&gt;(component, &quot;parentsM&quot;).and.returnValue(scheduled([mockItems], asyncScheduler));
    component.getParents();
    component.parents$.subscribe(items =&gt; { // &lt;== parents$
      expect(items).toEqual(mockItems);
    });
    
    spy.calls.reset();
}));

"
74199102,library (ecospat) problem with biomod2 version,"When I try to load 'ecospat' I find this problem:
&gt; library(ecospat)


Error: package or namespace load failed for â€˜ecospatâ€™ in loadNamespace(j &lt;- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
namespace â€˜biomod2â€™ 4.1-2 is being loaded, but &lt; 4.0 is required

So I have tried to load a 'biomod2' 3.5.1 version, but I can't because it's not available for my version of R (4.2.1)
&gt; install.packages(&quot;D:/Descargas/biomod2_3.5.1&quot;)

Installing package into â€˜C:/Users/danie/AppData/Local/R/win-library/4.2â€™
(as â€˜libâ€™ is unspecified)
Warning in install.packages :
  package â€˜D:/Descargas/biomod2_3.5.1â€™ is not available for this version of R

A version of this package for your version of R might be available elsewhere,
see the ideas at
https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages

Someone could help me with this problem?
",r,1,74202717,"You can install the biomod2_3.5.1 package using the following code
install.packages(&quot;https://cran.r-project.org/src/contrib/Archive/biomod2/biomod2_3.5.1.tar.gz&quot;, 
                 repo=NULL, type=&quot;source&quot;)

"
73354302,Firebase hosted website shows welcome page not the actual website,"I am trying to host React website using firebase. I have used firebase for backend. I have already deployed a website using firebase it worked fine before. Only this time the deployed url keeps showing the welcome page.
I have tried deleting firebase files and tried firebase init multiple times still facing the same issue . I tried opening the file in incognito mode but it shows the same thing.
Hosted url:
https://recipe-661e9.web.app/
I started with npm install -g firebase-tools and it worked fine
Then I did firebase login and it showed I'm logged in.
Then firebase init
After firebase init these were the choices I made
Which Firebase features do you want to set up for this director
y? Press Space to select features, then Enter to confirm your cho
ices. Hosting: Configure files for Firebase Hosting and (optional
ly) set up GitHub Action deploys

Please select an option: Use an existing project
? Select a default Firebase project for this directory: recipe-661e9 (Recipe)

 What do you want to use as your public directory? build
? Configure as a single-page app (rewrite all urls to /index.html)? Yes
? Set up automatic builds and deploys with GitHub? No
âœ”  Wrote build/index.html

i  Writing configuration info to firebase.json...
i  Writing project information to .firebaserc...

âœ”  Firebase initialization complete!

After this I ran npm run build
followed by firebase deploy --only hosting
I have googled multiple times but finding no solution.
I tried deleting firebase.json , .firebaserc file and its folder and running these commands again but same thing.
I have tried deleting build folder still no improvement
","reactjs, firebase, firebase-hosting, firebase-cli",0,73818913,"Deploy the public directory instead of build
"
73283623,Regex for URLs outside square bracket in text PHP,"I have this:
[(http(s)?):\/\/(www\.)?a-zA-Z0-9@:%._\+~#=]{2,256}\.[a-z]{2,6}\b([-a-zA-Z0-9@:%_\+.~#?&amp;\/\/=]*)

It matches for:
www.example.com 
http://example.com.nz 
example.com
http://www.example.com?2rjl6
example.com/first/second
https://example.us.edi?34535/534534?dfg=g&amp;fg

etc...

I want no match if any of the above URLs are enclosed in square brackets [ ] like this:
[www.example.com]
[http://example.com.nz]
etc...

The text is long and may or may not contain more than one URL, spaces, line breaks, and so on.

e.g.
Lorem ipsum dolor sit amet, consectetur [http://example.com.nz] llamcorper et lacus. Morbi sodales convallis lectus a efficitur: example.com/first/second vitae nisl placerat.
Fusce non ipsum a augue http://example.com.nz  http://www.example.com?2rjl6 aculis augue. Nullam eu nulla lectus.

In this case there should be only 3 matches.
I tried adding:
(?![^\[]*\])

But it doesn't work as expected.
Can you help me with this or recommend another approach? Thanks.
","php, regex",0,73283702,"You can match from an opening till closing square bracket, and then  make use of SKIP FAIL using php.
You might also shorten the pattern a bit. You have the whole first part in a character class [(http(s)?):\/\/(www\.)?a-zA-Z0-9@:%._\+~#=] but you can move the square bracket to before the [a-z,
And as you can write a-zA-Z0-9_ as \w, you can shorten the character class a bit starting with [\w
If you choose a different delimiter than / like ~ you don't have to escape the backslash.
\[[^][]*](*SKIP)(*F)|(?:https?://)?(?:www\.)?[\w@:%.+~#=]{2,256}\.[a-z]{2,6}\b[\w-@:%+.~#?&amp;/=]*

Explanation

\[[^][]*] Match from [...]
(*SKIP)(*F) Skip the match
| Or
(?:https?://)? Optionally match the protocol
(?:www\.)? Optionally match www.
[\w@:%.+~#=]{2,256} Repeat 2-256 times any of the listed in the character class
\.[a-z]{2,6}\b match a dot and 2-6 chars a-z followed by a word boundary
[\w-@:%+.~#?&amp;/=]* Optionally match what is listed in the character class

Regex demo
"
73262628,Python Won't Update a Variable Outside of My For Loop,"I'm following another tutorial on CodeSignal, and this time it wants me to figure out what the missing numbers are in a sequence from smallest to largest in a list. I figured out how to sort the list, but the program is not working as expected.
Here's the code that I have right now:
def solution(Statuses):
    Statuses.sort()
    firstNum = 0
    print(Statuses)
    for i in range(len(Statuses) - 1):
        if Statuses[(firstNum + 1)] - firstNum == 1:
            print(&quot;Yes&quot;)
        else:
            print(&quot;no&quot;)
        print(firstNum)
        firstNum += 1
solution([6, 2, 3, 8])

Here's the output that I get with the code above:
[2, 3, 6, 8]
no
0
no
1
no
2

Here's the expected output:
[2, 3, 6, 8]
yes
0
no
1
no
2

The reason that the first yes/no... thing should say &quot;yes&quot; is because the 2 and 3 that you can see in the list's difference is 1, while the others are not.
What's the issue?
","python, python-3.x, for-loop",-2,73262664,"If I understood correctly, what you want to do is check if the difference between two successive numbers in a list is 1. This is not what you are doing here :
if Statuses[(firstNum + 1)] - firstNum == 1:

the correct code is
if Statuses[firstNum + 1] - Statuses[firstNum] == 1:

"
73707930,why is ghostscript replacing embedded fonts?,"well I've given up. I don't think I understand how GS works... as far as I understand GS replaces all fonts that are not embedded and should not touch already embedded ones? why is it replacing them? I have a pdf file that contains 2 embedded fonts and 1 not embedded (ArialMT).
I'm using command:
&quot;gswin64c.exe -I &quot;C:/Program Files/gs/gs9.56.1/Resource/Init&quot; -sFONTMAP=&quot;Fontmap.GS&quot; -dNOSAFER -dPDFACompatibilityPolicy=1 -sColorConversionStrategy=LeaveColorUnchanged -dBATCH -dNOPAUSE -sDEVICE=&quot;pdfwrite&quot; -dAutoRotatePages=/None -dPDFA=3 -sOutputFile=&quot;pdfa.pdf&quot; &quot;original.pdf&quot; 

all I get with this command is this error:
GPL Ghostscript 9.56.1: Actual TT subtable offset xxxxx differs from one in the TT header yyyy. (multiple ones like this)

The following errors were encountered at least once while processing this file:
        error executing PDF token

   **** This file had errors that were repaired or ignored.
   **** The file was produced by:
   **** &gt;&gt;&gt;&gt; StreamServe Communication Server 16.6.1 GA Build 319 (64 bit) &lt;&lt;&lt;&lt;
   **** Please notify the author of the software that produced this
   **** file that it does not conform to Adobe's published PDF
   **** specification.

the output is a pdf without ANY fonts...

is there any way to force GS not to replace font if it wasn't found on the system?
why is it replacing ArialMT with NimbusSans-Regular even though I have declared a specific path to ArialMT in my FontMap.GS file?

I'd rather not share this pdf file as it contains sensitive customer data.

(osadzony podzestaw=embedded subset)
",ghostscript,-1,73710394,"Ghost Script substitution will require embeddable fonts on windows those are usually stored in C:\Windows\Fonts
Thus if font substitution was simple (without look-up) your command could be simplified
gswin64c.exe -sFONTPATH=&quot;C:\Windows\Fonts&quot; -dNOSAFER -sDEVICE=pdfwrite -dNEWPDF=false -dPDFA=3 -dPDFACompatibilityPolicy=1 -sColorConversionStrategy=LeaveColorUnchanged   -dAutoRotatePages=/None  -o&quot;pdfa.pdf&quot; &quot;original.pdf&quot;

you need to add -dNEWPDF=false Since to include additional mapping you add -I &quot;C:/Program Files/gs/gs9.56.1/Resource/Init&quot; -sFONTMAP=Fontmap.gs
Thus the following should be a startpoint
gswin64c.exe -sFONTPATH=&quot;C:\Windows\Fonts&quot; -I &quot;C:/Program Files/gs/gs9.56.1/Resource/Init&quot; -sFONTMAP=Fontmap.gs -dNOSAFER -sDEVICE=pdfwrite -dNEWPDF=false -dPDFA=3 -dPDFACompatibilityPolicy=1 -sColorConversionStrategy=LeaveColorUnchanged   -dAutoRotatePages=/None  -o&quot;pdfa.pdf&quot; &quot;original.pdf&quot;

It will not remove warnings using a PDF file from the same developer, the difference was now there is no mention of Nimbus, but the substitutions should be better/fuller as the warning messages verified the fonts were eventually applied from windows

Note the file is smaller although the fonts are embedded, and in side by side comparison they look the same.
GPL Ghostscript 9.56.1: PDFA doesn't allow images with Interpolate true.  

and  

The following errors were encountered at least once while processing this file:
        missing white space after number
        error executing PDF token

   **** This file had errors that were repaired or ignored.
   **** Please notify the author of the software that produced this
   **** file that it does not conform to Adobe's published PDF
   **** specification.

from their report.
If I save the file from Acrobat the file size drops but the same issues reside
"
74402927,Take values from a column if another contain something,"I'm trying to achieve a hard try in google sheet.
Let's start from what I right now, the A structure in the image.
What I would like to achieve using functions like =QUERY, is the B or C (whatever is fine for me) structure.

Can you help me with the syntax?
I appreciate it so much and thank you very much
Luco
I tried a couple of functions, but can't get to the point using QUERY function, maybe I'm using bad syntax.
","function, google-sheets, lambda, time, duration",1,74407871,"all in one B variant:
=INDEX(LAMBDA(x, TRIM(SPLIT(FLATTEN(QUERY(QUERY(SPLIT(FLATTEN(
 TRIM(SPLIT(OFFSET(x,,1), &quot;,&quot;)&amp;&quot;Ã—&quot;)&amp;&quot;â€‹&quot;&amp;x&amp;&quot;Ã—&quot;), &quot;â€‹&quot;), 
 &quot;select max(Col2) where Col1 &lt;&gt; 'Ã—' and Col2 is not null 
  group by Col2 pivot Col1&quot;),,9^9)), &quot;Ã—&quot;)))
 (A2:INDEX(A:A, MAX(ROW(A:A)*(A:A&lt;&gt;&quot;&quot;)))))


all in one C variant:
=INDEX(LAMBDA(x, REGEXREPLACE(TRIM(SPLIT(FLATTEN(QUERY(QUERY(SPLIT(FLATTEN(
 TRIM(SPLIT(OFFSET(x,,1), &quot;,&quot;)&amp;&quot;Ã—&quot;)&amp;&quot;â€‹&quot;&amp;x&amp;&quot;,&quot;), &quot;â€‹&quot;), 
 &quot;select max(Col2) where Col1 &lt;&gt; 'Ã—' and Col2 is not null 
  group by Col2 pivot Col1&quot;),,9^9)), &quot;Ã—&quot;)), &quot;,$&quot;, ))
 (A2:INDEX(A:A, MAX(ROW(A:A)*(A:A&lt;&gt;&quot;&quot;)))))


"
73746526,Mysql left join with limit returning join record for one row,"How do i join a table using limit?
I have the below query but it doesn't work as expected.
Am using left join to select only one row from table, but it only select one record as expected for the first row while it returns null on others
Even when they have file saved in TABLE_USER_FILES.
TABLE_USERS
uid | u_name  
----|---------
p1  | Peter 
j1  | John
f1  | Foo
b1  | Bar

TABLE_USER_POST
pid | p_name  | p_uid
----|---------|--------
xp1 | PHP     | p1
xp2 | SQL     | p1
xp3 | JS      | j1
xp4 | CSS     | b1

TABLE_USER_FILES
fid | f_uid  | f_url   | f_path
----|--------|---------|----------
fa1 | p1     | ax.png  | gallery
fb2 | p1     | bc.png  | gallery
bc3 | j1     | cc.png  | gallery
fd4 | f1     | cx.png  | gallery
fe5 | j1     | qd.png  | gallery

Query
SELECT post.*, user.u_name, files.f_url
FROM TABLE_USER_POST post

INNER JOIN TABLE_USERS user
ON user.uid = post.p_uid

LEFT JOIN (
    SELECT f_url, f_uid
        FROM TABLE_USER_FILES
        WHERE f_path = &quot;gallery&quot;
        ORDER BY fid DESC
    LIMIT 1
) files
ON files.f_uid = post.p_uid

ORDER BY post.pid DESC 
LIMIT 0, 20

Expected result
pid | p_name  | p_uid  | u_name  | f_url
----|---------|--------|---------|---------
xp1 | PHP     | p1     | Peter   | bc.png
xp2 | SQL     | p1     | Peter   | bc.png
xp3 | JS      | j1     | John    | qd.png
xp4 | CSS     | b1     | Bar     | NULL

","mysql, sql",0,73747835,"Please try this instead.
SELECT post.*, user.u_name, files.f_url 
  FROM TABLE_USER_POSTS post 
  LEFT JOIN TABLE_USER_FILES files 
       ON files.f_uid = post.p_uid 
       AND files.fid = (SELECT MAX(fid) FROM TABLE_USER_FILES WHERE f_uid = files.f_uid) 
 INNER JOIN TABLE_USERS user 
       ON user.uid = post.p_uid 
 ORDER BY post.pid DESC;

Thank you!
"
73806877,Postgresql trigger function with concatenate not working,"I'm new to trigger functions and PostgreSQL, and I'm trying create a calculated field combining other fields (I know that this might violate the normal forms, but I'm working with a pre-existing naming convention). The goal is to have the animal_id field be created at insertion or update of records and look like &quot;ANAM-2011-10&quot;. I have tried two different ways to insert a concatenated string, and each has their own issues. Here's the table:
CREATE TABLE capt_trial
(animal_id VARCHAR(15),
species CHAR(4),
capture_year SMALLINT,
tag_num NUMERIC,
tag_col CHAR(1));

Scenario #1: using SET field = concatenated string in function
CREATE OR REPLACE FUNCTION create_short_animal_id_1()
RETURNS trigger
LANGUAGE plpgsql
AS
$$
BEGIN
    SET NEW.animal_id = CONCAT(species, '-', capture_year, '-', tag_num);
    RETURN NEW;
END;
$$;

This is the error message when trying to create the function:
ERROR:  syntax error at or near &quot;(&quot;
LINE 7:  SET NEW.animal_id = CONCAT(species, '-', capture_year, '-',...
                                   ^
SQL state: 42601
Character: 125

Scenario #2: using INSERT INTO field VALUES concatenated string in function. The function and the trigger were created successfully.
CREATE OR REPLACE FUNCTION create_short_animal_id_2()
RETURNS trigger
LANGUAGE plpgsql
AS
$$
BEGIN
    INSERT INTO capt_trial(animal_id) 
    VALUES(CONCAT(species, '-', capture_year, '-', tag_num));
    RETURN NEW;
END;
$$;


CREATE TRIGGER trigger_create_short_animal_id_2
BEFORE INSERT OR UPDATE
ON public.&quot;capt_trial&quot;
FOR EACH ROW
EXECUTE PROCEDURE create_short_animal_id_2();

But when I tried to insert values into the table:
INSERT INTO capt_trial (species, capture_year, tag_num, tag_col)
VALUES ('ANAM', 2011, 10, 'B'),
       ('ANAM', 2012, 142, 'Y'),
       ('OVCA', 2013, 137, NULL),
       ('ODHE', 2014, 75, NULL);

I got this error:
ERROR:  column &quot;species&quot; does not exist
LINE 2:  VALUES(CONCAT(species, '-', capture_year, '-', tag_num))
                       ^
HINT:  There is a column named &quot;species&quot; in table &quot;capt_trial&quot;, but it cannot be referenced 
from this part of the query.
QUERY:  INSERT INTO capt_trial(animal_id) 
        VALUES(CONCAT(species, '-', capture_year, '-', tag_num))
CONTEXT:  PL/pgSQL function create_short_animal_id() line 3 at SQL statement
SQL state: 42703

Does anyone know what the issue is with the syntax or how to get this to run?
","postgresql, function, triggers, concatenation",0,73806948,"For first example do:
NEW.animal_id = CONCAT(NEW.species, '-', NEW.capture_year, '-', NEW.tag_num)
You are assigning to the NEW.animal_id not setting anything. FYI, := can also be used for assignment.
"
73630660,PySimpleGUI Combo: Bind key/value pair array or get selected index?,"I'm really astounded that there doesn't seem to be a way to bind a dictionary or key/value pair array to a simple dropdownlist that the Combo element is supposed to cover. The contents of a given Combo in my app is fetched from the database and I would like to know the primary key of any item that is selected from said Combo. However, it only seems possible to populate the Combo with a list of strings, so everytime I tried to &quot;get&quot; the item, the name string is all I've got left.
A temporary workaround where I fetch the source item from the database based on the name string is tenuous at best, as there's no guarantee that I'm getting the actual item and not some alternative that happens to have the same name. Also, it would be unneccesary to do another database trip, when you've already just fetched all the items!
A more reliable workaround where I keep the table rows in memory and then look up the row using the selected index, also falls short, because, in contrast with pysimplegui's Listbox element, you cannot get the selected item's index of a Combo!!!
What gives!? I'm about to completely give up on PySimpleGUI in favour of a (hopefully) better alternative. If you know of any, I would regard that as an answer to my question also.

EDIT: Thanks to Jason Yang's Answer I arrived at the following:
import PySimpleGUI as sg

# Internal 
import data_access as db
import util

collections = db.getRows('collection')
collList = util.convert_dbrow_list(collections)

layout = [[sg.Text('collections'), sg.Combo(collList, enable_events=True, key='cbxCollections', size=(30, 1))],]
window = sg.Window('testing', layout)

while True:
    event, values = window.read()
    if event == sg.WINDOW_CLOSED:
        break
    elif event =='cbxCollections':
        text = values[event]
        index = window[event].widget.current()
        id = collections[index]['id'] 
        spid = collections[index]['spid'] 
        print(index, id, spid, repr(values[event]))

window.close()

","python, combobox, pysimplegui, selectedindex",0,73631015,"You can use method current() for the widget of Combo element, or index the value of entry from the value list of Combo element.
import PySimpleGUI as sg

data = ['One', 'Two', 'Three', 'Four']

layout = [
    [sg.Combo(data, size=20, enable_events=True, key='COMBO')],
    [sg.Push(), sg.Button('Check')],
]
window = sg.Window('Title', layout)

while True:

    event, values = window.read()

    if event == sg.WIN_CLOSED:
        break
    elif event in ('COMBO', 'Check'):
        text = values['COMBO']
        index1 = window['COMBO'].widget.current()
        index2 = data.index(text) if text in data else -1
        print(index1, index2, repr(values['COMBO']))

window.close()

"
74338106,Using same partial but with different variable for loop Rails,"I want to use the same partial, but changing the main variable of the loop inside the partial so that the layout is the same, but different results show in each tab. I thought I could make this happen using locals, but I tried it with no luck. Any ideas?
&lt;div class=&quot;tab-content&quot; id=&quot;pills-tabContent&quot;&gt;
  &lt;div class=&quot;tab-pane fade show active&quot; id=&quot;pills-home&quot; role=&quot;tabpanel&quot; aria-labelledby=&quot;campaigns-active-tab&quot;&gt;
    &lt;%= render partial: 'campaigns_list' %&gt;
  &lt;/div&gt;
  &lt;div class=&quot;tab-pane fade&quot; id=&quot;pills-profile&quot; role=&quot;tabpanel&quot; aria-labelledby=&quot;campaigns-inactive-tab&quot;&gt;
    &lt;%= render partial: 'campaigns_list' %&gt;
  &lt;/div&gt;
&lt;/div&gt;

Controller:
@active_campaigns = @campaigns.where(status: 1).order(created_at: :desc)
@inactive_campaigns = @campaigns.where(status: 2).order(created_at: :desc)

Partial:
Here, the variable should change from active to inactive campaigns:
  &lt;% @campaigns.each do |campaign| %&gt;
      &lt;tr scope=&quot;row d-flex align-items-center justify-content-center&quot;&gt;

",ruby-on-rails,-1,74338494,"
I thought I could make this happen with locals

Yes you can; however, the code you provided does not use locals.
Local usage would be:
&lt;%= render partial: 'campaigns_list', locals: { campaigns: @active_campaigns } %&gt;
And you can thus loop through campaigns within the partial.
Docs for locals
"
73675612,"Why I got syntax error, when trying to use concept?","I am using Visual Studio 2022, with the latest compiler. I have a problem, when I am trying to create concept definition. I got many syntax error, for example
syntax error: identifier 'has_type_member'
syntax error: missing ';' before '{'
template&lt;typename T&gt;
        concept has_type_member = requires { typename T::type; };

I have tried many other basic examples about concepts.
Thanks for your help!
","c++, c++20, visual-studio-2022, c++-concepts",2,73676371,"In Visual Studio 2022, ISO C++ 14 Standard in enabled by default. Concept feature is available since C++20.
To enable ISO C++20 standard for your project, right click on the project name and select Properties, under Configuration Properties -&gt; General -&gt; C++ Language Standard select ISO C++20 Standard (/stdc++20).

"
74506570,Bad request instead of message,"i hava a problem that i am unble to figure whats i am doing wrong.
So basically backend sends the error message but somehow browser is overwrites the message with Bad request.
Screen shoot of message that browser retuens me.
This is the response from API
I want to know why my browser is giving me bad request instead of response.
","angular, error-handling, httpresponse, http-status-code-400, 400-bad-request",-1,74506615,"Without to see your code I think you can solve the problem with the observe option inside the http request. The observe option gives you the full response.
Angular Guide Http

Greetings, Flo
"
73518721,Set item opacity in RecyclerView depending if item is in center,"I want to display items in a horizontal list using RecyclerView. At a time, only 3 items will be displayed. 1 in the middle and the other 2 on the side, below is an image of what I'm trying to achieve:

I'm using LinearSnapHelper which centers an item all of the time. When an item is moved away from the center I would like the opacity to progessively change from 1f to 0.5f.
Here is the below code which I've written to help:
class CustomRecyclerView(context: Context, attrs: AttributeSet) : RecyclerView(context, attrs) {
    
    private var itemBoundsRect: Rect? = null

    init {
        itemBoundsRect = Rect()
        addOnScrollListener(object : OnScrollListener() {
            override fun onScrolled(recyclerView: RecyclerView, dx: Int, dy: Int) {
                super.onScrolled(recyclerView, dx, dy)
                calculateVisibility()
            }
        })
    }

    private fun calculateVisibility() {
        val linearLayoutManger: LinearLayoutManager = layoutManager as LinearLayoutManager
        val firstVisibleItem = linearLayoutManger.findFirstVisibleItemPosition()
        val lastVisibleItem = linearLayoutManger.findLastVisibleItemPosition()
        var indexes: MutableList&lt;Int&gt; = mutableListOf()
        for (i in firstVisibleItem..lastVisibleItem) {
            indexes.add(i)
            val item: View = layoutManager?.findViewByPosition(i) ?: continue
            item.getGlobalVisibleRect(itemBoundsRect)
            var itemSize = layoutManager!!.findViewByPosition(i)!!.width
            
            var visibleSize = 0
            if (indexes.size == 1) {
                visibleSize = itemBoundsRect!!.right
            } else {
                visibleSize = itemBoundsRect!!.right - itemBoundsRect!!.left
            }



            var visibilty = visibleSize * 100 / itemSize
            if (visibilty &gt; 0) {
                visibilty = 100 - visibilty
            }

            val viewHolder = findViewHolderForLayoutPosition(i)
            viewHolder!!.itemView.alpha = (100 - visibilty).toFloat() / 100f
        }
    }
}

It doesn't work as expected as the opacity changes at the wrong time. The image below demonstrates this better. I expect the opacity to progressively begin to change when the item edges come out of the red box. However, it only starts when the item reaches the yellow edges.

Is there a way to achieve this effect?
Thank you :)
","android, kotlin, android-recyclerview, android-animation",1,73519659,"Your code for calculateVisibility() is looking at global position when looking at the relative position within the RecyclerView is sufficient. Maybe there is more to the code than you posted, but try the following. This code looks at the x position of each visible view and calculates the alpha value as a function of displacement from the center of the RecyclerView. Comments are in the code.
private fun calculateVisibility(recycler: RecyclerView) {
    val midRecycler = recycler.width / 2
    val linearLayoutManger: LinearLayoutManager = recycler.layoutManager as LinearLayoutManager
    val firstVisibleItem = linearLayoutManger.findFirstVisibleItemPosition()
    val lastVisibleItem = linearLayoutManger.findLastVisibleItemPosition()
    for (i in firstVisibleItem..lastVisibleItem) {
        val viewHolder = recycler.findViewHolderForLayoutPosition(i)
        viewHolder?.itemView?.apply {
            // This is the end of the view in the parent's coordinates
            val viewEnd = x + width
            // This is the maximum pixels the view can slide left or right until it disappears.
            val maxSlide = (midRecycler + width / 2).toFloat()
            // Alpha is determined by the percentage of the maximum slide the view has moved.
            // This assumes a linear fade but can be adjusted to fade in alternate ways.
            alpha = 1f - abs(maxSlide - viewEnd) / maxSlide
            Log.d(&quot;Applog&quot;, String.format(&quot;pos=%d alpha=%f&quot;, i, alpha))
        }
    }
}

The foregoing assumes that sizes remain constant.
"
73694809,Attempting to solve â€œhow old is your dog in human years?â€ in python on coursera,"I keep running into a problem that I am unable to understand. Can someone please help me understand what it means. just need a hint if that's ok. I have attempted to google the error I have attempted asking my coworkers and my last resort is the stack overflow community. so far the only thing I was able to make out is the my print is incorrectly formatted but how I cannot understand.
Here is my code:
def calculator():
    age = input(&quot;Please enter dog age &quot;)
    d_age = 0
    try:
        d_age = float(age)
        if d_age &lt;= 0:
            raise NameError
        elif d_age &gt;= 5:
            d_age = ((d_age - 5) * 7 + 36)
          
        elif d_age &lt;= 1:
            d_age = (d_age * 15)
            
        elif d_age &lt;= 2:
            d_age = (d_age * 12)
            
        elif d_age &lt;= 3:
            d_age = (d_age * 9.3)
           
        elif d_age &lt;= 4:
            d_age = (d_age * 8)
            
        elif d_age &lt;= 5:
            d_age = (d_age * 7.2)

    except ValueError:
        print(&quot;entered age is invalid!&quot;)
    except NameError:
        print(&quot;Please enter a non negative age&quot;)
    print(&quot;The given dog age&quot;, age, &quot;is&quot;, round(d_age, 2), &quot;in human years.&quot;)

calculator()

",python,0,73694915,"Try this. Previously, if you inputted &quot;1&quot; if d_age &lt;= 1: would be true, and if d_age &lt;= 2: would be true, and so on so forth. This only allows one condition to be true which gives the correct answer.
Your second sneakier issue is that the course is assuming your calculator function does not take any arguments, but rather calls input from inside the function.
def calculator():
    age = input(&quot;Please enter dog age &quot;)
    d_age = 0
    try:
        d_age = float(age)
        if d_age &lt;= 0:
            raise NameError
        elif d_age &gt;= 5:
            d_age = ((d_age - 5) * 7 + 36)
          
        elif d_age &lt;= 1:
            d_age = (d_age * 15)
            
        elif d_age &lt;= 2:
            d_age = (d_age * 12)
            
        elif d_age &lt;= 3:
            d_age = (d_age * 9.3)
           
        elif d_age &lt;= 4:
            d_age = (d_age * 8)
            
        elif d_age &lt;= 5:
            d_age = (d_age * 7.2)

    except ValueError:
        print(&quot;entered age is invalid!&quot;)
    except NameError:
        print(&quot;Please enter a non negative age&quot;)
    print(&quot;The given dog age&quot;, age, &quot;is&quot;, round(d_age, 2), &quot;in human years.&quot;)

calculator()

"
74041404,How to get a list of main folders inside root directory in the S3 bucket? Amazon S3,"I am having a S3 bucket with folders and sub-folders containing files, I am trying to list all the folder names inside root directory. I dont want to list the sub-folders and files.
ex:
Test/Test1
Test/Test2
Test/Test3
Test/Test4
etc...

I have tried the following code which lists all the keys inside root directory
getListAllKeys(rootDirectory) {
    const containedEntities = {
      files: [],
      directories: []
    };
    const params = {
      Bucket: this.bucket,
      Prefix: Test/,
      Delimiter: Test/
    };

    return new Promise((resolve, reject) =&gt; this._listAllKeys(
      resolve,
      reject,
      params,
      containedEntities
    ));
  }

  
  _listAllKeys(resolve, reject, params, containedEntities) {
    this.s3.listObjectsV2(params).promise()
      .then(({
        Contents, IsTruncated, NextContinuationToken,
      }) =&gt; {                   
        // filter files and directories
        Contents.forEach((item) =&gt; {
          containedEntities[item.Key.endsWith('/') ? 'directories' : 'files'].push(item);
        });
        // fetch further info if response is truncated
        if (IsTruncated) {
          this._listAllKeys(
            resolve,
            reject,
            Object.assign(params, { ContinuationToken: NextContinuationToken }),
            containedEntities
          );
        } else {
          resolve(containedEntities);
        }
      })
      .catch(reject);
  }

I am using AWS-SDK package. Please let me know how to list only the main folders
","javascript, node.js, amazon-web-services, amazon-s3",1,74041708,"To obtain a list of directories, specify Delimiter='/' (with no Prefix specified).
A list of directories at the top (root) level will be returned in a list called CommonPrefixes.
It also works for sub-folders by specifying a Prefix.
"
72854554,Vuetify v-navigation-drawer cannot overflow button,"I have a v-navigation-drawer and it's design must include a toggle expand button that overflows the drawer itself like so:

But for some unknown reason, I  can't remove the overflow hidden property.
I tried to remove it like this:
    .v-navigation-drawer {
      overflow: auto;

      .v-navigation-drawer__content {
        overflow-x: auto;
      }
    }

No success:

Here the codepend reproducing the issue: https://codepen.io/aug-riedinger/pen/poLjJyq
Can anyone help on this?
Thanks
","vuetify.js, v-navigation-drawer",2,72900895,"Just as kael said, you need to set the overflow property to visible for normal and mini variant. Like this:
.v-navigation-drawer--mini-variant, .v-navigation-drawer {
  overflow: visible !important;
  
}

.expand-toggle {
  position: absolute;
  height: 3rem;
  z-index: 1;
  right: -14px;
  top: 30px;
  bottom: 0;
  .v-btn {
    margin: auto;
    border: thin solid white !important;
  }
}


"
74454140,How to conditionally chain iterators?,"Let's say I have:
let it = [1, 2, 3].into_iter();
let jt = [4, 5, 6].into_iter();
let kt = [7, 8, 9].into_iter();

Then I have boolean conditions i, j and k. I want to generate an iterator that conditionally chains it, jt and kt together based on the values of i, j and k. Can I do this with just the built-in Rust Iterator functionality?
","rust, iterator",2,74454267,"You can make Option into an iterator.
let it = i.then_some([1, 2, 3]).into_iter().flatten();
let jt = j.then_some([4, 5, 6]).into_iter().flatten();
let kt = k.then_some([7, 8, 9]).into_iter().flatten();
let iter = it.chain(jt).chain(kt);

If the condition is false, then condition.then_some(...) will return None, making an empty iterator. Otherwise a Some(...) is returned. into_iter().flatten() will transform Option&lt;impl IntoIterator&lt;Item=T&gt;&gt; to impl Iterator&lt;Item=T&gt;.
"
74014951,Adding columns and puting value in a new row in R Script,"I am trying to add particular columns of data frame and adding these values in a new row of the same data frame.
TCM&lt;-colSums(df[3:16])--this add all the values
Now in the same file &quot;TCM&quot; I want to have new added values at the last row named Total.
",r,0,74015396,"You will need the last row to be of the same length with your other rows if you want to bind them. I can write the code assuming you want the first column to be &quot;Total&quot; and second column to be NA. If you have different values in mind simply modify the inputs for the respective values.
first_val = &quot;Total&quot;
second_val = NA
to_bind = c(first_val,second_val,TCM)
df = rbind(df,to_bind)

"
74297221,Timing range from request to response in J1939,"Generally a request is sent via 0xEB00 and response is capured by 0xEC00 (Response more than 8 bytes) in J1939,what is the range for the response from request?
Example:-
0.00  - 0xEB00 - EC FE 00
xx.xx - 0xEC00 - xx xx xx xx xx EC FE 00.
What can be the possible range of xx.xx be ?
Looked into many options but unable to find the exact range.
Somewhere its mentioned as 10 - 200 =&gt; Datapackets
and somewhere its mentioned as 0 - 1250
","request, response, can-bus, j1939",0,74304230,"All devices, when required to provide a response, must do so within 0.20s (Tr). All devices expecting a response must wait at least 1.25s (T3) before giving up or retrying. These times assure that any latencies due to bus access or message forwarding across bridges do not cause unwanted timeouts. Different time values can be used for specific applications when required. For instance, for high-speed control messages, a 20 ms response may be expected. Reordering any buffered messages may be necessary to accomplish the faster response. There is no restriction on minimum response time.
Time between packets of a multipacket message directed to a specific destination is 0 to 200 ms. This means that backto-back messages can occur and they may contain the same identifier. The CTS mechanism can be used to assure a
given time spacing between packets. The required time interval between packets of a Multipacket Broadcast message is 50 to 200 ms. A minimum time of 50 ms assures the responder has time to pull the message from the CAN hardware.
The responder shall use a timeout of 250 ms (provides margin allowing for the maximum spacing of 200 ms).
a. Maximum forward delay time within a bridge is 50 ms Total number of bridges = 10 (i.e. 1 tractor + 5 trailers + 4 dollies = 10 bridges) Total network delay is 500 ms in one direction.
b. Number of request retries = 2 (3 requests total); this includes the situation where the CTS is used to request the retransmission of data   packet(s). c. 50 ms margin for timeouts
"
73587743,Android Alarm setExactAndAllowWhileIdle only triggers once,"I'm using the setExactAndAllowWhileIdle as follows:
notificationAlarmMgr?.setExactAndAllowWhileIdle(
    AlarmManager.RTC_WAKEUP,
    notificationCalendar.timeInMillis,
    notificationAlarmIntent
)

Before I used setInexactRepeating and I was able to fire the alarm once everyday:
notificationAlarmMgr?.setInexactRepeating(
    AlarmManager.RTC_WAKEUP,
    notificationCalendar.timeInMillis,
    AlarmManager.INTERVAL_DAY,
    notificationAlarmIntent
)

setExactAndAllowWhileIdle doesn't have a intervalMillis parameter like setInexactRepeating does, so I can't pass AlarmManager.INTERVAL_DAY as an argument so that the alarm goes off everyday.
How do I make my alarm go off once everyday using setExactAndAllowWhileIdle?
Update 1:
More code for sending the alarm:
notificationAlarmIntent = Intent(
    context,
    NotificationAlarmReceiver::class.java
).let { intent -&gt;
    PendingIntent.getBroadcast(
        context,
        NOTIFICATION_ID,
        intent,
        PendingIntent.FLAG_IMMUTABLE
    )
}

The BroadcastReceiver() for the notification:
@RequiresApi(Build.VERSION_CODES.O)
class NotificationAlarmReceiver : BroadcastReceiver() {
    override fun onReceive(context: Context, intent: Intent) {
        val i = Intent(context, SplashActivity::class.java).apply {
            flags = Intent.FLAG_ACTIVITY_NEW_TASK or Intent.FLAG_ACTIVITY_CLEAR_TASK
        }

        val pendingIntent = PendingIntent.getActivity(
            context,
            0,
            i,
            PendingIntent.FLAG_IMMUTABLE
        )

        val builder = NotificationCompat.Builder(context, Constants.NOTIFICATION_CHANNEL_ID)
            .setSmallIcon(R.drawable.ic_notification_icon)
            .setColor(ContextCompat.getColor(context, R.color.colorPrimary))
            .setContentTitle(context.getString(R.string.notification))
            .setContentText(NOTIFICATION_CONTEXT_TEXT)
            .setPriority(NotificationCompat.PRIORITY_DEFAULT)
            .setStyle(NotificationCompat.BigTextStyle().bigText(NOTIFICATION_CONTEXT_TEXT))
            .setContentIntent(pendingIntent)
            .setAutoCancel(true)

        with(NotificationManagerCompat.from(context)) {
            notify(Constants.NOTIFICATION_NOTIFICATION_ID, builder.build())
        }
    }

    companion object {
        private val NOTIFICATION_CONTEXT_TEXT: String by lazy { &quot;Lorem ipsum&quot; }
    }
}

","android, alarmmanager, android-alarms",1,73587758,"As part of the other work being done by whatever notificationAlarmIntent invokes, have it also call setExactAndAllowWhileIdle() for the next time you want to get control.
For example, you can put your setExactAndAllowWhileIdle() code in a utility function:
fun setTheCottonPickinAlarm(context: Context, whenDoesItGoOff: Calendar) {
    val alarmManager = context.getSystemService(AlarmManager::class.java)

    val notificationAlarmIntent = Intent(
        context,
        NotificationAlarmReceiver::class.java
    ).let { intent -&gt;
        PendingIntent.getBroadcast(
            context,
            NOTIFICATION_ID,
            intent,
            PendingIntent.FLAG_IMMUTABLE
        )
    }

    alarmManager?.setExactAndAllowWhileIdle(
        AlarmManager.RTC_WAKEUP,
        whenDoesItGoOff.timeInMillis,
        notificationAlarmIntent
    )
}

Then, in addition to wherever you are calling the existing AlarmManager code, you can call it from onReceive() of your NotificationAlarmReceiver:
@RequiresApi(Build.VERSION_CODES.O)
class NotificationAlarmReceiver : BroadcastReceiver() {
    override fun onReceive(context: Context, intent: Intent) {
        val i = Intent(context, SplashActivity::class.java).apply {
            flags = Intent.FLAG_ACTIVITY_NEW_TASK or Intent.FLAG_ACTIVITY_CLEAR_TASK
        }

        val pendingIntent = PendingIntent.getActivity(
            context,
            0,
            i,
            PendingIntent.FLAG_IMMUTABLE
        )

        val builder = NotificationCompat.Builder(context, Constants.NOTIFICATION_CHANNEL_ID)
            .setSmallIcon(R.drawable.ic_notification_icon)
            .setColor(ContextCompat.getColor(context, R.color.colorPrimary))
            .setContentTitle(context.getString(R.string.notification))
            .setContentText(NOTIFICATION_CONTEXT_TEXT)
            .setPriority(NotificationCompat.PRIORITY_DEFAULT)
            .setStyle(NotificationCompat.BigTextStyle().bigText(NOTIFICATION_CONTEXT_TEXT))
            .setContentIntent(pendingIntent)
            .setAutoCancel(true)

        with(NotificationManagerCompat.from(context)) {
            notify(Constants.NOTIFICATION_NOTIFICATION_ID, builder.build())
        }

        setTheCottonPickinAlarm(context, calculateTheNextAlarmTime())
    }

    companion object {
        private val NOTIFICATION_CONTEXT_TEXT: String by lazy { &quot;Lorem ipsum&quot; }
    }
}

(where you would supply the calculateTheNextAlarmTime() implementation, or add that logic to setTheCottonPickinAlarm() itself)
"
73422387,Sphinx: how to change the function signature display format?,"I have a sphinx theme that renders function signatures using italics rather than code.
(my_function(arg1, arg2) rather than my_function(arg1, arg2))
I'd like to change that behavior, but I'm not sure how... Any ideas?
I'm using autodoc so most of my .rst files just look like this rather than explicitly listed functions (if that helps to know).
.. automodule:: my_module
   :members:
   :undoc-members:
   :show-inheritance:

The theme in question is sphinx_material https://bashtage.github.io/sphinx-material/, maybe I should just switch themes, but it's pretty except for function signatures being italicized rather than rendered as code.
For an example function documentation, see here: https://bashtage.github.io/sphinx-material/pymethod.html?highlight=send_message
","python, material-design, python-sphinx",1,73561285,"Thanks to Steve and some more searching, I was able to do this:
See here for how to add custom CSS: How to add custom css file to Sphinx?
In my case, what I needed in the custom.css file was
@import 'material_sphinx.css';

.sig.sig-object.py{
    font-feature-settings: &quot;kern&quot;;
    font-family: &quot;Roboto Mono&quot;, &quot;Courier New&quot;, Courier, monospace;
    background: #f8f8f8;
}

"
74325785,How can I provide a RGBA png file to OpenAI PHP library,"I import Orhanerday\OpenAi library to my DALL-E Examples project but when I provide images, I got Invalid input image - format must be in ['RGBA'], got RGB. error. I search for this error on the internet but I got nothing.
My code looks like
&lt;?php

require __DIR__ . '/vendor/autoload.php'; // remove this line if you use a PHP Framework.

use Orhanerday\OpenAi\OpenAi;

$open_ai_key = getenv(&quot;OPENAIKEY&quot;);
$open_ai = new OpenAi($open_ai_key);
 
$otter = curl_file_create(&quot;C:\Users\dotor\OneDrive\Desktop\dalle-examples\otter.png&quot;);
$mask = curl_file_create(&quot;C:\Users\dotor\OneDrive\Desktop\dalle-examples\mask.png&quot;);

$result = $open_ai-&gt;imageEdit([
    &quot;image&quot; =&gt; $otter,
    &quot;mask&quot; =&gt; $mask,
    &quot;prompt&quot; =&gt; &quot;A cute baby sea otter wearing a beret&quot;,
    &quot;n&quot; =&gt; 2,
    &quot;size&quot; =&gt; &quot;256x256&quot;,
]);

var_dump($result);

Png files;
otter.png;

mask.png;

I need to get a result without any errors, what is an RGBA png file and how can I provide?
","php, rgba, openai-api",3,74339035,"The A in RGBA stands for Alpha, which is simply a value for opacity. Since this is the type needed for OpenAI, you should convert the plain RGB to RGBA leveraging an existing library. In python, I used the Python Image Library (PIL) convert function to complete this task.
"
73550999,How to extract text between two separators in R?,"I have a vector of strings like so:
mystr &lt;- c(&quot;./10g/13.9264.csv&quot;, &quot;./6g/62.0544.csv&quot;)

I only want the part between the two forward slashes, i.e., &quot;10g&quot; and &quot;6g&quot;.
","r, stringr",1,73551053,"You could sub() here with a capture group:
mystr &lt;- c(&quot;./10g/13.9264.csv&quot;, &quot;./6g/62.0544.csv&quot;)
sub(&quot;.*/([^/]+)/.*&quot;, &quot;\\1&quot;, mystr)

[1] &quot;10g&quot; &quot;6g&quot;

"
74495897,"When button is pressed, modify other buttons","Just getting started with SwiftUI so there is probably something straightforward I am missing.
When the &quot;CHECK&quot; button is pressed, I want to change the background color of the button with an index that matches question.correctChoiceIndex, as well as the button selected by the user, if it is not the correct one.
I am not sure how to actually reference the buttons with a function (if that is the best way), and I figured it might be difficult because the buttons are made with the AnswerButton struct.
Here is my code

import SwiftUI

struct ContentView: View {
    let question: Question
   @State var guessedIndex: Int? = nil
    
    var body: some View {
        
        VStack{
            Spacer()
            Text(question.questionText)
                .padding()
           
                
        VStack {
            ForEach(question.AnswerChoices.indices) {index in
                AnswerButton(text: question.AnswerChoices[index]){ 
                    guessedIndex = index
                }
                .border(selectChoice(at: index), width: 4)
            }}
            Spacer()
            Text(&quot;Answer feedback&quot;)
                .padding()
            Spacer()
        HStack{
            Button(&quot;CHECK&quot;) {
               
            }
            .padding()
            Button(&quot;NEXT&quot;) {
                /*@START_MENU_TOKEN@*//*@PLACEHOLDER=Action@*/ /*@END_MENU_TOKEN@*/
            }
            .padding()
        }
        }
        
    }
    func selectChoice(at buttonIndex: Int) -&gt; Color {
        if buttonIndex == guessedIndex {
            return .gray

    }
        else {
            return .clear
        }
    }
    
}


struct AnswerButton: View {
    let text: String
    let onClick: () -&gt; Void
    var body: some View {
        Button(action: {
            onClick()
        }) {
                Text(text)

            }
        .padding()
        .background(Color.yellow)
    }

}
               

struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        Group {
            ContentView(question: Question.AllQuestions[0])
           
        }
    }
}



I thought looping through all the buttons in the view and checking their index could work, but it also seems a bit inefficient to do.
","ios, swift, swiftui",1,74496389,"Had to make some assumptions about the Question, and there are better ways one could structure this, but here's something that works.
This will mark an incorrect answer as red if selected and checked, and will mark the correct answer as green.
You would need to likely disable the buttons or progress after the check as well.
import SwiftUI

struct Question {
    let questionText: String
    let answerChoices: [String]
    let correctAnswerIndex: Int
}

struct ContentView: View {
    
    let question: Question
    @State var guessedIndex: Int? = nil
    @State var didCheck = false
    
    var body: some View {
        
        VStack {
            Spacer()
            Text(question.questionText)
                .padding()
            
            ForEach(0 ..&lt; question.answerChoices.count) { index in
                let answer = question.answerChoices[index]
                AnswerButton(text: answer,
                             isCorrectAnswer: index == question.correctAnswerIndex,
                             didCheck: didCheck,
                             isSelected: index == guessedIndex) {
                    guessedIndex = index
                }
            }
            Spacer()
            Text(&quot;Answer feedback&quot;)
                .padding()
            Spacer()
            HStack{
                Button(&quot;CHECK&quot;) {
                    didCheck = true
                }
                .padding()
                Button(&quot;NEXT&quot;) {
                    
                }
                .padding()
            }
        }
        
    }
    
}


struct AnswerButton: View {
    
    let text: String
    let isCorrectAnswer: Bool
    let didCheck: Bool
    let isSelected: Bool
    let onClick: () -&gt; Void
    
    var body: some View {
        Button(text, action: onClick)
            .padding()
            .border(isSelected ? .gray : .clear)
            .background(backgroundColorForCurrentState())
    }
    
    func backgroundColorForCurrentState() -&gt; Color {
        switch (didCheck, isCorrectAnswer, isSelected) {
        case (true, false, true):
            return .red
            
        case (true, true, _):
            return .green
            
        case (_, _, _):
            return .yellow
        }
    }
    
    
}


struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        Group {
            ContentView(question: Question(questionText: &quot;examnple&quot;,
                                           answerChoices: [&quot;one&quot;, &quot;two&quot;, &quot;three&quot;],
                                           correctAnswerIndex: 1))
            
        }
    }
}


"
73750333,"How to call onchange from python xml rpc, for Odoo 15?","Hello I want to update a MO product_qty field, but keep all the related records (picking/transfers)
synched.
If I write to the record the product_qty gets updated, but not the related record. When doing this manually it works as intended.
I have tried the following, with no success.
update = models.execute_kw(db, uid, password,'mrp.production', 'onchange', [1223,{'product_qty': 10}])

","python, odoo",0,73755789,"The best thing to do here is more to check in the code what functions are called that have an @api.onchage with at least product_qty in it.
By quick looking in the model with _name = 'mrp.production', I can see 3 of them. Perhaps some other classes that '_inherit' from it can add some, to be verified.
So try this :
update = models.execute_kw(db, uid, password,'mrp.production', '_onchange_product_qty', [[1223]])
update = models.execute_kw(db, uid, password,'mrp.production', '_onchange_move_raw', [[1223]])
update = models.execute_kw(db, uid, password,'mrp.production', '_onchange_move_finished', [[1223]])

There is also the possibility (a bit more rare but exists) that another model has an onchange on its production_id.product_qty e.g.
Looking at relevant models with the Regex Search @api\.onchange.*'product_qty' in both Odoo and Enterprise (if used) can be a good idea ;)
Hope it helps !
"
74460252,Add group in column result (in dplyr),"I find myself doing this quite often.
set.seed(123)
test_data=data.frame(sample=sample(LETTERS[1:10], 100,replace = TRUE), type=sample(letters[1:2], 100, replace=TRUE ), area=sample(1:100, replace=TRUE) )

The content of test_data is:
head(test_data)
  sample type area
1      C    b   24
2      C    b   63
3      J    a   54
4      B    b   23
5      F    a   26
6      E    a   33

I usually want to sum a specific column by some grouping properties, and to do that I use:
res_sum=test_data %&gt;% group_by(sample, type) %&gt;% summarise_at( .vars = &quot;area&quot;, .funs = sum )

So far so good, the problem arrives when I want to put the results in a &quot;nice&quot; format.
The lines below put the result in the way I want, but I find this way cumbersome.
res_sum_a=res_sum[res_sum$type==&quot;a&quot;, ]
colnames(res_sum_a)[3]=paste0( colnames(res_sum)[3], &quot;.a&quot;)

res_sum_b=res_sum[res_sum$type==&quot;b&quot;, ]
colnames(res_sum_b)[3]=paste0( colnames(res_sum)[3], &quot;.b&quot;)

res_df=merge(res_sum_a[,c(1,3)], res_sum_b[, c(1,3)], by=&quot;sample&quot;, all=TRUE)

head(res_df)

  sample area.a area.b
1      A    244    147
2      B     17    152
3      C    153    541
4      D    107     94
5      E    246    266
6      F    189    286

Note, there may be more than 2 &quot;type&quot; in the original data frame (so, like a,b,c....).
Is there a way, that is more dplyr idiomatic to do this?
Thanks.
","r, dplyr",1,74460371,"What you're referring to is pivoting, which is provided by a separate package ({tidyr}).
I also updated your dplyr code to most recent syntax (e.g., summarise_at() has been repalced by across()).
library(dplyr)
#&gt; 
#&gt; Attaching package: 'dplyr'
#&gt; The following objects are masked from 'package:stats':
#&gt; 
#&gt;     filter, lag
#&gt; The following objects are masked from 'package:base':
#&gt; 
#&gt;     intersect, setdiff, setequal, union
library(tidyr)

set.seed(123)
test_data=data.frame(sample=sample(LETTERS[1:10], 100,replace = TRUE), type=sample(letters[1:2], 100, replace=TRUE ), area=sample(1:100, replace=TRUE) )

test_data |&gt; 
  group_by(sample, type) |&gt; 
  summarise(across(area, sum)) |&gt; 
  tidyr::pivot_wider(names_from = type, values_from = area)
#&gt; `summarise()` has grouped output by 'sample'. You can override using the
#&gt; `.groups` argument.
#&gt; # A tibble: 10 x 3
#&gt; # Groups:   sample [10]
#&gt;    sample     a     b
#&gt;    &lt;chr&gt;  &lt;int&gt; &lt;int&gt;
#&gt;  1 A        244   147
#&gt;  2 B         17   152
#&gt;  3 C        153   541
#&gt;  4 D        107    94
#&gt;  5 E        246   266
#&gt;  6 F        189   286
#&gt;  7 G         48   483
#&gt;  8 H        223    94
#&gt;  9 I        285   345
#&gt; 10 J        491   252

Created on 2022-11-16 with reprex v2.0.2
"
72830586,Compare two timeframes in two tables to receive validated timeframes,"I have two tables containing the same fields:

&quot;(first/second)id&quot;, identifying the row
&quot;valid_from&quot;, identifying the beginning date - involved in the join
&quot;valid_until&quot;, identifying the ending date - involved in the join
&quot;attribute&quot;, the matching information

Table &quot;first&quot;:




firstID
valid_from
valid_until
attribute




932
2021-01-04
2021-01-20
hello


932
2021-01-21
2021-10-07
whats


932
2021-10-08
9999-12-31
up




Table &quot;second&quot;:




secondID
valid_from
valid_until
sk_firstID
attribute2




1269
2021-01-21
2021-10-03
932
I


1269
2021-10-04
2021-10-07
932
need


1269
2021-10-08
9999-12-31
932
your


1123
2021-12-02
9999-12-31
932
help




Now I have to build timeframes to compare both tables and get all combinations, where the data matches.
Given the sample input tables, expected output should look like this:




first ID
secondID
valid_from
attribute1
attribute2




932

2021-01-04
hello



932
1269
2021-01-21
whats
I


932
1269
2021-10-04
whats
need


932
1269
2021-10-08
up
your


932
1123
2021-12-02
up
help




There are challenges I'm facing and didn't get to solve right now:

If there is no corresponding timeframe-match it should show null in the corresponding row
It can happen both ways that there are two or more timeframes that can fall into the timeframe of the other table and vice versa.
It occurs, that different ID's appear in table two, related to one firstID

I already tried to join the two tables with some conditions but never got the result I needed.
Here's my query:
SELECT f.firstid,
       s.secondid,
       attribute,
       attribute2,
       CASE WHEN f.valid_from &gt;= s.valid_from 
            THEN cast(f.valid_from as date)
            ELSE cast(s.valid_from as date)
       END AS valid_from
FROM first f
LEFT JOIN second AS s ON f.firstid = s.sk_firstID
                     AND s.valid_from &lt;= f.valid_until

Here's my current output:

Here's the DDL to generate and populate the tables:
CREATE TABLE first
    ([firstID] int, [valid_from] datetime, [valid_until] datetime, [attribute] varchar(5))
;
    
INSERT INTO first
    ([firstID], [valid_from], [valid_until], [attribute])
VALUES
    (932, '2021-01-04 00:00:00', '2021-01-20 00:00:00', 'hello'),
    (932, '2021-01-21 00:00:00', '2021-10-07 00:00:00', 'whats'),
    (932, '2021-10-08 00:00:00', '9999-12-31 00:00:00', 'up')
;

CREATE TABLE second
    ([secondID] int, [valid_from] datetime, [valid_until] datetime, [sk_firstID] int, [attribute2] varchar(4))
;
    
INSERT INTO second
    ([secondID], [valid_from], [valid_until], [sk_firstID], [attribute2])
VALUES
    (1269, '2021-01-21 00:00:00', '2021-10-03 00:00:00', 932, 'I'),
    (1269, '2021-10-04 00:00:00', '2021-10-07 00:00:00', 932, 'need'),
    (1269, '2021-10-08 00:00:00', '9999-12-31 00:00:00', 932, 'your'),
    (1123, '2021-12-02 00:00:00', '9999-12-31 00:00:00', 932, 'help')
;

","sql, sql-server",1,72831103,"You should enclose both dates from the table &quot;second&quot; inside dates from the table &quot;first&quot; and you should get your output:
SELECT f.firstid,
       s.secondid,
       attribute,
       attribute2,
       CASE WHEN f.valid_from &gt;= COALESCE(s.valid_from, -1) 
            THEN CAST(f.valid_from AS DATE)
            ELSE CAST(s.valid_from AS DATE)
       END AS valid_from
FROM      first  f
LEFT JOIN second s 
       ON f.firstid = s.sk_firstID
      AND s.valid_from &gt;= f.valid_from
      AND s.valid_until &lt;= f.valid_until

Check the demo here.
Note: in case your output should get you way more rows than the ones given here, one option is to do a cartesian product and filter out the rows you don't need.
"
73464752,Identify and save image content in selenium python3,"I am trying to use selenium as middleware in scrapy.
One issue is when I use the ImagesDownloader all my downloaded images are invalid and contain HTML. A bit of debugging leads me to this:
# python3
Python 3.8.10 (default, Jun 22 2022, 20:18:18) 
[GCC 9.4.0] on linux
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; u = 'https://www.gravatar.com/avatar/?s=256&amp;d=identicon&amp;r=PG&amp;f=1'
&gt;&gt;&gt; from selenium import webdriver
&gt;&gt;&gt; driver = webdriver.Firefox()
&gt;&gt;&gt; driver.get(u)
&gt;&gt;&gt; driver.page_source
'&lt;html&gt;&lt;head&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width; height=device-height;&quot;&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;resource://content-accessible/ImageDocument.css&quot;&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;resource://content-accessible/TopLevelImageDocument.css&quot;&gt;&lt;title&gt;(PNG Image, 256&amp;nbsp;Ã—&amp;nbsp;256 pixels)&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;img src=&quot;https://www.gravatar.com/avatar/?s=256&amp;amp;d=identicon&amp;amp;r=PG&amp;amp;f=1&quot; alt=&quot;https://www.gravatar.com/avatar/?s=256&amp;amp;d=identicon&amp;amp;r=PG&amp;amp;f=1&quot; class=&quot;transparent&quot;&gt;&lt;/body&gt;&lt;/html&gt;'
&gt;&gt;&gt; 

Note that the url in the variable u is my avatar image, a binary image. However when looking at the page_source we see HTML created by firefox (not stackoverflow) used to display the image in the browser.
Questions:
How can I get the raw image content and how can I know if I should retrieve page_source or the raw image content?
Note: The Chrome driver has similar results.
","python, selenium",0,73496446,"Selenium is not built for such tasks and does not have native support for extraction of details about raw content or communication such as HTTP headers. Selenium is a method to automate browser tasks that humans would do, and humans seldom look at such details.
There are however two main ways to try to solve this issue.

By forcing the browser used in selenium to go through a HTTP proxy, allowing the proxy to capture details about the protocol &amp; raw content, while still giving access to the browser handling of dynamic content. The most prominent seems to be selenium-wire: https://pypi.org/project/selenium-wire/
By using javascript execution feature in selenium, this way we can get much more details - but are limited to what the javascript engine has access to.

"
74141412,mail.php can't get it to email the correct data,"I've no experience with php, due to an old formtomail cgi script no longer working on a host server I decided to switch to a simple html to php mail for a contact page on a website.  I took a template online and set up the html page but having difficulty editing the mail.php file so that all the data requests on my html form get emailed over to me.  The template I use just had email and message.  My html contact page has different requests i.e contact name not name, and asks for more information.  so I need the php form to email all this information and need help on how to edit the php file to include whats requested on the html contact page.
I have a contact form HTML page with the following:
&lt;form action=&quot;mail.php&quot; method=&quot;POST&quot;&gt;
&lt;p class=&quot;bodytextgrey&quot;&gt;
Contact Name:&lt;br /&gt;&lt;input type=&quot;text&quot; name=&quot;contact name&quot; size=&quot;50&quot; /&gt;&lt;br /&gt;
Firm Name:&lt;br /&gt;&lt;input type=&quot;test&quot; name=&quot;firm name&quot; /&gt;&lt;br /&gt;&lt;br /&gt;
E-mail: (Please enter the email address you would like the document is to be sent to)&lt;br /&gt; 
&lt;input type=&quot;text&quot; name=&quot;email&quot; size=&quot;50&quot; /&gt;&lt;br /&gt;
Job Number:&lt;br /&gt;&lt;input type=&quot;test&quot; name=&quot;job number&quot; /&gt;&lt;br /&gt;&lt;br /&gt;
Document you require:&lt;br /&gt;&lt;form action=&quot;&quot;&gt;&lt;select name=&quot;Document you require&quot;&gt;
&lt;option value=&quot;Data Sheet&quot;&gt;Data Sheet&lt;/option&gt;
&lt;/select&gt;&lt;br/ &gt;&lt;br /&gt;
Discount code:&lt;br /&gt;&lt;input type=&quot;text&quot; name=&quot;Discount code&quot; size=&quot;20&quot; /&gt;&lt;br /&gt;&lt;br /&gt;
&lt;input type=&quot;submit&quot; value=&quot;Send&quot;&gt;&lt;input type=&quot;reset&quot; value=&quot;Clear&quot;&gt;
&lt;/form&gt;

I then have a mail.php with this (MY EMAIL is my actual email):
&lt;?php $name = $_POST['name'];
$email = $_POST['email'];
$message = $_POST['message'];
$formcontent=&quot;From: $name \n Message: $message&quot;;
$recipient = &quot;MY EMAIL&quot;;
$subject = &quot;Contact Form&quot;;
$mailheader = &quot;From: $email \r\n&quot;;
mail($recipient, $subject, $formcontent, $mailheader) or die(&quot;Error!&quot;);
echo &quot;Thank You!&quot;;
?&gt;

Would also like it to bring up an existing thank you.html page rather than just a thankyou word on a white page so also need help adding in how I link this.
Any help would be appreciated
","php, html, email",-2,74142132,"Formatting your code will help immensely to start debugging this. I've reformatted your current HTML with some indenting and line breaks to help make it clear:
&lt;form action=&quot;mail.php&quot; method=&quot;POST&quot;&gt; &lt;!-- missing closing tag --&gt;
    &lt;p class=&quot;bodytextgrey&quot;&gt; &lt;!-- missing closing tag --&gt;
        Contact Name:&lt;br /&gt;
        &lt;input type=&quot;text&quot; name=&quot;contact name&quot; size=&quot;50&quot; /&gt;&lt;br /&gt;

        Firm Name:&lt;br /&gt;
        &lt;input type=&quot;test&quot; name=&quot;firm name&quot; /&gt;&lt;br /&gt;&lt;br /&gt;

        E-mail: (Please enter the email address you would like the document to be sent to)&lt;br /&gt; 
        &lt;input type=&quot;text&quot; name=&quot;email&quot; size=&quot;50&quot; /&gt;&lt;br /&gt;

        Job Number:&lt;br /&gt;
        &lt;input type=&quot;test&quot; name=&quot;job number&quot; /&gt;&lt;br /&gt;&lt;br /&gt;

        Document you require:&lt;br /&gt;
        &lt;form action=&quot;&quot;&gt; &lt;!-- nested form in a form will break things --&gt;
            &lt;select name=&quot;Document you require&quot;&gt;
                &lt;option value=&quot;Data Sheet&quot;&gt;Data Sheet&lt;/option&gt;
            &lt;/select&gt;&lt;br/ &gt;&lt;br /&gt;

            Discount code:&lt;br /&gt;
            &lt;input type=&quot;text&quot; name=&quot;Discount code&quot; size=&quot;20&quot; /&gt;&lt;br /&gt;&lt;br /&gt;
            
            &lt;input type=&quot;submit&quot; value=&quot;Send&quot;&gt;
            &lt;input type=&quot;reset&quot; value=&quot;Clear&quot;&gt;
        &lt;/form&gt;

There are a few things wrong with this:

Opening &lt;p&gt; with no &lt;/p&gt; (closing tag) anywhere
&lt;form action=&quot;&quot;&gt; nested inside of an existing form isn't allowed and will cause submission issues (see &quot;Permitted content&quot; at https://developer.mozilla.org/en-US/docs/Web/HTML/Element/form)
The closing &lt;/form&gt; that exists matches the &lt;form action=&quot;&quot;&gt;, but you're missing a &lt;/form&gt;
You don't have a message field anywhere

Here's the updated HTML with my suggested fixes:
&lt;form action=&quot;mail.php&quot; method=&quot;POST&quot;&gt;
    &lt;p class=&quot;bodytextgrey&quot;&gt;
        Contact Name:&lt;br /&gt;
        &lt;input type=&quot;text&quot; name=&quot;contact_name&quot; size=&quot;50&quot; /&gt;&lt;br /&gt;

        Firm Name:&lt;br /&gt;
        &lt;input type=&quot;test&quot; name=&quot;firm_name&quot; /&gt;&lt;br /&gt;&lt;br /&gt;

        E-mail: (Please enter the email address you would like the document to be sent to)&lt;br /&gt; 
        &lt;input type=&quot;text&quot; name=&quot;email&quot; size=&quot;50&quot; /&gt;&lt;br /&gt;

        Job Number:&lt;br /&gt;
        &lt;input type=&quot;test&quot; name=&quot;job_number&quot; /&gt;&lt;br /&gt;&lt;br /&gt;

        Document you require:&lt;br /&gt;
        &lt;select name=&quot;document&quot;&gt;
            &lt;option value=&quot;Data Sheet&quot;&gt;Data Sheet&lt;/option&gt;
        &lt;/select&gt;&lt;br/ &gt;&lt;br /&gt;

        Discount code:&lt;br /&gt;
        &lt;input type=&quot;text&quot; name=&quot;discount&quot; size=&quot;20&quot; /&gt;&lt;br /&gt;&lt;br /&gt;

        Message:&lt;br /&gt;
        &lt;textarea name=&quot;message&quot;&gt;&lt;/textarea&gt;&lt;br /&gt;&lt;br /&gt;
        
        &lt;input type=&quot;submit&quot; value=&quot;Send&quot;&gt;
        &lt;input type=&quot;reset&quot; value=&quot;Clear&quot;&gt;
    &lt;/p&gt;
&lt;/form&gt;

As others have mentioned, it's not clear what the 500 error is, so that will need to be resolved before this will work. But here's a cleaned up version of the PHP. This has been simply tested at https://3v4l.org/WePRh, though it won't show the form or any input values, but it does prove that the script runs. This is formatted better, includes all form inputs, and should make things easier to work with:
&lt;?php
    // get all form values
    $input['Contact name'] = $_POST['contact_name'] ?? '';
    $input['Firm name'] = $_POST['firm_name'] ?? '';
    $input['Email'] = $_POST['email'] ?? '';
    $input['Job number'] = $_POST['job_number'] ?? '';
    $input['Document'] = $_POST['document'] ?? '';
    $input['Discount'] = $_POST['discount'] ?? '';
    $input['Message'] = $_POST['message'] ?? '';

    // generate the email content (i.e. each line is like &quot;Contact name: Mark&quot;)
    $formContent = '';
    foreach($input as $key =&gt; $value) {
        $formContent .= $key . &quot;: &quot; . $value . &quot;\n&quot;;
    }

    $to = &quot;my@email.com&quot;; // TODO: replace this with your email address
    $subject = &quot;Contact Form&quot;;
    
    /*
        Note that this was likely causing downstream issues. Most email clients (gmail, outlook) will mark emails as spam
        if you try to send an email from an email address that your server isn't configured to send from.
        See https://stackoverflow.com/questions/17533863/how-to-configure-php-to-send-e-mail for more info.
        It's also safer to define an email address like &quot;no-reply@example.com&quot; to send your emails from.
    */
    $mailheader = &quot;From: no-reply@example.com&quot;;

    mail($to, $subject, $formContent, $mailheader) or die('Error sending email');

    // redirect to the thank you page
    // TODO: update this URL to be yours
    header('Location: http://www.example.com/thankyou.html');

    exit;
?&gt;

"
73066189,How to run background task with Django?,"I'm looking to run heavy tasks (more than 5 minutes) in the background with django.
When a heavy task is launched, django stops responding and it becomes impossible for users to navigate between pages until the task is finished.
For me a solution would be to run these heavy tasks in the background or in parallel in order to allow the user to be able to navigate between the pages in the meantime. Do you know how I can do this ?
",django,1,73066267,"celery is the typical way of doing this and has direct support for Django.
Here are the docs to get started with celery in Django:  https://docs.celeryq.dev/en/latest/django/first-steps-with-django.html
"
73874791,How to create new list of lists using for loop,"I have two lists like
values = [['bert', '1234', 'xxx', 50], ['ernie', '5678', 'fff', 100]]
required = [1, 3]

I want to extract the required elements 1 and 3 from each list contained in values, to create a new list of lists like [['1234', 50], ['5678', 100]].
I was able to solve the problem with a list comprehension:
[[x[y] for y in required] for x in values]

But how can I write the equivalent with explicit for loops?
I tried:
new_list = []
for x in values:
    for y in required:
        new_list.append(x[y])

but the resulting new_list is a single flat list ['1234', 50, '5678', 100].
","python, list, for-loop, list-comprehension",-1,73874895,"You can make a new array before second looping, and then add x[y] in that array. Add the new array to the new_list after the second looping.
new_list = [] 
for x in values:
    temp_list = []
    for y in required:
       temp_list.append(x[y])
    new_list.append(temp_list)

"
72843205,how to manage multiple 'executable and datadir profile' for parallelizing the launch of scrappers?,"I am using , and have difficulties to launch 4 scripts at the same time.
I have used theses variable for local browser
let CHROMIUM_DATA_DIR = `/Users/yo/dataDir/datadir${this.cmd}`
let CHROMIUM_EXEC_PATH = `/Applications/Google-Chrome${this.cmd}.app/Contents/MacOS/Google Chrome`

I have multiplied by 4, the same datadir, et the same executable. I have just renamed the files/directories.
It does not work well. What would be your recomendation, to quickly scale the launch of the scrappers (). How could I install various chromes instance, et managing according datadir (to save some login session etc..)
tks

","google-chrome, playwright, multiple-instances",0,72844071,"Since you are using playwright, you can use persistent contexts.
You do not need to create your own data directories or executables by copying them, simply pass location of an empty directory when launching the browser and playwright will populate it itself, storing any session data.
I do not use node.js, but just to give an idea, sample code in python:
from playwright.sync_api import sync_playwright

with sync_playwright() as p:
    browser = p.chromium.launch_persistent_context(user_data_dir=r'C:\Users\me\Desktop\dir', headless=False)

    page = browser.new_page()
    page.goto(&quot;http://playwright.dev&quot;)
    print(page.title())
    browser.close()

"
73868350,extracting dataframes from list causes column name issue,"Based on the code and data below, the imap function converts every column name to 1. How can I use the following imap code in such a way that the column names don't change?
Code + Data:
# Create a large dummy dataset
df2 = data.frame(Year = 2022, Reference_Number = seq(1,6694), c = seq(1,6694),
                  d = seq(1,6694), e = seq(1,6694), f = seq(1,6694),
                  g = seq(1,6694), h = seq(1,6694), i = seq(1,6694),
                  k = seq(1,6694), l = seq(1,6694), m = seq(1,6694),
                  n = seq(1,6694), o = seq(1,6694), p = seq(1,6694),
                  q = seq(1,6694), replace = T)

# Create a list with splitted datasets
n = 1000
lst2 = split(df2, as.integer(gl(nrow(df2), n, nrow(df2))))

# Extract dataframes 
 imap(lst2, ~ set_names(tibble(.x), .y)) %&gt;%
        set_names(str_c(&quot;DFF&quot;, seq_along(.))) %&gt;% 
        list2env(.GlobalEnv)

","r, dplyr",1,73868654,"You don't need to use imap here as the first argument of list2env, x is already a list:
list2env(setNames(lst2, paste0(&quot;DFF&quot;, names(lst2))), envir = globalenv())

"
73475091,How do I drop values of a specific condition and replace those?,"My dataframe looks like this:




ID
first
second
fourth
fifth




1
one
one
Two
Three


2
one
Two
Two
Three


3
one
Three
Three
Three


4
one
one
one
one


5
one
one
two
one




Code:
df = {'ID': [1, 2, 3, 4, 5],
        'first': ['one', 'one', 'one', 'one', 'one']
'second': ['one', 'two', 'three','one','one']
'fourth': ['two', 'two', 'three','one','two']
'fifth': ['three','three','three','one', 'one']
        }

I want to drop/delete those values in one row that appear in the next column (right) as well.
So there are a lot of duplicates but if there is another value between one same value like in &quot;ID&quot; 5, then just the value of the second column should be deleted, so that the df looks like this in the end:




ID
first
second
fourth
fifth




1
one
Two
Three
NaN


2
one
Two
Three
NaN


3
one
Three
NaN
NaN


4
one
NaN
NaN
NaN


5
one
two
one
NaN



","python, pandas, dataframe",0,73475321,"You can just do shift then use the NaN replace the same
out = df.where(lambda x : df.ne(df.shift(1,axis=1))).transform(lambda x: sorted(x, key=pd.isnull),1)
Out[73]: 
  ID first second fourth fifth
0  1   one    Two  Three   NaN
1  2   one    Two  Three   NaN
2  3   one  Three    NaN   NaN
3  4   one    NaN    NaN   NaN
4  5   one    two    one   NaN

"
74363179,Make a view generic and usable with TYPE as well as Binding<TYPE>,"I just had a situation where I wanted to use a view which, takes a String, with a Binding:
struct MyButton: View {
    
    var text: String = &quot;&quot;
    
    var body: some View {
        Button{
            HStack {
                Text(text)
            }   
        }
    }
}

I couldn't get it to work in an acceptable time period, so I just created a second view:
struct MyBoundedButton: View {
    
    @Binding var text: String
    
    var body: some View {
        Button{
            HStack {
                Text(text)
            }   
        }
    }
}

This obviously works, but doesn't seem to be the most elegant solution. I tried to figure out how the SwiftUI framework does it, since there are plenty of examples of views which have very different initialisers (see the SwiftUI Button for instance). I still want to figure out how this might work, so since after work I'm trying to play around with generic view, but can't really get it to work. The following code doesn't work and is just to demonstrate the line of thinking I'm following:
struct MyButton&lt;T&gt;: View {
        
        var text: T
        
        var body: some View {
            Button{
                HStack {
                    Text(text)
                }   
            }
        }
    }

extension MyButton where text == Binding&lt;String&gt;{
    init(text: Binding&lt;String&gt;)
}

extension MyButton where text == String{
    init(text: String)
}

Does someone have an idea how this could be implemented or how Apple does this in their SwiftUI library?
Cheers,
Philip
","generics, swiftui",1,74363635,"This could be done different ways... your approach with generics seems more elegant, but I believed that you are seeking a more understandable code, simpler:
import SwiftUI

struct MyButton: View {
    
    private var text: Binding&lt;String&gt;?
    private var pureText: String?
    private var action: () -&gt; Void
    
    init(text: Binding&lt;String&gt;, action: @escaping () -&gt; Void) {
        self.action = action
        self.text = text
    }
    
    init(text: String, action: @escaping () -&gt; Void) {
        self.action = action
        self.pureText = text
    }
    
    var body: some View {
        Button(action: action) {
            if let text = text {
                Text(text.wrappedValue)
            }
            if let text = pureText {
                Text(text)
            }
        }
    }
}

struct ContentView: View {
    
    @State private var text = &quot;Press me&quot;
    
    
    var body: some View {
        VStack {
            Image(systemName: &quot;globe&quot;)
                .imageScale(.large)
                .foregroundColor(.accentColor)
            Text(&quot;Hello, world!&quot;)
            
            MyButton(text: $text) {
                print(&quot;Button pressed.&quot;)
            }
        }
    }
}

Although the binding in this case doesn't make much sense... binding is when you are changing the value of the variable and want to pass UP to the ParentView, a binding inside a Text(text) that will never change doesn't make sense to me, but this is how you done with multiple initializers.
"
74485432,Creating a new model with a one-to-one relationship with an existing model Django,"I want to add a Profile model relationship through a one-to-one field to the existing User model. However I already have a couple of users in the database. How can I migrate the new model while creating these default relationships at the same time?
So for example I have two users Foo and Bar already created in the database and after migrating the Profile model both users should have an associated Profile with them.
Models
class User(AbstractBaseUser, PermissionsMixin):

    email = models.EmailField(verbose_name=&quot;Email Address&quot;, max_length=255, unique=True)
    first_name = models.CharField(max_length=255)
    surname = models.CharField(max_length=255)

    is_active = models.BooleanField(default=True)
    staff = models.BooleanField(default=False)
    admin = models.BooleanField(default=False)

    objects = UserManager()

    USERNAME_FIELD = &quot;email&quot;
    REQUIRED_FIELDS = [&quot;first_name&quot;, &quot;surname&quot;]

    def get_full_name(self):
        return f&quot;{self.first_name} {self.surname}&quot;

    def __str__(self):
        return self.email

    def is_staff(self):
        return self.staff

    def is_admin(self):
        return self.admin

### New model I want to create
class Profile(models.Model):
    user = models.OneToOneField(User, on_delete=models.CASCADE)
    avatar = models.ImageField(default=&quot;gravatar.jpg&quot;, upload_to=&quot;avatars/&quot;)
    username = models.CharField(max_length=255, blank=True)
    phone = models.CharField(max_length=15, blank=True)

    def __str__(self):
        return f&quot;{self.user.first_name}'s profile&quot;

","django, django-models, database-migration",0,74485725,"In the newly created migration file simply include a RunPython script which will create related Profile objects for the existing users:
# xxxx_migration.py file

from django.db import migrations


def create_profiles(apps, schema_editor):
    User = apps.get_model(&lt;app_name&gt;, 'User')
    Profile = apps.get_model(&lt;app_name&gt;, 'Profile')
    users = User.objects.filter(profile__isnull=True)
    Profile.objects.bulk_create(
        [Profile(user=user, username=user.email) for user in users]
    )


class Migration(migrations.Migration):
    dependencies = [&lt;migration_dependencies&gt;]

    operations = [
        migrations.CreateModel(
            name='Profile',
            fields=[...]
        ),

        # Create profile objects
        migrations.RunPython(create_profiles, reverse_code=migrations.RunPython.noop)
    ]


More about custom scripts in migrations here
"
73093527,Find index in array based on given value,"I have a sorted array of numbers with array length as n. For a given item k find index i in the sorted array where elements from index i to n are greater than the given item k. If there is no index present then return -1
This is my program:
public static int getIndex(int[] arr, int k) {
     int x = -1;
     for(int i=0; i&lt;arr.length; i++) {
       if(arr[i] &gt; k) {
           x = i; break;
       }
     }
     return x;
}

The time complexity of this approach is O(n), and I want to reduce it further.
","java, arrays, algorithm",0,73093557,"Since the array is sorted, use binary search for a time complexity of O(log N).
public static int getIndex(int[] arr, int k) {
    int low = 0, high = arr.length - 1;
    while (low &lt;= high) {
        int mid = low + high &gt;&gt;&gt; 1;
        if(arr[mid] &gt; k) high = mid - 1;
        else low = mid + 1;
    }
    return low == arr.length ? -1 : low;
}

"
74027109,"How to create a dictionary with two querysets from different models, using a common DateTimeField as the dictionary keys?","I would like to create a dictionary from two models with a field dt in common. This field should be the dictionary keys, and fields value and last the keys's value. What is the most efficient way to do that ?
class Balance(models.Model):
    value = models.FloatField(default=0)
    dt = models.DateTimeField()

class Price(models.Model):
    last = models.FloatField(default=0)
    dt = models.DateTimeField()

The desired output would be something like this :
{
    &quot;2022-10-11T00:00:00Z&quot;: {
        &quot;value&quot;: 151.05,
        &quot;last&quot;: 1,
    },
    &quot;2022-10-10T00:00:00Z&quot;: {
        &quot;value&quot;: 151.1,
        &quot;last&quot;: 1.1,
    },
    &quot;2022-10-09T00:00:00Z&quot;: {
        &quot;value&quot;: 152,
        &quot;last&quot;: 1.1,
    },
    &quot;2022-10-08T00:00:00Z&quot;: {
        &quot;value&quot;: 154,
        &quot;last&quot;: 1.23,
    }
}

I could iterate through each dictionaries of the querysets with a nested loop and search the items with a common dt then populate key:value inside a new dictionary, but it's not elegant and I don't believe it's efficient.
","python, django, django-models",0,74027619,"This will do but not so sure about efficiency.
import datetime
balances = Balance.objects.annotate(date_only=Cast('dt',DateField())).values(&quot;date_only&quot;, &quot;value&quot;)
prices = Price.objects.annotate(date_only=Cast('dt',DateField())).values(&quot;date_only&quot;, &quot;last&quot;)


data = {}
for (balance, price) in zip(balances, prices):
    str_date = balance['date_only'].strftime(&quot;%Y/%m/%d&quot;)
    if balance['date_only'] == price['date_only']:
        data[str_date] = {}
        data[str_date]['last'] = price['last']
        data[str_date]['value'] = balance['value']


print(data)

"
73711919,Getting error (OSError: [WinError 5] Access is denied) while tryng to install selenium on jupyter notebook using pip,"I have used ! pip install selenium and getting the following error-
ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\programdata\\anaconda3\\lib\\site-packages\\certifi-2020.12.5-py3.8.egg-info\\dependency_links.txt'
Consider using the `--user` option or check the permissions.

Not getting how to consider '--user' while installing the package
","python, python-3.x, error-handling, package",1,73987810,"I had the same problem, this helped
pip install selenium --user

"
73187972,VIsual Studio 2022 stuck on Restoring Nuget packages,"I have same problem like someone have here:
Visual Studio get stuck on &quot;Restoring packages for solution&quot;
I try the following:

Clear nuget cache from Tools menu. and temp, %temp% folders from RUN command.
Clear visual studio cache from here. C:\Users\Dell\AppData\Roaming\Microsoft\VisualStudio\17.0_27e1b93f
Clear .vs hidden folder of solution.
Clean and Rebuild Solution. But stuck into Restoring Nuget packages...)
I wait 15 minutes.  But nothing happened.... (There's bug here?)
I only use less than 7 nuget packages from nuget.org

Here's Visual Studio Log:
Microsoft Visual Studio Community 2022
Version 17.2.6
VisualStudio.17.Release/17.2.6+32630.192
Microsoft .NET Framework
Version 4.8.03761

Installed Version: Community

.NET Core Debugging with WSL   1.0
.NET Core Debugging with WSL

ASP.NET and Web Tools 2019   17.2.393.26812
ASP.NET and Web Tools 2019

Azure App Service Tools v3.0.0   17.2.393.26812
Azure App Service Tools v3.0.0

Azure Functions and Web Jobs Tools   17.2.393.26812
Azure Functions and Web Jobs Tools

BusinessObjectEditor   1.0
Information about my package

C# Tools   4.2.0-4.22281.5+8d3180e5f00d42f0f0295165f756f368f0cbfa44
C# components used in the IDE. Depending on your project type and settings, a different version of the compiler may be used.

Common Azure Tools   1.10
Provides common services for use by Azure Mobile Services and Microsoft Azure Tools.

CreateLayoutWizard   1.0
Create layout wizard.
   
Microsoft JVM Debugger   1.0
Provides support for connecting the Visual Studio debugger to JDWP compatible Java Virtual Machines

NuGet Package Manager   6.2.1
NuGet Package Manager in Visual Studio. For more information about NuGet, visit https://docs.nuget.org/

Razor (ASP.NET Core)   17.0.0.2218101+885a343b00bcab620a90c1550c37dafd730ce984
Provides languages services for ASP.NET Core Razor.

SQL Server Data Tools   17.0.62204.01010
Microsoft SQL Server Data Tools

TypeScript Tools   17.0.10418.2001
TypeScript Tools for Microsoft Visual Studio

Visual Basic Tools   4.2.0-4.22281.5+8d3180e5f00d42f0f0295165f756f368f0cbfa44
Visual Basic components used in the IDE. Depending on your project type and settings, a different version of the compiler may be used.

Visual F# Tools   17.1.0-beta.22329.1+702b8e77f5fbfe21e6743324c1750503e02f182d
Microsoft Visual F# Tools

Visual Studio IntelliCode   2.2
AI-assisted development for Visual Studio.

More Information:

I use old *.csproj project template (non-sdk)
I use PackageReference not packages.config
.NET 4.8
Windows 7
No proxy used. and official nuget.org/api/.... works in browser.

NOTE: this happened when I re-installed operating system.... Sometimes it took time. Sometimes it freeze and hangs on Restoring Nuget packages... message
Please how to solve that?
","c#, .net, visual-studio, nuget, visual-studio-2022",4,73188544,"According to your description I think the problem is that you used PackageReference and use nuget.exe to restore the packages.
We can see from this link that For projects migrated to PackageReference, use msbuild -t:restore to restore packages instead.
You can try  msbuild -t:restore instead of nuget restore ***.csproj to restore packages if you are using PackageReference. For more details, please refer to the above link
"
73195147,Converting shift-jis encoded file to to utf-8 in c++,"I am trying with below code to convert from shift-jis file to utf-8, but when we open the output file it has corrupted characters, looks like something is missed out here, any thoughts?
// From file
FILE* shiftJisFile = _tfopen(lpszShiftJs, _T(&quot;rb&quot;));
int nLen = _filelength(fileno(shiftJisFile));
LPSTR lpszBuf = new char[nLen];
fread(lpszBuf, 1, nLen, shiftJisFile);

// convert multibyte to  wide char
int utf16size = ::MultiByteToWideChar(CP_ACP, 0, lpszBuf, -1, 0, 0);
LPWSTR pUTF16 = new WCHAR[utf16size];
::MultiByteToWideChar(CP_ACP, 0, lpszBuf, -1, pUTF16, utf16size);

wstring str(pUTF16);

// convert wide char to multi byte utf-8 before writing to a file
fstream File(&quot;filepath&quot;, std::ios::out);
string result = string();
result.resize(WideCharToMultiByte(CP_UTF8, 0, str.c_str(), -1, NULL, 0, 0, 0));
char* ptr = &amp;result[0];
WideCharToMultiByte(CP_UTF8, 0, str.c_str(), -1, ptr, result.size(), 0, 0);
File &lt;&lt; result;

File.close();

","c++, winapi, visual-c++, character-encoding, shift-jis",1,73196580,"There are multiple problems.
The first problem is that when you are writing the output file, you need to set it to binary for the same reason you need to do so when reading the input.
fstream File(&quot;filepath&quot;, std::ios::out | std::ios::binary);

The second problem is that when you are reading the input file, you are only reading the bytes of the input stream and treat them like a string. However, those bytes do not have a terminating null character. If you call MultiByteToWideChar with a -1 length, it infers the input string length from the terminating null character, which is missing in your case. That means both utf16size and the contents of  pUTF16 are already wrong. Add it manually after reading the file:
int nLen = _filelength(fileno(shiftJisFile));
LPSTR lpszBuf = new char[nLen+1];
fread(lpszBuf, 1, nLen, shiftJisFile);
lpszBuf[nLen] = 0;

The last problem is that you are using CP_ACP. That means &quot;the current code page&quot;. In your question, you were specifically asking how to convert Shift-JIS. The code page Windows uses for its closes equivalent to what is commonly called &quot;Shift-JIS&quot; is 932 (you can look that up on wikipedia for example). So use 932 instead of CP_ACP:
int utf16size = ::MultiByteToWideChar(932, 0, lpszBuf, -1, 0, 0);
LPWSTR pUTF16 = new WCHAR[utf16size];
::MultiByteToWideChar(932, 0, lpszBuf, -1, pUTF16, utf16size);

Additionally, there is no reason to create wstring str(pUTF16). Just use pUTF16 directly in the WideCharToMultiByte calls.
Also, I'm not sure how kosher char *ptr = &amp;result[0] is. I personally would not create a string specifically as a buffer for this.
Here is the corrected code. I would personally not write it this way, but I don't want to impose my coding ideology on you, so I made only the changes necessary to fix it:
// From file
FILE* shiftJisFile = _tfopen(lpszShiftJs, _T(&quot;rb&quot;));
int nLen = _filelength(fileno(shiftJisFile));
LPSTR lpszBuf = new char[nLen+1];
fread(lpszBuf, 1, nLen, shiftJisFile);
lpszBuf[nLen] = 0;

// convert multibyte to  wide char
int utf16size = ::MultiByteToWideChar(932, 0, lpszBuf, -1, 0, 0);
LPWSTR pUTF16 = new WCHAR[utf16size];
::MultiByteToWideChar(932, 0, lpszBuf, -1, pUTF16, utf16size);

// convert wide char to multi byte utf-8 before writing to a file
fstream File(&quot;filepath&quot;, std::ios::out | std::ios::binary);
string result;
result.resize(WideCharToMultiByte(CP_UTF8, 0, pUTF16, -1, NULL, 0, 0, 0));
char *ptr = &amp;result[0];
WideCharToMultiByte(CP_UTF8, 0, pUTF16, -1, ptr, result.size(), 0, 0);
File &lt;&lt; ptr;

File.close();

Also, you have a memory leak -- lpszBuf and pUTF16 are not cleaned up.
"
74223372,"Bitwise operators:- Ball, carrot, ampersand, tilde","I want the step by step explanation of the following code:
print(1 | 0 ^ 1 &amp; ~0)

I tried with the output bit (output with  first and second bit) and got the answer as 0. The tilde function got me hooked up for some time I found it a bit hard. The answer is 1.
","python, bitwise-operators, ampersand, tilde",-3,74223613,"First you must understand what each operator does
| - Bitwise OR: Returns True (1) if either of its operands is 1. e.g.
1 | 0 == True
&amp; - Bitwise AND: Returns True if both of its operands are 1. e.g.
0 &amp; 1 == False
^ - Bitwise XOR: Returns True if only one of its operands is 1. e.g.
0 ^ 1 == True
~ - Bitwise NOT: Flips the bit of its operand.
edit: As noted by Daniel Martin, In Python specifically, it flips all of the bits of an arbitrary integer. The formula would be ~x == -x - 1 e.g.
~0 == -1
Then you must understand the order of bitwise operations
In order of precedence:
~ -&gt; &amp; -&gt; ^ -&gt; |
Solving the expression in that order

1 | 0 ^ 1 &amp; ~0  == 1 | 0 ^ 1 &amp; -1 - ~ is applied first
1 | 0 ^ 1 &amp; -1  == 1 | 0 ^ 1     - &amp; is applied second
1 | 0 ^ 1       == 1 | 1         - ^ is applied third
1 | 1           == 1             - | is applied last

"
74560568,Angular:How to load the image in full before I navigate to the page?,"I tried to add a delay between navigation and navigation but still the image takes time to load
ts:
navigate(name:string,title:string) {
    Swal.fire({
      position: 'center',
      icon: 'success',
      title: `You go to the page ${title}`,
      showConfirmButton: false,
      timer: 1500,
    })
    setTimeout(() =&gt; {
      this.router.navigate([`${name}`]);
    }
      , 1500);
  }

html:
 &lt;div class=&quot;home-container&quot;&gt;
          &lt;li (click)=&quot;navigate('home','Home')&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; data-prefix=&quot;fas&quot; data-icon=&quot;house&quot;
              class=&quot;svg-inline--fa fa-house &quot; role=&quot;img&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot; viewBox=&quot;0 0 576 512&quot;
              color=&quot;#4d4d4e&quot;&gt;
              &lt;path fill=&quot;currentColor&quot;
                d=&quot;M575.8 255.5c0 18-15 32.1-32 32.1h-32l.7 160.2c0 2.7-.2 5.4-.5 8.1V472c0 22.1-17.9 40-40 40H456c-1.1 0-2.2 0-3.3-.1c-1.4 .1-2.8 .1-4.2 .1H416 392c-22.1 0-40-17.9-40-40V448 384c0-17.7-14.3-32-32-32H256c-17.7 0-32 14.3-32 32v64 24c0 22.1-17.9 40-40 40H160 128.1c-1.5 0-3-.1-4.5-.2c-1.2 .1-2.4 .2-3.6 .2H104c-22.1 0-40-17.9-40-40V360c0-.9 0-1.9 .1-2.8V287.6H32c-18 0-32-14-32-32.1c0-9 3-17 10-24L266.4 8c7-7 15-8 22-8s15 2 21 7L564.8 231.5c8 7 12 15 11 24z&quot;&gt;
              &lt;/path&gt;
            &lt;/svg&gt;
            &lt;span class=&quot;home&quot;&gt;Home&lt;/span&gt;
          &lt;/li&gt;
        &lt;/div&gt;

html image in the home page:
&lt;img class=&quot;mor-image&quot; src=&quot;../../assets/images/Mor.png&quot; alt=&quot;mor&quot;&gt;

","angular, image",-1,74578203,"Delay won't do the job in this case. The reason is the image only load when you're in the page.
There's a trick to connect faster which is use the preload attribute. This is a technique for improving loading speed of your site.
&lt;link rel=&quot;preload&quot; as=&quot;image&quot; href=&quot;image.png&quot; /&gt;
By putting that line to the head tag (just like other script tags), you're telling browsers that this is a high priority resource, so load it as soon as possible.
More info here: https://developer.mozilla.org/en-US/docs/Web/HTML/Link_types/preload
"
72957907,"Inability to use ""MaxBy"" on ""Where"" clauses with EFCore + MySQL","My database has the following structure:
public class Ticket
{
    public int Id { get; set; }
    public List&lt;History&gt; Histories { get; set; }
}

public class Employee
{
    public int Id { get; set; }
    public string Name { get; set; }
}

public class History
{
    public int Id { get; set; }
    public Employee Employee { get; set; }
    public DateTime Timestamp { get; set; }
}

The user provides the name of the property to filter by and the query string. What I had in mind is that I needed to allow the users to query Tickets by a computed property in Tickets, such as
public Employee LatestEmployee
{
    get =&gt; History.MaxBy(x=&gt;x.Timestamp).Employee;
}

I was suggested to leave the Entity models strictly to reflect the db structure and use a separate class to represent queryable properties of the entity:
public class TicketSummary
{
    public int TicketId {get;set;}
    public Employee LatestEmployee {get;set;}
}

public IQueryable&lt;TicketSummary&gt; BuildSummaryQuery()
{
    return _context.Tickets.Select(t =&gt; new TicketSummary
        {
            TicketId = t.Id,
            LatestEmployee = t.History.MaxBy(x=&gt;x.Timestamp).Employee
        });
}

And then call BuildSummaryQuery().Where(x=&gt;x.LatestEmployee.Name == &quot;Batman&quot;). However, I found out MaxBy() could not be translated into a valid query on the MySQL Database. I keep getting a The LINQ expression could not be translated. How can I work out a similar, valid query?
","c#, mysql, dynamic-linq, ef-core-6.0",0,72957908,"As per StriplingWarrior's comment (What is the correct way to use computed properties with Dynamic LINQ?), instead of using MaxBy(), I successfully managed to create a valid query using OrderByDescending() and FirstOrDefault()
First, instead of computed properties on the entity, the actual queryable entity is
public class TicketSummary
{
    public string TicketId { get; set; }
    public History? LatestHistory { get; set; }
}

Then, the query is composed as follows
//Includes the tables needed for the filterable properties.
var firstQuery = _context.Tickets.Include(t =&gt; t.Histories).ThenInclude(h =&gt; h.Employee);

//Creates an IQueryable&lt;TicketSummary&gt; with the latest History entity
var ticketSummariesQueryable = firstQuery.Select(x =&gt; new TicketSummary
{
    TicketId = x.Id.ToString(),
    LatestHistory = x.Histories.OrderByDescending(x=&gt;x.Timestamp).FirstOrDefault()
});

//Finally apply the filters given by the user
var filteredQuery = ticketSummariesQueryable.Where(ts=&gt;ts.LatestHistory.Employee.Name == &quot;Black Canary&quot;);

This way the most recent History is stored on LatestHistory to be promptly used on queries.
"
73206867,"Failed to build capnproto on ARM, test failed","I am trying to build capnproto library for linux arm machine using arm-linux-gnueabihf-clang++ and it builds correctly but because tests is a part of a build it fails to finish build because i am building it on x64 machine for arm platform and capn binary cannot be started on x64 machine because it is compiled for arm. I was searching for similar problem and found that when you use make command you should not write make -j6 check but simply make , but this didn't help and using --with-external-capnp flag also didn't help. So the question is how to prevent running tests during the build.
","c++, embedded-linux, capnproto",0,73211398,"When cross-compiling, you need to first build and install Cap'n Proto on the host machine, so that the commands capnp and capnpc-c++ are available on the command line.
Once you've done that, you can cross-compile. Pass --with-external-capnp to ./configure when configuring cross-compiling, to tell it to use the installed copy of the tools rather than the self-built copy. Also make sure you make clean or build in a different directory so that the build doesn't accidentally try to use the host-built objects.
If this &quot;doesn't help&quot;, you'll need to provide more detail on what you're doing and what went wrong.
"
74422137,Using Hibernate @Where annotation to show non null deleted timestamp,"Hello I am using Spring Boot and JPA. My entity has a deleted_at timestamp in the DB. How do I correctly use the @Where annotation to show only entities that the deleted_at column is NOT NULL.
I tried using the @Where annotation but when it equals null I get an empty array as a response. I have tried
clause = &quot;deleted_at=null&quot;
clause = &quot;deleted_at=NULL&quot;
clause = &quot;deleted_at='NULL'&quot;

None of them worked
@Data
@Entity
@Table(name=&quot;examples&quot;)
@NamedQuery(name=&quot;Example.findAll&quot;, query=&quot;SELECT l FROM Example l&quot;)
@SQLDelete(sql = &quot;UPDATE examples SET deleted_at = CURRENT_TIMESTAMP() WHERE id = ?&quot;)
@Where(clause = &quot;deleted_at=null&quot;)
public class Example {
  @Id
  @GeneratedValue(strategy= GenerationType.IDENTITY)
  Long id;
  String name;
  Timestamp deletedAt;
}

","spring-boot, hibernate, annotations",0,74422372,"For anyone looking into this in the future, the solution is to use
@Where(clause = &quot;deleted_at IS NULL&quot;)

"
74569969,Adding Bearer Tokens to swagger doesn't work Spring Boot,"I have added the swagger config class as below,
@Configuration
@SecurityScheme(
        name = &quot;Bearer Authentication&quot;,
        type = SecuritySchemeType.HTTP,
        bearerFormat = &quot;JWT&quot;,
        scheme = &quot;bearer&quot;
)

public class SwaggerConfig {
    @Bean
    public OpenAPI customOpenAPI() {
        return new OpenAPI().info(new Info().title(&quot;Tutor Student API&quot;)
                .version(&quot;1.0.0&quot;)
                .description(&quot;Desc&quot;));
    }

And in the controller I have added like this.
@CrossOrigin(&quot;*&quot;)
@RestController
@RequestMapping(&quot;/api/v1/tutors/&quot;)
@SecurityRequirement(name = &quot;bearerAuth&quot;)
public class tutorController {
  @PostMapping(save&quot;)
  public ResponseEntity&lt;TutorResponse&gt; saveTutor(Authentication authentication,
                                                                        @Valid @RequestBody(required = true) Tutor tutor, BindingResult bindingResult) {

Here after all these changes  still I can submit a post request without the Bearer token and get 200 Success response.
","spring-boot, jwt, swagger, swagger-ui, bearer-token",0,74570029,"In the controller :
@SecurityRequirement(name = &quot;bearerAuth&quot;) has to name the right requirement name :
try :
@SecurityRequirement(name = &quot;Bearer Authentication&quot;)
Regards
"
73003300,Do not ignore NULL in MAX,"Using this dataframe:
from pyspark.sql import functions as F
df = spark.createDataFrame([(None,), (1,), (2,)], ['col_name'])
df.show()
# +--------+
# |col_name|
# +--------+
# |    null|
# |       1|
# |       2|
# +--------+

calculating MAX ignores nulls by default:
max = F.max('col_name').alias('col_name')
df.agg(max).show()
# +--------+
# |col_name|
# +--------+
# |       2|
# +--------+

Is there a way to aggregate using MAX, but not ignoring null values? If there's null, it should return null.
","apache-spark, pyspark, apache-spark-sql, null, max",0,73003301,"We can do this, but it's quite verbose...
max = F.when(F.expr(&quot;every(col_name is not null)&quot;), F.max(&quot;col_name&quot;)).alias(&quot;col_name&quot;)
df.agg(max).show()
# +--------+
# |col_name|
# +--------+
# |    null|
# +--------+

Shorter syntax:
max = F.when(~F.expr(&quot;any(col_name is null)&quot;), F.max(&quot;col_name&quot;)).alias(&quot;col_name&quot;)
df.agg(max).show()

"
74367732,With gradle how to get the dependency tree of a library?,"Say I want to retrieve with graddle the dependancy tree of this artifact : com.google.firebase:firebase-firestore:24.4.0
How can I do ?
","java, maven, gradle, android-gradle-plugin, build.gradle",1,74373137,"You can't do that, An aar does not contain any dependency information by itself.
All the information of this aar is stored in pom.xml which can be found here over google maven repo.
And this will only show you what Gradle dependencies command will do, and those are the transitive dependencies meaning the direct dependencies for this aar, Which By default, Gradle resolves them automatically.
the pom.xml for com.google.firebase:firebase-firestore:24.4.0
&lt;?xml version='1.0' encoding='UTF-8'?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
  &lt;groupId&gt;com.google.firebase&lt;/groupId&gt;
  &lt;artifactId&gt;firebase-firestore&lt;/artifactId&gt;
  &lt;version&gt;24.4.0&lt;/version&gt;
  &lt;packaging&gt;aar&lt;/packaging&gt;
  &lt;dependencies&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;androidx.annotation&lt;/groupId&gt;
      &lt;artifactId&gt;annotation&lt;/artifactId&gt;
      &lt;version&gt;1.1.0&lt;/version&gt;
      &lt;scope&gt;compile&lt;/scope&gt;
      &lt;type&gt;jar&lt;/type&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;com.google.android.gms&lt;/groupId&gt;
      &lt;artifactId&gt;play-services-base&lt;/artifactId&gt;
      &lt;version&gt;18.0.1&lt;/version&gt;
      &lt;scope&gt;compile&lt;/scope&gt;
      &lt;type&gt;aar&lt;/type&gt;
    &lt;/dependency&gt;
  &lt;/dependencies&gt;
  &lt;name&gt;firebase-firestore&lt;/name&gt;
  &lt;licenses&gt;
    &lt;license&gt;
      &lt;name&gt;The Apache Software License, Version 2.0&lt;/name&gt;
      &lt;url&gt;http://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt;
      &lt;distribution&gt;repo&lt;/distribution&gt;
    &lt;/license&gt;
  &lt;/licenses&gt;
&lt;/project&gt;


This pom.xml include com.google.android.gms which has its own pom.xml
&lt;?xml version='1.0' encoding='UTF-8'?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
  &lt;groupId&gt;com.google.android.gms&lt;/groupId&gt;
  &lt;artifactId&gt;play-services-basement&lt;/artifactId&gt;
  &lt;version&gt;18.1.0&lt;/version&gt;
  &lt;packaging&gt;aar&lt;/packaging&gt;
  &lt;dependencies&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;androidx.collection&lt;/groupId&gt;
      &lt;artifactId&gt;collection&lt;/artifactId&gt;
      &lt;version&gt;1.0.0&lt;/version&gt;
      &lt;scope&gt;compile&lt;/scope&gt;
      &lt;type&gt;jar&lt;/type&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;androidx.core&lt;/groupId&gt;
      &lt;artifactId&gt;core&lt;/artifactId&gt;
      &lt;version&gt;1.2.0&lt;/version&gt;
      &lt;scope&gt;compile&lt;/scope&gt;
      &lt;type&gt;aar&lt;/type&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;androidx.fragment&lt;/groupId&gt;
      &lt;artifactId&gt;fragment&lt;/artifactId&gt;
      &lt;version&gt;1.0.0&lt;/version&gt;
      &lt;scope&gt;compile&lt;/scope&gt;
      &lt;type&gt;aar&lt;/type&gt;
    &lt;/dependency&gt;
  &lt;/dependencies&gt;
  &lt;name&gt;play-services-basement&lt;/name&gt;
  &lt;licenses&gt;
    &lt;license&gt;
      &lt;name&gt;Android Software Development Kit License&lt;/name&gt;
      &lt;url&gt;https://developer.android.com/studio/terms.html&lt;/url&gt;
      &lt;distribution&gt;repo&lt;/distribution&gt;
    &lt;/license&gt;
  &lt;/licenses&gt;
&lt;/project&gt;

What I am trying to say, Is that unless you iterate the process and fetch the POM files of the dependencies yourself, with a custom task, All you can use is gradle dependencies command to check the transitive dependencies used by your project or module.
UPDATE:
You can easily start a new gradle project by following these simple steps.

mkdir gradleExp
 cd gradleExp
gradle init  # 1.basic 1.groovy random name
update the empty build.gradle with the following

plugins {
    id 'java'
}
repositories {
    google()
    mavenCentral()
}

dependencies {
    implementation &quot;com.google.firebase:firebase-firestore:24.4.0&quot;
}


gradle dependencies # to list all
gradle dependencies --configuration compileClasspath  # reduce output to show only Compile classpath for source set 'main'

NOTE: missing either google() or mavenCentral() will show some failure in the result shown.
"
74500669,Accessing an element by index of EventTarget type in TypeScript,"I am trying to access an input element on a event.target object using event.target[0] in TypeScript but I keep getting this error:
Element implicitly has an 'any' type because expression of type '0' can't be used to index type 'EventTarget'.
Property '0' does not exist on type 'EventTarget'.
This is my code so far:
const counterDecrement = document.getElementById(&quot;counter__decrement&quot;)!;
const counterIncrement = document.getElementById(&quot;counter__increment&quot;)!;
const counterForm = document.getElementById(&quot;counter__form&quot;)!;

counterDecrement.addEventListener(&quot;click&quot;, () =&gt; {
  counterValue.innerText = (+counterValue.innerText - 1).toString();
});

counterIncrement.addEventListener(&quot;click&quot;, () =&gt; {
  counterValue.innerText = (+counterValue.innerText + 1).toString();
});

counterForm.addEventListener(&quot;submit&quot;, event =&gt; {
  event.preventDefault();
  event.target as HTMLInputElement;
  if (event.target) {
    console.log(event.target[0]);
  }
});

I get a squiggly red line under event.target[0] (line 18)
Any ideas how to resolve this?
Thanks
",typescript,0,74500824,"I think you can access it via counterForm's elements and you need to set what kind of html element is counterForm
you can simply use it in this way :
const counterForm = document.getElementById(&quot;counter__form&quot;) as HTMLFormElement;
counterForm.elements[0];

"
73989407,Pandas: Average of columns with incremented names in the middle,"I have the following data frame:
df_ex = pd.DataFrame({
'alpha.1.try': [2,4,2.0,-0.5,6,120], 
'alpha.1.test': [1, 3, 4, 2,40,11], 
'alpha.1.sample': [3, 2, 3, 4,2,2], 
'alpha.3.try': [6, 2.2, 7, 0,3,3],
'alpha.3.test': [12, 4, 7, -5,5,5],
'alpha.3.sample': [2, 3, 8, 2,12,8],
'alpha.5.try': [6, 2.2, 7, 0,3,3],
'alpha.5.test': [12, 4, 11, -5,5,5],
'alpha.5.sample': [2, 3, 8, 2,12,8]})
df_ex

|    |   alpha.1.try |   alpha.1.test |   alpha.1.sample |   alpha.3.try |   alpha.3.test |   alpha.3.sample |   alpha.5.try |   alpha.5.test |   alpha.5.sample |
|---:|--------------:|---------------:|-----------------:|--------------:|---------------:|-----------------:|--------------:|---------------:|-----------------:|
|  0 |           2   |              1 |                3 |           6   |             12 |                2 |           6   |             12 |                2 |
|  1 |           4   |              3 |                2 |           2.2 |              4 |                3 |           2.2 |              4 |                3 |
|  2 |           2   |              4 |                3 |           7   |              7 |                8 |           7   |             11 |                8 |
|  3 |          -0.5 |              2 |                4 |           0   |             -5 |                2 |           0   |             -5 |                2 |
|  4 |           6   |             40 |                2 |           3   |              5 |               12 |           3   |              5 |               12 |
|  5 |         120   |             11 |                2 |           3   |              5 |                8 |           3   |              5 |                8 |

but it could be quite large, the names would vary in number and suffix, .number.suffix is a group to average throughout.
I would like to average the contents of prefix.1.suffix with prefix.3.suffix with prefix.5.suffix and put these averages in a new column prefix.135.suffix
I have tried
avg135 = df_ex.columns[(df.columns.str.contains('alpha.1') | df.columns.str.contains('alpha.3') | 
                           df.columns.str.contains('alpha.5')].tolist()

to create a list of columns to slice the data frame because there could be more than the headers seen here and I want the option to select a subset. But the rest, grouping similar suffix and averaging them is a bit out of my programming skills.
","pandas, average, prefix, suffix",1,73991673,"You can use MultiIndex:
# Split each column header into a 3-tuple, e.g.: (&quot;alpha&quot;, &quot;1&quot;, &quot;try&quot;),
# (&quot;alpha&quot;, &quot;1&quot;, &quot;test&quot;), etc.
df_ex.columns = pd.MultiIndex.from_tuples([col.split(&quot;.&quot;) for col in df_ex.columns])

# Group by prefix and suffix and take the mean of each column group
result = df_ex.groupby(level=[0,2], axis=1).mean()

# Rename the resulting columns
result.columns = [f&quot;{a}.135.{b}&quot; for a, b in result.columns]

"
74065917,Looking to get the frequency of an int array through a hashmap,"public int[] topKFrequent(int[] nums, int k) {
    if (nums == null || nums.length == 0 || k &lt;= 0) return new int[0];
    Map&lt;Integer, Integer&gt; freqMap = new HashMap&lt;&gt;();
    for (int currNum : nums) freqMap.put(currNum, freqMap.getOrDefault(currNum, 0)+1);

I don't understand what the .getOrDefault(currNum, 0)+1); is doing, but it seems to calculate the frequency properly. I'd like some clearance on this method please and how exactly it's working.
",java,0,74066067,"
The getOrDefault(Object key, V defaultValue) method of Map
interface, implemented by HashMap class is used to get the value
mapped with specified key. If no value is mapped with the provided key
then the default value is returned.
Syntax: default V getOrDefault(Object key, V defaultValue)
Parameters: This method accepts two parameters:

key: which is the key of the element whose value has to be obtained.

defaultValue: which is the default value that has to be returned, if no value is mapped with the specified key.


Return Value: This method returns value mapped with the specified key, otherwise default value is returned.

Reference: https://www.geeksforgeeks.org/hashmap-getordefaultkey-defaultvalue-method-in-java-with-examples/
So, by using that method, first, you're trying to get key's value from the freqMap. If you can find it in map, then you're adding 1 to it and putting it back to freqMap. So, that means that you encountered this key before. Otherwise, that method , .getOrDefault(), returns you default value, which is 0, then you're adding 1 to it since you encountered it recently. And putting that value 1 to back to map. So, in the future, when you see that key again, you'll get it's value 1 that you added to the map before, will increase it to 2, and will put it back into the map.
"
74425498,Powershell: Create table with extracted values from between tags without any white spaces (seperated by ; ),"I have a text file that looks like the below which contains a table at line 8. Now the table can vary in length, but it always contains 4 values per line.
Input file:
0001117945
14102022
0001056.98
GBP
0000000.00
0000000.00
\\GLORSAWA01\EHIShared\Remittance\UK01\UKI_REM_COL58652cbc13ca49aabf000.pdf                                                                                                                                                                                         
&lt;LineItemTable&gt;&lt;LINEITEM&gt;&lt;LINEITEMFIELD&gt;20220916&lt;/LINEITEMFIELD&gt;&lt;LINEITEMFIELD&gt;2525636         &lt;/LINEITEMFIELD&gt;&lt;LINEITEMFIELD&gt;0.00                            &lt;/LINEITEMFIELD&gt;&lt;LINEITEMFIELD&gt;246.05                          &lt;/LINEITEMFIELD&gt;&lt;/LINEITEM&gt;&lt;LINEITEM&gt;&lt;LINEITEMFIELD&gt;20220920&lt;/LINEITEMFIELD&gt;&lt;LINEITEMFIELD&gt;2527541         &lt;/LINEITEMFIELD&gt;&lt;LINEITEMFIELD&gt;0.00                            &lt;/LINEITEMFIELD&gt;&lt;LINEITEMFIELD&gt;450.12                          &lt;/LINEITEMFIELD&gt;&lt;/LINEITEM&gt;&lt;LINEITEM&gt;&lt;LINEITEMFIELD&gt;20220922&lt;/LINEITEMFIELD&gt;&lt;LINEITEMFIELD&gt;2531147         &lt;/LINEITEMFIELD&gt;&lt;LINEITEMFIELD&gt;0.00                            &lt;/LINEITEMFIELD&gt;&lt;LINEITEMFIELD&gt;360.81                          &lt;/LINEITEMFIELD&gt;&lt;/LINEITEM&gt;&lt;/LineItemTable&gt;

The structure of the table in line 8 is always the same and looks like the below when (formatted just for better visibility).
&lt;LineItemTable&gt;
    &lt;LINEITEM&gt;
        &lt;LINEITEMFIELD&gt;20220916&lt;/LINEITEMFIELD&gt;
        &lt;LINEITEMFIELD&gt;2525636         &lt;/LINEITEMFIELD&gt;
        &lt;LINEITEMFIELD&gt;0.00                            &lt;/LINEITEMFIELD&gt;
        &lt;LINEITEMFIELD&gt;246.05                          &lt;/LINEITEMFIELD&gt;
    &lt;/LINEITEM&gt;
    &lt;LINEITEM&gt;
        &lt;LINEITEMFIELD&gt;20220920&lt;/LINEITEMFIELD&gt;
        &lt;LINEITEMFIELD&gt;2527541         &lt;/LINEITEMFIELD&gt;
        &lt;LINEITEMFIELD&gt;0.00                            &lt;/LINEITEMFIELD&gt;
        &lt;LINEITEMFIELD&gt;450.12                          &lt;/LINEITEMFIELD&gt;
    &lt;/LINEITEM&gt;
    &lt;LINEITEM&gt;
        &lt;LINEITEMFIELD&gt;20220922&lt;/LINEITEMFIELD&gt;
        &lt;LINEITEMFIELD&gt;2531147         &lt;/LINEITEMFIELD&gt;
        &lt;LINEITEMFIELD&gt;0.00                            &lt;/LINEITEMFIELD&gt;
        &lt;LINEITEMFIELD&gt;360.81                          &lt;/LINEITEMFIELD&gt;
    &lt;/LINEITEM&gt;
&lt;/LineItemTable&gt;

I'm trying to extract all the values from the text file and writing them into another file but I want to keep the first 7 lines as is and then have the values from line 8 displayed in multiple lines seperated by ; without any white spaces.
Desired output file:
0001117945
14102022
0001056.98
GBP
0000000.00
0000000.00
\\GLORSAWA01\EHIShared\Remittance\UK01\UKI_REM_COL58652cbc13ca49aabf000.pdf                                                                                                                                                                                         
20220916;2525636;0.00;246.05
20220920;2527541;0.00;450.12
20220922;2531147;0.00;360.81

This is how far I got but I cannot get the table from line 8 converted into my desired output. Any help would be greatly appreciated.
$importfolder = &quot;.\PowerShell_script\&quot; 
$outputfolder = &quot;.\PowerShell_script\Output\&quot;
$files = &quot;.\PowerShell script\*.txt&quot; 
$list = Get-ChildItem -Path $files | select Name


$find1 = &quot;&lt;LineItemTable&gt;&lt;LINEITEM&gt;&lt;LINEITEMFIELD&gt;&quot;
$find2 = &quot;&lt;/LINEITEMFIELD&gt;&lt;LINEITEMFIELD&gt;&quot; 
$find3 = &quot;&lt;/LINEITEMFIELD&gt;&lt;/LINEITEM&gt;&lt;LINEITEM&gt;&lt;LINEITEMFIELD&gt;&quot;

$replace1 = &quot;&quot;
$replace2 = &quot;`t&quot; 
$replace3 = &quot;`n&quot;

ForEach($file in $list){
  
    echo $file.Name
    $filename = $file.Name
    $file = $importfolder + $file.Name
    $outputfile = $outputfolder + $filename

    $filecontent = Get-Content $file | 
    ForEach-Object { 
        if($_ -Match $find1)
            {$_ -replace $replace1}         

        if($_ -Match $find2)
            {$_ -replace $replace2} 

        if($_ -Match $find3)
            {$_ -replace $replace3} 

        else {$_} # output the line as is
     } | Set-Content $outputfile
}

",powershell,1,74425576,"It looks like this logic works properly for the example file in question:
$file = Get-Content path\to\examplefile.txt
$(
    $file[0..($file.Length - 2)]
    ($file[-1] -as [xml]).SelectNodes('*/LINEITEM').ForEach{
        $_.LINEITEMFIELD.Trim() -join ';'
    }
)

Basically, leave the all lines up until the one before last as they are and the last line treat it as an XML.
Implementing this in your loop, the code would look like this:
foreach($file in $list) {
    $filename   = $file.Name
    $file       = $importfolder + $file.Name
    $outputfile = $outputfolder + $filename

    $content = Get-Content $file
    $(
        $content[0..($content.Length - 2)]
        ($content[-1] -as [xml]).SelectNodes('*/LINEITEM').ForEach{
            $_.LINEITEMFIELD.Trim() -join ';'
        }
    ) | Set-Content $outputfile
}

"
73616779,Get CPU usage in Azure App Service with C#,"I am trying to measure CPU usage for my application hosted with Azure App Service programmatically.
I use Performance Counter but it needs administration privilege which is not possible on App Service. on another hand it only works fully functional if the operation system of App Service is Windows.
Does someone know how I can get the CPU usage of my application on Azure App Service programmatically?
","c#, azure, azure-appservice",0,73622903,"For a cross platform cpu measurement use event counters:

EventCounters are .NET APIs used for lightweight, cross-platform, and near real-time performance metric collection. EventCounters were added as a cross-platform alternative to the &quot;performance counters&quot; of .NET Framework on Windows. In this article, you'll learn what EventCounters are, how to implement them, and how to consume them.
The .NET runtime and a few .NET libraries publish basic diagnostics information using EventCounters starting in .NET Core 3.0. Apart from the EventCounters that are provided by the .NET runtime, you may choose to implement your own EventCounters. EventCounters can be used to track various metrics. Learn more about them in well-known EventCounters in .NET
EventCounters live as a part of an EventSource, and are automatically pushed to listener tools on a regular basis. Like all other events on an EventSource, they can be consumed both in-proc and out-of-proc via EventListener and EventPipe. This article focuses on the cross-platform capabilities of EventCounters, and intentionally excludes PerfView and ETW (Event Tracing for Windows) - although both can be used with EventCounters.

There are several event counter provided by the .Net framework, listened here.
You can listen to these events in-proc using an EventListener. The code below shows an example implementation. The value of EventCounterIntervalSec determines the frequency in seconds of the measurements.
First, we need a hosted service that listens to the runtime event source during the lifetime of the web app process
public class CpuUsageListenerService : BackgroundService
{
    private CpuUsageListener cpuListener;

    protected override Task ExecuteAsync(CancellationToken stoppingToken)
    {
        cpuListener = new CpuUsageListener();

        return Task.CompletedTask;
    }

    public double LastValue =&gt; cpuListener.LastValue;
}

public sealed class CpuUsageListener : EventListener
{
    public double LastValue { get; private set; }

    protected override void OnEventSourceCreated(EventSource eventSource)
    {
        if (eventSource.Name.Equals(&quot;System.Runtime&quot;))
            EnableEvents(eventSource, EventLevel.LogAlways, EventKeywords.All, new Dictionary&lt;string, string&gt; { { &quot;EventCounterIntervalSec&quot;, &quot;1&quot; } });
    }

    protected override void OnEventWritten(EventWrittenEventArgs eventData)
    {
        if (eventData.EventName != &quot;EventCounters&quot;)
            return;

        var payload = (IDictionary&lt;string, object&gt;)eventData.Payload[0];
        var isCpuCounterValue = payload[&quot;Name&quot;] == &quot;cpu-usage&quot;;
        if (!isCpuCounterValue)
            return;

        LastValue = (double)payload[&quot;Mean&quot;];
        Console.WriteLine(LastValue); // Output value to console every second
    }
}

Register the service in your startup.cs:
public void ConfigureServices(IServiceCollection services)
{
    ...
            
    services.AddSingleton&lt;CpuUsageListenerService&gt;();
    services.AddHostedService(sp =&gt; sp.GetService&lt;CpuUsageListenerService&gt;());
            
    ...
}

The, finally, in your controller you can get the last value like this:
public class ValuesController : ControllerBase
{
    private readonly CpuUsageListenerService cpuUsageListenerService;

    public ValuesController(CpuUsageListenerService cpuUsageListenerService)
    {
        this.cpuUsageListenerService = cpuUsageListenerService;
    }

    [HttpGet(&quot;/api/cpu&quot;)]
    public ActionResult&lt;double&gt; CpuUsage()
    {
        return cpuUsageListenerService.LastValue;
    }
}

"
73000455,Problem adding link in anchor inside paragraph with dom,"I am trying to add an href in an anchor that is inside a paragraph.
var newa= document.createElement('p'); 
  newa.innerHTML = &quot;&lt;span&gt;Or&lt;/span&gt; &lt;a&gt;make your renewal payment&lt;/a&gt;&quot;;

I added it this way because the client needs them to have different styles with a border in the anchor only.
I tried this:
var linkdiv = document.querySelector(&quot;.renewnow&quot;); /*parent div*/
const getlink = linkdiv.getElementsByTagName(&quot;a&quot;);
getlink.href=&quot;/newa&quot;

I feel it's not possible to do that, but I tried it anyway
","javascript, dom",0,73000573,"The way you are trying to handle the element with innerHTML is not wrong, but then you have a string that you have to work with and the only way to modify this string is using Regex. But there is an easier way if you just create all required elements.


const p = document.createElement('p');
const span = document.createElement('span');
span.innerText = 'Or ';
const a = document.createElement('a');
a.innerText = 'make your renewal payment';
a.href = 'https://example.com';

p.append(span);
p.append(a);

document.body.append(p);



"
73297257,Intellij: Warning: 'List<String>' may not contain objects of type 'List<String>' (Suspicious collections method calls),"Below is a code snippet where intellij is throwing a Suspicious collections method calls warning, but I don't understand why. The only thing I can think of is that maybe intellij thinks one of the lists could be null, but that also throws the same error.
Is this an Intellij bug, or is there really some corner case that I'm not thinking of?
public class Foo {
    public static void main(String[] args) {
        List&lt;String&gt; foo = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);
        List&lt;String&gt; bar = new ArrayList&lt;&gt;(foo);
        bar.remove(foo); // Warning: 'List&lt;String&gt;' may not contain objects of type 'List&lt;String&gt;'
    }
}


public class Foo {
    public static void main(String[] args) {
        List&lt;String&gt; foo = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);
        List&lt;String&gt; bar = new ArrayList&lt;&gt;(foo);
        if (foo != null &amp;&amp; bar !=null) {
            bar.remove(foo); // Warning: 'List&lt;String&gt;' may not contain objects of type 'List&lt;String&gt;'
        }
    }
}

Intellij version 2022.1.4 Ultimate
","java, intellij-idea, intellij-14",0,73297302,"List&lt;String&gt; foo = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);
List&lt;String&gt; bar = new ArrayList&lt;&gt;(foo);

// bar.remove(foo); This is the same thing as:
bar.remove(Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)); // still makes no sense.

// What would make sense:
bar.remove(&quot;a&quot;); // remove the element &quot;a&quot;
bar.removeAll(foo); // remove all the elements in foo

In short, in a List&lt;String&gt;, you're usually going to be calling remove(String) or removeAll(Collection&lt;String&gt;), not remove(List&lt;String&gt;), which won't really do what you want.
"
73410047,Displaying random RGB pixels in Python,"I am starting a little project and I am having some difficulty in finding the answer that I am looking for. I don't really know exactly what terms I should be using to search, and couldn't find anything similar so I am sorry if this has been asked previously.
I am essentially trying to have a 2D plot of a set size, 300x300 for example full of random RGB pixels. I have figured out how to plot them with imshow and remove the axis labels so far, but it looks odd like it is zoomed in too far. Also, I know I can use RGB arguements in imshow, but the matplotlib manual touches on it, but never gives any examples. The closest cmap I have found to RGB is hsv so I am using that for now until I find the RGB solution.
Can anyone help me with assigning a random RGB value to each pixel instead of using cmap, and maybe adjusting the apparent size of the image so the pixels are less &quot;zoomed in&quot;? I am open to using something other than imshow for flexibility, it is just the only thing I found to do what I want. Thank you very much in advance!
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from numpy import random

Z = random.random((300,300))
plt.imshow(Z, cm.get_cmap(&quot;hsv&quot;), interpolation='nearest')
plt.axis('off')
plt.show()

","python, matplotlib, rgb, imshow",0,73410091,"Here's how you do it with PIL:
from PIL import Image
import numpy as np

data = (np.random.random( (300,300,3) ) * 256).astype(np.uint8)
img = Image.fromarray(data)
img.show()
img.save('rand.png')

"
74363222,Vue doesn't fetch data from API in first render,"After logging in I call await router.push('/'); to redirect to the home page where I load users and I get this error GET http://localhost:8080/users 401 then when I  refrehs the page in the exact same component I get the data just fine with a 200 status. I'm not sure what's going on
async login (username, password) {

    const response = await axios.post('/auth/login', {
        username: username,
        password: password
    });

    this.user = response.data;
    localStorage.setItem('user', JSON.stringify(this.user));

    await router.push('/');
},

This is the function I call after logging in
This is the router.js
import { createRouter, createWebHistory } from 'vue-router';
import Login from '../views/Auth/Login.vue';
import { useAuthStore } from '../stores/auth.store.js';
import IndexUser from &quot;../views/Users/IndexUser.vue&quot;;
import IndexHive from '../views/Hives/IndexHive.vue';

const routes = [
    { path: '/', name: 'Home', component: IndexUser },
    { path: '/login', name: 'Login', component: Login },
    { path: '/users', redirect: { name: 'Home' } },
    { path: '/users/create', name: 'CreateUser', component: CreateUser },
    { path: '/hives', name: 'IndexHive', component: IndexHive }

];

import CreateUser from '../views/Users/CreateUser.vue';

const router = createRouter({
    history: createWebHistory(),
    routes
});

router.beforeEach(to =&gt; {

    const authStore = useAuthStore();

    const publicPages = ['/login'];
    const authRequired = !publicPages.includes(to.path);

    if (authRequired &amp;&amp; !authStore.user) {
        return '/login';
    }
})

export default router;

This is the component I redirect to after logging in
onMounted( async () =&gt; {
  const response = await axios.get('/users');
  users.value = response.data;
})

Devtools

Network tab

Axios Error

details of request/response


Response of login

","vue.js, axios, vuejs3, vue-router",0,74363995,"Update 2
Having seen the code, I think the problem is here:
import axios from &quot;axios&quot;;

axios.defaults.baseURL = import.meta.env.VITE_API_URL;

if (localStorage.getItem('user')) {
    const user = JSON.parse(localStorage.getItem('user'));
    axios.defaults.headers.common['Authorization'] = `Bearer ${user?.accessToken}`;
}

this will read the axios.defaults.headers when the helpers/axios.js file is loaded. This is why axios.get('/users'); only works on second load, or rather only when the authentication is already loaded into localStorage. A change to the user object or a local storage will not update since this code only runs once at the beginning, the change to axios.defaults.headers needs to be dynamic.
Update
if setTimeout didn't work that could be due to a different issue. Also, if your request works a second time, but it also works if the authentication is passed directly, it seems to me that it has something to do with the authentication being handled implicitly.
I think what's happening is that you are creating multiple instances of axios and relying on shared authentication
// create single axios instance
export const api = axios.create({
   withCredentials: true,
   baseURL: BASE_URL // optional
})

// then use
await api.post('/auth/login', {
  username: username,
  password: password
});

// and 
await api.get('/users');

This might make the axios instance remember the authentication information between calls. It may still require handling race condition if you have an app that doesn't wait on the login request to finish.

I think this is just an issue with a race condition
POST:/login and GET:/users requests appear to be done in parallel.
onMounted( async () =&gt; {
  // this should wait until the `login` has been handled
  const response = await axios.get('/users');
  users.value = response.data;
})

I don't see how you call login so can't offer the the exact solution, but if you can store the login request state as a reactive variable, you can do something like
watch: {
  loginState:{
    immediate: true
    handler(value){
      if (value === LOADED) {
        const response = await axios.get('/users');
        users.value = response.data;
      }
    }
  }
})

here's what the changes to the authStore might look like
export const STATES = {
  INIT:&quot;INIT&quot;,
  PROCESSING:&quot;PROCESSING&quot;,
  ERROR:&quot;ERROR&quot;,
  LOADED:&quot;LOADED&quot;,
}
export const loginState = ref(STATES.INIT);

async login (username, password) {
    loginState.value = STATES.PROCESSING
    try{
      const response = await axios.post('/auth/login', {
        username: username,
        password: password
      });
      loginState.value = STATES.LOADED
      this.user = response.data;
      localStorage.setItem('user', JSON.stringify(this.user));

      await router.push('/');
    }catch(e){
      // handle error
      loginState.value = STATES.ERROR
    }
},

"
73443078,How to get ID from conditionally rendered item in modal component?,"I have a conditionally-rendered notes and I want to delete specific note, depends on ID.
I have no problem with deleting without modal, but my problem is that I want to delete note only when modal is accepted.
There is modal component:
 &lt;DeleteModal
    :modalVisible=&quot;modalVisible&quot;
    :restore=&quot;modalType&quot;
    @closeModal=&quot;modalVisible = false&quot;
    @deleteItem=&quot;deleteNote(note.id)&quot;
    @restoreItem=&quot;restore()&quot;
  /&gt;

Delete method:
const deleteNote = (id) =&gt; {
  Inertia.delete(route('notes.destroy', id));
  getNotes();
};

and there is how I render notes:
 &lt;div class=&quot;my-4&quot; v-for=&quot;note in notesForIssue&quot; :key=&quot;note&quot;&gt;
                &lt;div class=&quot;flex flex-row justify-between&quot;&gt;&lt;/div&gt;

                &lt;div class=&quot;bg-gray-100 w-full min-h-16 mt-2 rounded whitespace-normal&quot;&gt;
                  &lt;div class=&quot;px-8 py-4&quot;&gt;
                    &lt;p&gt;{{ note.text }}&lt;/p&gt; 

                    &lt;div class=&quot;flex flex-row items-center justify-between&quot;&gt;
                      &lt;div class=&quot;flex flex-row text-xs&quot;&gt;
                        &lt;span class=&quot;text-[#2563EB]&quot;&gt;{{ note.updated_at }}&lt;/span&gt;
                        &lt;p class=&quot;ml-2&quot;&gt;{{ __('history.by') }}&lt;/p&gt;
                        &lt;p class=&quot;font-bold ml-2 text-[#2563EB]&quot;&gt;{{ note.updated_by }}&lt;/p&gt;
                      &lt;/div&gt;
                      &lt;div @click=&quot;modalType=false; modalVisible=true;&quot;&gt;
                      &lt;/div&gt;
                    &lt;/div&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;

But I have no access to note.id here:  @deleteItem=&quot;deleteNote(note.id)&quot;. Any ideas, how to solve this problem?
","vue.js, vuejs3, vue-composition-api, vue-script-setup",0,73444594,"Try this approach.
When you click on the div, instead of set visibality of modal,

set selectedItem
set visibility

then you accept by modal, you have a `selectedItem' for delete
After delete, clear the selectedItem.
"
73750290,How to exract specific values from the lists created by a statistical model (t-test)?,"How can extract statistics from this model. To conduct several T-tests I used this:
A&lt;-lapply(merged_DF_final[2:6], function(x) t.test(x ~ merged_DF_final$Group))

How can I extract information about the p-value, t statistics, confidence interval, and group means for each specific subtest and output on a single table?
This is what is saved on A:
$HC_HC_L_amygdala_baseline

    Welch Two Sample t-test

data:  x by merged_DF_final$Group t = 0.039543, df = 47.412, p-value =
0.9686 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval:  -0.4694404  0.4882694 sample estimates: mean in group CONN   mean in group HC 
         0.2954200          0.2860055 


$HC_HC_L_culmen_baseline

    Welch Two Sample t-test

data:  x by merged_DF_final$Group t = 0.81387, df = 53.695, p-value =
0.4193 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval:  -0.2970321  0.7028955 sample estimates: mean in group CONN   mean in group HC 
         0.4020883          0.1991566 


$HC_HC_L_fusiform_baseline

    Welch Two Sample t-test

data:  x by merged_DF_final$Group t = 0.024945, df = 53.851, p-value =
0.9802 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval:  -0.5768786  0.5914136 sample estimates: mean in group CONN   mean in group HC 
         0.5552184          0.5479509 


$HC_HC_L_insula_baseline

    Welch Two Sample t-test

data:  x by merged_DF_final$Group t = 0.79659, df = 52.141, p-value =
0.4293 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval:  -0.3000513  0.6951466 sample estimates: mean in group CONN   mean in group HC 
        0.12436946        -0.07317818 


$HC_HC_L_lingual_gyrus_baseline

    Welch Two Sample t-test

data:  x by merged_DF_final$Group t = -0.11033, df = 53.756, p-value =
0.9126 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval:  -0.5172863  0.4633268 sample estimates: mean in group CONN   mean in group HC 
         0.4395066          0.4664864

","r, list, statistics, t-test",0,73750326,"Look at names(A[[1]]) or str(A[[1]]) to see what the components are, then use $ or [[ to extract them, e.g.
names(t.test(extra ~ group, data = sleep))
 [1] &quot;statistic&quot;   &quot;parameter&quot;   &quot;p.value&quot;     &quot;conf.int&quot;    &quot;estimate&quot;   
 [6] &quot;null.value&quot;  &quot;stderr&quot;      &quot;alternative&quot; &quot;method&quot;      &quot;data.name&quot;

You can then sapply(A, &quot;[[&quot;, &quot;statistic&quot;) or (being more careful) vapply(A, &quot;[[&quot;, &quot;statistic&quot;, FUN.VALUE = numeric(1))
If you like tidyverse you can purrr::map_dbl(A, &quot;statistic&quot;) (for results with a single value); you'll need purrr::map(A, ~.$estimate[1]) for the mean of the first group etc.. (sapply() will automatically collapse to a matrix.)
"
73232841,How the datas are get in Power Bi (direct query) with a filter,"I was wondering, when you get the data in power bi (with Direct Query)
And you filter the data in the Power Query Editor.(Lignes filtrÃ©es = Filtered rows)
You will get the data first then you filter the data,
or you filter the data first the you get the data?

","powerbi, directquery",0,73232937,"Actually, both are data which contains different values.
PowerBI is operating data from top to bottom. So, it gets the data from Source, then navigates to the selected table, then applies filters and some other jobs.
So, getting the data first and then filtering it is meaningful because you can see all the data changes in the Edit Query page.
But getting the data after filtering it in query may also meaningful because all the filtering is handled in database and if you have a good infrastructure, your data will come faster.
And the best case approach is: &quot;using filtering in queries is OK but don't be complex on your database queries&quot;. So, there is no correct answer for your question, you should just use a little bit of this and that depend on the quality of your data.
"
74053380,Going to the next Input Field using enter key instead of tab key for pypsimplegui,"I have created a form using pypsimplegui for manual input of some data.
Noticed that the default setting is to use tab button to move to the next input field.
I like to change to use enter key to move to the next input field.
Does anyone know how to get about to do it ?
",python,0,74057142,"I managed to find a solution to my question. First we use window.bind and follow by an event =='Return'.
window = sg.Window(&quot;Verification Inspection Records&quot;,[[sg.Menu(menu_layout)],
            [sg.Text(&quot;              Verification Inspection Records               &quot;, size=(None, None), font=(&quot;Arial&quot;,30,'bold'), text_color=&quot;Dark Blue&quot;, background_color=&quot;white&quot; )],
            [sg.Text(&quot;&quot;, size=(None, None), font=(&quot;Arial&quot;,5, 'bold'),)],
            [sg.Text(&quot;Inspected By:&quot;, size=(15,None), font=(&quot;Arial&quot;,18)), sg.Input(size=(30,None), font=(&quot;Arial&quot;,18), key='employee_id')],
            [sg.Text(&quot;&quot;, size=(None, None), font=(&quot;Arial&quot;,5, 'bold'),)],
            [sg.Text(&quot;Inspection Layer:&quot;, size=(15,None), font=(&quot;Arial&quot;,18)), sg.InputCombo(process_list,key='inspect_layer', size=(30,None), font=(&quot;Arial&quot;,18))],   
            #[sg.Text(&quot;&quot;, size=(None, None), font=(&quot;Arial&quot;,5, 'bold'),)],
            [sg.Text(&quot;ID:&quot;, size=(15,None), font=(&quot;Arial&quot;,18)), sg.Input(key='id', size=(30,None), font=(&quot;Arial&quot;,18))],],
         
            [sg.Output(size=(77, 5), font=(&quot;Arial&quot;,12), text_color='red',key=&quot;output&quot;)]
        ],finalize=True)
    
    window.bind(&quot;&lt;Return&gt;&quot;, &quot;Return&quot;)    
        while True:
                    event, values = win.read()
                    if event in (None, &quot;Exit&quot;):
                        break
                    elif event =='Return':
                        user_event = win.user_bind_event
                        user_event.widget.tk_focusNext().focus()

"
73539348,How to make a vectors unmodifiable when passing?,"My wording might not be correct, but I hope you'll understand what I mean.
Basically I have a map&lt;enum class, vector&lt;struct*&gt;&gt;. I want to pass the whole map without the vectors' contents being modifiable.
I need the structs as pointers, because I save references to some of them e.g. to the player instance and they'll get invalidated otherwhise.
It seems I can neither pass the map nor the vectors by reference. So this..
    std::map&lt;myEnum, std::vector&lt;const myStruct&amp;&gt;&gt; getMap() {
        return myMap;
    }

..aswell as..
    const std::map&lt;myEnum, std::vector&lt;myStruct*&gt;&gt;&amp; getMap() {
        return myMap;
    }

doesnt work.
Is there any way to solve this?
Sorry if the question is dumb, I'm kinda new to C++ and often don't know what to search for.
Thanks for you help!
",c++,0,73539390,"First of all, you should declare the member function itself const, otherwise it can't pick the member function for the const circumstance when the object itself is const.
Second, you don't have to think about the exact typing, you can let the compiler figure it out by saying const auto&amp;. then it will return a constant reference, so it won't be modifiable:
const auto&amp; GameLogic::getMap() const {
    return myMap;
}

"
72907961,Floating Action Button is not getting INVISIBLE OR GONE,"My Floating Action Buttons are not getting INVISIBLE OR GONE
When I click on add_btn it work fine it show animation and others buttons also get visible.

But when I click on add_btn second time animation work but buttons do not get INVISIVLE.

This is my java code for making floating action button visible and gone.
addFloatingBtn.setOnClickListener(view -&gt; {
            if (!isFloatingActionBtnVisible){
                // Making Buttons Visible
                addVideoFloatingBtn.setVisibility(View.VISIBLE);
                addNotesFloatingBtn.setVisibility(View.VISIBLE);
                // Starting Animation
                addVideoFloatingBtn.startAnimation(fromBottom);
                addNotesFloatingBtn.startAnimation(fromBottom);
                addFloatingBtn.startAnimation(rotateOpen);
                isFloatingActionBtnVisible = true;
                Toast.makeText(getContext(), &quot;Animation Added&quot;, Toast.LENGTH_SHORT).show();
            }else {
                // Starting Animation
                addVideoFloatingBtn.startAnimation(toBottom);
                addNotesFloatingBtn.startAnimation(toBottom);
                addFloatingBtn.startAnimation(rotateClose);
                // Making Buttons Visible
                addVideoFloatingBtn.setVisibility(View.GONE);
                addNotesFloatingBtn.setVisibility(View.GONE);
                isFloatingActionBtnVisible = false;
            }
        });

This is xml code for three floating buttons.
&lt;com.google.android.material.floatingactionbutton.FloatingActionButton
        android:id=&quot;@+id/add_floating_btn&quot;
        android:layout_width=&quot;wrap_content&quot;
        android:layout_height=&quot;wrap_content&quot;
        android:layout_marginEnd=&quot;16dp&quot;
        android:layout_marginBottom=&quot;16dp&quot;
        android:clickable=&quot;true&quot;
        android:src=&quot;@drawable/ic_add&quot;
        android:tint=&quot;@color/white&quot;
        android:background=&quot;@color/purple_500&quot;
        app:layout_constraintBottom_toBottomOf=&quot;parent&quot;
        app:layout_constraintEnd_toEndOf=&quot;parent&quot;
        android:focusable=&quot;true&quot; /&gt;

    &lt;com.google.android.material.floatingactionbutton.FloatingActionButton
        android:id=&quot;@+id/add_video_floating_btn&quot;
        android:layout_width=&quot;50dp&quot;
        android:layout_height=&quot;50dp&quot;
        android:layout_marginBottom=&quot;16dp&quot;
        android:clickable=&quot;true&quot;
        android:src=&quot;@drawable/ic_add_video&quot;
        android:visibility=&quot;invisible&quot;
        app:layout_constraintBottom_toTopOf=&quot;@+id/add_floating_btn&quot;
        app:layout_constraintEnd_toEndOf=&quot;@+id/add_floating_btn&quot;
        app:layout_constraintStart_toStartOf=&quot;@+id/add_floating_btn&quot; /&gt;

    &lt;com.google.android.material.floatingactionbutton.FloatingActionButton
        android:id=&quot;@+id/add_notes_floating_btn&quot;
        android:layout_width=&quot;50dp&quot;
        android:layout_height=&quot;50dp&quot;
        android:layout_marginBottom=&quot;16dp&quot;
        android:clickable=&quot;true&quot;
        android:src=&quot;@drawable/ic_notes&quot;
        android:visibility=&quot;invisible&quot;
        app:layout_constraintBottom_toTopOf=&quot;@+id/add_video_floating_btn&quot;
        app:layout_constraintEnd_toEndOf=&quot;@+id/add_video_floating_btn&quot;
        app:layout_constraintStart_toStartOf=&quot;@+id/add_video_floating_btn&quot; /&gt;


I want other floating action buttons get INVISIBLE when I click second time but they don't.

","java, android",0,72912294,"Thank you Beant Singh for your suggestion. There was mistake in animation resource file.
This was my animation xml file.
&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;set xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot;
    android:fillAfter=&quot;true&quot;&gt;

    &lt;translate android:fromYDelta=&quot;0%&quot;
        android:toYDelta=&quot;100%&quot;
        android:duration=&quot;300&quot;/&gt;

    &lt;scale
        android:pivotX=&quot;50%&quot;
        android:pivotY=&quot;50%&quot;
        android:toYScale=&quot;0.8&quot;
        android:toXScale=&quot;0.8&quot;/&gt;

    &lt;alpha
        android:duration=&quot;150&quot;
        android:fromAlpha=&quot;0&quot;
        android:toAlpha=&quot;100&quot;/&gt;

        &lt;!-- Here is the mistake. I set fromAlpha=&quot;0&quot; and toAlpha=&quot;100&quot;.
         Which was making floating action button visible even I set
         invisible from code. So I just fromAlpha=&quot;100&quot; and toAlpha=&quot;0&quot; and problem fixed.  --&gt;


"
72849419,Pandas get column header name for column which contains bracket around value of another column,"Consider this sample df
sample_df = pd.DataFrame({'our_value':[14,24], 'opt1':['10 - 20','10 - 20'],'opt2':['21 - 30','21 - 30'],'opt3':['31 - 40','31 - 40'],'opt4':['41 - 50','41 - 50']})

    our_value   opt1      opt2    opt3    opt4
0      14      10 - 20  21 - 30 31 - 40 41 - 50
1      24      10 - 20  21 - 30 31 - 40 41 - 50

I am attempting to create a column that contains the name of the column header if the value in the 'our_value' column is between the two values in the respective column.  So, intended outcome is:
     our_value    opt1    opt2    opt3    opt4   our_opt
0      14      10 - 20  21 - 30 31 - 40 41 - 50     opt1
1      24      10 - 20  21 - 30 31 - 40 41 - 50     opt2

Tried various approaches including a dictionary of keys of the column headers and values being a list with two items, the lower and upper bound of the column like this:
test_dict = {'opt1':['10, 20], 'opt2':[21,30]....}  

Using map to apply that did not work.
These approaches, likewise, did not work
for k,v in test_dict.items():
    df[k] = df['our_value'].map(lambda x: v[0] if x &lt; v[1] else v[1])
      if df['our_value'].between(v[0], v[1]).all():
         df['our_opt'] = k

I am sure I am missing something fundamental at this point.  But, like writing your own novel or article, I am unable to proofread this code and find what is missing.  Thanks for taking a look.
","python, pandas",0,72849636,"Let us get the low and high for the range , then we can do
s = sample_df.filter(like='opt')
low = s.apply(lambda x : x.str.split(' - ').str[0].astype(int))
high = s.apply(lambda x : x.str.split(' - ').str[1].astype(int))
sample_df['out'] = (low.le(sample_df['our_value'],axis=0) &amp; high.ge(sample_df['our_value'],axis=0)).dot(s.columns)
Out[63]: 
0    opt1
1    opt2
dtype: object

"
72965331,"Async ""not expected"" result","I'm trying to understand how async works. All the examples I've seen use asyncio.sleep, but I would like to get an example without that. Below I have provided a simple example to demonstrate my confusion regarding how async/await works.
import asyncio
import time

from functools import wraps

def timing_async(f):
    @wraps(f)
    async def inner(*args, **kwargs):
        start = time.perf_counter()
        val = await f(*args, **kwargs)
        end = time.perf_counter()
        print(f&quot;Async function {f.__qualname__} finished in {end - start:.2f} seconds&quot;)
        return val
    
    return inner

  
async def _simple_count(n=10000000):
    return [i for i in range(n)]

@timing_async
async def simple_count(n=100000000):
    t = await _simple_count(n)
    return t

@timing_async
async def sleep_short():
    await asyncio.sleep(0.1)
    return 10


@timing_async
async def sleep_long():
    await asyncio.sleep(0.2)
    return 20

async def main():
    tasks = [sleep_long(), sleep_short(),sleep_short()]
    return await asyncio.gather(*tasks)

If I run the main function, I will get back:
Async function sleep_short finished in 0.11 seconds
Async function sleep_short finished in 0.11 seconds
Async function sleep_long finished in 0.20 seconds
    
[20, 10, 10]

which looks sensible, since sleep_short takes shorter time to complete. However, if I define the function:
async def main():
    tasks = [simple_count(), sleep_short(), sleep_short()]
    return await asyncio.gather(*tasks)

I will get this output:
Async function simple_count finished in 4.18 seconds
Async function sleep_short finished in 0.10 seconds
Async function sleep_short finished in 0.10 seconds

which implies (?) that the simple_count coroutine is completed first, even though it is much slower to sleep_short.
I am pretty sure this is due to my misconception of how async/await works, so I would appreciate it, if you could help me understand this concept better through this example.
","python, asynchronous, async-await",0,72965870,"Asynchronous functions allow you to run concurrent tasks, i.e. coroutines, that yield control back to the caller at certain points. Concurrent execution is by no means parallelization. For the latter you'll want to use threads or processes. Since _simple_count() only performs one lengthy task without ever yielding back control to the calling function, it will block other concurrent tasks until it is done, since you literally await its result in the timing decorator's wrapper.
"
73147931,React i18next trans component with text after link,"I have a simple trans component that looks like this:
    &lt;Trans
      i18nKey=&quot;login_screen:terms_of_use&quot;
      components={{
        privacy_policy: (
          &lt;TouchableOpacity
            onPress={() =&gt; {
              void Linking.openURL(
                'https:.....',
              )
            }}
          &gt;
            &lt;Link&gt;{t('privacy_policy')}&lt;/Link&gt;
          &lt;/TouchableOpacity&gt;
        ),
      }}
    /&gt; 

And I want to have the following text:
&quot;Ich stimme die app Dattenschutzbestimmungen zu&quot; where the link is the Dattenschutzbestimmungen.
Here is my json:
&quot;terms_of_use&quot;: &quot;Ich stimme die app &lt;privacy_policy&gt;&lt;0&gt;&lt;0&gt;&lt;/privacy_policy&gt; zu&quot;,
&quot;privacy_policy&quot;: &quot;Datenschutzbestimmungen&quot;,

With the current solution I get the following text: Ich stimme die app Datenschutzbestimmungen
Any help?
Thanks!
","javascript, reactjs, react-native, i18next",0,73148899,"Try to use the Trans component in this way:
&lt;Trans
  i18nKey=&quot;login_screen:terms_of_use&quot;
&gt;
  Ich stimme den app
  &lt;TouchableOpacity
    onPress={() =&gt; {
      void Linking.openURL(
        'https:.....',
      )
    }}
  &gt;
    &lt;Link&gt;Dattenschutzbestimmungen&lt;/Link&gt;
  &lt;/TouchableOpacity&gt;
  zu.
&lt;/Trans&gt;

with this resources:
&quot;terms_of_use&quot;: &quot;Ich stimme die app &lt;1&gt;&lt;0&gt;Datenschutzbestimmungen&lt;/0&gt;&lt;/1&gt; zu.&quot;

"
73369911,Filter objects in python list on the basis of string value,"Hi I have a data like this
data = [{'name': 'root/folder1/f1/s1.csv' , 'last_modified': datetime.datetime(2022, 8, 4, 18, 43, 13)},
        {'name': 'root/folder2/f2/s2/file.csv', 'last_modified': datetime.datetime(2022, 8, 4, 18, 43, 13)}, 
        {'name': 'root/folder2/f_1/f_2/f_3/file.csv', 'last_modified': datetime.datetime(2022, 8, 4, 18, 43, 13)},
        {'name': 'root/folder2/f_1/f_2/f_3/f_4/f_5/file.csv','last_modified': datetime.datetime(2022, 8, 4, 18, 43, 13)}, 
        {'name': 'root/folder2/f3/s3/file.csv', 'last_modified': datetime.datetime(2022, 8, 4, 18, 43, 13)},
        {'name': 'root/folder3/f3/s3/s4/file4.csv','last_modified': datetime.datetime(2022, 8, 4, 18, 43, 13)},
        {'name' : 'root/folder3/f3/s3/s4/s5/s6/file4.csv','last_modified': datetime.datetime(2022, 8, 4, 18, 43, 13)}
       ]

I want to get files in each folder with minimum path for example
in  folder1 there is only 1 file then it will come same way.
in  folder2  2 path carrying a file for example root/folder2/f_1/f_2/f_3  and this path root/folder2/f_1/f_2/f_3/f_4/f_5 so I want to get minimum here . and a 3rd path aswell exist in folder2   'root/folder2/f3/s3/file.csv'  but it will come as it is. and folder3 will as well get file with minimum path like  root/folder3/f3/s3/s4/file4.csv
Expected output
data = [{'name': 'root/folder1/f1/s1.csv'},
        {'name': 'root/folder2/f2/s2/file.csv'}, 
        {'name': 'root/folder2/f_1/f_2/f_3/file.csv'},
        {'name': 'root/folder2/f3/s3/file.csv'},
        {'name': 'root/folder3/f3/s3/s4/file4.csv'}
       ]

Tried till now:
I am trying to get paths with minimum slashes but not sure how to check for each sub folder etc for example did this
data_dict = {}
for item in data:
    dir = os.path.dirname(item['name'])
    if dir not in data_dict:
        item['count'] = 1
        data_dict[dir] = item
    else:
        count = data_dic[dir]['count'] + 1
        if item['last_modified'] &gt; data_dict[dir]['last_modified']:
            data_dict[dir] = item
        data_dic[dir]['count'] = count

result = list(data_dict.values())

",python,2,73370710,"Something like this would probably work.
import os
import datetime
from collections import Counter

data = [{'name': 'root/folder1/f1/s1.csv' , 'last_modified': datetime.datetime(2022, 8, 4, 18, 43, 13)},
        {'name': 'root/folder2/f2/s2/file.csv', 'last_modified': datetime.datetime(2022, 8, 4, 18, 43, 13)},
        {'name': 'root/folder2/f_1/f_2/f_3/file.csv', 'last_modified': datetime.datetime(2022, 8, 4, 18, 43, 13)},
        {'name': 'root/folder2/f_1/f_2/f_3/f_4/f_5/file.csv','last_modified': datetime.datetime(2022, 8, 4, 18, 43, 13)},
        {'name': 'root/folder2/f3/s3/file.csv', 'last_modified': datetime.datetime(2022, 8, 4, 18, 43, 13)},
        {'name': 'root/folder3/f3/s3/s4/file4.csv','last_modified': datetime.datetime(2022, 8, 4, 18, 43, 13)},
        {'name' : 'root/folder3/f3/s3/s4/s5/s6/file4.csv','last_modified': datetime.datetime(2022, 8, 4, 18, 43, 13)}
       ]

results = []

# this next line creates a list of all the paths minus their file name
# and counts them, which shows us how many duplicate paths there are
# so we can filter those based on the timestamp later on
paths = Counter([os.path.dirname(i['name']) for i in data])

for row in data:
    name = row[&quot;name&quot;]
    path, filename = os.path.split(name) # split the path from filename

    # this next block is where we check if duplicate counter is greater
    # than 1 and if it is it compares the timestamps and either
    # ignores the entry if it isn't the most recent, or it allows
    # the loop to continue through the rest of the logic
    # if you want to allow to keep 2 files instead of 1 &gt;&gt;&gt;
    if paths[path] &gt; 1:
        # this `lst` contains only the duplicate files paths with different file names 
        lst = [i for i in data if i['name'].startswith(path)]
        # &gt;&gt;&gt; you would run this next line again after removing the
        # the first result from the `lst` above, and allow the script
        # to continue for both of the collected output files.
        least = min(lst, key=lambda x: x['last_modified'])
        if least['name'] != name:
            continue

    # this next loop is where it simply goes through each parent 
    # directory and checks if it has already seen the exact path 
    # as the current path, if it has then it breaks and continues
    # to next item in `data` &gt;&gt;&gt;
    while path:
        dirname = os.path.dirname(path) 
        if dirname in paths:
            break
        path = dirname
    # &gt;&gt;&gt; if it doesn't then that means it is the shallowest copy
    # so it appends the full pathname to the results list
    else:
        results.append({'name': name})

print(results)

OUTPUT
[
  {'name': 'root/folder1/f1/s1.csv'}, 
  {'name': 'root/folder2/f2/s2/file.csv'}, 
  {'name': 'root/folder2/f_1/f_2/f_3/file.csv'}, 
  {'name': 'root/folder2/f3/s3/file.csv'}, 
  {'name': 'root/folder3/f3/s3/s4/file4.csv'}
]

"
73841384,how to make return type a LinearGradient or an AngularGradient in swift based on a condition?,"I have a function that currently returns LinearGradient as a background color. I would like to modify the return type such that the return type is either LinearGradient or AngularGradient based on a value of a variable?
This is the code I have:
func colors() -&gt; LinearGradient {
   return LinearGradient(
            gradient: Gradient(colors: [
                Color(red: 135/255, green: 206/255, blue: 235/255),
                Color(red: 255/255, green: 160/255, blue: 122/255)
            ]),
            startPoint: .topLeading,
            endPoint: .top
        )
 }

Instead, I would like to do something like this:
enum BackgroundType {
   case linear
   case angular
}

then do the following: (the function is used inside .background() modifier)
func colors(backgroundColor: BackgroundType) -&gt; ShapeStyle {
   if backgroundColor == .linear {
    return LinearGradient(
            gradient: Gradient(colors: [
                Color(red: 135/255, green: 206/255, blue: 235/255),
                Color(red: 255/255, green: 160/255, blue: 122/255)
            ]),
            startPoint: .topLeading,
            endPoint: .top
        )
   } else {
       return AngularGradient(gradient: Gradient(colors: [
            Color(red: 135/255, green: 206/255, blue: 235/255),
            Color(red: 255/255, green: 160/255, blue: 122/255)
        ]),
                        center: .topLeading,
                        angle: .degrees(180 + 45))
 }

Any suggestions please? Thanks!
","ios, swift, iphone, swiftui, mobile-development",2,73841443,"Turn your colors function into a ViewBuilder.  Add @ViewBuilder, return some View, and remove the return statements.  Then this function will return the appropriate View based upon the backgroundColor:
@ViewBuilder
func colors(backgroundColor: BackgroundType) -&gt; some View {
    if backgroundColor == .linear {
        LinearGradient(
            gradient: Gradient(colors: [
                Color(red: 135/255, green: 206/255, blue: 235/255),
                Color(red: 255/255, green: 160/255, blue: 122/255)
            ]),
            startPoint: .topLeading,
            endPoint: .top
        )
    } else {
        AngularGradient(gradient: Gradient(colors: [
            Color(red: 135/255, green: 206/255, blue: 235/255),
            Color(red: 255/255, green: 160/255, blue: 122/255)
        ]),
                        center: .topLeading,
                        angle: .degrees(180 + 45))
    }
}

"
73704007,SQL query editor crashes when i run this query,"SELECT job.*
FROM job,job_application
WHERE job.id != job_application.jobId
AND job_application.freelancerId = '4ac4bac0-23bf-4ff6-a3a6-61282e87f7bc'

I am trying to select rows from job table where id of job not in job_application table and freelancer id = (i and providing manually) but query editor freezes and crashes when i try to run this.
","sql, database, amazon-web-services, amazon-rds",-1,73704619,"The database is likely trying to join these tables on your != condition, and as a result is producing (or trying to produce) a cartesian product of the tables. Essentially all records from job are being joined with all records from job_application. Depending on table sizes this is likely a HUGE result.
Instead use NOT IN in your WHERE clause to filter the records in job:
SELECT job.*
FROM job
WHERE job.id NOT IN 
    (
         SELECT jobID 
         FROM job_application 
         WHERE freelancerID = '4ac4bac0-23bf-4ff6-a3a6-61282e87f7bc'
    )

"
73791548,Teradata - find a value from preceding second row,"WITH data (cust, amt, rnk) AS (
VALUES(a, 10, 1),
    (a, 5, 2),
    (a, 15, 3),
    (b, 20, 1),
    (b, 30, 2),
    (c, 3, 1))

I have the data like above. I need to find the amt for each cust where either if the  max(rnk) = 1 then amt from that row. Else amt from rnk = 2.
So the result would be as below:
a,5,2
b,30,2
c,3,1

I can't seem to get to that. Any help would be great. Thanks.
","sql, teradata",0,73791852,"I believe Teradata supports CTE:
with max_rank as (
  select cust, max(rnk) as m_rank
  from data
  where rnk in (1,2)
  group by cust
  )
select d.cust, d.amt, d.rnk
from data d
join max_rank r
  on d.cust = r.cust
 and d.rnk = r.m_rank





cust
amt
rnk




a
5
2


b
30
2


c
3
1




fiddle
"
74489862,WinUI3 : Understanding WinUI3 desktop app,"As we can create a WinUI3 app in both the desktop app(win32 app) and the UWP app. What exactly does it mean to create a WinUI3 in a desktop app? As I understand, this app will follow the Win32 App model, that is, the app will not run on sandbox and the app will not have activation and lifecycle management like UWP apps. Is this right?
In this case, How can we use Win32 APIs in this project, and can we follow the event loop like the WNDPROC callback function instead of Application::Start()?
Thank You
","c++, winapi, windows-runtime, winui-3",0,74513942,"I found that you have posted the same case on the Q&amp;A forum: https://learn.microsoft.com/en-us/answers/questions/1095079/winui3-understanding-winui3-desktop-app.html
You could refer to the answer provided by Castorix 31. To prevent the link from expiring, I will post the answer to Castorix 31:

Application::Start replaces the main message loop.
As it is a Win32 app, you can have access to the main window WndProc with
SetWindowSubclass.

"
72882674,VBA userform as variable in functions,"I have the following problem: I have a userform menu, from there I can navigate to other pages, and I want to create a &quot;back button&quot; for each page to return to the menu.
I tried to create this:
Private Sub btnback_Click()
Call back_menu(Actions)
End Sub

Sub back_menu(stage)  'Tried: stage As Object
    Unload stage
    Menu.Show
End Sub

Another example:
Sub next_page(from,to)
Unload from
to.show

This 1st is working now, but everytime I close the userform i got an error:
Run-type error'13'
Type missmatch
I know I could write one by one or I could us the Unload Me, but I have other Functions where I would like to use this method to call the right userform.
Thanks in advance
","vba, function, object, variables, userform",0,72882906,"Try using the hide method of the userform
Sub back_menu(stage as UserForm)  'Tried: stage As Object
    stage.hide
    Menu.Show
End Sub

Sub next_page(frmFrom as UserForm, frmTo as UserForm)
  frmFrom.hide
  frmTo.show
end Sub

You shoud avoid variable names that are code words as well --&gt; like to in For i = 1 to 10.
"
73102323,Query multiple columns in Google Sheet,"I have products as columns and companies as rows, the selections are shown with the checkboxes.
sheet setup
However I am not interested in querying companies, I want to query and count the products selections and display them like this:
query result setup
What query formula should I used for this?
",google-sheets,0,73102439,"Solution
Try this, look at this Example Sheet

Paste this formula next to products name and drag down.

=COUNTIF(FILTER($B$2:$L$16,$B$1:$L$1=N2),TRUE)


Explanation
FILTER the range $B$2:$L$16 where the headers $L$1 = the value in range N2:N12 products, the output is TRUE and FALSE Array.
count TRUE value in the Array resulted from FILTER with COUNTIF function COUNTIFFILTER[ True / false array ], TRUE TRUE is COUNTIF criterion.
From another tab
=COUNTIF(FILTER(Selections!$B$2:$L$16,Selections!$B$1:$L$1=B2),TRUE)


At a glance


A tweek on player0 answer keep ranges open to add more values
=ARRAYFORMULA({FLATTEN(Selections!B1:L1), 
 FLATTEN(MMULT(TRANSPOSE(Selections!B2:L*1), 
 SEQUENCE(ROWS(Selections!B2:B), 1, 1, 0)))})

"
73223467,How to reverse a specific dimension/sample of a tensor only when a per-dimension/sample condition is met,"In short, how do I translate this tensor:
[[1. 1. 1. 1.]
 [1. 1. 1. 0.]
 [1. 1. 0. 0.]
 [1. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 1.]
 [0. 0. 1. 1.]
 [0. 1. 1. 1.]]

into this one:
[[1. 1. 1. 1.]
 [1. 1. 1. 0.]
 [1. 1. 0. 0.]
 [1. 0. 0. 0.]
 [0. 0. 0. 0.]
 [1. 0. 0. 0.]
 [1. 1. 0. 0.]
 [1. 1. 1. 0.]]

If the input tensor's 0th value on dimension 1 == 0, I want to reverse the entire dimension 1 of that specific sample; otherwise, leave it alone. I am actually working with a 3-dimensional tensor (batch, horizon, feature) but I simplified the example tensors here.
","python, tensorflow, reverse",-1,73224287,"Assuming you tried everything in your power to solve this, here is something that might be useful:
import tensorflow as tf

x = tf.constant([[1., 1., 1., 1.],
                [1., 1., 1., 0.],
                [1., 1., 0., 0.],
                [1., 0., 0., 0.],
                [0., 0., 0., 0.],
                [0., 0., 0., 1.],
                [0., 0., 1., 1.],
                [0., 1., 1., 1.]])

indices = tf.where(x[:, 0] == 0.0)
new_indices = tf.stack([tf.repeat(indices[:, 0], tf.shape(x)[-1]), tf.tile(tf.range(tf.shape(x)[-1], dtype=tf.int64), [tf.shape(indices)[0]])], axis=-1)
values = tf.reverse(tf.squeeze(tf.gather(x, indices), axis=1), axis = [-1])
tf.tensor_scatter_nd_update(x, new_indices, tf.reshape(values, [-1]))

tf.Tensor(
[[1. 1. 1. 1.]
 [1. 1. 1. 0.]
 [1. 1. 0. 0.]
 [1. 0. 0. 0.]
 [0. 0. 0. 0.]
 [1. 0. 0. 0.]
 [1. 1. 0. 0.]
 [1. 1. 1. 0.]], shape=(8, 4), dtype=float32)

"
73526145,How to implement near-real time autocompletion using lucene?,"Lucene offers different Autocompletion options:
org.apache.lucene.search.suggest.Lookup
I was using the AnalyzingSuggester which is good but it does not support changing data, i.e. when the index changes one needs to reindex everything.
Therefore I tries out the AnalyzingInfixSuggester. This has and add method and an update method but no remove.
Does someone know if it is possible to implement near-real time suggestions with pure lucene?
","autocomplete, lucene",1,73542616,"I do not know why this is not part of the public implementation. At the end I extended the AnalyzingInfixSuggester like this:
public class MyAnalyzingInfixSuggester extends AnalyzingInfixSuggester {

    public MyAnalyzingInfixSuggester(Directory dir, Analyzer analyzer) throws IOException {
        super(dir, analyzer);
    }

    public void remove(String text) throws IOException, NoSuchMethodException, InvocationTargetException, IllegalAccessException {
        // call method ensureOpen via reflection since it is private
        Method method = AnalyzingInfixSuggester.class.getDeclaredMethod(&quot;ensureOpen&quot;);
        method.setAccessible(true);
        method.invoke(this);
        Query query1 = new TermQuery(new Term(TEXT_FIELD_NAME, text.toLowerCase()));

        BooleanQuery booleanQuery = new BooleanQuery.Builder()
                .add(query1, BooleanClause.Occur.MUST)
                .build();
        writer.deleteDocuments(booleanQuery);
    }
}

"
73961325,anonymous nested struct usage,"I've asked this question before and deleted it. but I don't understand. I tried everything but still getting error. how can i use this struct. or am i doing it wrong
type Unit struct{
    category struct{
        name string
    }
}

",go,-2,73961388,"Doing the following:
var unit = Unit{
    category: {
        name: &quot;foo&quot;,
    },
}

will NOT work because the language specification says that you MUST specify the type when initializing a struct's field with a composite literal value. E.g. a nested struct, or a map, or a slice, etc.

Since category's type is an unnamed composite type, to initialize the field you MUST repeat the unnamed composite type's definition.
type Unit struct{
    category struct{
        name string
    }
}

var unit = Unit{
    category: struct{
        name string
    }{
        name: &quot;foo&quot;,
    },
}

Alternative, do not use anonymous structs.
type Category struct {
    name string
}

type Unit struct{
    category Category
}

var unit = Unit{
    category: Category{
        name: &quot;foo&quot;,
    },
}

And if you want to use this struct outside of the package in which it is declared you MUST export its fields
type Category struct {
    Name string
}

type Unit struct{
    Category Category
}

// ...

var unit = mypkg.Unit{
    Category: mypkg.Category{
        Name: &quot;foo&quot;,
    },
}

"
73034413,Access last 3 elements of the array in c# and perform action in a single statement,"For example, I have n number of integer array elements in c#. Can we access the last 3 elements of the array and modify these elements for instance multiple each element by 4. Can we achieve this in a single statement instead of using foreach/for loop(can we use the regular expression)?
Before operation
arr[0] = 3
..
..
arr[n-3] = 1
arr[n-2] = 5
arr[n-1] = 6
After operation
arr[0] = 3
..
..
arr[n-3] = 4
arr[n-2] = 20
arr[n-1] = 24
","c#, .net-core",0,73034582,"You can do this:
var arr = new int[] {1, 2, 3, 4, 5};
        
var result = arr.TakeLast(3).Select(x =&gt; x * 4).ToArray();

p.s. this is done in .NET 6
"
74365144,How to filter userid's todos in todoslist,"I am practicing React now and I have a task that I am not sure how to do
The main idea is to filter tasks in todos list when you type user ID
I created another button and when you type user's id it will show exact user's tasks
I did filter tasks as well just for practice, but don't know how to filter user's tasks when you type his id
upd: the problem seems like when you type something in input type becomes string, but I need number
import React from &quot;react&quot;
import {useState, useMemo, useEffect} from &quot;react&quot;

function App() {
  const [tasks, setTasks] = useState([])
  const [completed, setCompleted] = useState(false)
  const [title, setTitle] = useState(&quot;&quot;)
  const [userId, setUserId] = useState(1)

  const onToggleFilter = () =&gt; {
    setCompleted(!completed)
  }

  const onTitleChange = (event) =&gt; {
    setTitle(event.target.value)
  }

  const onUserChange = (event) =&gt; {
    setUserId(event.target.value)
  }

  let filteredTask = useMemo(() =&gt; {
    console.log(&quot;Filter by status&quot;)
    return tasks.filter((task) =&gt; task.completed === completed)
  }, [tasks, completed])
    

  //console.log(&quot;Rerender&quot;)

  if(title) {
    filteredTask = filteredTask.filter((task) =&gt; task.title.indexOf(title) &gt;= 0)
  }

  if(userId) {
    filteredTask = filteredTask.filter((item) =&gt; item.userId === userId)
  }

  console.log(userId)

  useEffect(() =&gt; {
    fetch(&quot;https://jsonplaceholder.typicode.com/todos&quot;)
    .then(response =&gt; response.json())
    .then(todos =&gt; setTasks(todos))
  }, [])


  return(
    &lt;div className=&quot;App&quot;&gt;
      &lt;h1&gt;Task list&lt;/h1&gt;
      &lt;div&gt;
        &lt;button onClick={onToggleFilter}&gt;
          {
            completed ? &quot;Show tasks in work&quot; : &quot;Show completed tasks&quot;
          }
        &lt;/button&gt;
        &lt;br/&gt;
        &lt;br/&gt;
        &lt;input onChange={onTitleChange}/&gt;
        &lt;input onChange={onUserChange}/&gt;
        &lt;br/&gt;
        &lt;br/&gt;
        {
          filteredTask.map((task) =&gt; &lt;div key={task.id}&gt;{task.title}&lt;/div&gt;)
        }
      &lt;/div&gt;
      &lt;/div&gt;
  )
}

export default App

",reactjs,1,74365814,"Use parseInt to convert string to number.
const onUserChange = (event) =&gt; {
  setUserId(parseInt(event.target.value))
}

"
73354652,How to create All Day Calendar Event 14 days from now,"I'm trying to create an all-day calendar event to 14 days from today using Google App Script but I keep getting the error

Exception: The parameters (String,String) don't match the method signature for CalendarApp.Calendar.createAllDayEvent.

My script is:
  var SheetApp = SpreadsheetApp.getActiveSheet();  
  var SelectedRow = SheetApp.getActiveRange().getRowIndex();
  var value = SheetApp.getRange(SelectedRow, 8).getValue(); //Name of the event

  var eventCal = CalendarApp.getCalendarById(&quot;sampleemail@gmail.com&quot;);
  eventCal.createAllDayEvent(value.toString(), new Date() + 14);

","javascript, datetime, google-apps-script, google-calendar-api",0,73354877,"When you add a number to a Date object, the Date is automatically converted to its underlying value, i.e., the number of milliseconds since the epoch. The result of the addition will be that number of milliseconds  plus 14, which is just a big integer. The createAllDayEvent() method expects a Date object rather than an integer.
To get a date that is 14 days from now, use Date.setDate(). This method has the benefit that it automatically takes care of rolling into the next month or next year as necessary, but be careful. The setDate() method modifies a Date object in place, but does not return the Date object. Instead, it returns the underlying value, i.e., the number of milliseconds since the epoch.
This means that you cannot just assign the result you get from setDate() to a variable in the hope of getting a valid Date. Something like const twoWeeksFromNow = new Date().setDate(new Date().getDate() + 14) will not work if you expect twoWeeksFromNow to contain a Date.
An easy way to get it right is to use a short utility function, like this:
function testCreateAllDayEvent() {
  const twoWeeksFromNow = dateOffset_(new Date(), +14);
  const eventCal = CalendarApp.getCalendarById(&quot;sample_email@gmail.com&quot;);
  const sheet = SpreadsheetApp.getActiveSheet();
  const eventTitle = sheet
    .getRange('H' + sheet.getActiveRange().getRow())
    .getDisplayValue();
  eventCal.createAllDayEvent(eventTitle, twoWeeksFromNow);
}

/**
* Gets a new Date object that is offset by numDays from date.
*
* @param {Date} date The date from which to count.
* @param {Number} numDays The number of days to add or subtract from date.
* @return {Date} A new Date object that is offset by numDays from date.
*/
function dateOffset_(date, numDays) {
  const newDate = new Date(date);
  newDate.setDate(date.getDate() + numDays);
  return newDate;
}

"
74405956,How to handle HTTP request using Java Socket?,"I am trying to implement sample HTTP server using Java socket and executor service for concurrency. However every 2nd request is failing when I run the test using JMeter with 2 or more requests  or browser for example.
How to properly handle the request? Here is the sample source code:
public class Service {
    public static void main(String[] args) throws Exception {
        var serverSocket = new ServerSocket(8080);
        var executors = Executors.newFixedThreadPool(4);
        while(true) {
            try {
                var server = serverSocket.accept();

                executors.submit(() -&gt; {
                    try {
                        var text = &quot;sample&quot;;
                        System.out.println(&quot;Waiting for client on port &quot; +
                                serverSocket.getLocalPort() + &quot;...&quot;);

                        System.out.println(&quot;Getting empty request&quot;);
                        var response = &quot;HTTP/1.1 200 OK\r\n&quot; +
                                    &quot;Content-Type: text/plain\r\n&quot; +
                                    &quot;Content-Length: &quot; + text.length() + &quot;\r\n\r\n&quot;
                                    + text;
                        server.getOutputStream().write(response.getBytes(StandardCharsets.UTF_8));
                    } catch (Exception e) {
                        System.out.println(&quot;Executor error:&quot; + e.toString());
                        e.printStackTrace();
                    } finally {
                        try {
                            System.out.println(&quot;Closing server&quot;);
                            server.close();
                        } catch (Exception e) {
                            System.out.println(&quot;Executor error2: &quot;);
                            e.printStackTrace();
                        }
                    }
                });
            } catch (Exception e) {
                e.printStackTrace();
                break;
            }
        }

        serverSocket.close();
    }
}

","java, multithreading, serversocket, java-threads, java-server",0,74517950,"Your first problem lies in your response.
&quot;HTTP/1.1 200 OK\r\n&quot;

That allows for keep-alive, which you're not handling. A basic JMeter sampler tries to use keep alive, that is why you always fail on the second attempt.
You can change it to
&quot;HTTP/1.0 200 OK\r\n&quot;

That does not support keep alive, so you'll get a lot more successes with your current code. For me I only get a couple 1000 responses before JMeter has another error, but I don't know what the error is.
To support keep alive, I need to parse the request. Here is an example.
    int clients = 0;
    while(true) {
        try {
            System.out.println(&quot;Waiting for client on port &quot; +
                            serverSocket.getLocalPort() + &quot;...&quot;);
            var server = serverSocket.accept();
            final int client_no = clients++;
            System.out.println(&quot;handling: &quot; + client_no);
            executors.submit(() -&gt; {
                int sent = 0;
                try {
                    var is = server.getInputStream();
                    var os = server.getOutputStream();
                    
                    var text = &quot;sample&quot;;
                    byte[] tb = text.getBytes(StandardCharsets.UTF_8);

                    char[] buffer = new char[256];
                    int cr_count = 0;
                    while( true ){
                        
                        int i=0;
                        int r = is.read();
                        if(r == -1) break;
                        
                        while( r != -1 ){
                            char c = (char)r;
                            if( c == '\n' ){
                                cr_count++;
                            } else if( c != '\r' ){
                                cr_count = 0;
                            }
                            buffer[i++] = c;
                            if(cr_count == 2) break;
                            r = is.read();
                        }
                        //System.out.println(&quot;request: &quot; + new String(buffer));
                        var response = &quot;HTTP/1.1 200 OK\r\n&quot; +
                                    &quot;Content-Type: text/plain\r\n&quot; +
                                    &quot;Content-Length: &quot; + tb.length + &quot;\r\n\r\n&quot;;
                        os.write(response.getBytes(StandardCharsets.UTF_8));
                        os.write(tb);
                        os.flush();
                        sent++;
                    }
                } catch (Exception e) {
                    System.out.println(&quot;Executor error:&quot; + e.toString());
                    e.printStackTrace();
                } finally {
                    try {
                        System.out.println(&quot;Closing connection!&quot;);
                        server.close();
                    } catch (Exception e) {
                        System.out.println(&quot;Executor error2: &quot;);
                        e.printStackTrace();
                    }
                    System.out.println(&quot;sent &quot; + sent + &quot; responses to client &quot; + client_no);
                }
            });
        } catch (Exception e) {
            e.printStackTrace();
            break;
        }
    }

This will run a JMeter test for me. It can use either 1.0 or 1.1 and finish 10's of thousands of requests. If I use keep alive (1.1) each client handles many requests, if I don't use keep alive (1.0) each client handles 1 request.
If I dont read the request header, then the http 1.0 version will stop after a couple thousand requests.
It is also a separate issue from your original &quot;dies after the second request.&quot; which is because your are not actually using HTTP 1.1 !
"
73073571,Go - JSON validation throwing error unless I use pointer in the struct. Why?,"Here is my validation structure:
type PostEmail struct {
    Username       string `json:&quot;username&quot; validate:&quot;required&quot;`
    Email          string `json:&quot;email&quot; validate:&quot;required&quot;`
    IsRefreshEmail *bool  `json:&quot;isRefreshEmail&quot; validate:&quot;required&quot;`
}

I'm pointing the value of IsRefreshEmail with *bool. If I remove the pointer and I try to call my API without it, the API will throw a bad syntax error.
That will happen only if the boolean value will be false. If it's true even if you remove the pointer the API will respond correctly.
Why is this happening? It's normal? I can't understand it and i don't even know if I'm doing it wrong with the pointer. What I surely know is that if I remove the * from bool and I insert false as value in postman for the field isRefreshEmail the API will throw an exception.
Someone can explain please? Thank you.
","json, validation, go",2,73074076,"A boolean can represent two values, false or true:
var IsRefreshEmail bool

A boolean pointer can represent three values, false, true or nil:
var IsRefreshEmail *bool

The benefit of this, is that you can compare false with nil:
{&quot;email&quot;: &quot;hello&quot;, &quot;isRefreshEmail&quot;: false}
{&quot;email&quot;: &quot;hello&quot;}

without the pointer, the two JSON above will be identical after Unmarshal.
Depending on your situation, you might not care about that. However if you need
to know if the value was omitted, then pointer is required.
"
74603346,Postgres 9.3 Symlinks in pg_tblspc broken,"I have a postgres 9.3 database in a windows installation. The complete installation is on a raid installed.
We wanted to replace that raid with new drives since the old ones started to die. We copied all data from the raid to a new drive with the file explorer (wasn't me...), then replaced all drives and created a new raid, put back on all the old data and changed the drive letter back to the old one. Thinking that everything would work as normal.
Sadly not with postgres. The copying with file explorer destroyed all symlinks in the pg_tblspc folder. They arent symlinks anymore, they are just empty folders. So I have now 147 broken symlinks...
I checked how the symlinks working and compared to a working postgres installation. I found out that every table has an OID. For each OID there are 2 symlinks in that folder. The symlinks have an increased number.
For example, the OID of a table is 17530, then I have 2 symlinks 17538 and 17541. These pointing towards the data folder with the database name. In the folder with the database name I have 2 folders again. One of these symlinks pointing to one of these folders.
The increased numbers are always so same. So its always OID +8 and +11 (on other working installation its always +4 and +7).
All the table management is done by a program (FTK). So if you do stuff in there, its creating/deleting/updating the databases and tables for you. I think that its always 2 folders in there is because FTK is doing that in that way.
My question is now: Can I just manually create these symlinks? And then everything should work? Or is there maybe a function from postgres, where I can point to the &quot;new&quot; folder and it recreates the symlinks? It looks like the symlinks are managed by postgres itself. But so far I couldnt find anything about a repair function
","postgresql, postgresql-9.3",0,74604143,"Mistake number one was not to take a backup. Mistake number two was to create 147 tablespaces. But let's no dwell on that. What can you do?
First, facts. In the directory pg_tblspc is one symbolic link per tablespace, not per table. The name of the symbolic link is the object ID of the tablespace. You can find the object IDs with
SELECT oid, spcname FROM pg_tablespace;

Then you have to figure out what directory belong to which tablespace. There i no help for that, since that is the information that got lost. Once you know the path for a tablespace:

change to the pg_tblspc directory

run
ln -s /path/to/tablespace 12345

where 12345 is the OID of the tablespace.


Needless to say, PostgreSQL must be shut down when you do that.  Once you have re-created the symbolic links for all tablespaces, you should be good.
"
73583513,Get a subresource with api-platform for a User's roles in Symfony5,"In Symfony5 security Roles are plain strings. So, a User entity generally has a $roles array that stores the role name strings, for example:
class User {
  /** @ORM\Column(type=&quot;json&quot;) */
  protected array $roles = ['ROLE_USER'];
  // ...
}

However, in my environment I want to enrich Roles with descriptions and other meta data, so I have a Role class, and I want to be able to fetch a list of roles for a single user using the api-platform framework (note: fetching a collection of Roles is not an issue and can be done  out-of-the-box).
","php, symfony, api-platform.com",0,73583514,"This can be accomplished by defining a custom Subresource DataProvider in Api-Platform. And the beautiful part is all filters and pagination will work naturally (however, the filters will not show up in the API Docs; I'm not sure how to fix that).

Define the @ApiSubresource on your User::$roles property:

/**
 * @ApiSubresource(maxDepth=1)
 * @ORM\Column(type=&quot;json&quot;)
 */
protected array $roles = [];


Create your DataProvider. This is what I use but could use some improvements to be more generic.

&lt;?php

namespace App\DataProvider;

use ApiPlatform\Core\Bridge\Doctrine\Orm\Extension\QueryResultCollectionExtensionInterface;
use ApiPlatform\Core\Bridge\Doctrine\Orm\Util\QueryNameGenerator;
use ApiPlatform\Core\DataProvider\RestrictedDataProviderInterface;
use ApiPlatform\Core\DataProvider\SubresourceDataProviderInterface;
use ApiPlatform\Core\Exception\InvalidResourceException;
use ApiPlatform\Core\Exception\RuntimeException;
use App\Entity\Role;
use App\Entity\User;
use Doctrine\ORM\EntityManagerInterface;
use Doctrine\ORM\QueryBuilder;
use Doctrine\Persistence\ManagerRegistry;

/**
 * Converts the User::$roles plain array into a collection of Role entities.
 */
class UserRoleDataProvider implements SubresourceDataProviderInterface, RestrictedDataProviderInterface
{
    private iterable        $collectionExtensions;
    private ManagerRegistry $managerRegistry;

    public function __construct(ManagerRegistry $managerRegistry, iterable $collectionExtensions = [])
    {
        $this-&gt;managerRegistry = $managerRegistry;
        $this-&gt;collectionExtensions = $collectionExtensions;
    }

    public function getSubresource(string $resourceClass, array $identifiers, array $context, string $operationName = null)
    {
        $manager = $this-&gt;managerRegistry-&gt;getManagerForClass(Role::class);
        $repository = $manager-&gt;getRepository(Role::class);
        if (!method_exists($repository, 'createQueryBuilder')) {
            throw new RuntimeException('The repository class must have a &quot;createQueryBuilder&quot; method.');
        }

        /** @var User $user */
        $user = $this-&gt;managerRegistry-&gt;getManagerForClass(User::class)-&gt;getRepository(User::class)-&gt;find($identifiers['id']['id']);
        if (!$user) {
            throw new InvalidResourceException('Resource not found');
        }

        /** @var QueryBuilder $queryBuilder */
        $queryBuilder = $repository-&gt;createQueryBuilder('o');
        $queryNameGenerator = new QueryNameGenerator();

        $param = $queryNameGenerator-&gt;generateParameterName('roleNames');
        $queryBuilder-&gt;where(sprintf('o.name IN (:%s)', $param))-&gt;setParameter($param, $user-&gt;getRoles());

        foreach ($this-&gt;collectionExtensions as $extension) {
            $extension-&gt;applyToCollection($queryBuilder, $queryNameGenerator, Role::class, $operationName, $context);

            if ($extension instanceof QueryResultCollectionExtensionInterface &amp;&amp; $extension-&gt;supportsResult(Role::class, $operationName, $context)) {
                return $extension-&gt;getResult($queryBuilder, $resourceClass, $operationName, $context);
            }
        }

        return $queryBuilder;
    }

    public function supports(string $resourceClass, string $operationName = null, array $context = []): bool
    {
        return User::class === $resourceClass
            &amp;&amp; $context['property'] === 'roles'
            &amp;&amp; $this-&gt;managerRegistry-&gt;getManagerForClass($resourceClass) instanceof EntityManagerInterface;
    }
}


Configure the service

App\DataProvider\UserRoleDataProvider:
    arguments:
        $collectionExtensions: !tagged api_platform.doctrine.orm.query_extension.collection


You can now call your route: path('api_users_roles_get_subresource', {id: user.id})

It took me a bit to figure this out, so I hope this helps someone.
"
73436929,Microtask as macrotask in javascript code,"I've found this note in whatwg spec:

It is possible for a microtask to be moved to a regular task queue, if, during its initial execution, it spins the event loop. This is the only case in which the source, document, and script evaluation environment settings object set of the microtask are consulted; they are ignored by the perform a microtask checkpoint algorithm.

What is an example of it, that expresses this quote? How is it possible to move a microtask from the microtask stack to the macrotask stack and perform it like a macrotask?
","javascript, event-loop",3,73439078,"This was here for showModalDialog, which used to load a document in a modal, blocking the initial document until this modal is closed... For this to happen the UA had to &quot;spin the event loop&quot; until the modal's document is closed. This &quot;spin the event loop&quot; macro does convert the microtask to a &quot;simple&quot; task.
The showModalDialog() method has been removed from the specs but this remained since it can also be used in other modals or to allow &quot;long tasks&quot; to be short circuited by the UA, so that they can update the rendering and e.g show a message to the user about the long script.
This is for instance advised in a note about pausing, called by all modals like alert(), prompt(), etc.:

Pausing is highly detrimental to the user experience, especially in scenarios where a single event loop is shared among multiple documents. User agents are encouraged to experiment with alternatives to pausing, such as spinning the event loop or even simply proceeding without any kind of suspended execution at all, insofar as it is possible to do so while preserving compatibility with existing content.

You also have that in some browsers with infinite loops, where they'll pause the script and show a message along the lines of &quot;A script on this page is taking too long, do you want to wait or kill it with fire?&quot;.
As an example, in Firefox, both cases will trigger a rendering update when the prompt is shown to the user, i.e they do spin the event loop. So if the &quot;pause&quot; was triggered from inside of a microtask, they should move it to a macrotask when it's resumed.
However IIRC, they actually use a custom version of spin the event loop that only allow for the rendering phase (without callbacks) and nothing more. And the microtask isn't really converted to a task even there.
There are active discussions, where it is planned to &quot;remove this concept&quot; of reentering microtasks, since it's actually not really used by implementers. And even if it was, I'm not sure that'd be observable to us.
"
73858913,How to pass IJSObjectReference to JS code as argument,"I've already read that I can invoke JS methods on IJSObjectReference but how to pass such object to JS code as an argument?
Let' say I have such JS code:
    addLayer: function (group,layer) {
      ...

In C# I have two references IJSObjectReference for both &quot;group&quot; and &quot;layer&quot;, how do I pass them to such function?

Obtaining JS reference, example.
    createGroup: function () {
        var js_group = L.markerClusterGroup();
        return js_group;
    },


and C# call:
var js_ref = await jsRuntime.InvokeAsync&lt;IJSObjectReference&gt;($&quot;{MarkerClusterInterop.BaseObjectContainer}.createGroup&quot;).ConfigureAwait(false);

","javascript, c#, blazor, interop",0,73859685,"You can invoke addLayer function using IJSRuntime and pass the IJSObjectReferences as parameters after the function identifier.
@inject IJSRuntime JS

@code {
    private IJSObjectReference _groupJSObjectRef;
    private IJSObjectReference _layerJSObjectRef;

    ...

    private async Task SomeMethodAsync()
    {
        await JS.InvokeVoidAsync($&quot;{MarkerClusterInterop.BaseObjectContainer}.addLayer&quot;, _groupJSObjectRef, _layerJSObjectRef);
    }
}

"
73964168,Default CodeIgniter controller not working or is it my htaccess?,"I'm using CodeIgniter 3.1.13 and configured my htaccess file to remove &quot;index.php&quot; but when I try to go to a webpage it doesn't work unless I put the default controller in the URL.  Any advice?
Going to the following URLs work fine...

https://www.example.com
https://www.example.com/index.php
https://www.example.com/welcome
https://www.example.com/welcome/page/test

But the following URL does not work...

https://www.example.com/page/test

How do I get this URL to work?
Here's my htaccess file...
&lt;IfModule mod_rewrite.c&gt;

RewriteEngine On
RewriteBase /
RewriteCond %{REQUEST_FILENAME} !-f
RewriteCond %{REQUEST_FILENAME} !-d
RewriteRule ^(.*)$ index.php/$1 [L]

#force https
RewriteCond %{HTTP_HOST} example\.com [NC]
RewriteCond %{SERVER_PORT} 80
RewriteRule ^(.*)$ https://example.com/$1 [R,L]
&lt;/IfModule&gt;

&lt;IfModule !mod_rewrite.c&gt;

# Without mod_rewrite, route 404's to the front controller
ErrorDocument 404 /index.php

&lt;/IfModule&gt;

I changed my config.php to this...
$config['base_url'] = 'https://www.example.com/';
$config['index_page'] = '';

Here's my Welcome.php controller...
&lt;?php if ( ! defined('BASEPATH')) exit('No direct script access allowed');

class Welcome extends CI_Controller {

function __construct()
{   
    parent::__construct();
}

function index()
{
    $this-&gt;load-&gt;view('homepage', $data);
}

function page($pageName)
{
    $data['content'] = $this-&gt;load-&gt;view($pageName, '', TRUE);
    $this-&gt;load-&gt;view('template_page', $data);
}

}

","php, .htaccess, codeigniter-3",-1,73967559,"$route['default_controller'] only specifies which controller gets executed when the root directory of the website is requested. That is: when no controller/method subdirectory/string is given. In your example that would be when www.example.com or www.example.com/index.php are requested.
The default controller does not get executed when the requested url subdirectory/string starts with one of its methods.
For the www.example.com/page/test url to work, you need to either have a Page controller with a test method in it:
&lt;?php if ( ! defined('BASEPATH')) exit('No direct script access allowed');

class Page extends CI_Controller {

    function __construct()
    {   
        parent::__construct();
    }

    function test()
    {
        $this-&gt;load-&gt;view('test');
    }

}

Or add the following to config/routes.php to have the www.example.com/page/* urls be handled by the Welcome controller's page method:
$route['page/(:any)'] = 'welcome/page/$1';

"
74167747,"After you create a class, how do you add information from a csv to a python object, without using a module","I am struggling to understand classes/objects and using a csv with them.
I have a CSV with 26 rows, 1 being the header, the other containing rows of info. Small example below
id,food,food_print,cal1,cal2,expi1999,expi2000,expi2001
1,bun,bun_bun,45.3434,199.32323,23.3333,45.4444,33.33333
2,burger,burger_bun,45.342343,200.34243,34.3333,0,9
3,pickle,pickle_seed,67.345454,34.3434,34,56,33
4,chicken,chicken_egg,44.34343,43.343343,43,434,34343

I have my class as follows:
class City(object):
    def __init__(self, food = 'n/a', foodprint = 'n/a', cal1 = -999, cal2 = -999, 
    expi1999 = -999, expi2000 = -999, expi2001 = -999) 
        self.food = food
        self.foodprint = foodprint
        self.cal1 = cal1
        self.cal2 = cal2
        self.expi1999 = expi1999
        self.expi2000 = expi2000
        self.expi2001 = expi2001

meals = []

foodfile = open('Food.csv', 'rt')
headers = foodfile.readline().strip().split(',')
headers = headers.split(',')

for line in foodfile:
    foodfields = foodfile.readline().strip().split(',')

How do I write in the rows from my food csv into an object to be referenced in the class?
","python, csv",0,74167802,"Assuming all colums are filled in every row:
try:
for line in foodfile:
    foodfields = foodfile.readline().strip().split(',')
    meals.append(City(foodfields[1],foodfields[2],foodfields[3],foodfields[4],foodfields[5],foodfields[6],foodfields[7]))

"
74349234,Pandas : add sub rows sum in multi-columns pivot,"I've got a dataframe build fromRecordsa django queryset, that I pivot by 2 columns to get a dashboard view of it.
I manage to have the global sums byr row and column of the whole table, but I'm trying to get the sum by the first pivot columns (a sub total by row for the first column of each group).
I know absolutely nothing of pandas, but I'm learning.
My dataFrame looks like :
    type                    amount      source  fund
0   Ressource Humaine CDD   -36470.36   Expense fund2
1   Mission                 -1686.47    Expense fund2
2   Fonctionnement          -817465.91  Expense fund1
3   Fonctionnement          1118691.65  Budget  fund1
4   Fonctionnement          -6000       Expense fund3
5   Fonctionnement          -23621.83   Expense fund2
6   Frais de Gestion        -53499      Expense fund2
7   Fonctionnement          15000       Budget  fund3
8   Frais de Gestion        53499       Budget  fund2
9   Fonctionnement          186718.78   Budget  fund2
10  Mission                 1686.47     Budget  fund2
1   Ressource Humaine CDD   38676.53    Budget  fund2



To get an overview of availability by funds in my dash board I pivot it like :
piv=cpd.pivot_table(index=&quot;type&quot;, columns=[&quot;fund&quot;,&quot;source&quot;], values=&quot;amount&quot;, aggfunc='sum', margins=True, margins_name='Sum')
to get :
fund                    fund1                   fund2                       fund3
source                  Budget      Expense     Budget      Expense         Budget      Expense
type
Fonctionnement          1118691.65  -817465.91  186718.78   -23621.83       15000.00    -6000.00
Frais de Gestion        NaN         NaN         53499.00    -53499.00       NaN         NaN
Mission                 NaN         NaN         1686.47     -1686.47        NaN         NaN
Ressource Humaine CDD   NaN         NaN         38676.53    -36470.36       NaN         NaN

(it misses the total here, but I've got it)
I would like to land on something like :
fund                    fund1                                       fund2                                   fund3
source                  Budget      Expense         total fund1     Budget      Expense     total fund2     Budget      Expense     total fund3
type
Fonctionnement          1118691.65  -817465.91      301 226â‚¬        186718.78   -23621.83   163 097â‚¬        15000.00    -6000.00    9 000â‚¬
Frais de Gestion        NaN         NaN             NaN             53499.00    -53499.00   0               NaN         NaN         NaN 
Mission                 NaN         NaN             NaN             1686.47     -1686.47    0               NaN         NaN         NaN
Ressource Humaine CDD   NaN         NaN             NaN             38676.53    -36470.36   2 207â‚¬          NaN         NaN         NaN

I've seen some tips with pandas concat for multi index pivot (eg : Pivot table subtotals in Pandas)
I'm trying to loop by columns or read header or... but I can go further as I'm a deep noob!
How could I insert/append a mid column with sum, and how calculate this sub sum?
","python, pandas, pivot, subtotal",1,74349690,"You can do normal pivot and then compute/append the total sum:
# do a normal pivot
df = df.pivot_table(
    index=&quot;type&quot;,
    columns=[&quot;fund&quot;, &quot;source&quot;],
    values=&quot;amount&quot;,
    aggfunc=&quot;sum&quot;,
)

# compute &quot;sum&quot; dataframes
dfs = []
for c in df.columns.get_level_values(0).unique():
    s = df.loc[:, c].sum(axis=1, skipna=False)
    dfs.append(pd.DataFrame(s, index=s.index, columns=[(c, f&quot;Total {c}&quot;)]))

# concat them together, sort the columns:
out = pd.concat([df, pd.concat(dfs, axis=1)], axis=1)
out = out[sorted(out.columns)]
print(out)

Prints:
fund                        fund1                             fund2                          fund3                    
source                     Budget    Expense Total fund1     Budget   Expense Total fund2   Budget Expense Total fund3
type                                                                                                                  
Fonctionnement         1118691.65 -817465.91   301225.74  186718.78 -23621.83   163096.95  15000.0 -6000.0      9000.0
Frais de Gestion              NaN        NaN         NaN   53499.00 -53499.00        0.00      NaN     NaN         NaN
Mission                       NaN        NaN         NaN    1686.47  -1686.47        0.00      NaN     NaN         NaN
Ressource Humaine CDD         NaN        NaN         NaN   38676.53 -36470.36     2206.17      NaN     NaN         NaN

"
73549943,RestSharp not sending certificate but Postman will,"I just can't see what I'm doing wrong. I have a certificate that I obtained (not self signed). I have a pfx file and a password. I added the certificate in Postman and the API call works. I try to add the same certificate using RestSharp and it fails - the server returns a 400 error with a message saying no SSL certificate was supplied.
 public void AttachCertificate(RestClient client)
        {
            try
            {
                
                X509Certificate2 cert = new X509Certificate2(@&quot;C:\...\xxx.pfx&quot;, &quot;-password-&quot;);
                if (client.Options.ClientCertificates == null) client.Options.ClientCertificates = new X509CertificateCollection();
                if (cert != null) client.Options.ClientCertificates.Add(cert);
            } catch(Exception ex)
            {
                var x = ex;
            }

       
        }

I can see the certificate is there (in RestClient.Options.ClientCertificates) in debugger after this code runs.
This is in .Net Core 3.1
","c#, ssl, restsharp, x509certificate2",1,73559615,"I figured it out by looking at the source for RestSharp RestClient. In the constructor for RestClient it configures the HttpMessageHandler (HttpClientHandler class) and adds any certificates from RestClient Options. But if you add the certificate to the Options object after the fact (as I was doing), it never goes on to update the underlying HTTP objects.
I'm sure this same issue impacts CookieContainer, AutomaticDecompression, Credentials, Proxy, FollowRedirects, PreAuthenticate, RemoteCertificateValidationCallback options on the HttpClientHandler object; and MaxTimeout, UserAgent and Expect100Continue options on the HttpClient.
IMHO either: setting any of these Options after the RestClient is constructed should cascade to the underlying objects, OR the Options object should be read-only. But that is a decision for the RestSharp developers...
I have just tested my code that I changed to get the PFX certificate BEFORE creating the RestClient, and setting it in the RestClient Options object as passed into the RestClient constructor - and it worked.
"
73290373,Copy single sheet from multiple workbooks to a single workbook,"I have multiple Excel files in one folder. I have to extract a single sheet named &quot;sheet 1&quot;. (All the files have it, but sheet 1 isn't the only sheet in those workbooks.) Then I have to paste them in a new workbook. (I don't mind if each of them are in different sheet.)
I copied code from the Internet:
Sub Combine_files()
Dim Path As String
Dim Filename As String
Dim Sheet As Worksheet

Path = &quot;C:\Users\prayag.purohit\OneDrive\Desktop\Project KC\New folder\&quot;
Filename = Dir(Path &amp; &quot;*.xlsx&quot;)
Do While Filename &lt;&gt; &quot;&quot;

    Workbooks.Open Filename:=Path &amp; Filename, ReadOnly:=True

    For Each Sheet In ActiveWorkbook.Sheets
        Sheet.Copy After:=ThisWorkbook.Sheets(1)
    Next Sheet

    Workbooks(Filename).Close

    Filename = Dir()
Loop
End Sub

","excel, vba",1,73291468,"Below code takes the first sheet in every file and names the sheet to the filename.
Option Explicit

Sub Combine_files()
Dim Path As String, Filename As String
Dim wbFile As Workbook, wbActive As Workbook
Set wbActive = ActiveWorkbook
Path = &quot;C:\Users\prayag.purohit\OneDrive\Desktop\Project KC\New folder\&quot;
Filename = Dir(Path &amp; &quot;*.xlsx&quot;)

With Application
    .ScreenUpdating = False
End With

Do While Filename &lt;&gt; &quot;&quot;

Set wbFile = Workbooks.Open(Path &amp; Filename, False, True)
wbFile.Sheets(1).Copy After:=wbActive.Sheets(1)
wbActive.Sheets(2).Name = Filename
wbFile.Close SaveChanges:=False

Filename = Dir()
Loop

wbActive.Sheets(1).Select

With Application
    .ScreenUpdating = True
End With

End Sub

"
74077744,I got a negative number while trying to return a long long value,"I created a function seriesSum to return a sum of the series of a number, and I used long long return data type but it returns a negative number if I insert for example 46341 output will be -1073716337 and what I am expected is 1073767311 here is my code:
#include &lt;iostream&gt;
using namespace std;

long long seriesSum(int n)
{return n*(n+1)/2;}

int main()
{
    cout&lt;&lt;seriesSum(46341); // expected 1073767311 but output is -1073716337

    return 0;
}

","c++, function-definition, integer-arithmetic",0,74077769,"The argument variable n is an int.
All operations you perform in the function are done using int values. Which you will overflow, leading to undefined behavior.
Change the argument type to unsigned long long.
I also recommend you change the return type to be unsigned as well, if you're not going to get negative results.
"
73646644,default values for record properies,"If I have a Java record with 2 properties and I want to define default values for the properties which should be used instead of null. I can either override the getters
public record MyRecord(

    Set&lt;String&gt; strings,

    Boolean required) {

    @Override
    public Boolean required() {
        return Objects.requireNonNullElse(this.required, Boolean.TRUE);
    }

    @Override
    public Set&lt;String&gt; strings() {
        return Objects.requireNonNullElse(this.strings, Set.of());
    }
}

Or I can achieve much the same thing by overriding the default constructor
public record MyRecord(

    Set&lt;String&gt; strings,

    Boolean required) {

    public MyRecord(Set&lt;String&gt; strings, Boolean required) {
        this.strings = Objects.requireNonNullElse(strings, Set.of());
        this.required = Objects.requireNonNullElse(required, Boolean.TRUE);
    }
}

Both of these seem a bit verbose, is there a more concise way to assign default values to record properties?
","java, record",4,74069263,"Overriding the accessor methods like in your first variant violates the expectation that you can create an equal object using the accessor methods and the canonical constructor. From the documentation

For all record classes, the following invariant must hold: if a record R's components are c1, c2, ... cn, then if a record instance is copied as follows:
    R copy = new R(r.c1(), r.c2(), ..., r.cn());

then it must be the case that r.equals(copy).

But with your overridden accessor method, the following assertion fails:
MyRecord r1 = new MyRecord(null, null), r2 = new MyRecord(r1.strings(), r1.required());
assert r1.equals(r2);

because the internal fields contain different data.
So the only correct way to fix input data is during the construction, e.g.
public record MyRecord(Set&lt;String&gt; strings, Boolean required) {
    public MyRecord {
        if(strings == null) strings = Set.of();
        if(required == null) required = true;
    }
}

However, you shouldnâ€™t do this null handling at all. Collections should never be null and using Boolean for the constructor implies having a Boolean record component type in general, i.e. also returned by the accessor method. And writing new MyRecord(null, null) instead of new MyRecord(Set.of(), true) doesnâ€™t even save much typing.
If you want to support default values, you should overload the constructor, e.g.
public record MyRecord(Set&lt;String&gt; strings, boolean required) {
    public MyRecord {
        strings = Set.copyOf(strings); // enforce non-null immutable set
    }
    public MyRecord() {
        this(Set.of(), true);
    }
}

So you can use new MyRecord() for the defaults. Or you consider that records are immutable, so constructing multiple instances of defaults isnâ€™t necessary
public record MyRecord(Set&lt;String&gt; strings, boolean required) {
    public static final MyRecord DEFAULT = new MyRecord(Set.of(), true);
    public MyRecord {
        strings = Set.copyOf(strings); // enforce non-null immutable set
    }
}

and use MyRecord.DEFAULT whenever you need the default values. Of course, you still can provide overloaded constructors for the cases that only one parameter should have default values, if that is needed.
"
73277769,How to get rid of extra slashes in pandas to_latex function?,"I am trying to convert pandas data frame to latex format but it's returning extra slashes in the output.
Data
df = pd.DataFrame({'model_name': {0: 'ALBERT', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e'}, 'macro_precision_first': {0: 91.89396817624747, 1: 92.17133890858452, 2: 92.6826295632407, 3: 92.80299948526579, 4: 93.34410168004217, 5: 92.0346638078341}, 'macro_recall_first': {0: 92.2318448502444, 1: 92.3357692328841, 2: 93.0292033013862, 3: 93.12015088280738, 4: 93.66748596470968, 5: 92.36958589707638}, 'macro_f1_first': {0: 91.95372391665576, 1: 92.23312713937592, 2: 92.71221623765801, 3: 92.88621653320901, 4: 93.43123707996612, 5: 92.1035266749227}})

When I am trying df.to_latex(), the output looks like this:
'\\begin{tabular}{llrrr}\n\\toprule\n{} &amp; model\\_name &amp;  macro\\_precision\\_first &amp;  macro\\_recall\\_first &amp;  macro\\_f1\\_first \\\\\n\\midrule\n0 &amp;     ALBERT &amp;                  91.89 &amp;               92.23 &amp;           91.95 \\\\\n1 &amp;          a &amp;                  92.17 &amp;               92.34 &amp;           92.23 \\\\\n2 &amp;          b &amp;                  92.68 &amp;               93.03 &amp;           92.71 \\\\\n3 &amp;          c &amp;                  92.80 &amp;               93.12 &amp;           92.89 \\\\\n4 &amp;          d &amp;                  93.34 &amp;               93.67 &amp;           93.43 \\\\\n5 &amp;          e &amp;                  92.03 &amp;               92.37 &amp;           92.10 \\\\\n\\bottomrule\n\\end{tabular}\n'

What I am expecting is the rows like this:
ALBERT &amp;                  91.89 &amp;               92.23 &amp;           91.95 \\ 
a      &amp;                  92.17 &amp;               92.34 &amp;           92.23 \\
b      &amp;                  92.68 &amp;               93.03 &amp;           92.71 \\
c      &amp;                  92.80 &amp;               93.12 &amp;           92.89 \\
d      &amp;                  93.34 &amp;               93.67 &amp;           93.43 \\
e      &amp;                  92.03 &amp;               92.37 &amp;           92.10 \\

How I can get rid of extra slashes and \\\n?
","python, pandas, dataframe, latex",1,73277798,"The slashes are escape characters in the string. They are not really present. Try to print:
print(df.to_latex())

output:
\begin{tabular}{llrrr}
\toprule
{} &amp; model\_name &amp;  macro\_precision\_first &amp;  macro\_recall\_first &amp;  macro\_f1\_first \\
\midrule
0 &amp;     ALBERT &amp;              91.893968 &amp;           92.231845 &amp;       91.953724 \\
1 &amp;          a &amp;              92.171339 &amp;           92.335769 &amp;       92.233127 \\
2 &amp;          b &amp;              92.682630 &amp;           93.029203 &amp;       92.712216 \\
3 &amp;          c &amp;              92.802999 &amp;           93.120151 &amp;       92.886217 \\
4 &amp;          d &amp;              93.344102 &amp;           93.667486 &amp;       93.431237 \\
5 &amp;          e &amp;              92.034664 &amp;           92.369586 &amp;       92.103527 \\
\bottomrule
\end{tabular}

"
73504314,"Type hint for ""can be compared"" objects","I am writing several functions that handle ordered datasets.
Sometime, there is an argument that can be a int or float or a timestamp or anything that supports comparison (larger than / smaller than) and that I can use for trimming data for instance.
Is there a way to type-hint such a parameter? The typing module doesn't seem to include this, but is there some other way?
","python, type-hinting",3,73504415,"There is no standard 'comparable' ABC, no, as the rich comparison methods are really very flexible and don't necessarily return booleans.
The default built-in types return NotImplemented when applied to a type they can't be compared with, for example, while specialised libraries like SQLAlchemy and numpy use rich comparison methods to return completely different objects. See the documentation for the rich comparison methods for the details.
But you should be able to define a
a Protocol subclass for specific expectations:
from typing import Protocol, TypeVar

T = TypeVar(&quot;T&quot;)

class Comparable(Protocol[T]):
    def __eq__(self: T, other: T) -&gt; bool:
        ...

    def __lt__(self: T, other: T) -&gt; bool:
        ...

    # ... etc

You may need to tweak the protocol to fit your exact expectations, and / or use a non-generic version that's specific to the types you use (perhaps with @overloaded definitions for specific types).
For sorting with the builtin sorted() function, __eq__ and __lt__ suffice.
"
74318528,Iterating over groovy file contents,"I have two groovy scipts (executed in Jenkins pipeline), one with variables:
// Params file
PARAM1 = &quot;1&quot;
PARAM2 = &quot;2&quot;
PARAM3 = &quot;3&quot;
PARAM4 = &quot;4&quot;

return this

and the second one that loads this file and uses the params:
def load_params() {
    def parameters = load &quot;params.groovy&quot;
        final_parameter = &quot;&quot;
    
        for (parameter in parameters) {
            if(final_parameter == &quot;&quot;) {
                final_parameter = parameter.key.toUpperCase() + &quot;=&quot; + parameter.value
            } else {
                final_parameter = final_parameter+ &quot;&amp;|&amp;&quot; + parameter.key.toUpperCase() + &quot;=&quot; + parameter.value
            }
        }
    
        return final_parameter
    }
    
    return this

Issue is that doing the iteration over parameters is not working. The type is not a map so I cannot access variables like that.
I would use parameters.PARAM1 to handle it, but the first script is dynamic and names change so there is a need to do it without hard defining the name.
Is there any way to change/iterate the parameters to get the &quot;key&quot; and &quot;values&quot;?
","jenkins, groovy, jenkins-pipeline, jenkins-groovy",0,74319680,"Here are a few things you can do.
Option 01: Make the Parameters a Map
This is the best solution I guess.
// Params file
parameters = [ &quot;PARAM1&quot;: &quot;1&quot;, &quot;PARAM2&quot;: &quot;2&quot;, &quot;PARAM3&quot;: &quot;3&quot;, &quot;PARAM4&quot;: &quot;4&quot;]

return this

Option 02 : Read the Parameters as a file
Instead of loading as a Script, you can read the Params as a File, then iterate over it line-by-line and read the parameters.
Option 03: Get all the Variables defined in the current binding.
This will probably return all the variables in the current Binding, so you may have to filter out the ones you defined in the param file.
def load_params() {
    def parameters = load &quot;params.groovy&quot;
        final_parameter = &quot;&quot;
        paramMap = [:] &lt;&lt; parameters.getBinding().getVariables()
        for (parameter in paramMap) {
            if(final_parameter == &quot;&quot;) {
                final_parameter = parameter.key.toUpperCase() + &quot;=&quot; + parameter.value
            } else {
                final_parameter = final_parameter+ &quot;&amp;|&amp;&quot; + parameter.key.toUpperCase() + &quot;=&quot; + parameter.value
            }
        }
    
        return final_parameter
    }
    
    return this

"
72935457,How to disable an option based on a specific value in an array?,"When the stock value in the Product array is less than 0 or 1,
I want to disable that value in the options so that it cannot be selected.(disable =true)
And if product stock is greater than 0,
I want to be able to select that value.(disable =false)
What should I do?
import React, {useState} from 'react'
import {Form, Button} from 'antd' 

const Products = [    
    { key: 1, value: &quot;A&quot;, stock: 0 },
    { key: 2, value: &quot;B&quot;, stock: 1  },
    { key: 3, value: &quot;C&quot;, stock: 2 },
    { key: 4, value: &quot;D&quot;, stock: 0  },
    { key: 5, value: &quot;E&quot;, stock: 0 },
    { key: 6, value: &quot;F&quot;, stock: 3  },
    { key: 7, value: &quot;G&quot;, stock: 4 },    
]

function ProductPage() {

// States
const [product, setProduct] = useState(1) // initial value : 1

// Handlers
const productChangeHandler = (event) =&gt; {
    setProduct(event.currentTarget.value)
}


return (
    &lt;div style={{ maxWidth: '700px', margin: '2rem auto' }}&gt;
        &lt;div style={{textAlign: 'center', marginBottom: '2rem'}}&gt;
            &lt;h2&gt;Product Soldout State&lt;/h2&gt;
        &lt;/div&gt;
        
        &lt;Form&gt;

            {/* DropZone */}
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;select onChange={productChangeHandler} value={product} &gt;
                {Products.map(item =&gt; (
                    &lt;option key={item.key} value={item.key} &gt;{item.value}&lt;/option&gt;
                ))}                    
            &lt;/select&gt;
            &lt;Button&gt;Upload&lt;/Button&gt;

        &lt;/Form&gt;

    &lt;/div&gt;
)

}
export default ProductPage
","javascript, reactjs, typescript, drop-down-menu, disabled-input",-1,72935487,"Use the disabled JSX property, which maps to the disabled attribute: disabled={item.stock &lt; 1}
In context:
{Products.map(item =&gt; (
    &lt;option key={item.key} value={item.key} disabled={item.stock &lt; 1}&gt;{item.value}&lt;/option&gt;
))}    

More minimal example:


const options = [
    {value: 1, stock: 40, text: ""Plenty""},
    {value: 2, stock: 1, text: ""Just enough""},
    {vlaue: 3, stock: 0, text: ""None""},
];
const Example = () =&gt; {
    return &lt;select&gt;
        {options.map((option) =&gt; (
            &lt;option value={option.value} disabled={option.stock &lt; 1}&gt;{option.text}&lt;/option&gt;
        ))}
    &lt;/select&gt;;
};

const root = ReactDOM.createRoot(document.getElementById(""root""));
root.render(&lt;Example /&gt;);
&lt;div id=""root""&gt;&lt;/div&gt;

&lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/react/18.1.0/umd/react.development.js""&gt;&lt;/script&gt;
&lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/react-dom/18.1.0/umd/react-dom.development.js""&gt;&lt;/script&gt;



"
73206798,Launch EC2 Instance using IAM Role on Multiple AWS accounts,"We have multiple AWS accounts and one management account. We have one web application server in management account. From this server we can create EC2 instances on multiple AWS accounts using secret and access key. However, we would like to launch instance on other AWS accounts using IAM role. Is possible to lauch instances on other AWS accounts using IAM role (Instead of using access and secret key) ?
","amazon-web-services, amazon-ec2, amazon-iam",0,73214917,"The typical setup would be:

Create an IAM Role in each 'other' AWS Account

Give it the same name in each account to keep things simple
Grant it permission to launch an Amazon EC2 instance


To launch an instance in an 'other' account:

Assume the IAM Role in the target account (the desired Account ID would be specified in the chosen IAM Role's ARN)
Use the returned temporary credentials to launch the EC2 instance



"
73676116,Specify callback function in dart/flutter that accepts two possible sets of parameters,"Is there a way to create a callback function that accepts one of two different sets of parameters? Or have two separate callback functions as options, and make sure at least one of them is specified?
I have a view that I want to pass a callback function, that either includes a Goal or a title and description (which would end up being put together into a goal).
void Function({required String title, String? description}) onGoalPopupCompletionWithString;
void Function({required Goal goal}) onGoalPopupCompletionWithGoal;
I want one, but not both of these callbacks to be required - if there is a function with a goal as a parameter, I'd execute that, but if not, I'd execute the one with a String title and a String description. Something like this:
if (onGoalPopupCompletionWithGoal != null) {
    // execute this callback function
} else {
    // execute onGoalPopupCompletionWithString
}

","dart, callback",0,73680911,"That's not something which can be expressed in the Dart type system.
A single function which can be called as void Function({required String title, String? description}) or void Function({required Goal goal}) will have a signature of:
  void Function({String title, String? description, Goal goal})

Any implementation of that type will either have to make title and goal optional, or provide them with default values.
In either case, there is no way, in the type system, to ensure that the function is always invoked as one of the original types.
Also, it'll be highly annoying to write, you'd probably be better off with two different callbacks.
You can provide two callback parameters, one of each kind, and require that at least one of them is required ... but not in the type system. You'd have to make both optional, and check at runtime that at least one was provided.
Having as single parameter which accepts either function type, that requires a union type. A union type allows either one type or another, in this case either void Function({required String title, String? description}) or void Function({required Goal goal}). Dart does not have union types in general.
If you need to pass both of these types through the same currently valid Dart type, the type needs to be a supertype of both.
The closest common supertype of those two types is Function.
(The only function types that void Function({required Goal goal}) can be assigned to are void Function({required X goal}) where X is a subtype of Goal. I guess you can also change the void to another, equivalent, top-type.
Any other function type allows its functions to be called in a way that void Function({required Goal goal}) does not.)
Dart does have one kind of type union: Classes with subclasses.
You can declare a callback class:
abstract class MyCallback {
}
class TitleCallback extends Callback {
  final void Function({required String title, String? description}) callback;
  TitleCallback(this.callback);
}  
class GoalCallback extends Callback {
  final void Function({required Goal goal}) callback;
  GoalCallback(this.callback);
}  

Then you can require one such callback, and dispatch on it as necessary.
"
73364270,Independant margin for the submit button and the text input,"I don't know why, but my text input and my submit button margin are linked, so it's ugly and very annoying.
I have this on my main html file :


.banner {
  width: 100%;
  height: 100px;
  display: inline-flex;
  margin: 0px;
  background-color: #1b2936;
}

.logo {
  width: 200px;
  height: 100px;
}

input[type=text] {
  background-color: #10151b;
  border: #10151b 5px solid;
  border-radius: 7px;
  height: 50px;
  width: 500px;
  color: white;
  font-family: jetbrainsRegular;
}

.search {
  width: 50px;
  height: 50px;
}

.searchbtn {
  margin-top: 0px;
  border: #1fa2f3 5px solid;
  border-radius: 30px;
  background-color: #1fa2f3;
}

.nomargin {
  margin-top: 0;
}
&lt;div class=""banner""&gt;
  &lt;img class=""logo"" src=""logo.png""&gt;
  &lt;form action=""query.php""&gt;
    &lt;label&gt;
                &lt;input type=""text"" id=""query"" placeholder=""Mot"" class=""nomargin""&gt;
            &lt;/label&gt;
    &lt;label&gt;
                &lt;button type=""submit"" class=""searchbtn""&gt;&lt;img src=""search.png"" class=""search""/&gt;&lt;/button&gt;
            &lt;/label&gt;
  &lt;/form&gt;
&lt;/div&gt;



I am searching for a way to unlink their margins...
","html, css, margin",0,73364473,"There is no margin, it's an issue with your form. Try this:
form{
  display:flex;
}

Or (but I don't recommend it):
input[type=text]{
  float:left;
}

Flex gives you much more flexibility (pun intended) and it's much easier to work with. https://css-tricks.com/snippets/css/a-guide-to-flexbox/
"
74587470,How use View.OnClickListener with FirestoreRecyclerAdapter,"I'm trying to create an application and considering my level it's not easy! I hope you could help me since I didn't succeed with the many links I found on the internet.
I can't add the onClick function of View.OnClickListener, each time the Intent function is not recognized. I tried to implement it in the UserViewHolder and FirestoreRecyclerAdapter class but it doesn't work.
Here is my current code:
---------- kotlin part ---------
    package edu.stanford.rkpandey.emojistatus

import android.content.Intent
import android.os.Bundle
import android.util.Log
import android.view.*
import android.widget.TextView
import androidx.appcompat.app.AppCompatActivity
import androidx.recyclerview.widget.LinearLayoutManager
import androidx.recyclerview.widget.RecyclerView
import com.firebase.ui.firestore.FirestoreRecyclerAdapter
import com.firebase.ui.firestore.FirestoreRecyclerOptions
import com.google.firebase.auth.FirebaseAuth
import com.google.firebase.auth.ktx.auth
import com.google.firebase.firestore.ktx.firestore
import com.google.firebase.ktx.Firebase
import kotlinx.android.synthetic.main.activity_main.*


data class User(
    val displayName: String? = &quot;&quot;,
    val emojis: String? = &quot;&quot;
)

class UserViewHolder(itemView: View) : RecyclerView.ViewHolder(itemView)


class MainActivity : AppCompatActivity() {

    private val db = Firebase.firestore
    private lateinit var auth: FirebaseAuth

    // Query the users collection
    private val query = db.collection(&quot;users&quot;)
    val options = FirestoreRecyclerOptions.Builder&lt;User&gt;()
        .setQuery(query, User::class.java)
        .setLifecycleOwner(this).build()
    
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)
        auth = Firebase.auth

        val adapter = object: FirestoreRecyclerAdapter&lt;User, UserViewHolder&gt;(options) {

            override fun onCreateViewHolder(parent: ViewGroup, viewType: Int): UserViewHolder {
                val view = LayoutInflater.from(this@MainActivity).inflate(R.layout.item_pack, parent, false)
                return UserViewHolder(view)
            }

            override fun onBindViewHolder(
                holder: UserViewHolder,
                position: Int,
                model: User
            ) {
                val tvName: TextView = holder.itemView.findViewById(R.id.title)
                val tvEmojis: TextView = holder.itemView.findViewById(R.id.excerpt)
                tvName.text = model.displayName
                tvEmojis.text = model.emojis
            }

        }
        rvUsers.adapter = adapter
        rvUsers.layoutManager = LinearLayoutManager(this)
    }

    override fun onCreateOptionsMenu(menu: Menu?): Boolean {
        menuInflater.inflate(R.menu.menu_main, menu)
        return true
    }

    override fun onOptionsItemSelected(item: MenuItem): Boolean {
        if (item.itemId == R.id.miLogout) {
            Log.i(&quot;MainActivity&quot;, &quot;Logout&quot;)
            auth.signOut()
            val logoutIntent = Intent(this, LoginActivity::class.java)
            logoutIntent.flags = Intent.FLAG_ACTIVITY_NEW_TASK or Intent.FLAG_ACTIVITY_CLEAR_TASK
            startActivity(logoutIntent)
        }
        return super.onOptionsItemSelected(item)
    }

}

------- xml part -------
=&gt; activity_main
&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot;
    xmlns:app=&quot;http://schemas.android.com/apk/res-auto&quot;
    xmlns:tools=&quot;http://schemas.android.com/tools&quot;
    android:layout_width=&quot;match_parent&quot;
    android:layout_height=&quot;match_parent&quot;
    tools:context=&quot;.MainActivity&quot;&gt;

    &lt;androidx.recyclerview.widget.RecyclerView
        android:id=&quot;@+id/rvUsers&quot;
        android:layout_width=&quot;match_parent&quot;
        android:layout_height=&quot;match_parent&quot;
        app:layout_constraintEnd_toEndOf=&quot;parent&quot;
        app:layout_constraintStart_toStartOf=&quot;parent&quot;
        app:layout_constraintTop_toTopOf=&quot;parent&quot; /&gt;
&lt;/androidx.constraintlayout.widget.ConstraintLayout&gt;

=&gt; item_pack
&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;

&lt;RelativeLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot;
    xmlns:tools=&quot;http://schemas.android.com/tools&quot;
    android:layout_width=&quot;match_parent&quot;
    android:layout_height=&quot;100sp&quot;
    xmlns:app=&quot;http://schemas.android.com/apk/res-auto&quot;&gt;

&lt;androidx.cardview.widget.CardView
    android:id=&quot;@+id/card_view&quot;
    android:layout_width=&quot;match_parent&quot;
    android:layout_height=&quot;match_parent&quot;
    android:layout_marginStart=&quot;12sp&quot;
    android:layout_marginTop=&quot;12sp&quot;
    android:layout_marginEnd=&quot;12sp&quot;
    android:focusable=&quot;true&quot;
    android:clickable=&quot;true&quot;
    app:cardCornerRadius=&quot;10dp&quot;
    android:foreground=&quot;?android:attr/selectableItemBackground&quot;&gt;

    &lt;RelativeLayout
        android:layout_width=&quot;match_parent&quot;
        android:layout_height=&quot;match_parent&quot;
        android:padding=&quot;10dp&quot;
        android:background=&quot;@color/colorPack&quot;&gt;

        &lt;TextView
            android:id=&quot;@+id/title&quot;
            android:layout_width=&quot;wrap_content&quot;
            android:layout_height=&quot;wrap_content&quot;
            android:layout_marginTop=&quot;5sp&quot;
            style=&quot;@style/NoteTitleFont&quot;
            android:textColor=&quot;@color/colorTitle&quot;
            tools:text=&quot;Note 1&quot; /&gt;

        &lt;TextView
            android:id=&quot;@+id/excerpt&quot;
            android:layout_width=&quot;wrap_content&quot;
            android:layout_height=&quot;wrap_content&quot;
            android:layout_marginTop=&quot;12sp&quot;
            android:layout_below=&quot;@id/title&quot;
            android:maxLines=&quot;1&quot;
            android:ellipsize=&quot;end&quot;
            android:textStyle=&quot;italic&quot;
            android:textColor=&quot;@color/colorDescribe&quot;
            tools:text=&quot;test text va se trouver ici, Ã§a va contenir le dÃ©but de la description du package.&quot; /&gt;

    &lt;/RelativeLayout&gt;

&lt;/androidx.cardview.widget.CardView&gt;

&lt;/RelativeLayout&gt;

This code gives this result :

I would like that when I click on one of the carviews it can go to the activity_pack_detail.
Do you know how to do Intent to PackDetailActivity?
I get this error no matter what I do =&gt;

","android, firebase, kotlin, google-cloud-firestore",0,74597515,"You're getting that error because you are calling Intent's class constructor with a wrong argument. The first argument should be a Context and not a View. The keyword this is referring in your code to a View and not to a context, hence the error.
To solve this, you have to pass a Context object like this:
val i = Intent(view.getContext(), PackDetailActivity::class.java)

And your error will go away.
"
73760219,Dialogflow CX - Transition to page using sentiment analysis score,"Does anyone know if itâ€™s possible to transition to a different page solely off of a sentiment analysis score ($request.sentiment.score) of the end-userâ€™s response?
I basically want the agent to ask the end-user a question and then have the agent route the user to a page strictly using the sentiment analysis score of the userâ€™s response and nothing more

What I tried so far:
Through the Dialogflow-CX simulator, I am trying to transition to a different page using the conditional statement $request.sentiment.score &lt;= 0 in the route, however the agent does not transition to the next page and cannot match my input to the strictly conditional route (it just jumps to the sys.no-match-default event handler)
Here is a screenshot of the route I have set up:

As you can see, the route has no intents other than a conditional trigger that has $request.sentiment.score &lt;= 0 as the parameter.
I simply want the agent to direct the end-user to the next page whenever it detects a message with a negative sentiment score. The next screenshot shows that the agent detects that the sentiment score is negative, however the agent does not transition to the next page.

Does anyone know what I seem to be doing wrong?
",dialogflow-cx,0,74728484,
73946426,Listening to one added document in Firestore - Swift,"I'm listening to only one added document in a collection, and after it is read I need this document to be deleted. This is the code I implemented:
func createListener(){
    guard let currentUid = Auth.auth().currentUser?.uid else { return }
    listener = db.collection(&quot;Collection&quot;).document(currentUid).collection(&quot;Collection&quot;).addSnapshotListener({ listenerSnapshot, error in
        if let error = error{
            print(error.localizedDescription)
            return
        }
        listenerSnapshot?.documentChanges.forEach({ change in
            if change.type == .added{
                let data = change.document.data()
                
                let myview = MYView(data: data)
                guard let window = UIApplication.shared.windows.last else { return }
                myview.present(to: window) {
                    change.document.reference.delete()
                }
            }
        })
    })
}

The problem is that after the document is deleted with

change.document.reference.delete()

The listener snippet change.type == .added is triggered even if the document has been deleted. I don't know why...
How can I only listen for actually ADDED documents in a Firestore Collection?
EDIT:
listening for a specific document but still closure called when document is deleted:
listener = db.collection(&quot;Collection&quot;).document(currentUid).addSnapshotListener({ listenerSnapshot, error in
        if let error = error{
            print(error.localizedDescription)
            return
        }
        guard let data = listenerSnapshot?.data() else { return }
        let myview = MYView(data: data)
            
        guard let window = UIApplication.shared.windows.last else { return }
        myview.present(to: window) {
            listenerSnapshot?.reference.delete()
        }
    })

","ios, swift, firebase, google-cloud-platform, google-cloud-firestore",1,73946809,"
I'm listening to only one added document in a collection.

No, you're not. You're attaching a snapshot listener to a collection and not to a single document:
db.collection(&quot;Collection&quot;)
  .document(currentUid)
  .collection(&quot;Collection&quot;) //ðŸ‘ˆ
  .addSnapshotListener(/* ... */)

This means that you're listening for real-time updates for each operation that takes place inside the entire sub-collection called &quot;Collection&quot;.
What you're basically doing, you're saying, hey Firestore, give me all documents that exist in that sub-collection and keep the listener alive. This listener will be invoked every time a document in that collection changes over time.
If you want to listen to a single document, then you should add a call to .document() and pass a specific document ID:
db.collection(&quot;Collection&quot;)
  .document(currentUid)
  .collection(&quot;Collection&quot;)
  .document(&quot;someDocumentId&quot;) //ðŸ‘ˆ
  .addSnapshotListener(/* ... */)

In this way, you'll only be notified about the changes to a single document.
"
73393051,Convert a print statement to a dictionary Pandas,"Here I am comparing a data frame to a list of standard values (seen below). Instead of the print statement I would like it convert it to a dictionary. Here is the code I have so far:
valid= {'Industry': ['Automotive', 'Banking / Finance','Biotech / Pharma','Commercial Buildings','Construction / Distribution',
                  'Consumer Products','Education','Education - K-12','Education - University / Higher','Entertainment / Media','Financial',
                  'Food &amp; Beverage','Gas','Government','Government - Federal','Government - State / Local','Healthcare','High Security',
                  'Hospitality / Entertainment','Manufacturing / Communications','Other','Petrochem / Energy',
                  'Property Management / Real Estate','Public Facility / Non-Profit','Residential','Restaurant','Retail','Services - B2B',
                  'Technology','Telecom / Utilities','Transportation','Utilities','Food Retail','Specialized Retail','IT','Corrections',
                  'Core Commercial (SME)'],
        'SME Vertical': ['Agriculture, Food and Manufacturing','Architectural services','Arts, entertainment and recreation','Automobile',
                'Chemistry / Pharmacy','Construction','Education','Hotels','Offices','Other Industries','Other Services',
                'Project management and design','Real Estate and promotion','Restaurants, CafÃ© and Bars',
                'Energy, Infrastructure, Environment and Mining','Financial and Insurance Services',
                'Human health and social work activities','Professional, scientific, technical and communication activities',
                'Public administration and defence, compulsory social security','Retail/Wholesale','Transport, Logistics and Storage'],
        'System Type': ['Access','Access Control','Alarm Systems','Asset Tracking','Banking','Commander','EAS','Financial products','Fire',
                    'Fire Alarm','Integrated Solution','Intercom','Intercom systems','Intrusion - Traditional','Locking devices &amp; Systems',
                    'Locks &amp; Safes','Paging','Personal Safety','Retail &amp; EAS Products','SaaS','SATS','Services',
                    'Sonitrol Integrated Solution','Sonitrol - Integrated Solution','Sonitrol - Managed Access',
                    'Sonitrol - Verified Audio Intrusion','Time &amp; Attendance','TV-Distribution','Unknown','Video','Video Systems'],
        'Account Type': ['Commercial','International','National','Regional','Reseller','Residential','Small']}
 
mask = df1.apply(lambda c: c.isin(valid[c.name]))
df1.mask(mask|df1.eq(' ')).stack()
 
for r, v in df1.mask(mask|df1.eq(' ')).stack().iteritems():
    print(f'error found in row &quot;{r[0]}&quot;, column &quot;{r[1]}&quot;: &quot;{v}&quot; is invalid')

Here is the current output of the print statements
error found in row &quot;1&quot;, column &quot;Industry&quot;: &quot;gas&quot; is invalid
error found in row &quot;1&quot;, column &quot;SME Vertical&quot;: &quot;hotels&quot; is invalid
error found in row &quot;2&quot;, column &quot;Industry&quot;: &quot;healthcare&quot; is invalid
error found in row &quot;3&quot;, column &quot;Industry&quot;: &quot;other&quot; is invalid
error found in row &quot;3&quot;, column &quot;SME Vertical&quot;: &quot;project management and design&quot; is invalid
error found in row &quot;4&quot;, column &quot;Account Type&quot;: &quot;small&quot; is invalid

This output is good in terms of the format but I canâ€™t get it to write to a dictionary.
Example output from the dictionary:
{row â€œ1â€: column: &quot;Industry&quot;, message: &quot;gas&quot; is invalid, .... etc}

","python, pandas",0,73393191,"This is straightforward, but YOU need to decide what the format will be.  What you have shown above is not a valid dictionary.
Maybe like this, as a list of dictionaries, one for each error?
errors = []
for r, v in df1.mask(mask|df1.eq(' ')).stack().iteritems():
    errors.append({
        &quot;row&quot;: r[0],
        &quot;column&quot;: r[1],
        &quot;message&quot;: v + &quot; is invalid&quot;
    })

"
73410719,"Flutter mobile app dev- ""the named parameter title' isn't defined. I have change it to label"" but still getting error. What would be the problem?","This is the code:
Have changed title to label as below. But Text(....) was all highlighted in red. Error - &quot;the argument type 'Text' can't be assigned to the parameter type 'String'.&quot;
    @override
 Widget build(BuildContext context) {
        var data = EasyLocalizationProvider.of(context).data;
  return EasyLocalizationProvider(
          data: data,
      child: Scaffold(
     body: callPage(currentIndex),
     bottomNavigationBar: Theme(
         data: Theme.of(context).copyWith(
             canvasColor: Colors.white,
             textTheme: Theme.of(context).textTheme.copyWith(
                 caption: TextStyle(color: Colors.black26.withOpacity(0.15)))),
         child: BottomNavigationBar(
          type: BottomNavigationBarType.fixed,
          currentIndex: currentIndex,
          fixedColor: Color(0xFF6991C7),
          onTap: (value) {
           currentIndex = value;
           setState(() {});
          },
BottomNavigationBarItem(
               icon: Icon(Icons.shop),
               label: Text(
                 AppLocalizations.of(context).tr('Produce'),
                style: TextStyle(fontFamily: &quot;Berlin&quot;, letterSpacing: 0.5),
               )),

Error image
","flutter, dart, flutter-bottomnavigation, flutter-appbar",0,73410789,"Try replace
label: Text(
   AppLocalizations.of(context).tr('Produce'),
   style: TextStyle(fontFamily: &quot;Berlin&quot;, letterSpacing: 0.5),
),

with
label: AppLocalizations.of(context).tr('Produce')

"
73611950,How can i pass parameters to a function inside click eventlistner,"function changeColor(btn){
    btn.style.backgroundColor = &quot;red&quot;;
}
let btn1 = document.getElementById(&quot;1&quot;);
btn1.addEventListener(&quot;click&quot;,changeColor(btn1));

I know that calling a function in the &quot;addEventListner&quot; immediately call the function . But I do need to pass a object to my function inside &quot;addEventListner()&quot; because I'm planning to use only one general function to handle clicks of 10 buttons.
","javascript, function, event-handling, dom-events, addeventlistener",-1,73619828,"From the above comment ...

&quot;A handler function gets passed an Event type to it. An UI event always features a currentTarget and a target property. The OP should access the former ... event.currentTarget.style.backgroundColor = &quot;red&quot;;.&quot;

Instead of using the color changing function as callback one could implement a button specific click handler which forwards its current target to a generic function which changes the background color of any passed element reference.


function changeElementColor(elm){
  elm.style.backgroundColor = 'red';
}
function handleButtonClick(evt) {
  changeElementColor(evt.currentTarget);
}

document
  .querySelectorAll('button')
  .forEach(btnElm =&gt;

    btnElm.addEventListener('click', handleButtonClick)
  );
&lt;button&gt;&lt;em&gt;Hallo&lt;/em&gt;&lt;/button&gt;
&lt;button&gt;&lt;b&gt;World&lt;/b&gt;&lt;/button&gt;



"
73546092,How do websites like jam.dev achieve their screenshotting functionality?,"does anyone know how websites like jam.dev achieve their click and drag screenshotting functionality?
I am trying to create a tool which involves screenshotting on the client side and my preferred way was to implement it in a similar fashion. Is anyone kind enough to point me in the right direction?
Some things I have tried and researched, but these don't provide the exact results I want:

html2canvas and other libraries that use svg and foreign object - these just don't produce consistent results.
rendering server side with puppeteer - it would be much better if the screenshotting could be achieved client side.
using webRTC - asking for permission and having the user select a screen/window is just not very intuitive.

Any insight would be greatly appreciated!
","javascript, screenshot",-2,73546137,"Browsers share api for extensions that allows making a screenshot
Accoding to this answwer
chrome.tabs.captureVisibleTab(null, {}, function (image) {
   // You can add that image HTML5 canvas, or Element.
});

"
73300008,".NET Core Web API only gets JSON from the Mock Lambda Tool. Using Postman, Swagger & AWS Lambda fail","I recently wrote a .NET Core Web API to receive JSON from a Lambda SNS message event. The Lambda sends the SNS event message JSON (via a POST request) to the API.
When I use the 'Mock Lambda Tool' to send the SNS message to the API, all is well. It works great. The data arrives, my API's controller sees it and it sends it over to the class that parses the data sends it into a database.
So, I then published the API to IIS and tested it from the Mock Lambda Tool. That worked too.
Feeling good about the work I uploaded the Lambda to AWS (for real world scenarios), I did a quick test of the same SNS message (JSON) using the AWS Lambda console. It times out.
So, I decided to go back and try testing the API on IIS using Postman. It shows:
**POST** https://my.company.com/api/Transaction/
**201**
2.69 s
POST /api/Transaction/ HTTP/1.1
Content-Type: application/json
User-Agent: PostmanRuntime/7.29.2
Accept: */*
Cache-Control: no-cache
Postman-Token: 4173d96a-1583-4c64-82b1-f67acaf8f0c7
Host: my.company.com
Accept-Encoding: gzip, deflate, br
Connection: keep-alive
Content-Length: 4274

*(I'm omitting the HUGE json message area. It's standard format.)*

**HEADER INFO**
HTTP/1.1 201 Created
Transfer-Encoding: chunked
Content-Type: application/json; charset=utf-8
Location: https://my.company.com/api/Transaction/
Server: Microsoft-IIS/10.0
Date: Wed, 10 Aug 2022 01:04:41 GMT

**RESPONSE BODY**
{&quot;Id&quot;:0,&quot;email&quot;:null,&quot;token&quot;:null,&quot;storeNumber&quot;:null,&quot;transactionDateTime&quot;:&quot;0001-01-01T00:00:00&quot;,&quot;transactionId&quot;:null,&quot;orderData&quot;:null}

There is NO error, but note that the Response Body is all nulls.
I decided to run the API from Visual Studio so that I could step through the code as the SNS message arrives from the Lambda.

Using the Mock Lambda Tool, no errors. Data goes all the way through.
Using Postman, a breakpoint on the controller shows no Transaction data arriving (NULL).
Using Swagger, a breakpoint on the controller shows no Transaction data arriving (NULL).

Are there any ideas as to what I am missing or doing incorrectly?
This is my controller in the API:
using Microsoft.AspNetCore.Mvc;
using MyWebAPI.TransactionData;
using MyWebAPI.Models;

namespace MyWebAPI.Controllers
{
    [ApiController]
    [Route(&quot;api/[controller]&quot;)]
    public class TransactionController : ControllerBase
    {
        private readonly ITransactionData _transactionData;

        public TransactionController(ITransactionData transactionData)
        {
            _transactionData = transactionData;
        }

        [HttpGet]
        public string Get()
        {
            return &quot;You have reached the .NET Core Web API (web service).&quot;;
        }

        [HttpPost]
        public IActionResult DataTranslation(Transaction transactionData)
        {
            _transactionData.DataTranslation(transactionData); // entry point

            return Created(
                HttpContext.Request.Scheme
                + &quot;://&quot; + HttpContext.Request.Host
                + &quot;&quot; + HttpContext.Request.Path
                + &quot;/&quot; + transactionData.transactionId, transactionData
                );
        }
    }
}

Here is my POST request in the Lambda:
public void PostRequest(string msg)
{
    var url = &quot;https://my.company.com/api/Transaction/&quot;; // IIS
    var httpRequest = (HttpWebRequest)WebRequest.Create(url);
    httpRequest.Method = &quot;POST&quot;;
    httpRequest.Accept = &quot;application/json&quot;;
    httpRequest.ContentType = &quot;application/json&quot;;

    var data = msg;

    try
    {
        // Write request data to stream
        using (var streamWriter = new StreamWriter(httpRequest.GetRequestStream()))
        {
            streamWriter.Write(data);
        }

        // Get a response from IIS (REST API)
        var httpResponse = (HttpWebResponse)httpRequest.GetResponse();

        // Read the body of the response from the server
        using (var streamReader = new StreamReader(httpResponse.GetResponseStream()))
        {
            var result = streamReader.ReadToEnd();
        }                

        // Log the status code
        Log.Logger.Information(@&quot;httpResponse: &quot; + httpResponse.StatusCode);
    }

    catch (WebException wex)
    {
        Log.Logger.Information($&quot;[ERROR] WebException, {wex}&quot;);
        Log.Logger.Information($&quot;[ERROR] WebException Message, {wex.Message}&quot;);
        Log.Logger.Information($&quot;[ERROR] WebException Response, {wex.Response}&quot;);
        Log.Logger.Information($&quot;[ERROR] WebException Response, {wex.Response.Headers}&quot;);
        Log.Logger.Information($&quot;[ERROR] WebException Response, {wex.Response.ResponseUri}&quot;);

        string pageContent = new StreamReader(wex.Response.GetResponseStream()).ReadToEnd().ToString();
        Log.Logger.Information($&quot;[ERROR] pageContent, {pageContent}&quot;);
    }
    catch (Exception ex)
    {
        Log.Logger.Information($&quot;[ERROR] Exception, {ex}&quot;);
    }

    return;
}


I'm curious if it's my Post Request that is the problem?
Why is the 'Mock Lambda Tool' the only way I can get the data over to the API?
Thanks
","c#, json, api, iis, aws-lambda",0,73312138,"UPDATE. I learned that the Lambda at AWS required a VPC to my internal VM that hosts the API on IIS. That solves why the Lambda at AWS timed out repeatedly.
As for Postman and Swagger problem, the issue is that the Mock Lambda Tool sends the entire SNS message event in its natural full format, then the Lambda extracts the Message portion only to send over to the API.
I was sending this entire SNS message event across Swagger and Postman both of which DO NOT do the work that the Lambda does which is strip just the Message portion out of the SNS event.
Once I sent only the Message portion across with Swagger and Postman, both worked.
I must give credit to my work buddy Dorian for helping me with this. Thanks! :)
"
74367079,Where are the elevation colors in Flutter material you?,"I want my TextField widget to be elevated like Card or NavigationBar widgets. I'm using Material 3 (You).
I've tried using surface color from colors like:
Theme.of(context).colorScheme.surface

but it appears to be the same color as
Theme.of(context).colorScheme.background

","flutter, material-design",0,74367121,"You can wrap your text_form_field widget with Card widget and give it elevation as well as boxShadow. It will work for you.
Card(
        child: //Your_text_form_field,
      elevation: 10,
      decoration: BoxDecoration(
        boxShadow: [
          new BoxShadow(
            color: Colors.red,
            blurRadius: 20.0,
          ),
        ],
      ),

"
73766357,django autofil with the pk page,"I would like to add documents to an employee's profile in a form but I would like the form to automatically select the id or the (pk) of the employee's page, anyone have the solution?
view.py
def createDocument(request):
forms = documentForm()

if request.method == 'POST':
    forms = documentForm(request.POST, request.FILES)
    if forms.is_valid():
        forms.save()
        return redirect('/employe')

context = {'forms':forms}
return render(request, 'accounts/document_form.html', context)

add document
form
","python, html, django",0,73766454,"Please, read how to work with Django-GCBV, more here:
https://docs.djangoproject.com/en/4.1/ref/class-based-views/generic-editing/#django.views.generic.edit.UpdateView
in your case:
# views.py
def createDocument(UpdateView):
    model = Employer
    form_class = documentForm
    sucsess_url = '/employe'
    template_name = 'accounts/document_form.html'

If you named template like employe_form.html you can avoid template_name attribute.
don't forget to setup urls.py:
urlpatterns = [
    ... # other urls
    path('add_document_to_employe/&lt;pk&gt;', createDocument.as_view(), name='create_document'),
    ... # other urls
]

"
73972027,How can I return value from callback in Kotlin?,"How can I send the result to the ViewModel in this case???
    val callback: (OAuthToken?, Throwable?) -&gt; Unit = { token, error -&gt;
        if (error != null) {
            // TODO: error return to viewModel
        } else if (token != null) {
            // TODO: success return to viewModel
        }
    }

    fun signInWithABC() {
        abcApi.signIn(callback = callback)
    }

I think signInWithABC should returns to the ViewModel, not from callback directly...
maybe like this..
fun signInWithABC(): Result&lt;AuthData&gt; {
    return abcApi.signIn(callback = callback)
}

But, I don't know how to do it..
Should I fix it like this? It doesn't look clean though.
    fun signInWithABC() {
        abcApi.signIn(){ token, error -&gt;
            if (error != null) {
                // TODO: error return to viewModel
            } else if (token != null) {
                // TODO: success return to viewModel
            }
        }
    }

And I also tried it with this.. but it has return problem. lamda can't return the value for the function. But it can only return for the block..
 fun signInWithABC(): Result&lt;String&gt; {
        abcApi.signIn(){ token, error -&gt;
            if (error != null) {
                return Result.failure&lt;Throwable&gt;(error)
            } else if (token != null) {
                return Result.success(token)
            }
        }
        return Result.failure(throw IllegalAccessException())
    }

","android, kotlin, callback",0,73986251,"You may need to do callback to suspend conversion.
Here is a simple example of doing this:
suspend fun signInWithABC(): String = suspendCoroutine { continuation -&gt; 
        abcApi.signIn(){ token, error -&gt;
            if (error != null) {
               continuation.resume(&quot;Error&quot;)
            } else {
               continuation.resume(token) // Assuming token is a string
            }
        }            
    }

"
74354445,What does the FC field represent in the MIPS machine code for floating point compare instructions? Refer to figure below,"
Can you also tell me how to assembler behaves for values of FC=00,01,10 and 11.
When I execute the instruction on my assembler - I found FC=11. But I have no idea what it means.
","assembly, mips, machine-code, mips32, mars-simulator",0,74354638,"The 2-bit fc field and the following 4 bits, both together, are really just the 6-bit func field.
I don't know why those authors choose break this apart into two side-by-side fields as it seems to serve no particular purpose that I can see.
Further, while they break the func field in two just for those several instructions, they revert to depiction of a 6-bit func field for all other instruction descriptions.
Because of this notation, in looking for an fc field of 0x0, 0x1, 0x2, 0x3, with the subsequent 4 bits being 0xc, we can also look for func field values of 0x0c, 0x1c, 0x2c, and 0x3c, some of which can be found.
A func value of 0x3c is for c.lt.s/d (with the proper opcode=0x11 and fmt=0x10/0x11 for single vs. double, of course).
A func field value of 0x0c is for round.w.s/d.
The other values, 0x1c &amp; 0x2c are not to be found in the documentation, and this sort of omission is typical of unused opcodes, so one possibility is then that these are indeed unused opcodes for the R2000.
Entering 46 00 00 3c into https://disasm.pro/ (MIPS/big-endian) yields the proper c.lt.s, and 46 00 00 0c yields the expected round.w.s, whereas ending in 1c or 2c yield no disassembly.
Another source, MIPS green sheet, offers the same answers: 0x0c is for round and 0x3c for compare, while 0x1c and 0x2c are shown as unassigned.

What would we expect the processor to do with unassigned opcodes?Â  It is unclear and typically unspecified in great detail.Â  It takes work to detect these things so designers may allow the implementation to do what is most convenient (i.e. lowest hardware effort).Â  Thus, unspecified can be by omission or maybe even by explicitly being defined as undefined behavior!Â  Possibilities for execution range from causing some kind of exception/fault (unimplemented), to decoding the instruction improperly, which might mean running an instruction of very similar encoding.
"
74543156,How to create multiple glue jobs as one glue job in terraform,"i am new to the terraform scripting, i want to create multiple glue jobs which containing different name and different script for each. is there any possibility to create this multiple jobs as one job with help of variables?
for example: variable.tf
variable &quot;db2jobnames&quot; {
  description = &quot;db2 glue job names&quot;
  type        = list
  default     = [&quot;sql_db_job&quot;, &quot;sql_db_job2&quot;]
}

variable &quot;script_location&quot; {
  description = &quot;db2 glue job scripts&quot;
  type        = list
  default     = [&quot;s3://s3_buget/sql_db_job.py&quot;, &quot;s3://s3_buget/sql_db_job.py&quot;]
}

glue-connection.tf
resource &quot;aws_glue_connection&quot; &quot;conn_db2&quot; {
  count           = var.created_CR ? 1 : 0
  connection_type = &quot;JDBC&quot;
  connection_properties = {
    JDBC_CONNECTION_URL = &quot;jdbc:db2://lkidjhyft:50000/ZXHAG006G&quot;
    PASSWORD            = &quot;acfg3&quot;
    USERNAME            = &quot;ndhygsf&quot;
  }

  name = &quot;${var.department}-${var.application}-connection&quot;

  physical_connection_requirements {
    availability_zone      = var.connection_availability_zone
    security_group_id_list = data.aws_security_groups.AWS_Public_Services.ids
    subnet_id              = data.aws_subnet.selected.id
  }
}

and my glue job. main.tf
resource &quot;aws_glue_job&quot; &quot;etl_jobs&quot; {
  count    = var.created_GL ? 1 : 0
  count    = &quot;${length(var.db2jobnames)}&quot;
  count    = &quot;${length(var.script_location)}&quot;
  name     = &quot;${var.db2jobnames[count.index]}_db2etljobs&quot;
  role_arn = aws_iam_role.glue_role.arn

  command {
    python_version  = var.python_version
    script_location = &quot;${var.script_location[count.index]}&quot;
  }
  default_arguments = {
    &quot;--extra-jars&quot;                       = &quot;${var.JarDir}&quot;
    &quot;--TempDir&quot;                          = &quot;${var.TempDir}&quot;
    &quot;--class&quot;                            = &quot;GlueApp&quot;
    &quot;--enable-continuous-cloudwatch-log&quot; = &quot;${var.enable-continuous-cloudwatch_log}&quot;
    &quot;--enable-glue-datacatalog&quot;          = &quot;${var.enable-glue-datacatalog}&quot;
    &quot;--enable-metrics&quot;                   = &quot;${var.enable-metrics}&quot;
    &quot;--enable-spark-ui&quot;                  = &quot;${var.enable-spark-ui}&quot;
    &quot;--job-bookmark-option&quot;              = &quot;${var.job-bookmark-option}&quot;
    &quot;--job-language&quot;                     = &quot;python&quot;
    &quot;--env&quot;                              = &quot;${var.paramregion}&quot;
    &quot;--spark-event-logs-path&quot;            = &quot;${var.sparkeventlogpath}&quot;
  }
  execution_property {
    max_concurrent_runs = var.max_concurrent_runs
  }
  connections = [
    &quot;${aws_glue_connection.conn_db2[count.index].name}&quot;
  ]
  glue_version      = var.glue_version
  max_retries       = 0
  worker_type       = var.worker_type
  number_of_workers = 20
  timeout           = 2880
  tags              = local.common_tags
}

i have tried to insert two counts but i am getting error. how could we create two jobs with one job. like one job needs to create with first dbname and first script location as showed below.
job1--&gt; sql_db_job - s3://s3_buget/sql_db_job.py
job2--&gt; sql_db_job2 - s3://s3_buget/sql_db_job2.py

any responses would be appreciated. thank you.
","amazon-web-services, terraform, aws-glue, terraform-provider-aws",0,74543286,"Based on the variables and code you have provided, you would have to change count so it uses the length of one of the lists. For example:
resource &quot;aws_glue_job&quot; &quot;etl_jobs&quot; {
  count    = var.created_GL ? length(var.db2jobnames) : 0
  name     = &quot;${var.db2jobnames[count.index]}_db2etljobs&quot;
  role_arn = aws_iam_role.glue_role.arn

  command {
    python_version  = var.python_version
    script_location = var.script_location[count.index]
  }
  default_arguments = {
    &quot;--extra-jars&quot;                       = var.JarDir
    &quot;--TempDir&quot;                          = var.TempDir
    &quot;--class&quot;                            = &quot;GlueApp&quot;
    &quot;--enable-continuous-cloudwatch-log&quot; = var.enable-continuous-cloudwatch_log
    &quot;--enable-glue-datacatalog&quot;          = var.enable-glue-datacatalog
    &quot;--enable-metrics&quot;                   = var.enable-metrics
    &quot;--enable-spark-ui&quot;                  = var.enable-spark-ui
    &quot;--job-bookmark-option&quot;              = var.job-bookmark-option
    &quot;--job-language&quot;                     = &quot;python&quot;
    &quot;--env&quot;                              = var.paramregion
    &quot;--spark-event-logs-path&quot;            = var.sparkeventlogpath
  }
  execution_property {
    max_concurrent_runs = var.max_concurrent_runs
  }
  connections = [
    aws_glue_connection.conn_db2[0].name
  ]
  glue_version      = var.glue_version
  max_retries       = 0
  worker_type       = var.worker_type
  number_of_workers = 20
  timeout           = 2880
  tags              = local.common_tags
}

"
73525303,Setting value for each item in for loop to true or false,"I am trying to create a v-for that shows a list of exercises containing several sets. I have created a loop with a row for each set underneath each exercise.
my data looks like this.
const exercises = [ 
{ id: 1, name: exercise1, sets: 3 },
{ id:2, name: exercise2, sets: 2 } 
{ id:3, name: exercise3, sets: 4 } 
]

And my component looks something like this:
 &lt;template v-for=&quot;exercise in exercises&quot; :key=&quot;exercise.id&quot;&gt;
   &lt;span&gt; {{ exercise.name }} &lt;/span&gt;
    &lt;template v-for=&quot;set in exercise.sets&quot; :key=&quot;set&quot;&gt;
      &lt;span @click=&quot;completeSet()&quot;&gt; {{ set }} &lt;/span&gt;
    &lt;/template&gt;
  &lt;/template&gt;

Now I want to be able to mark each set as completed by setting the value on each set to either true or false through a click event. But I am not sure about how to do this since each set doesn't have a property to set a value because it's looping through a number.
What would be the right approach to this problem?
","javascript, vue.js, vuejs3, v-for",2,73525936,"You can create array with finished sets and compare it (try the snippet pls):


new Vue({
  el: ""#demo"",
  data() {
    return {
      exercises: [{ id: 1, name: 'exercise1', sets: 3 }, { id: 2, name: 'exercise2', sets: 2 }, { id: 3, name: 'exercise3', sets: 4 }],
      finishedSets: []
    }
  },
  computed: {
    checkAll() {
      return this.exercises.reduce((acc, curr) =&gt; acc + curr.sets, 0) === this.finishedSets.length
    }
  },
  methods: {
    compareObjects(o1, o2) {
      return Object.entries(o1).sort().toString() !== Object.entries(o2).sort().toString()
    },
    findObject(id, set) {
      return this.finishedSets.find(f =&gt; f.id === id &amp;&amp; f.set === set)
    },
    completeSet(id, set) {
      this.findObject(id, set) ? 
        this.finishedSets = this.finishedSets.filter(f =&gt; {return this.compareObjects(f, this.findObject(id, set))}) :
        this.finishedSets.push({id, set})
    },
    isFinished(id, set) {
      return this.findObject(id, set) ? true : false
    },
  }
})
.set {
  width: 70px;
  cursor: pointer;
}
.finished {
  background-color: seagreen;
}
.finished__not {
  background-color: tomato;
}
&lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/vue/2.5.17/vue.js""&gt;&lt;/script&gt;
&lt;div id=""demo""&gt;
  &lt;div v-for=""exercise in exercises"" :key=""exercise.id""&gt;
   &lt;span&gt; {{ exercise.name }} &lt;/span&gt;
    &lt;div v-for=""set in exercise.sets"" :key=""set""&gt;
      &lt;div @click=""completeSet(exercise.id, set)"" class=""set"" :class=""isFinished(exercise.id, set) ? 'finished' : 'finished__not'""&gt; {{ set }} &lt;span&gt;
      &lt;span v-if=""isFinished(exercise.id, set)""&gt;finished&lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;button v-if=""checkAll""&gt;submit&lt;/button&gt;
  &lt;p&gt;{{finishedSets}}&lt;/p&gt;
&lt;/div&gt;



"
74603229,Full blled background onto two side-by-side Boxes,"I'd need to have two side-by-side Boxes, with background that is extended to full page width, but text content should be contained inside main container that is limited a specific size.
I tried the following HTML code:
&lt;div class=&quot;wrapper&quot;&gt;
  &lt;div class=&quot;container&quot;&gt;
    &lt;section class=&quot;left&quot;&gt;LEFT&lt;/section&gt;
    &lt;section class=&quot;right&quot;&gt;RIGHT&lt;/section&gt;
  &lt;/div&gt;
&lt;/div&gt;

and here the sCSS:
.wrapper {
  background: lightgray;
  padding-block: 10px;
  overflow: hidden;
}

.container {
  border: dotted 1px red;
  display: flex;
  max-width: 900px;
  margin-inline: auto;
  
  section {
    padding-block: 100px;
    border: solid 1px blue;
    flex: 1;
    position: relative;
    isolation: isolate;
    
    &amp;.left {
      background: green;
      
      &amp;:before {
        content:&quot;&quot;;
        display: block;
        background: green;
        position: absolute;
        top: 0;
        right: 0;
        height: 100%;
        width: 500%;
        z-index: -1;
      }
    }
    
    &amp;.right {
      background: orange;
      
      &amp;:before {
        content:&quot;&quot;;
        display: block;
        background: orange;
        position: absolute;
        top: 0;
        left: 0;
        height: 100%;
        width: 500%;
        z-index: -1;
      }
    }
  }
}

Here a working example. Have you any suggestion to have a better solution with almost the same result?
",css,0,74603579,"You could add an extra div inside your wrapper and use a linear gradient on it:


.wrapper {
  background: lightgray;
  padding-block: 10px;
  overflow: hidden;
}

.background {
  background: linear-gradient(to right, green, green 50%, orange 50%, orange 100%);
}

.container {
  border: dotted 1px red;
  display: flex;
  max-width: 900px;
  margin-inline: auto;
}

.column {
  width: 50%;
}
&lt;div class=""wrapper""&gt;
  &lt;div class=""background""&gt;
    &lt;div class=""container""&gt;
      &lt;section class=""column left""&gt;LEFT&lt;/section&gt;
      &lt;section class=""column right""&gt;RIGHT&lt;/section&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;



"
73201201,Is there a standard best way to join unrelated single-row/value results?,"I have a query of the form:
SELECT 
    values, fee, values + fee AS total 
FROM
    (SELECT 1 AS joint, SUM(value) AS values 
     FROM table_one 
     WHERE condition)
LEFT JOIN
    (SELECT 1 AS joint, fee 
     FROM table_two 
     WHERE condition) f USING (joint);

I've never seen anyone do anything like this before, and I feel like I'm probably doing something stupid.  I'm not an experienced SQL dev.
I could retrieve them in separate queries, but it would make things uglier.
Edit: Assume table_one has one column: 'value', and table_two has columns: 'id' and 'fee' for the sake of this example.
","sql, postgresql",0,73256340,"Thank you, @shawnt00:
CROSS JOIN is a simpler join for this scenario.
Another solution I've found since asking is
LEFT JOIN ON true

"
73954718,Recode NA when another column value is NA in R,"I have a quick recoding question. Here is my sample dataset looks like:
df &lt;- data.frame(id = c(1,2,3),
                 i1 = c(1,NA,0),
                 i2 = c(1,1,1))

&gt; df
  id i1 i2
1  1  1  1
2  2 NA  1
3  3  0  1

When, i1==NA , then I need to recode i2==NA. I tried below but not luck.
df %&gt;%
  mutate(i2 = case_when(
    i1 == NA ~  NA_real_,
    TRUE ~ as.character(i2)))

Error in `mutate()`:
! Problem while computing `i2 = case_when(i1 == &quot;NA&quot; ~ NA_real_, TRUE ~ as.character(i2))`.
Caused by error in `` names(message) &lt;- `*vtmp*` ``:
! 'names' attribute [1] must be the same length as the vector [0]

my desired output looks like this:
&gt; df
  id i1 i2
1  1  1  1
2  2 NA  NA
3  3  0  1

","r, recode",0,73957295,"Would a simple assignment meet your requirements for this?
df$i2[is.na(df$i1)] &lt;- NA
"
74590672,How to include asio boost in cmake project,"I'm trying to include asio boost using CMakein my project but I'm getting this error. libraries linking is working in VS but I don't know how to link them in Cmake project.
Working Solution with VS:-
asio boost version: 1.24.0

VS ScreenShot
cmake_minimum_required(VERSION 3.10)
project(networking_examples)

#set(CMAKE_CXX_COMPILER D:/System/msys2/mingw64/bin/clang++)
set(CMAKE_CXX_STANDARD 17)
set(CMAKE_CXX_STANDARD_REQUIRED ON)

# Link Boost Asio library
target_include_directories(networking_examples PRIVATE &quot;./asio-1.24.0/include&quot;)

add_executable(
  networking_examples
  ./src/index.cpp
)


CMake Project

I want to link ./asio-1.24.0/include   with my project using CMAKE.

Error:
CMake Error at CMakeLists.txt:9 (target_include_directories):
  Cannot specify include directories for target &quot;networking_examples&quot; which
  is not built by this project.


-- Configuring incomplete, errors occurred!
See also &quot;D:/Git Repo/c++/networking/cmake-build-debug/CMakeFiles/CMakeOutput.log&quot;.

","c++, cmake, boost-asio, static-libraries, cmake-language",0,74590713,"When you use target_include_directories there is not target named networking_examples. You add that target after.
Order matters, and just like in C++ symbols must be defined before they can be used.
So you need to change to:
add_executable(
  networking_examples
  ./src/index.cpp
)

# Asio library header directory
target_include_directories(networking_examples PRIVATE &quot;./asio-1.24.0/include&quot;)


On another couple of notes: First you don't seem to be using Boost ASIO but rather the standalone header-only library.
Secondly, you don't link with the library (it's a header-only library). You only tell the build-system where it can find the ASIO header files.
"
73611112,Is there way to create types like Array in typescript,"Is there a way to create type in typescript with methods that when I call these methods, they have access to the variable's value? Equals what the array, for example, which has the method find.
Example:
const arrayVar: Array = [1,2,3];

array.find(el =&gt; el === 1); 

In this case, find has access to the value of the array arrayVar without me having to pass it via a parameter to a function, for example, I wanted to create something in this way, for example:
const myVar: MyCustomType = 5;

myVar.add(2); // Nesse caso, o retorno seria 7. 

I know it can be done with classes and functions, but then I would have to pass the value of &quot;myVar&quot; as a parameter (function add (value1, value2), for example), I wanted a way to access it directly, just like the type Array does in its methods.
","javascript, typescript, types",-1,73611654,"To make a subclass of Number with new methods:
class SwagNumber extends Number {
  add(number: number) {
    // Tell the TS compiler that `this` is an unboxed Number
    return (this as unknown as number) + number;
  }
}

Then to use:
const six = new SwagNumber(6);

six will be typed to SwagNumber by the TS compiler.
And to show it works:
six.add(5)
&gt; 11

Let's look at the Constructor used, part of the Class:
&gt; six.constructor
[class SwagNumber extends Number]

This will also leave the original Number prototype unchanged, which will stop any potential issues (double dots are used to use a method on a number, to distinguish the dot from a decimal point!)
&gt; 3..constructor
[Function: Number]

or:
&gt; (3).constructor
[Function: Number]

See Classes on MDN
However there's some danger here
Since SwagNumber is an object, and a regular number isn't an object by default (until you call its methods), comparisons won't work properly:
&gt; six === 6
false

See Why should you not use Number as a constructor?
"
74406469,Sorting items by date. And adding numbers from today,"This is Model and View Model. I am using UserDefaults for saving data.
import Foundation


struct Item: Identifiable, Codable {
    var id = UUID()
    var name: String
    var int: Int
    var date = Date()
}

class ItemViewModel: ObservableObject {
    @Published var ItemList = [Item] ()
    
    init() {
        load()
    }
    
    func load() {
        guard let data = UserDefaults.standard.data(forKey: &quot;ItemList&quot;),
              let savedItems = try? JSONDecoder().decode([Item].self, from: data) else { ItemList = []; return }
        
        ItemList = savedItems
    }
    
    func save() {
        do {
            let data = try JSONEncoder().encode(ItemList)
            UserDefaults.standard.set(data, forKey: &quot;ItemList&quot;)
        } catch {
            print(error)
        }
    }
    
    
}

and this is the view. I am tryng too add new item and sort them by date. After that adding numbers on totalNumber. I tried .sorted() in ForEach but its not work for sort by date. and I try to create a func for adding numbers and that func is not work thoo.
import SwiftUI

struct ContentView: View {
    
    @State private var name = &quot;&quot;
    @State private var int = 0
    
    @AppStorage(&quot;TOTAL_NUMBER&quot;) var totalNumber = 0
    
    
    @StateObject var VM = ItemViewModel()
    
    var body: some View {
        
        VStack(spacing: 30) {
            VStack(alignment: .leading) {
                
                HStack {
                    Text(&quot;Name:&quot;)
                    TextField(&quot;Type Here...&quot;, text: $name)
                }
                HStack {
                    Text(&quot;Number:&quot;)
                    TextField(&quot;Type Here...&quot;, value: $int, formatter: NumberFormatter())
                }
                
                Button {
                    addItem()
                    VM.save()
                    name = &quot;&quot;
                    int = 0
                } label: {
                    Text (&quot;ADD PERSON&quot;)
                }
            }
            .padding()
            
            VStack(alignment: .leading) {
                
                List(VM.ItemList) { Item in
                    Text(Item.name)
                    Text(&quot;\(Item.int)&quot;)
                    Text(&quot;\(Item.date, format: .dateTime.day().month().year())&quot;)
                }
                
                Text(&quot;\(totalNumber)&quot;)
                    .padding()
            }
            
        }
        
        
    }
    
    func addItem() {
        VM.ItemList.append(Item(name: name, int: int))
    }
    
    
}

struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        ContentView()
    }
}

","ios, swiftui",0,74411897,"First of all please name variables always with starting lowercase letter for example
@Published var itemList = [Item] ()
@StateObject var vm = ItemViewModel()

To sort the items by date in the view model replace
itemList = savedItems

with
itemList = savedItems.sorted{ $0.date &lt; $1.date }

To show the sum of all int properties of the today items add a @Published var totalNumber in the view model and a method to calculate the value. Call this method in load and save
class ItemViewModel: ObservableObject {
    @Published var itemList = [Item] ()
    @Published var totalNumber = 0
    
    init() {
        load()
    }
    
    func load() {
        guard let data = UserDefaults.standard.data(forKey: &quot;ItemList&quot;),
              let savedItems = try? JSONDecoder().decode([Item].self, from: data) else { itemList = []; return }
        
        itemList = savedItems.sorted{ $0.date &lt; $1.date }
        calculateTotalNumber()
    }
    
    func save() {
        do {
            let data = try JSONEncoder().encode(itemList)
            UserDefaults.standard.set(data, forKey: &quot;ItemList&quot;)
            calculateTotalNumber()
        } catch {
            print(error)
        }
    }
    
    func calculateTotalNumber() {
        let todayItems = itemList.filter{ Calendar.current.isDateInToday($0.date) }
        totalNumber = todayItems.map(\.int).reduce(0, +)
    }
}

In the view delete the @AppStorage line because the value is calculated on demand and replace
Text(&quot;\(totalNumber)&quot;)

with
 Text(&quot;\(vm.totalNumber)&quot;)

"
74574699,Create new columns in a dataframe from another with multiple options,"a dataframe as list:
dfcheck &lt;- data.frame(status = c(&quot;open/close&quot;, &quot;close&quot;, &quot;open&quot;), stock = c(&quot;company energy&quot;,&quot;goods and books&quot;,&quot;other&quot;), name = c(&quot;amazon1;google1&quot;,&quot;google3;yahoo1&quot;,&quot;yahoo2;amazon2;google2&quot;))

And an input dataframe like this:
dfdata &lt;- data.frame(id = c(&quot;id1&quot;, &quot;id2&quot;, &quot;id3&quot;), title1 = c(&quot;amazon1&quot;,&quot;google1&quot;,&quot;yahoo1&quot;), title2 = c(&quot;yahoo2&quot;,NA,&quot;amazon2&quot;))

How is it possible to produce a dataframe with columns based the previous list:
Expected output:
dfdata &lt;- data.frame(id = c(&quot;id1&quot;, &quot;id2&quot;, &quot;id3&quot;), title1 = c(&quot;amazon1&quot;,&quot;google1&quot;,&quot;yahoo1&quot;), title2 = c(&quot;yahoo2&quot;,NA,&quot;amazon2&quot;), status1 = c(&quot;open/close&quot;,&quot;open/close&quot;,&quot;close&quot;), stock1 = c(&quot;company energy&quot;,&quot;company energy&quot;,&quot;goods and books&quot;), status2 = c(&quot;open&quot;,NA,&quot;open&quot;), stock2 = c(&quot;other&quot;,NA,&quot;other&quot;))

 id  title1  title2    status1          stock1 status2
1 id1 amazon1  yahoo2 open/close  company energy    open
2 id2 google1    &lt;NA&gt; open/close  company energy    &lt;NA&gt;
3 id3  yahoo1 amazon2      close goods and books    open
  stock2
1  other
2   &lt;NA&gt;
3  other


This dataframe checks in dfdata in every column, expect the first id column, if any of the values in dfcheck dataframe exist and creates two new columns with the status and stock of dfcheck. From the dfcheck the column name has more than one values separated by &quot;;&quot;
",r,1,74575047,"Libraries:
library(dplyr)
library(stringr)
library(tidyr)

First you'd need to tidy your dfcheck data.frame:
dfcheck_tidy &lt;- dfcheck %&gt;%
  mutate(name = str_split(name, &quot;;&quot;)) %&gt;%
  unnest(name)

(I'm not using tidyr::separate to do this as it seems from your example that you can have a variable length of names separated by &quot;;&quot;.)
And now you can perform the two joins:
dfdata %&gt;%
  left_join(dfcheck_tidy,
            by = c(&quot;title1&quot; = &quot;name&quot;)) %&gt;%
  left_join(dfcheck_tidy,
            by = c(&quot;title2&quot; = &quot;name&quot;),
            suffix = c(&quot;1&quot;, &quot;2&quot;))
#    id  title1  title2    status1          stock1 status2 stock2
# 1 id1 amazon1  yahoo2 open/close  company energy    open  other
# 2 id2 google1    &lt;NA&gt; open/close  company energy    &lt;NA&gt;   &lt;NA&gt;
# 3 id3  yahoo1 amazon2      close goods and books    open  other

"
74484753,Communication between injected class service (AppState) and components,"I want to figure out what's the best approach to send re-render requests to a component when an application wide class' (AppState pattern) property has changed.
Following this nice blog post from Chris Sainty, the third example is exactly the kind of thing I want to achieve.
Have a singleton/scoped service, AppState, with the main purpose to store session data to be consumed by several components, invoking an event action when one of it's properties changes, after getting some data from an external api for example. The component can then listen to that and call StateHasChanged() to re-render the page.
This works but I have a couple of questions about the method.

Is it the best approach for doing this or are there more appropriate
ways implemented into the language by default? Either for the event based communication or the whole AppState service. I'd imagine this is quite a common problem and perhaps I'm missing some default functionality like @bind.

Are there any drawbacks to @implements IDisposable? I understand why
it needs to be disposed of, but why don't we need to do it when, for
instance, binding some data to an input field to essentially do the
same thing? Does the @bind attribute already handle that under the hood?


Thanks in advance and sorry if I'm missing something obvious, still learning the ropes of Blazor.
","asp.net-core, blazor",0,74485661,"
Is it the best approach for doing this or are there more appropriate
ways implemented into the language by default?

For Communication between unrelated components, we have different options:

AppState registered as Scoped/Singleton. (extra overhead of registering and disposing event).
AppState as razor file (code example is given below).
Follow MVVM pattern for storing state, but there is downside to this approach we need to inject every view model as Scoped/Singleton. (If we are re using same component multiple times then each component state will be same).

Based on the requirement you can choose the best.
Example for AppState as razor file (preserving state of counter)
App.razor will look like this:
&lt;AppState&gt;
    &lt;Router AppAssembly=&quot;@typeof(App).Assembly&quot;&gt;
        &lt;Found Context=&quot;routeData&quot;&gt;
            &lt;RouteView RouteData=&quot;@routeData&quot; DefaultLayout=&quot;@typeof(MainLayout)&quot; /&gt;
            &lt;FocusOnNavigate RouteData=&quot;@routeData&quot; Selector=&quot;h1&quot; /&gt;
        &lt;/Found&gt;
        &lt;NotFound&gt;
            &lt;PageTitle&gt;Not found&lt;/PageTitle&gt;
            &lt;LayoutView Layout=&quot;@typeof(MainLayout)&quot;&gt;
                &lt;p role=&quot;alert&quot;&gt;Sorry, there's nothing at this address.&lt;/p&gt;
            &lt;/LayoutView&gt;
        &lt;/NotFound&gt;
    &lt;/Router&gt;
&lt;/AppState&gt;

and AppState.razor will look like this:
&lt;CascadingValue Value=&quot;this&quot;&gt;
    @ChildContent
&lt;/CascadingValue&gt;

@code {
    private int _count;

    [Parameter]
    public required RenderFragment ChildContent { get; set; }//use 'required' only if .net version is 7 &amp; above

    public int Count
    {
        get =&gt; _count; 
        set
        {
            _count = value;
            StateHasChanged();
        }
    }
}

and Counter.razor will look like this:
@page &quot;/counter&quot;

&lt;PageTitle&gt;Counter&lt;/PageTitle&gt;

&lt;h1&gt;Counter&lt;/h1&gt;

&lt;p role=&quot;status&quot;&gt;Current count: @State.Count&lt;/p&gt;

&lt;button class=&quot;btn btn-primary&quot; @onclick=&quot;IncrementCount&quot;&gt;Click me&lt;/button&gt;

@code {
    [CascadingParameter]
    public required AppState State { get; set; }//use 'required' only if .net version is 7 &amp; above

    private void IncrementCount()
    {
        State.Count++;
    }
}


Are there any drawbacks to @implements IDisposable?

No, only an extra overhead, we need to dispose all unmanged resource manually.
"
72921785,"I have a array like this in laravel , I want to remove the array which is having total greater than 480","  array (
    0 =&gt; 
    array (
      'user_code' =&gt; '073',
      'name' =&gt; 'Ashish',
      'email' =&gt; 'ashishm@gmail.com',
    ),
    1 =&gt; 
    array (
      'user_code' =&gt; '073',
      'date' =&gt; '2022-07-04',
      'total' =&gt; '915',
    ),
    2 =&gt; 
    array (
      'user_code' =&gt; '073',
      'date' =&gt; '2022-07-05',
      'total' =&gt; 0,
    ),
    3 =&gt; 
    array (
      'user_code' =&gt; '073',
      'date' =&gt; '2022-07-06',
      'total' =&gt; '360',
    ),
)  

","php, arrays, laravel",0,72921901,"If I understand you correctly, you have an array that contains 4 entries. Each of those are arrays. You want to remove the one that has total = 915. This would be the resulting array:
  array (
    0 =&gt; 
    array (
      'user_code' =&gt; '073',
      'name' =&gt; 'Ashish',
      'email' =&gt; 'ashishm@gmail.com',
    ),
    1 =&gt; 
    array (
      'user_code' =&gt; '073',
      'date' =&gt; '2022-07-05',
      'total' =&gt; 0,
    ),
    2 =&gt; 
    array (
      'user_code' =&gt; '073',
      'date' =&gt; '2022-07-06',
      'total' =&gt; '360',
    ),
)  

Is this what you are looking for or are you trying to remove several entries whenever the total exceeds 480 via some sort of script or validation before it's created. If so, I need to see more code to understand where this array comes from.
----EDITED AFTER FURTHER INFO PROVIDED ------
So it sounds like you are getting two arrays from a database and then merging them. Is this what you are doing?
$arrayOne = array(

    0 =&gt;
    array(
        'user_code' =&gt; '073',
        'name' =&gt; 'Ashish',
        'email' =&gt; 'ashishm@gmail.com',
    ),
    1 =&gt;
    array(
        'user_code' =&gt; '078',
        'name' =&gt; 'Tyler',
        'email' =&gt; 'test@example.com',
    ),
);

$arrayTwo = array(
    0 =&gt;
    array(
        'user_code' =&gt; '073',
        'date' =&gt; '2022-07-04',
        'total' =&gt; '915',
    ),
    1 =&gt;
    array(
        'user_code' =&gt; '073',
        'date' =&gt; '2022-07-05',
        'total' =&gt; 0,
    ),
    2 =&gt;
    array(
        'user_code' =&gt; '073',
        'date' =&gt; '2022-07-06',
        'total' =&gt; '360',
    ),
    4 =&gt;
    array(
        'user_code' =&gt; '073',
        'date' =&gt; '2022-07-04',
        'total' =&gt; '805',
    ),
    5 =&gt;
    array(
        'user_code' =&gt; '073',
        'date' =&gt; '2022-07-04',
        'total' =&gt; '10000',
    ),
);

$mergedArray = array_merge($arrayOne, $arrayTwo);


If so, array_filter should work. @Bruce solution was close but it was not testing the value below 480.

$filteredArray = array_filter($mergedArray, function ($val) {
    if (!isset($val['total'])) return true;
    if ($val['total'] &lt; 480) return true;
    return false;
});



"
74438621,How to export Azure Prices REST API to CSV,"I would like to save the whole Azure Prices REST API to CSV.
In order to do so I have to query the endpoint https://prices.azure.com/api/retail/prices which ends with a:
&quot;NextPageLink&quot;:&quot;https://prices.azure.com:443/api/retail/prices?$skip=100&quot;,&quot;Count&quot;:100}

I wrote a Python scripts that could help me grab that NextPageLink and loop it into a function:
import requests
import json
import pandas as pd 
from timeit import default_timer as timer
from datetime import timedelta

start = timer()
NextPageLink = &quot;https://prices.azure.com/api/retail/prices&quot;

def GetJSON(NextPageLink):
    wjdata = requests.get(NextPageLink).json()
    df = pd.DataFrame(wjdata)
    df.to_csv(&quot;test.csv&quot;, index=False)
    if 'NextPageLink' in wjdata:
        print (timer(), wjdata['NextPageLink'])
        NextPageLink = wjdata['NextPageLink']
        return NextPageLink

GetJSON(NextPageLink) 

The script is quite simple but it just saves the first page and doesn't query the NextPageLink.
What am I doing wrong?
","python, json, pandas, rest, web-scraping",1,74438737,"To get all data from the API you can try (there are 4558 requests total):
import requests
import pandas as pd

url = &quot;https://prices.azure.com/api/retail/prices&quot;

all_data = []
while True:
    print(url)
    data = requests.get(url).json()
    all_data.extend(data[&quot;Items&quot;])
    if data[&quot;NextPageLink&quot;]:
        url = data[&quot;NextPageLink&quot;]
    else:
        break

df = pd.DataFrame(all_data)
print(df.head().to_markdown(index=False))
df.to_csv(&quot;data.csv&quot;, index=False)

Prints:

......

https://prices.azure.com:443/api/retail/prices?$skip=455600
https://prices.azure.com:443/api/retail/prices?$skip=455700
https://prices.azure.com:443/api/retail/prices?$skip=455800





currencyCode
tierMinimumUnits
retailPrice
unitPrice
armRegionName
location
effectiveStartDate
meterId
meterName
productId
skuId
availabilityId
productName
skuName
serviceName
serviceId
serviceFamily
unitOfMeasure
type
isPrimaryMeterRegion
armSkuName
reservationTerm
effectiveEndDate




USD
0
3
3
southindia
IN South
2016-12-01T00:00:00Z
ff92c14c-af83-412e-9144-a2542dfe0b4f
Certificate Renewal Request
DZH318Z0BQG0
DZH318Z0BQG0/0001

Key Vault
Premium
Key Vault
DZH3157JCZ2M
Security
1
Consumption
False

nan
nan


USD
0
3
3
southcentralus
US South Central
2016-12-01T00:00:00Z
ff92c14c-af83-412e-9144-a2542dfe0b4f
Certificate Renewal Request
DZH318Z0BQG0
DZH318Z0BQG0/002Q

Key Vault
Standard
Key Vault
DZH3157JCZ2M
Security
1
Consumption
False

nan
nan


USD
0
3
3
jioindiawest
IN West Jio
2021-04-15T00:00:00Z
ff92c14c-af83-412e-9144-a2542dfe0b4f
Certificate Renewal Request
DZH318Z0BQG0
DZH318Z0BQG0/004V

Key Vault
Premium
Key Vault
DZH3157JCZ2M
Security
1
Consumption
False

nan
nan


USD
0
3
3
germanywestcentral
DE West Central
2016-12-01T00:00:00Z
ff92c14c-af83-412e-9144-a2542dfe0b4f
Certificate Renewal Request
DZH318Z0BQG0
DZH318Z0BQG0/003Q

Key Vault
Premium
Key Vault
DZH3157JCZ2M
Security
1
Consumption
False

nan
nan


USD
0
3
3
westeurope
EU West
2016-12-01T00:00:00Z
ff92c14c-af83-412e-9144-a2542dfe0b4f
Certificate Renewal Request
DZH318Z0BQG0
DZH318Z0BQG0/001Z

Key Vault
Premium
Key Vault
DZH3157JCZ2M
Security
1
Consumption
False

nan
nan




and saves data.csv (screenshot from LibreOffice):

"
73296988,Propper way to describe request body as java class,"What is the propper way to describe json body like this in spring-boot app?
{
  &quot;name&quot;: &quot;name&quot;,
  &quot;releaseDate&quot;: &quot;2000-01-01&quot;,
  &quot;description&quot;: &quot;desc&quot;,
  &quot;duration&quot;: 10,
  &quot;rate&quot;: 1,
  &quot;mpa&quot;: { &quot;id&quot;: 3},
  &quot;genres&quot;: [{ &quot;id&quot;: 1}]
}

For now i have class like bellow, but i have problem with serialization of mpa and genres fields.
@Data
@JsonInclude(JsonInclude.Include.NON_NULL)
public class Film extends Entity implements Comparable&lt;Film&gt; {

    @Builder
    public Film(long id, String name, @NonNull String description, @NonNull LocalDate releaseDate, @NonNull int duration, List&lt;Genre&gt; genres, Rating mpa, Set&lt;Long&gt; likes) {
        super(id);
        this.name = name;
        this.description = description;
        this.releaseDate = releaseDate;
        this.duration = duration;
        this.genres = genres;
        this.mpa = mpa;
        this.likes = likes;
    }

    @NotBlank
    private final String name;
    @NonNull
    @Size(max = 200, message = &quot;Description name longer than 200 symbols&quot;)
    private final String description;
    @NonNull
    @Past
    @JsonFormat(pattern = &quot;yyyy-MM-dd&quot;, shape = JsonFormat.Shape.STRING)
    private LocalDate releaseDate;

    @NonNull
    @Positive
    private int duration;

    private Rating mpa;

    private List&lt;Genre&gt; genres;

    @Setter(value = AccessLevel.PRIVATE)
    private Set&lt;Long&gt; likes;
}

Genre and Rating:
@Data
public class Genre {

    @Positive
    private final long id;

}

@Data
public class Rating {

    @Positive
    private final long id;

}

","java, spring-boot",0,73300995,"Jackson ObjectMapper cannot create the object, because neither default constructor exists nor any other creator is provided (e.g. @JsonCreator, @ConstructorProperties).
You also have a rate property that is not defined in the Film class, which will cause problems unless you use the @JsonIgnoreProperties annotation (possibly with ignoreUnknown attribute set to true) or configure the ObjectMapper globally (DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES). It could also be that you wanted the likes property to handle that - anyway, it should be fixed.
I've also stumbled upon lack of the jackson-datatype-jsr310 dependency, but maybe your project already has it (it's required for the Java 8 classes like LocalDate).

There are different ways to solve the first problem described above, but generally you need to either provide a default constructor or define a creator for Jackson.
If you don't want to expose the default constructor, you can change the settings of the ObjectMapper (for Spring Boot read about Jackson2ObjectMapperBuilder) to allow usage of private creators (setVisibility method). In Lombok there's an annotation: @NoArgsConstructor. To limit the visibility, use the access annotation attribute.
The creator can be handled by annotating the constructor with ordered argument names:
@ConstructorProperties({&quot;id&quot;, &quot;name&quot;, &quot;description&quot;, &quot;releaseDate&quot;, &quot;duration&quot;, &quot;genres&quot;, &quot;mpa&quot;, &quot;likes&quot;}). It gets complicated with the Genre and Rating classes as you do not have an explicit access to their constructors. You could either create them and mark appropriately or create a lombok.config file in your project's root directory and inside the file define the property:
lombok.anyConstructor.addConstructorProperties = true
This way Lombok will automatically add the @ConstructorProperties annotations to the classes.

I've created a GitHub repository with the tests for the solution - you can find it here. The lombok.config file is also included, as well as the fixed Film class.
"
74173571,Gradle Could not GET. Received status code 502 from server: Bad Gateway,"When I add image_picker: ^0.6.5+3 as a dependency in my pubspec.yaml file, I get the following:
Terminal Output:
Launching lib/main.dart on sdk gphone64 x86 64 in debug mode...
lib/main.dart:1

FAILURE: Build failed with an exception.

* What went wrong:
Could not determine the dependencies of task ':app:processDebugResources'.
&gt; Could not resolve all task dependencies for configuration ':app:debugRuntimeClasspath'.
   &gt; Could not resolve com.google.android.gms:play-services-measurement-base:[21.1.1].
     Required by:
         project :app &gt; com.google.firebase:firebase-analytics:21.1.1 &gt; com.google.android.gms:play-services-measurement:21.1.1
         project :app &gt; com.google.firebase:firebase-analytics:21.1.1 &gt; com.google.android.gms:play-services-measurement-api:21.1.1
         project :app &gt; com.google.firebase:firebase-analytics:21.1.1 &gt; com.google.android.gms:play-services-measurement-sdk:21.1.1
         project :app &gt; com.google.firebase:firebase-analytics:21.1.1 &gt; com.google.android.gms:play-services-measurement:21.1.1 &gt; com.google.android.gms:play-services-measurement-impl:21.1.1
         project :app &gt; com.google.firebase:firebase-analytics:21.1.1 &gt; com.google.android.gms:play-services-measurement-api:21.1.1 &gt; com.google.android.gms:play-services-measurement-sdk-api:21.1.1
      &gt; Failed to list versions for com.google.android.gms:play-services-measurement-base.
         &gt; Unable to load Maven meta-data from https://google.bintray.com/exoplayer/com/google/android/gms/play-services-measurement-base/maven-metadata.xml.
            &gt; Could not get resource 'https://google.bintray.com/exoplayer/com/google/android/gms/play-services-measurement-base/maven-metadata.xml'.
               &gt; Could not GET 'https://google.bintray.com/exoplayer/com/google/android/gms/play-services-measurement-base/maven-metadata.xml'. Received status code 502 from server: Bad Gateway

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.

* Get more help at https://help.gradle.org

BUILD FAILED in 9s
Exception: Gradle task assembleDebug failed with exit code 1
Exited (sigterm)

build.gradle:
buildscript {
    ext.kotlin_version = '1.3.50'
    repositories {
        google()
        jcenter()
    }

    dependencies {
        classpath 'com.android.tools.build:gradle:3.5.0'
        classpath &quot;org.jetbrains.kotlin:kotlin-gradle-plugin:$kotlin_version&quot;
        classpath 'com.google.gms:google-services:4.3.13'
    }
}

allprojects {
    repositories {
        google()
        jcenter()
    }
}

rootProject.buildDir = '../build'
subprojects {
    project.buildDir = &quot;${rootProject.buildDir}/${project.name}&quot;
}
subprojects {
    project.evaluationDependsOn(':app')
}

task clean(type: Delete) {
    delete rootProject.buildDir
}

Flutter doctor -v:
[âœ“] Flutter (Channel stable, 1.22.6, on macOS 12.5 21G72 darwin-x64, locale
    en-US)
    â€¢ Flutter version 1.22.6 at /Library/flutter
    â€¢ Framework revision 9b2d32b605 (1 year, 9 months ago), 2021-01-22 14:36:39
      -0800
    â€¢ Engine revision 2f0af37152
    â€¢ Dart version 2.10.5

 
[âœ“] Android toolchain - develop for Android devices (Android SDK version 30.0.3)
    â€¢ Android SDK at /Users/jcastro2/Library/Android/sdk
    â€¢ Platform android-32, build-tools 30.0.3
    â€¢ Java binary at: /Applications/Android
      Studio.app/Contents/jre/jdk/Contents/Home/bin/java
    â€¢ Java version OpenJDK Runtime Environment (build
      11.0.12+0-b1504.28-7817840)
    â€¢ All Android licenses accepted.

[âœ“] Xcode - develop for iOS and macOS (Xcode 14.0.1)
    â€¢ Xcode at /Applications/Xcode.app/Contents/Developer
    â€¢ Xcode 14.0.1, Build version 14A400
    â€¢ CocoaPods version 1.11.2

[!] Android Studio (version 2021.2)
    â€¢ Android Studio at /Applications/Android Studio.app/Contents
    âœ— Flutter plugin not installed; this adds Flutter specific functionality.
    âœ— Dart plugin not installed; this adds Dart specific functionality.
    â€¢ Java version OpenJDK Runtime Environment (build
      11.0.12+0-b1504.28-7817840)

[âœ“] VS Code (version 1.72.2)
    â€¢ VS Code at /Applications/Visual Studio Code.app/Contents
    â€¢ Flutter extension version 3.50.0

[âœ“] Connected device (1 available)
    â€¢ sdk gphone64 x86 64 (mobile) â€¢ emulator-5554 â€¢ android-x64 â€¢ Android 12
      (API 31) (emulator)

! Doctor found issues in 1 category.

pubspec.yaml
name: chat_app
description: A new Flutter project.

publish_to: 'none'

version: 1.0.0+1

environment:
  sdk: &quot;&gt;=2.7.0 &lt;3.0.0&quot;

dependencies:
  flutter:
    sdk: flutter
  cloud_firestore: ^0.13.5
  firebase_auth: 0.16.1
  image_picker: ^0.6.5+3

  cupertino_icons: ^1.0.0

dev_dependencies:
  flutter_test:
    sdk: flutter
  change_app_package_name: ^0.1.3

flutter:
  uses-material-design: true

","flutter, gradle, build.gradle, pubspec, flutter-doctor",0,74175375,"You have packages that are way out of date. You need to 1) update your packages and 2) go back to the firebase documentation for flutter and follow the suggested steps since you are also missing firebase_core which is needed to use firebase_auth and cloud_firestore in your project.
"
73211933,Extending short key for AES256 (SNMPv3),"I am currently working on security of a switch that runs SNMPv3.
I am expected to code it in such a way, that any SHA (1 - 2-512) is compatible with any AES (128 - 256C).
Everything, like the algorithms alone, works pretty well. The problem is, that its been estabilished, that we are going to use SHA for key generation for both authentification and encryption.
When I want to use, let's say, SHA512 with AES256, there's no problem, since SHA has output of 64B and I need just 32B for key for AES256.
But when I want to use SHA1 with AES256, SHA1 produces only 20B, which is insufficient for the key.
I've searched the internet through and through and I found out, that it's common to use this combination (snmpget, openssl), but I havent found a single word about how are you supposed to prolong the key.
How can I extend the key from 20B to 32B so it works?
P. S.: Yes, I know SHA isn't KDF, yes, I know it's not that common to use this combination, but this is just how it is in my job assignment.
","encryption, aes, snmp, sha",2,73214218,"Here is a page discussing your exact question. In short, there is no standard way to do this (as you have already discovered), however, Cisco has adopted the approach outlined in section 2.1 of this document:

Chaining is described as follows.  First, run the password-to-key algorithm with inputs of the passphrase and engineID as described in the USM document.  This will output as many key bits as the hash algorithm used to implement the password-to-key algorithm.  Secondly, run the password-to-key algorithm again with the previous output (instead of the passphrase) and the same engineID as inputs.  Repeat this process as many times as necessary in order to generate the minimum number of key bits for the chosen privacy protocol.  The outputs of each execution are concatenated into a single string of key bits.
When this process results in more key bits than are necessary, only the most significant bits of the string should be used.
For example, if password-to-key implemented with SHA creates a 40-octet string string for use as key bits, only the first 32 octets will be used for usm3DESEDEPrivProtocol.

"
73805636,Remove words from a String based on a list,"Here's what I need to accomplish. I have a string with several words separated by a comma. Now, I need to remove any word from that string that is part of a list of words in another column.
You can see in the image that the String on Column D. On column E is my expected result, so basically, it removed any words listed in column B.
I've been trying to do that with regex, but I don't know how to tell regex to use a list of words.
Any ideas?

Here's the link for the spreadsheet
",google-sheets,0,73805698,"Use this formula
=ArrayFormula(IF(D2:D=&quot;&quot;,,BYROW(REGEXREPLACE( D2:D, TEXTJOIN(&quot;|&quot;, 1,$B$2:$B), &quot;&quot;), 
                                LAMBDA(v, ArrayFormula(TEXTJOIN( &quot;, &quot;, 1, TRIM(SPLIT(v, &quot;,&quot;))))))))


Resources
Make a copy of this example sheet or create your own from the tables down below.
String
mole, dugong, porcupine
ocelot, parakeet, colt
chimpanzee, cougar, mole, parakeet, ocelot
skunk, snake, mole
squirrel, skunk
raccoon, donkey
parakeet, lemur, dugong, giraffe
squirrel, ocelot
polar bear, cougar, lemur, dugong
parakeet, musk-ox, mountain goat, highland cow
raccoon, polar bear, gnu
raccoon, lemur, porcupine, mountain goat
raccoon, giraffe, ocelot
cougar, snake, donkey, porcupine, gnu, chimpanzee
donkey, parakeet, gnu, squirrel, musk-ox, giraffe
porcupine, giraffe
chimpanzee, porcupine
raccoon, highland cow, ocelot, lemur, squirrel
snake, giraffe, chimpanzee, musk-ox, squirrel
porcupine, colt, ocelot, highland cow, skunk

+---------------+-------------------+
|  Words I want | Words I dont want |
+---------------+-------------------+
| lemur         | cougar            |
+---------------+-------------------+
| colt          | highland cow      |
+---------------+-------------------+
| mountain goat | donkey            |
+---------------+-------------------+
| gnu           | snake             |
+---------------+-------------------+
| chimpanzee    | raccoon           |
+---------------+-------------------+
| squirrel      |                   |
+---------------+-------------------+
| skunk         |                   |
+---------------+-------------------+
| mole          |                   |
+---------------+-------------------+
| polar bear    |                   |
+---------------+-------------------+
| giraffe       |                   |
+---------------+-------------------+
| musk-ox       |                   |
+---------------+-------------------+
| dugong        |                   |
+---------------+-------------------+
| ocelot        |                   |
+---------------+-------------------+
| porcupine     |                   |
+---------------+-------------------+
| parakeet      |                   |
+---------------+-------------------+

"
74132943,spring mockito: when an object containing a list is an argument,"The issue is that the list of ids within the pageRequest object can be in any order. Is there a way to specify that below? The test fails since the pageRequest has a list of ids in a different order than the one specified below. The &quot;when&quot; clause returns null in that case.
PageRequest pageRequest = PageRequest.builder()
                .ids(List.of(serviceId2, serviceId1, serviceId3))
                .build();
 when(client.getServices(eq(pageRequest))).thenAnswer(a -&gt; {.......

","java, spring, mockito, spring-test, springmockito",0,74134292,"You can implement a custom ArgumentMatcher to define the matching logic and then use argThat with this ArgumentMatcher during stubbing :
@Test
public void test(){
        when(someMock.getSerivce(argThat(pageRequestContainId(List.of(1,4,5,6))))).thenReturn(blablabla);
}

private ArgumentMatcher&lt;PageRequest&gt; pageRequestContainId(List&lt;Integer&gt; ids) {
        return pageReq -&gt; pageReq.ids.containsAll(ids) &amp;&amp; pageReq.ids.size() == ids.size();
}


"
74456405,Cinema Seating With Gaps,"Given and Array
**[0,0,0,1,0,0,1,0,0,0]**

of occupied and unoccupied seats, where 1 indicated occupied and 0 indicated unoccupied, we have return the maximum maximum number of people who can be seated  as long  as there is a gap  of **2 seats **between people.
I trid a sliding window approac but it didnt worked
`
// maxim seats question

// [0,0,0,1,0,0,1,0,0,0]

function cinSeating(array) {
  let seats = 0;

  for (let p1 = 0, p2 = 3; p1, p2 &lt;= array.length; p1++, p2++) {
    if (array[p1] !== array[p2]) {
      seats++;
    }
  }
  return seats;
}

console.log(cinSeating([0, 0, 0, 1, 0, 0, 1, 0, 0, 0]));


`
","javascript, data-structures",0,74461936,"Try using dynamic programming to solve this problem.
Basic approach:

Parse through the array one by one recursively
At every point, check if that seat can be filled in or not. At this point, you can take either one of the two options - YES or NO
If YES - increment the total count and call the same function with the next index and incremented count
If YES - call the same function with the next index and existing count
Find out the max between the two calculations and return the answer

Code will look something like this:
function hasAPerson(array, index){
    // Utility function to encapsulate all the checks while checking the next index for possible vacant seat
    if(index &gt;= array.length){
        return false;
    }
    
    else return array[index] === 1;
}

function cinSeating(array, existingNumber, leftIndex, index) {
  let newlyAdded = 0;

  if(index &gt;= array.length){
      return existingNumber;
  }

  if(array[index] === 1){
      return cinSeating(array, existingNumber, index, index + 1);
  }
  
  let excludeCurrentSeat = currentValue = cinSeating(array, existingNumber, leftIndex, index + 1);
  
  let includeCurrentSeat = existingNumber;
  
  //Check if last leftIndex with 1 is beyond index-2
  if(leftIndex &lt; index-2){
      
      let next = index+1;
      let nextToNext = next+1;
      
      //Check if next or next to next index has any 1
      if(!hasAPerson(array, next) &amp;&amp; !hasAPerson(array, nextToNext)){
          includeCurrentSeat = cinSeating(array, existingNumber + 1, index, index+1);
      }
  }
  
  return Math.max(currentValue, includeCurrentSeat);
}

You can call the cinSeating function with the following arguments:

input array

existing number of people (seats already booked) - basically number of 1s in the array

last left index that had 1. When we start we can pass -3 so that left check gets passed

index to process
console.log(cinSeating([0, 0, 0, 1, 0, 0, 1, 0, 0, 0], 2, -3, 0));


This is something that I wrote quickly to illustrate my approach. This code can definitely be optimised. Feel free to play around with it
"
73367075,IndexError: tuple index out of range Mysql,"Hello everyone I'm trying to write a telegram bot that can delete code from a Mysql database. I still can't solve the problem that I have. The code that I need to check is stored in the &quot;item&quot; variable, but when I do the check, it writes to me: if check_code[0][0] == item:
IndexError: tuple index out of range. Please help solve this problem! I just started programming in this cool language!
@dp.message_handler(state=dataBase.user1)
async def user_code(message: types.Message, state: FSMContext):
    item = message.text
    await state.update_data(
        {
            'item': item
        }

    )
    data = await state.get_data()
    item = data.get('item')
    if len(item) == 0:
        return
    cursor.execute(f'DELETE FROM users WHERE code=&quot;{item}&quot;')
    check_code = cursor.fetchall()
    if check_code[0][0] == item:
        await bot.send_message(message.from_user.id,&quot;The user has been successfully deleted!&quot;)
    else:
        await bot.send_message(message.from_user.id, &quot;There is no such user!&quot;)


    await state.finish()

","python, mysql",0,73367270,".fetchall() method will return a list of tuples for the table you are querying. In this case, your query deletes the records so it is possibly returning an empty tuple. You need a SELECT query for fetchall() to return any results. If you want to see if the record was successfully deleted, you can run the following after the delete query:
cursor.execute(f'SELECT * FROM users WHERE code=&quot;{item}&quot;')
check_code = cursor.fetchall()

If this doesn't return anything, then you know that the record was deleted.
"
74237232,Typescript string union of object values as constants,"If I have an array of objects, how can I get a property of each object and create string union of its constant value? For example, below I have the array options. I want to create a type like type Values = 'firstName' | 'lastName' | 'email'.
const options = [
  { label: 'First Name', value: 'firstName' }, 
  { label: 'Last Name', value: 'lastName' },
  { label: 'Email', value: 'email' }
] as const;

// Close, but not quite what I need
const values = options.map(x =&gt; x.value) // (&quot;firstName&quot;|&quot;lastName&quot;|&quot;email&quot;)[]

","typescript, typescript-typings, react-typescript",0,74237359,"You'll be able to retrieve the type by using typeof and indexing into the array type with number:
type Values = (typeof values)[number];

Please note that typeof behaves differently when used in this context. It gets the type of a variable; in this case it's values that has a type of (&quot;firstName&quot; | &quot;lastName&quot; | &quot;email&quot;)[].
Playground
"
74263069,OpenMP tasks execution time varies depending on where I put the pragmas,"I'm trying to parallelize some code using OpenMP (and MPI) using tasks. I have the following code:
double t_copy = 0, t_forward = 0, t_backward = 0, t_diag = 0;
void pc_ssor_poisson3d(int N, void *data,
                       double *restrict Ax,
                       double *restrict x)
{
// clocks for timing
#define COPY_CLOCK 20
#define FW_SSOR_CLOCK 21
#define DIAG_SSOR_CLOCK 22
#define BW_SSOR_CLOCK 23

    pc_ssor_p3d_t *ssor_data = (pc_ssor_p3d_t *)data;
    int n = ssor_data-&gt;n;
    double w = ssor_data-&gt;omega;
    tic(COPY_CLOCK);
#ifdef PAR_PC
    parallel_copy(N, Ax, x);
#else
    memcpy(Ax, x, N * sizeof(double));
#endif
    t_copy += toc(COPY_CLOCK);
    tic(FW_SSOR_CLOCK);
#ifdef PAR_PC

        parallel_ssor_forward_sweep(n, 0, n, 0, n, 0, n, Ax, w); // --1--

#else
...

This is the function parallel_ssor_forward_sweep:
void parallel_ssor_forward_sweep(int n, int i1, int i2, int j1, int j2, int k1, int k2, double *restrict Ax, double w)
{
    char *dep_matrix = (char *)malloc(sizeof(char) * (i2 - i1) / BS * (j2 - j1) / BS * (k2 - k1) / BS);
    // --2--
    for (int k = 0; k &lt; (k2 - k1) / BS; k++)
    {
        for (int j = 0; j &lt; (j2 - j1) / BS; j++)
        {
            for (int i = 0; i &lt; (i2 - i1) / BS; i++)
            {
                // ssor_forward_sweep_pwrap(n, i1 + i * BS, i1 + (i + 1) * BS, j1 + j * BS, j1 + (j + 1) * BS, k1 + k * BS, k1 + (k + 1) * BS, Ax, w, dep_matrix, i, j, k);
                ssor_forward_sweep_pwrap(n, i1, i2, j1, j2, k1, k2, Ax, w, dep_matrix, i, j, k);
            }
        }
    }
    free(dep_matrix);
    
}

The function ssor_forward_sweep_pwrap actually creates the OpenMP task, I'll attach the code:
void ssor_forward_sweep_pwrap(int n, int i1, int i2, int j1, int j2, int k1, int k2, double *restrict Ax, double w, char *dep_matrix, int i, int j, int k)
{
#define dep_mat(i, j, k) (dep_matrix[(k * (j2 - j1) + j) * (i2 - i1) + i])

    char *top_dep = k - 1 &gt;= 0 ? &amp;dep_mat(i, j, k - 1) : NULL;
    char *left_dep = j - 1 &gt;= 0 ? &amp;dep_mat(i, j - 1, k) : NULL;
    char *back_dep = i - 1 &gt;= 0 ? &amp;dep_mat(i - 1, j, k) : NULL;
    char *out_dep = &amp;dep_mat(i, j, k);

#pragma omp task depend(in                                          \
                        : *top_dep, *left_dep, *back_dep) depend(inout \
                                                              : *out_dep)

    {
        ssor_forward_sweep(n, i1 + i * BS, i1 + (i + 1) * BS, j1 + j * BS, j1 + (j + 1) * BS, k1 + k * BS, k1 + (k + 1) * BS, Ax, w);
    }
#undef dep_mat
}

Pragma directive:
#pragma omp parallel
#pragma omp single
    {
    }

Now the problem is that if I put the directive above to make the code parallel around the parallel_ssor_forward_sweep call (marked with the comment --1-- in the code) I get much better times (around 9.6/9.7 seconds for that code section) vs if I put it around the for marked in the code with --2-- comment, so getting the whole function code but the malloc (times 12.7/12.8 seconds).
I've executed the code 3 times for each to make sure it wasn't a fluke and with the same number of threads (6 in this case).
I'm running on my university machine which supposedly should not have any other program running at the same time as mine for the allocated resources.
The reason why I believe this behaviour is strange is that inside the pragma omp single region I expect one single thread to execute the code, so I don't think having the malloc inside or outside the region should lead to such a difference.
Also the code gives the same result and is run with the same input.
","c, openmp, timing",0,74292832,"The problem, as mentioned by @JohnBollinger in the comments, was due to the fact that when I put the pragma as below, the thread that executed the #pragma omp single region could get to the free(dep_matrix) before the other threads had ended.
#ifdef PAR_PC
#pragma omp parallel
#pragma omp single
    {
        parallel_ssor_forward_sweep(n, 0, n, 0, n, 0, n, Ax, w);
    }
#else

By putting pragma inside the parallel_ssor_forward_sweep function like below, the thread executing the #pragma omp single region has to wait for the other threads at the end of the region (i.e. before the free(dep_matrix)), and so the matrix is still available when the other threads need it.
void parallel_ssor_forward_sweep(int n, int i1, int i2, int j1, int j2, int k1, int k2, double *restrict Ax, double w)
{
    char *dep_matrix = (char *)malloc(sizeof(char) * (i2 - i1) / BS * (j2 - j1) / BS * (k2 - k1) / BS);
#pragma omp parallel
#pragma omp single
    {
        for (int k = 0; k &lt; (k2 - k1) / BS; k++)
        {
            for (int j = 0; j &lt; (j2 - j1) / BS; j++)
            {
                for (int i = 0; i &lt; (i2 - i1) / BS; i++)
                {
                    // ssor_forward_sweep_pwrap(n, i1 + i * BS, i1 + (i + 1) * BS, j1 + j * BS, j1 + (j + 1) * BS, k1 + k * BS, k1 + (k + 1) * BS, Ax, w, dep_matrix, i, j, k);
                    ssor_forward_sweep_pwrap(n, i1, i2, j1, j2, k1, k2, Ax, w, dep_matrix, i, j, k);
                }
            }
        }
    }
    free(dep_matrix);
}

"
74214976,How do you sort input in Python?,"beginning coder here. I was trying to sort words and numbers, and it mostly work. However, when I provided input to sort, it doesn't seem to work.
I tried inserting the input as a variable and it broke the numbers down into single digits, which I did not want to do. I tried converting the input into a float and integers and it did not work. I tried
input1 = input() #I input in 23, 12, 45
sorted(input1)

And I got
[' ', ' ', ',', ',', '1', '2', '2', '3', '4', '5']

I was expecting for it to sort by whole numbers without being broken down.
","python, sorting",-2,74215080,"If your input is a String, you can convert it to int and add to a list.
Then you can sort the list:
list =  []
x = input(&quot;write:&quot;)
x = x.replace(&quot; &quot;,&quot;&quot;)
y = x.split(&quot;,&quot;)
for i in y:
    if i.isnumeric():
        i = int(i)
        list.append(i)
list.sort()
print(list)

"
73903529,How to set the state in react with a delay in a for loop,"i want to set a state in react in a loop going from 0 to &quot;last step&quot; but the state has to be set with a delay in other words:
-click a button, after the delay the state is set to 0, again after the delay the state is set to previous state +1, once the state is equal to &quot;last step&quot; end.
i tried this but is not working
const handleReplay = () =&gt; {
   setTimeout(() =&gt; {
     for (let i = 0; i &lt; lastStep; i++) {
       setStepNumber(i)
     }
   }, 500);
  };

","javascript, reactjs",0,73903868,"If the button starts a counter from 0 to lastStep, then you need more than useState:
Solution 1: states and effect
import { useEffect, useState } from &quot;react&quot;;

// global constants:
const INIT_STEP = -1;
const LAST_STEP = 9; // for steps 0...9 (10 steps)
const DELAY = 1000;

export default () =&gt; {
  // not active by default
  const [active, setActive] = useState(false);
  const [step, setStep] = useState(INIT_STEP);

  useEffect(() =&gt; {
    // if we are active, then start the incrementing timer
    if (active) {
      // set the internal step state
      let currentStep = INIT_STEP;

      // create an interval which will increment the step
      const timer = setInterval(() =&gt; {
        if (currentStep &lt; LAST_STEP) {
          currentStep = currentStep + 1;
          setStep(currentStep);
        } else {
          // stop here because we have reached the end of steps
          setActive(false);
        }
      }, DELAY);

      // will be called when active is set to false
      return () =&gt; clearInterval(timer);
    }
  }, [active]);

  // external control
  const handleButtonStart = () =&gt; {
    setStep(INIT_STEP);
    setActive(true);
  };
  const handleButtonStop = () =&gt; setActive(false);

  return (
    &lt;div&gt;
      &lt;h3&gt;Solution 1: states and effect!&lt;/h3&gt;

      &lt;div&gt;
        {active ? (step &gt; INIT_STEP ? `Step ${step}` : &quot;Pending&quot;) : &quot;Stopped&quot;}
      &lt;/div&gt;

      &lt;button onClick={handleButtonStart}&gt;Start&lt;/button&gt;
      &lt;button onClick={handleButtonStop}&gt;Stop&lt;/button&gt;
    &lt;/div&gt;
  );
};

Solution 2: reducer
import { useEffect, useReducer } from &quot;react&quot;;

const INIT_STEP = -1;
const LAST_STEP = 9; // for steps 0...9 (10 steps)
const DELAY = 1000;

const INIT_STATE = {
  step: INIT_STEP,
  active: false
};

const counterReducer = (state, action) =&gt; {
  if (action.type === &quot;start&quot;) {
    return { step: INIT_STEP, active: true };
  } else if (action.type === &quot;stop&quot;) {
    return { ...state, active: false };
  } else if (action.type === &quot;next&quot; &amp;&amp; state.active) {
    if (state.step &lt; LAST_STEP) {
      return { ...state, step: state.step + 1 };
    } else {
      return { ...state, active: false };
    }
  } else {
    return state; // no change
  }
};

export default () =&gt; {
  const [{ step, active }, dispatch] = useReducer(counterReducer, INIT_STATE);

  useEffect(() =&gt; {
    if (active) {
      const timer = setInterval(() =&gt; {
        dispatch({ type: &quot;next&quot; });
      }, DELAY);

      return () =&gt; clearInterval(timer);
    }
  }, [active]);

  const handleButtonStart = () =&gt; dispatch({ type: &quot;start&quot; });
  const handleButtonStop = () =&gt; dispatch({ type: &quot;stop&quot; });

  return (
    &lt;div&gt;
      &lt;h3&gt;Solution 2: reducer!&lt;/h3&gt;
      &lt;div&gt;
        {active ? (step &gt; INIT_STEP ? `Step ${step}` : &quot;Pending&quot;) : &quot;Stopped&quot;}
      &lt;/div&gt;

      &lt;button onClick={handleButtonStart}&gt;Start&lt;/button&gt;
      &lt;button onClick={handleButtonStop}&gt;Stop&lt;/button&gt;
    &lt;/div&gt;
  );
};

The code can be tested here.
"
73131247,Unhandled promise rejection: TypeError: undefined is not an object (evaluating '_asyncStorage.AsyncStorage.getItem'),"I am working on my first react-native app and I am in the process of developing the login page. I am using AsyncStorage to remember a user's token and log them in automatically. But it does not work and I get Unhandled promise rejection: TypeError: undefined is not an object (evaluating '_asyncStorage.AsyncStorage.getItem').
here's my code:
import { StatusBar } from 'expo-status-bar';
import { StyleSheet, Text, View, FlatList, Image, Button,  } from 'react-native';
import { FontAwesomeIcon } from '@fortawesome/react-native-fontawesome';
import { faStar } from '@fortawesome/free-solid-svg-icons'
import React, {useState, useEffect} from 'react'
import { TextInput } from 'react-native-gesture-handler';
import { AsyncStorage } from '@react-native-async-storage/async-storage';

export default function Login(props) { 

  const [ username, setUsername] = useState(&quot;&quot;)
  const [ password, setPassword] = useState(&quot;&quot;)

  useEffect(()=&gt; {
      getData();

  }, [])

  const auth = () =&gt; {
      

     fetch(`http://192.168.5.213:8000/auth/`, {
         method: 'POST',
         headers: {
             &quot;Content-Type&quot;: 'application/json'
            },
         body: JSON.stringify({ username: username, password: password}),
     })
     .then( res =&gt; res.json())
     .then( res =&gt; {
        saveData(res.token)
        props.navigation.navigate(&quot;MovieList&quot;)
        
     })
     .catch( error =&gt; console.log(error))
     

     props.navigation.goBack();

  }

  const saveData = async (token)=&gt; {
      await AsyncStorage.setItem('Token', token)

  }
  const getData = async () =&gt; {
    const token = await AsyncStorage.getItem('Token');
    if(token) props.navigation.navigate(&quot;MovieList&quot;)

}

  return (
    &lt;View style={styles.container}&gt;
        &lt;Text style={styles.label}&gt; Username&lt;/Text&gt;
        &lt;TextInput 
        style={styles.input}
        placeholder=&quot;Username&quot;
        onChangeText={ text =&gt; setUsername(text) }
        value={username}
        /&gt;
        &lt;Text style={styles.label}&gt; Password&lt;/Text&gt;
        &lt;TextInput 
        style={styles.input}
        placeholder=&quot;Password&quot;
        onChangeText={ text =&gt; setPassword(text) }
        value={password}
        secureTextEntry={true}
        autoCapitalize={'none'}
        /&gt;
        &lt;Button onPress= {() =&gt; auth()} title=&quot;Login&quot;/&gt;
    &lt;/View&gt;
  );
  }

Login.navigationOptions = screenProps =&gt; ({
    title: &quot;Login&quot;,
    headerStyle: {
        backgroundColor: 'orange',

    },
    headerTintColor: '#fff',
    headerTitleStyle: {
        fontWeight: 'bold',
        fontSize: 24,
    },
   

})


const styles = StyleSheet.create({
  container: {
    flex: 1, 
    padding: 10,
    backgroundColor: '#282C35',
    
  },
  label: {
    fontSize: 24,
    color: &quot;white&quot;,
    padding: 10,

  },

  input: {
    fontSize: 24,
    backgroundColor: &quot;white&quot;,
    padding: 10,
    margin: 10,
  },

  item: {
    flex: 1,
    padding: 10,
    height: 50,
    backgroundColor: '#282C35'

  },

  itemText: {
    color:'#ffff',
    fontSize: 24,
  },

  starContainer: {
    alignItems: &quot;center&quot;,
    justifyContent: &quot;center&quot;,
    flexDirection: &quot;row&quot;,
  },

  orange: {
      color: 'orange',

  },

  white: {
      color: 'white',
  },

  description: {
    fontSize: 20,
    color: 'white',
    padding: 10,
  },
});

How can I make this work?
","reactjs, react-native, authentication, asyncstorage",0,73131378,"Try the default import
import AsyncStorage from '@react-native-async-storage/async-storage';


https://react-native-async-storage.github.io/async-storage/docs/usage
"
74452093,"SwiftUI extract Childview with Bindings, @State","I have the following component in a view
HStack {
  TextField(&quot;New Note&quot;, text: $newNoteContent)
  .onSubmit(submitNewNote)
  .focused($newNoteIsFocused)
  if (!newNoteContent.isEmpty) {
    Button(action: submitNewNote) {
      Image(systemName: &quot;checkmark&quot;)
    }
  }
}

The variables are defined as follows
@State private var newNoteContent: String = &quot;&quot;
@FocusState private var newNoteIsFocused: Bool

func submitNewNote() {
  Note.add(content: newNoteContent)
  newNoteContent = &quot;&quot;
  newNoteIsFocused = false
}

I would like to extract it and make it either a computed variable returning a view or a  function that returns a view (I dont know which is better). I want to extract it because I reuse a similar struct.
Full code in case its needed: https://github.com/charelF/RemindMeApp/blob/main/RemindMe/NotesView.swift
I have tried the following:
func editCell(
  noteContent: Binding&lt;String&gt;,
  submitFunc: @escaping () -&gt; (),
  focus: FocusState&lt;Bool&gt;.Binding
) -&gt; some View {
  return HStack {
    TextField(&quot;New Note&quot;, text: noteContent)
    .onSubmit(submitFunc)
    .focused(focus)
    if (!noteContent.isEmpty) {
      Button(action: submitFunc) {
        Image(systemName: &quot;checkmark&quot;)
      }
    }
  }
}

But there are some errors and its generally just playing around -- I have no idea what I am really doing here and need some feedback/help.

Update from comment:
So I extracted the view as follows for now
struct ExtractedView: View {
  @State private var editNoteContent: String = &quot;&quot;
  @FocusState private var editNoteIsFocused: Bool
  @State private var editNote: Note? = nil
  
  func editExistingNote(note: Note?) {
    guard let note else { return }
    note.content = editNoteContent
    PersistenceController.shared.save()
    editNoteContent = &quot;&quot;
    editNoteIsFocused = false
    editNote = nil
  }

But I dont understand how to call it. If I call it with ExtractedView() then the code compiles and the app runs, but it crashes when I enter this path of the app. And when I call it like this:
ExtractedView(
  editNoteContent: editNoteContent,
  editNoteIsFocused: editNoteIsFocused,
  editNote: editNote
)

Then i get lots of errors ... 
","ios, swift, swiftui",1,74457561,"Thanks to the comments and this answer here: https://developer.apple.com/forums/thread/682448 I got it to work. I extracted the view as follows:
struct EditNoteView: View {
  
  @Binding var noteContent: String
  @FocusState var isNoteFocused: Bool
  var onsubmit: () -&gt; ()
  var placeholder: String
  
  var body: some View {
    HStack {
      TextField(placeholder, text: $noteContent)
        .onSubmit(onsubmit)
        .focused($isNoteFocused)
      if (!noteContent.isEmpty) {
        Button(action: onsubmit) {
          Image(systemName: &quot;checkmark&quot;)
        }
      }
    }
  }
}

and then I call this child view from my parent view (inside the body) with
EditNoteView(
  noteContent: $newNoteContent,
  isNoteFocused: _newNoteIsFocused,
  onsubmit: submitNewNote,
  placeholder: &quot;New Note&quot;
)

Also in my parent views, I have the following definitions for the variables
@State private var newNoteContent: String = &quot;&quot;
@FocusState private var newNoteIsFocused: Bool
func submitNewNote() {
    Note.add(content: newNoteContent)
    newNoteContent = &quot;&quot;
    newNoteIsFocused = false
  }

The main takeaways is that all of the @State things map to @Binding in the childview, and the @FocusState maps to another @FocusState, but there is a _ required before the parameter in the call.
"
72929659,React child component state is lost after parent component re-renders,"I am using a React hook for parent/child component.
Now I have state in my parent component (companyIcon), which I need to update based on some validation in the child component. I pass validationCallback as a callback function to the child component and update my parent state based on the value I get from the child.
Now the issue is after I update the parent state, the state value in my child component gets reset. What I am doing wrong in the below implementation ?
function ParentComp(props) {
    const [companyIcon, setCompanyIcon] = useState({ name: &quot;icon&quot;, value: '' });

    const validationCallback = useCallback((tabId, hasError) =&gt; {
        if (hasError) {
            setCompanyIcon(prevItem =&gt; ({ ...prevItem, value: 'error'}));
// AFTER ABOVE LINE IS EXECUTED, my Child component state &quot;myAddress&quot; is lost i.e. it seems to reset back to empty value.
        }
    }, []);
    

    const MyChildCmp = (props) =&gt; { 
        const [myAddress, setmyAddress] = useState('');

        useEffect(() =&gt; {
                if (myAddressExceptions.length &gt; 0) {
                    props.validationCallback('MyInfo', true);
                } else {
                    props.validationCallback('MyInfo', false);
                }
            }, [myAddressExceptions])

    
        const handlemyAddressChange = (event) =&gt; {        
            //setmyAddress(event.target.value);
            //setmyAddressExceptions(event.target.value);
            console.log(myAddressExceptions);
        }

        return (
            &lt;&gt;
                &lt;div className=&quot;row&quot; style={{ display: 'flex', flexDirection: 'row', width: '1000px'}}&gt;
                        &lt;div style={{ width: '20%'}}&gt;
                            &lt;FormField 
                                label='Company Address' 
                                required
                                helperText={mergedErrorMessages(myAddressExceptions)}
                                validationState={
                                    myAddressExceptions[0] ? myAddressExceptions[0].type : ''
                                }
                            &gt;
                                &lt;Input id='myAddress'
                                    value={myAddress}
                                    //onChange={handlemyAddressChange}
                                    onChange={({ target: { value } }) =&gt; {
                                        validateInputValue(value);
                                    }}
                                    onBlur={handleBlur}
                                    inputProps={{maxLength: 9}} /&gt;
                            &lt;/FormField&gt;
                        &lt;/div&gt;
                &lt;/div&gt;
            &lt;/&gt;
        ); 
    }

    return (
        &lt;div className=&quot;mainBlock&quot;&gt;
            Parent : {companyIcon}
            {displayMyChild &amp;&amp; &lt;MyChildCmp validationCallback={validationCallback}/&gt;}
        &lt;/div&gt;
    )
}

export default withRouter(ParentComp);

","javascript, reactjs, react-hooks, use-effect, use-state",5,72931861,"Here are some reasons why you can lose state in child (there could be more, but these apply to you most):
    {displayMyChild &amp;&amp; &lt;MyChildCmp validationCallback={validationCallback}/&gt;}

Here if at one point displayMyChild is truthy, then made falsy, this means the component MyChildCmp will get unmounted, hence all its state will be gone.
But now, even if you didn't have that condition and rendered the MyChildCmp always you would still run into similar problem, this is because you defined MyChildCmp inside another component. When you do that, on each render of the parent component, the function MyChildCmp is recreated, and the reconciliation algorithm of react thinks you rendered a different component type on next render, so it will destroy the component instance. Move definition of that component outside the parent component.
"
73101069,Testing custom exceptions in Kotlin with JUnit,"I have the following class
data class CarDefects(
    private val _carModel: CarModel,
    private val _affectedYearsOfIssue: List&lt;Year&gt;,
    private val _defectCode: String
) {

    init {
        validateDefectCode(_defectCode)

    }
}

Validating function
fun validateDefectCode(defectCode: String) {
    val pattern = Pattern.compile(&quot;^[a-zA-Z0-9-]*\$&quot;)
    val m = pattern.matcher(defectCode)
    if (defectCode.length !in 4..4) {
        throw InvalidDefectCodeException(defectCode, &quot;Defect code must be 4 characters long&quot;)
    }
    if (!m.matches()) {
        throw InvalidDefectCodeException(defectCode, &quot;Defect code can only contain alphanumeric characters&quot;)
    }
}

And the exception class:
class InvalidDefectCodeException(_defectCode:String, message:String):
    IllegalArgumentException(&quot;Invalid defect code $_defectCode. $message&quot;) {
}

I'm trying to test the validating function with JUnit
import car.exceptions.InvalidDefectCodeException
import car.validators.carDefectsValidators.validateDefectCode
import org.junit.jupiter.api.Assertions
import org.junit.jupiter.api.Test
import java.time.Year
import kotlin.test.assertFailsWith

internal class CarDefectsTest {

    val carModel = CarModel(Brand.BMW, &quot;X5&quot;, 199219)
    val carModel2 = CarModel(Brand.AUDI, &quot;X434&quot;, 199219)


    val defect = CarDefects(carModel, listOf(Year.of(2020), Year.of(2021)), &quot;SE2@&quot;)
    val defect2 = CarDefects(carModel2, listOf(Year.of(2020), Year.of(2021)), &quot;122F4&quot;)

    @Test
    fun testDefectCodeExceptions() {

        val exception = Assertions.assertThrows(InvalidDefectCodeException::class.java) {
            validateDefectCode(defect.getDefectCode())
        }
    }

    @Test
    fun testDefectCodeExceptions2() {

        assertFailsWith&lt;InvalidDefectCodeException&gt; {
            validateDefectCode(defect2.getDefectCode())
        }
    }
}

Both tests fail, however expected exceptions are still thrown, from what i understand shouldn't both tests pass?
I've already seen the following post: Test expected exceptions in Kotlin
",kotlin,1,73102274,"Inside class CarDefects, you're having this init block:
init {
    validateDefectCode(_defectCode)
}

Hence, the exception will be thrown during construction.
Let's test the constructor instead with a stripped down CarDefects class. The following tests are passing on my computer.
import car.exceptions.InvalidDefectCodeException
import org.junit.jupiter.api.Assertions
import org.junit.jupiter.api.Test
import kotlin.test.assertFailsWith

data class CarDefects(
    private val defectCode: String
) {
    init {
        validateDefectCode(defectCode)
    }
}

internal class CarDefectsTest {

    @Test
    fun testDefectCodeExceptions() {
        Assertions.assertThrows(InvalidDefectCodeException::class.java) {
            CarDefects(defectCode = &quot;SE2@&quot;)
        }
    }


    @Test
    fun testDefectCodeExceptions2() {
        assertFailsWith&lt;InvalidDefectCodeException&gt; {
            CarDefects(defectCode = &quot;122F4&quot;)
        }
    }
}

"
73977102,Java Operator Precedence and Ternary Operator,"The code
return &quot;Unexpected Error: &quot; + (e.getMessage() == null ? &quot;No further details!&quot; : e.getMessage());

produces my expected result. For example, for an e IndexOutOfBoundsException, I get
Unexpected Error: Index 0 out of bounds for length 0

However when I remove the extra parentheses surrounding the ternary expression like
return &quot;Unexpected Error: &quot; + e.getMessage() == null ? &quot;No further details!&quot; : e.getMessage();

I get
Index 0 out of bounds for length 0

I am unable to understand the order of evaluation.
Java Version 1.8.0_341-b10 (64 bit)
","java, conditional-operator, operator-precedence",0,73977465,"The operator, + has higher precedence than the operator, ==
Therefore
return &quot;Unexpected Error: &quot; + e.getMessage() == null ? &quot;No further details!&quot; : e.getMessage()

is evaluated as follows:
if (&quot;Unexpected Error: &quot; + e.getMessage() == null)
    return &quot;No further details!&quot;;
else
    return e.getMessage();

whereas
return &quot;Unexpected Error: &quot; + (e.getMessage() == null ? &quot;No further details!&quot; : e.getMessage());

is evaluated as
if (e.getMessage() == null)
    return &quot;Unexpected Error: &quot; + &quot;No further details!&quot;;
else
    return &quot;Unexpected Error: &quot; + e.getMessage();

I hope it clears your doubt.
"
73316485,Rust: Idomatic way to iterate over columns of a 2d vector,"I am new to Rust and wanted to know whats the idomatic way to iterate over columns on a 2d vector.
I know how to do it for a rows, for example finding maximum for each row as below
let my_2d_vector: Vec&lt;Vec&lt;u64&gt;&gt; = vec![];
let max_in_each_rows = my_2d_vector.iter()
   .map(|&amp;row| row.iter().max())
   .collect::&lt;Vec&lt;64&gt;&gt;();

How do I find maximum for each column without using loops?
","multidimensional-array, vector, rust, functional-programming, iterator",4,73316927,"One way to approach this functionally would be something like this:
let my_2d_vector: Vec&lt;Vec&lt;u64&gt;&gt; = vec![vec![1, 4, 3], vec![3, 3, 3]];
let max_in_each_col =
    my_2d_vector
        .iter()
        .skip(1)
        .fold(my_2d_vector[0].clone(), |mut maxes, row| {
            maxes
                .iter_mut()
                .zip(row.iter())
                .for_each(|(m, col)| *m = std::cmp::max(*m, *col));
            maxes
        });

println!(&quot;{:?}&quot;, max_in_each_col); // [3, 4, 3]

However, it's a misconception that loops aren't idiomatic Rust. You may find that the above isn't all that readable, and rustfmt formats it into 11 lines. Whereas using loops, although the logic is exactly the same, you get this
let my_2d_vector: Vec&lt;Vec&lt;u64&gt;&gt; = vec![vec![1, 4, 3], vec![3, 3, 3]];
let mut max_in_each_col = my_2d_vector[0].clone();
for row in &amp;my_2d_vector[1..] {
    for (m, col) in max_in_each_col.iter_mut().zip(row.iter()) {
        *m = std::cmp::max(*m, *col);
    }
}

println!(&quot;{:?}&quot;, max_in_each_col); // [3, 4, 3]

in only 6 lines and very readably.
"
72940123,How to use port 443 for both IIS and Tomcat on same server for two different applications,"We are having an application server , we need to host .Net Web api with secure HTTPS link on port 443 using IIS , also a front application (using JAVA) in Tomcat with secured HTTPS link on same 443 port.
We deployed Java front end in tomcat with 443 port but now when tried to start a site in IIS on same port 443 it is not starting since port already in use.
So what steps can be taken so that we will have two different application hosted in IIS and Tomcat with using same 443 port.
",".net, tomcat, iis, hosting",1,72949362,"You can configure a reverse proxy for IIS, use port 443 as the traffic forwarding port, and set the two different applications to other ports. Because IIS is used as a reverse proxy server, you can use port 443 to forward to by creating a rewrite rule. on two other different application ports.
you can look at this: Proxy IIS Server to Tomcat Application
"
73693052,How to find elements and count in JSON array using groovy,"[
{
&quot;Organization&quot;: &quot;Global&quot;,
&quot;Roles&quot;: [
  {
    &quot;Role_Name&quot;: &quot;Talent Partner&quot;
  },
  
  {
    &quot;Role_Name&quot;: &quot;Partner&quot;
  }
  ]
 },
 {
&quot;Organization&quot;: &quot;Mfg&quot;,
&quot;Roles&quot;: [
  {
    &quot;Role_Name&quot;: &quot;Talent Partner&quot;
  }
 ]
 }
]

OUTPUT:
   [
   {
  &quot;Organization&quot;: &quot;Global&quot;,
  &quot;Talent Partner&quot;: &quot;1&quot;, 
  &quot;Partner&quot;: &quot;1&quot;
  },
  {
  &quot;Organization&quot;: &quot;Mfg&quot;,
  &quot;Talent Partner&quot;: &quot;1&quot;
   }
   ]

Groovy:
def slurper = new JsonSlurper();
def jsonDoc = slurper.parseText(doc);
List&lt;String&gt; EntryList = new ArrayList&lt;String&gt;();
def NoOfTP = 0;
def Roles =jsonDoc.Roles;
def NumberOfElements = Roles.size();
for( int p = 0; p &lt; NumberOfElements; p++ ) {
if (Roles.Role_Name[p].trim()).toUpperCase() == 'Talent Partner').toUpperCase() )
{
NoOfTP = NoOfTP + 1;}
EntryList.add(Roles.Role_Name[p]);}
props.setProperty(&quot;document.dynamic.userdefined.NoOfTP&quot;, NoOfTP.toString());}
is = new ByteArrayInputStream(JsonOutput.toJson(jsonDoc).getBytes());
dataContext.storeStream(is, props);}

How to count the occourence of the role_name within roles
",groovy,1,73693463,"Something like:
import groovy.json.*

def txt = '[ { &quot;Organization&quot;: &quot;Global&quot;, &quot;Roles&quot;: [   {     &quot;Role_Name&quot;: &quot;Talent Partner&quot;   },      {     &quot;Role_Name&quot;: &quot;Partner&quot;   }   ]  },  { &quot;Organization&quot;: &quot;Mfg&quot;, &quot;Roles&quot;: [   {     &quot;Role_Name&quot;: &quot;Talent Partner&quot;   }  ]  } ]'

def json = new JsonSlurper().parseText txt

def res = json.collect{ curr -&gt;
  def elem = [ Organization:curr.Organization ].withDefault{ 0 }
  curr.Roles*.each{ elem[ it.value ]++ }
  elem
}

assert res.toString() == '[[Organization:Global, Talent Partner:1, Partner:1], [Organization:Mfg, Talent Partner:1]]'

"
74475086,Conditional aggregation into a mean value,"I have the following situation:
  ID           VAR       HSP     VAR2      CODE
00001           56        B       345       1       
00001           52        B       306       1       
00002           5         C       32        2       
00002           22        A       31        2       
00003           55        D       23        1       
00003           5         E       87        1       

What I need to do is to: for replicated IDs perform the mean of VAR and VAR2 (i.e. all the numeric variables. I have many other numeric columns). The mean should not be done for the column code. Moreover since I have different types of HSP for the final data frame I need to keep the first as it appears in the sorting. The same for the column code.
Desired output:
  ID           VAR       HSP     VAR2      CODE
00001           54        B       325.5     1       
00002           13.5      C       31.5      2       
00003           30        D       55        1       

Edit: the case with 0s:
  ID           VAR       HSP     VAR2      CODE
00001           56        B       345       1       
00001           0         B       306       1       
00002           5         C       32        2       
00002           22        A       0         2       
00003           55        D       23        1       
00003           5         E       87        1       

Desired output:
  ID           VAR       HSP     VAR2      CODE
00001           56        B       325.5     1       
00002           13.5      C       32        2       
00003           30        D       55        1       

So if there are 0s the mean should not be done.
",r,0,74475158,"For this specific case, you can summarise the IDs like this.
library(dplyr)

df %&gt;%
  group_by(ID) %&gt;%
  summarise(VAR = mean(VAR), HSP = first(HSP), VAR2 = mean(VAR2), CODE = first(CODE))

For a more generalized solution, here's how you get the mean for all numerical columns and the first value for all non-numerical values.
library(dplyr)

df %&gt;% 
  group_by(ID) %&gt;% 
  summarise(across(where(~ is.numeric(.x)), mean),
            across(where(~ !is.numeric(.x)), first))

"
73674092,How to relation with two table when column value is a array in Laravel,"I need all reports with all officers included in the participants column.
please check the attached image.
https://prnt.sc/CRoELD48J-L5
","laravel, eloquent-relationship",-1,73674266,"You should really have a participant pivot table with report_id and officer_id, and create proper relationships.
What you're asking for is possible through loops and lazy loading, but it will be extremely slow and unoptimized.
"
74571672,VS Code not tracking file changes and says install git,"extension: GitHub Pull Requests and Issues
Don't know why its behaving like this, git is installed... still its saying install git
showing:
Activating the Pull Requests and Issues extension failed. Please make sure you have git installed.
","macos, visual-studio-code",-1,74571673,"Go to setting and search git path
edit the setting.json in there, the last parameter git.path

find the git path with this command in terminal
which git
then reload the VS Code
"
73613668,What are transforming approaches that collect array items from a nested data-structure into a single flat array?,"Given is a nested data-structure which I want to get transformed into a single flat array of non nested array-items.
The data and the code I came up with so far are as follows ...


const data = [{
  heading: [{
    name: ""Heading 01"",
    Items: [{
      name: ""Item 01"",
      layers: [{
        name: ""layer01"",
        id: 4,
        parent: 3,
        droppable: false,
      }, {
        name: ""layer02"",
        id: 5,
        parent: 3,
        droppable: false,
      }],
      id: 3,
      parent: 2,
      droppable: true,
    }],
    id: 2,
    parent: 1,
    droppable: true,
  }],
  id: 1,
  parent: 0,
  droppable: true,
}];

const flatArray = [];
const flatObject = {};
  
for (let index = 0; index &lt; data.length; index++) {
  for (const prop in data[index]) {

    const value = data[index][prop];

    if (Array.isArray(value)) {
      for (let i = 0; i &lt; value.length; i++) {
        for (const inProp in value[i]) {
          flatObject[inProp] = value[i][inProp];
        }
      }
    } else {
      flatObject[prop] = value;
    }
  }
  flatArray.push(flatObject);
}

console.log(flatArray)
.as-console-wrapper { min-height: 100%!important; top: 0; }



... and the result is expected to be equal to the next provided data structure ...
[{
  id: 1,
  parent: 0,
  droppable: true,
}, {
  name: &quot;Heading 01&quot;,
  id: 2,
  parent: 1,
  droppable: true,
}, {
  name: &quot;Item 01&quot;,
  id: 3,
  parent: 2,
  droppable: true,
}, {
  name: &quot;layer01&quot;,
  id: 4,
  parent: 3,
  droppable: false,
}, {
  name: &quot;layer02&quot;,
  id: 5,
  parent: 3,
  droppable: false,
}]

","javascript, arrays, recursion, data-structures, flatten",0,73618942,"One could come up with a recursive approach which targets specific array items by any wanted array's key/identifier which are all going to be used by a destructuring assignment with default values and rest property.
The advantage of the destructuring is the separation and the direct access of all relevant data, the possible to be targeted array(s) and the rest of the currently processed data item.


function collectSpecificArrayItemsRecursively(data) {
  const result = [];

  if (Array.isArray(data)) {

    result
      .push(
        ...data
          .flatMap(collectSpecificArrayItemsRecursively)
      );
  } else {

    const {
      // destructuring into specific
      // arrays and the data's rest.
      heading = [], Items = [], layers = [], ...rest
    } = data;

    result
      .push(
        rest,
        ...heading
          .concat(Items)
          .concat(layers)
          .flatMap(collectSpecificArrayItemsRecursively),
      );    
  }
  return result;
}
const data = [{
  heading: [{
    name: ""Heading 01"",
    Items: [{
      name: ""Item 01"",
      layers: [{
        name: ""layer01"",
        id: 4,
        parent: 3,
        droppable: false,
      }, {
        name: ""layer02"",
        id: 5,
        parent: 3,
        droppable: false,
      }],
      id: 3,
      parent: 2,
      droppable: true,
    }],
    id: 2,
    parent: 1,
    droppable: true,
  }],
  id: 1,
  parent: 0,
  droppable: true,
}];

console.log(
  collectSpecificArrayItemsRecursively(data)
);
.as-console-wrapper { min-height: 100%!important; top: 0; }



"
73001297,Use multiple values from the page in an assertion,"I have a fairly complex test involving quite a few elements on the page, need to save the values and use them later in an assertion.
Currently I am using aliases to save the values, as per the docs recommendation. Is there a way to avoid deeply nesting like this?
For example,
cy.get(selector1).invoke('val').as('alias1')
cy.get(selector2).invoke('val').as('alias2')
cy.get(selector3).invoke('text').as('alias3')
cy.get(selector4).invoke('text').as('alias4')
cy.get(selector5).invoke('text').as('alias5')
// etc

cy.get('@alias1').then((val1) =&gt; {
  cy.get('@alias1').then((val2) =&gt; {
    cy.get('@alias1').then((val3) =&gt; {
      cy.get('@alias1').then((val4) =&gt; {
        cy.get('@alias1').then((val5)=&gt; {
          // assert values against fixture
          expect([val1, val2, val3, val4, val5]).to.deep.eq(myFixture)

",cypress,3,73001309,"When you set an alias, a property of the same name is also added to the test context.
You can use the function syntax to access &quot;this&quot; context, and read the values in a single callback at the end of the test.
cy.get(selector1).invoke('val').as('val1')
cy.get(selector2).invoke('val').as('val2')
cy.get(selector3).invoke('text').as('val3')
cy.get(selector4).invoke('text').as('val4')
cy.get(selector5).invoke('text').as('val5')

cy.then(function() {
  const actual = [this.val1, this.val2, this.val3, this.val4, this.val5]
  expect(actual).to.deep.eq(myFixture)
})

"
72970327,Unity - UnityEvent<object> as parameter but pass in UnityEvent<CustomClass> not working,"Not sure if this is possible, I can get this to work if I used the explicit type but if I do it that way it will require me to define every possible type, which could be a lot.
BACKGROUND:
I'm trying to add my custom generated list of unity event actions to a target unity event. This is meant to be a generic helper function that I can use in many of my automated editor scripts.
WHAT IM DOING:
I have a function that looks like the following:
public static void SetUnityEvents(UnityEvent&lt;object&gt; targetEvent, List&lt;UnityEventEntry&gt; entries, bool removeAllListeners = false)
{
  ...
}

Then I'm trying to use it like:
UnityEventsUtil.SetUnityEvents(target.GetComponent&lt;vLadderAction&gt;().OnDoAction, newEntry, true);

Where newEntry is a custom List&lt;UnityEventEntry&gt; object that contains all the unity events that I want to add to the target.GetComponent&lt;vLadderAction&gt;().OnDoAction UnityEvent.
However, when I pass target.GetComponent&lt;vLadderAction&gt;().OnDoAction UnityEvent to the function I throws the following error:
Argument 1: cannot convert from 'Invector.vCharacterController.vActions.vOnActionHandle' to 'UnityEngine.Events.UnityEvent&lt;object&gt;'

Like I said before I could change my above function to be:
public static void SetUnityEvents(UnityEvent&lt;vOnActionHandle&gt; targetEvent, List&lt;UnityEventEntry&gt; entries, bool removeAllListeners = false)

and it would work. However, it's no longer generic and I would need to pass in every type.
Is this possible to make something like this generic? If so how would I do that conversion?
","c#, unity3d, generics",1,72970823,"I was able to get it to work by not using UnityEvent&lt;object&gt; but instead taking advantage of the concept of generics. Helpful youtube video talking about it here: https://www.youtube.com/watch?v=LnjuFeHLQ2Y
So I converted my above function to be a generic:
public static void SetUnityEvents&lt;T&gt;(T unityEvent, List&lt;UnityEventEntry&gt; entries, bool removeAllListeners = false) where T : UnityEventBase
{
  ...
}

That requires that a UnityEvent gets passed to unityEvent and doesn't just take anything because all UnityEvents derive from UnityEventBase base. So this allows me to keep the original type and pass ANY type of unity event into this function. Even UnityEvents that take any number of parameters, including custom classes. Pretty awesome!
"
73332258,If case only checks one of the things,"This code accepts either one, what i need is for both of them to be checked and return. Where am i making the mistake?
 if(!email.endsWith(&quot;.com&quot;) &amp;&amp; !email.contains(&quot;@&quot;)) {
                Toast.makeText(view.context,
                      &quot;Please enter a correct email&quot;, Toast.LENGTH_SHORT).show();

","android, kotlin",1,73332320,"Just change the AND to a OR.
if(!email.endsWith(&quot;.com&quot;) || !email.contains(&quot;@&quot;)) {
                Toast.makeText(view.context,
                      &quot;Please enter a correct email&quot;, Toast.LENGTH_SHORT).show();

"
73907799,Do we need separate DB Index for a SQL query containing multiple OR conditions,"For example I have a query:-
Select *
from table
where (column1 = 'A' and Column2 = 'B' and Column3 = 'C')
   OR (Column1= 'z' and Column4 = 'X');

If I have to create a DB index for this query,
Do we need separate DB index for the first half and second half of the OR condition of the query ?
or
A single DB index would be enough containing all columns present in the query?
","sql, sql-server",0,73908311,"TL;DR
Create 2 INDEXes, one on Columns1-3 and the other on Columns1 &amp; 4, INCLUDE all the other columns in the table on both INDEXes, and then use a UNION ALL query instead.
Demonstration
As I mention in the comment, if you wanted to do this in a single query, without a UNION (unlike in Tim Biegeleisen's answer) then more likely you would want an INDEX on Column1, and then INCLUDE all the other columns in your table (all, because you use SELECT * and so return all the columns, even those in referenced in the WHERE).
I do think that Tim's solution would likely be better though, especially with a much larger data set, however, that too should have some INCLUDEs in it. Without those then either a scan will be performed (which isn't helpful here) or a potentially expensive key lookup.
Here's a little demonstration with a sample table and images of the query plans.
Sample data:
CREATE TABLE dbo.YourTable (Column1 char(1),
                            Column2 char(1),
                            Column3 char(1),
                            Column4 char(1),
                            Column5 int);
GO

INSERT INTO dbo.YourTable
VALUES('A','B','C','D',7),
      ('A','B','C','F',9),
      ('A','B','D','Z',1),
      ('D','B','C','X',9),
      ('Z','B','C','X',7),
      ('Z','D','C','X',4),
      ('Z','B','C','Y',9);
GO

Create Tim's indexes and test:
CREATE INDEX idx1_tim ON dbo.yourTable (Column1, Column2, Column3);
CREATE INDEX idx2_tim ON dbo.yourTable (Column1, Column4);
GO

SELECT *
FROM dbo.yourTable
WHERE Column1 = 'A'
  AND Column2 = 'B'
  AND Column3 = 'C'
UNION ALL
SELECT *
FROM dbo.yourTable
WHERE Column1 = 'z'
  AND Column4 = 'X';
GO


Notice this have 2 table scans, as there are no INCLUDEs (this is not Column5's fault, and I demonstrate this later)
Single SELECT with an INDEX on Column1, but Column5 excluded from INCLUDE:
CREATE INDEX idx_larnu ON dbo.YourTable (Column1) INCLUDE(Column2, Column3, Column4);
GO
SELECT *
FROM dbo.YourTable
WHERE (Column1 = 'A' AND Column2 = 'B' AND Column3 = 'C')
   OR (Column1= 'z' AND Column4 = 'X');
GO


Note this too has a table scan, due to the ommission of Column5. If we add that to the INCLUDE:
CREATE INDEX idx_larnu_fullinc ON dbo.YourTable (Column1) INCLUDE(Column2, Column3, Column4,Column5);
GO

SELECT *
FROM dbo.YourTable
WHERE (Column1 = 'A' AND Column2 = 'B' AND Column3 = 'C')
   OR (Column1= 'z' AND Column4 = 'X');
GO


This unfortunately still results in a scan, but of the index this time not the table. For a larger table or for different values of Column1, SQL Server may make a different decision.
Now let's just add an INCLUDE to Tim's indexes:
--Drop mine so that they definitely aren't used
DROP INDEX idx_larnu_fullinc ON dbo.YourTable; 
DROP INDEX idx_larnu ON dbo.YourTable;
CREATE INDEX idx1_tim_inc ON dbo.yourTable (Column1, Column2, Column3) INCLUDE (Column4,Column5);
CREATE INDEX idx2_tim_inc ON dbo.yourTable (Column1, Column4) INCLUDE (Column2, Column3,Column5);
GO

SELECT *
FROM dbo.yourTable
WHERE Column1 = 'A'
  AND Column2 = 'B'
  AND Column3 = 'C'
UNION ALL
SELECT *
FROM dbo.yourTable
WHERE Column1 = 'z'
  AND Column4 = 'X';
GO


Hazaar! This is what we want. Also, just to confirm however that Column5 wasn't causing the scans earlier, let's drop those INDEXes and also Column5:
DROP INDEX idx1_tim_inc ON dbo.YourTable;
DROP INDEX idx2_tim_inc ON dbo.YourTable;
ALTER TABLE dbo.YourTable DROP COLUMN Column5;
GO
SELECT *
FROM dbo.yourTable
WHERE Column1 = 'A'
  AND Column2 = 'B'
  AND Column3 = 'C'
UNION ALL
SELECT *
FROM dbo.yourTable
WHERE Column1 = 'z'
  AND Column4 = 'X';
GO


So, there you can see that Column5 wasn't the cause the scans
--Clean up
DROP TABLE dbo.YourTable;

"
73503049,"Ext4 ""unused inodes"" ""free inodes"" diffrence?","When I use the dumpe2fs command to look at the Block Group of the ext4 filesystem, I see &quot;free inodes&quot; and &quot;unused inodes&quot;.
I want to know the difference between them ?
Why do they have different values in Group 0 ?
Group 0: (Blocks 0-32767) [ITABLE_ZEROED]
  Checksum 0xd1a1, unused inodes 0
  Primary superblock at 0, Group descriptors at 1-3
  Reserved GDT blocks at 4-350
  Block bitmap at 351 (+351), Inode bitmap at 367 (+367)
  Inode table at 383-892 (+383)
  12 free blocks, 1 free inodes, 1088 directories
  Free blocks: 9564, 12379-12380, 12401-12408, 12411
  Free inodes: 168
Group 1: (Blocks 32768-65535) [ITABLE_ZEROED]
  Checksum 0x0432, unused inodes 0
  Backup superblock at 32768, Group descriptors at 32769-32771
  Reserved GDT blocks at 32772-33118
  Block bitmap at 352 (+4294934880), Inode bitmap at 368 (+4294934896)
  Inode table at 893-1402 (+4294935421)
  30 free blocks, 0 free inodes, 420 directories
  Free blocks: 37379-37384, 37386-37397, 42822-42823, 42856-42859, 42954-42955, 44946-44947, 45014-45015
  Free inodes:

","linux, filesystems, inode, ext4, group",0,73516111,"The &quot;unused inodes&quot; reported are inodes at the end of the inode table for each group that have never been used in the lifetime of the filesystem, so e2fsck does not need to scan them during repair. This can speed up e2fsck pass-1 scanning significantly.
The &quot;free inodes&quot; are the current unallocated inodes in the group. This number includes the &quot;unused inodes&quot; number, so that they will still be used if there are many (typically very small) inodes allocated in a single group.
From:
https://unix.stackexchange.com/a/715165/536354
"
73076798,How to compare two ints in expect shell?,"I want subtract a number in expect shell until it equals 0, then close this shell, such as :
#!/usr/bin/expect
set round [lindex $argv 0];
incr round -1
if round &lt;= 0 close  // ??how to write this sentence?

","shell, expect",0,73078469,"Your last line would be:
if {$round &lt;= 0} exit

BUT I think you actually want to decrement the counter repeatedly, for which you would need a loop:
while {$round &gt; 0} {
    incr round -1
}

"
73067624,"Function ""IDENTITY"" not found when inserting audited revision using Hibernate Envers (5.6.10) with Spring Boot 2.7 (H2 2.1.214, Hibernate-core 5.6.9)","When inserting an audited revision I get the following error:
Hibernate: insert into audited_revision (id, timestamp) values (default, ?)
2022-07-21 15:46:09.496 TRACE 67111 --- [  XNIO-1 task-1] o.h.type.descriptor.sql.BasicBinder      : binding parameter [1] as [TIMESTAMP] - [Thu Jul 21 15:46:09 CEST 2022]
Hibernate: call identity()
2022-07-21 15:46:09.504  WARN 67111 --- [  XNIO-1 task-1] o.h.engine.jdbc.spi.SqlExceptionHelper   : SQL Error: 90022, SQLState: 90022
2022-07-21 15:46:09.504 ERROR 67111 --- [  XNIO-1 task-1] o.h.engine.jdbc.spi.SqlExceptionHelper   : Function &quot;IDENTITY&quot; not found; SQL statement:
call identity() [90022-214]
2022-07-21 15:46:09.518 ERROR 67111 --- [  XNIO-1 task-1] o.z.problem.spring.common.AdviceTraits   : Internal Server Error

org.springframework.dao.InvalidDataAccessResourceUsageException: could not prepare statement; SQL [call identity()]; nested exception is org.hibernate.exception.SQLGrammarException: could not prepare statement

According to this issue on the Hibernate Jira it is supposed to be fixed in Hibernate core 5.6.5. https://hibernate.atlassian.net/browse/HHH-14985
I'm currently using Hibernate core 5.6.9 provided by Spring Boot 2.7.2 and I still get the above issue. The column is correctly created according to this piece of logging:
Hibernate: create table audited_revision (id bigint generated by default as identity, timestamp timestamp, primary key (id))

My relevant piece of application.yaml config:
spring:
  jpa:
    defer-datasource-initialization: true
    database: H2
    hibernate:
      ddl-auto: create-drop
    open-in-view: false
    properties:
      format_sql: true
      org:
        hibernate:
          envers:
            store_data_at_delete: true
      hibernate:
        temp:
          use_jdbc_metadata_defaults: false
        dialect: org.hibernate.dialect.H2Dialect
    show-sql: true

Is this a bug in Hibernate or am I doing something wrong?
","spring-boot, hibernate, spring-data-jpa, h2, hibernate-envers",2,74371311,"This issue is fixed in Hibernate core 5.6.13
https://hibernate.atlassian.net/browse/HHH-15561
"
73493717,"If my ITVF's only argument is used solely as part of a WHERE clause, is there any way to skip that clause?","I recently wrote a view for my users
CREATE VIEW FOO AS SELECT * FROM EMPLOYEES

They used this view to populate an Excel sheet and they were very happy. They later decided that they wanted one Excel sheet per employee grade, but also wanted to keep the original view. This was no big deal and the following code let my users do just what they wanted
CREATE FUNCTION FOO_WITH_GRADES {@GRADE NVARCHAR(30)} AS
SELECT * FROM EMPLOYEES WHERE GRADE = @GRADE

however, for data that didn't filter by grade, they still needed the original view. I don't like that. Is there any argument that can be passed to FOO_WITH_GRADES, or any change that I can make to that function, such that my users can get the results of FOO by calling FOO_WITH_GRADES?
","sql, sql-server, function, tsql, inline-table-function",0,73493741,"You can check for @GRADE to be NULL.
CREATE FUNCTION FOO_WITH_GRADES (@GRADE NVARCHAR(30))
RETURNS TABLE
AS RETURN
    SELECT *
    FROM EMPLOYEES
    WHERE GRADE = @GRADE OR @GRADE IS NULL;

"
73581456,Error Type mismatch error in Akka scaladsl in Akka-Http code,"Im new to Akka framework and i get the below error message when im trying to run my code.
The method which is called through the api code returns a
Future[List[HashMap[String,Object]]]
The api code(akka-http route) which calls this method:
@GET
  @Path(&quot;getList/{name}&quot;)
  @Authorization(&quot;basicAuth&quot;)
  @Operation(summary = &quot;Get list&quot;, description = &quot;Returns a list&quot;,
    parameters = Array(new Parameter(name = &quot;name&quot;, in = ParameterIn.PATH, description = &quot;name&quot;, required=true)),
    security = Array(new SecurityRequirement(name=&quot;basicAuth&quot;)),
  )
    def getList: Route = {
      path(&quot;getList&quot; / Segment) { name =&gt;
        get {
          complete(getListService(name))
        }
      }
    }


I get the below error message
type mismatch;
 found   : scala.concurrent.Future[List[scala.collection.immutable.HashMap[String,Object]]]
 required: akka.http.scaladsl.marshalling.ToResponseMarshallable
          complete(getList(param))

returning a future should not be giving this error, i'm a bit confused as im not able to pinpoint where the mistake is.
Any suggestions would greatly help.Kindly let me know if any more info is required.
","scala, akka, future, akka-http",0,73670196,"It requires an entity that it can serialize to JSON. HashMap[String, Object] isn't something that Akka is able to serialize out of the box. You have to either change the return type to something other than Object or define a custom marshaller. I doubt that you need an Object serializer, you probably want to have some class here instead. Here you have examples of serialization using spray: https://doc.akka.io/docs/akka-http/current/common/json-support.html
"
73111730,Does the R2DBC connection pool reuse DB connections?,"I am building a spring application using R2DBC and MySQL. Running an application by deploying it on a server, I noticed a few surprising things.

MySQL connection id grows very fast. my database server already exceeded 1 million connection IDs in 10 days.
As a result of checking with the SHOW PROCESSLIST command, it seems that after R2DBC queries the database, it closes and reconnects instead of returning it to the connection pool immediately. The screenshot is when the application is running the query. The part that says &quot;unauthenticated user&quot; seems to reestablish the database connection.

This seems to cause excessive CPU usage on the database.

My opinion is that if it is a connection pool, it should be used as it is by inheriting the connection, rather than unconditionally closing and reopening the connection when returning it.
Is this behavior intentional in R2DBC? Or is it a connection pool management bug?
","mysql, spring-data-r2dbc",0,73274687,"This issue occurred because the version of the R2DBC Pool library referenced in Spring Boot had a bug that immediately evicts the connection pool after use. After upgrading the version of the R2DBC Pool library to 0.9.1, the issue was resolved.
Related PR : https://github.com/r2dbc/r2dbc-pool/issues/129
"
73870058,How can you use iOS 16's UIPasteControl with React Native?,"iOS 16 introduces UIPasteControl as a way of avoiding the paste permission dialog appearing when an app programmatically accesses the clipboard contents.
To enable UIPasteControl, its target needs to be set to an object that conforms to UIPasteConfigurationSupporting, so typically a UIResponder like UIViewController or UIView. Then you would ensure the object's pasteConfiguration is set to allow the types you want to paste.
I've got a React Native app so there are no native iOS UIView etc. type objects being used directly.
If, for example, a paste button was to be added to a React Native view, then how can that be hooked up so that its using UIPasteControl?
","ios, react-native, uiview, uipasteboard",0,73956850,"If we consider the latest version of react native, there might we not see the functionality for UIPasteControl as per new iOS versions.
for this, I guess we should create our implementation and export the functionality to react-native to accomplish this requirement.
If you have hands-on experience with iOS native development and custom native UI views implementation in React Native then you can check out the following blog about the UIPasteControl implementation in native, to implement it natively and export it to React Native.
UIPasteControl(Native) demo : https://blog.kylelanchman.com/how-to-use-uipastecontrol-in-ios-16/
"
74244055,In C++ get smallest integer type that can hold given amount of bits,"If I have compile time constant num_bits how can I get smallest integer type that can hold this amount of bits?
Of course I can do:
Try it online!
#include &lt;cstdint&gt;
#include &lt;type_traits&gt;
std::size_t constexpr num_bits = 19;
using T =
    std::conditional_t&lt;num_bits &lt;=  8, uint8_t,
    std::conditional_t&lt;num_bits &lt;= 16, uint16_t,
    std::conditional_t&lt;num_bits &lt;= 32, uint32_t,
    std::conditional_t&lt;num_bits &lt;= 64, uint64_t,
        void&gt;&gt;&gt;&gt;;

But maybe there exists some ready made meta function in standard library for achieving this goal?
I created this question only to find out single meta function specifically from standard library. But if you have other nice suggestions how to solve this task besides my proposed above solution, then please post such solutions too...

Update. As suggested in comments, uint_leastX_t should be used instead of uintX_t everywhere in my code above, as uintX_t may not exist on some platforms, while uint_leastX_t always exist.
","c++, c++20, c++23",2,74250856,"There is currently no template type for this in the c++ standard library.
The standard library does have something to do the reverse of what you're looking for (std::numeric_limits&lt;T&gt;::max).
There is a proposal to add such functionality to the c++ standard library in p0102: &quot;C++ Parametric Number Type Aliases&quot;. A similar question to yours has been asked on lists.isocpp.org/std-proposals, where p0102 was mentioned.
In case you're interested in / okay with using Boost, Boost has boost::int_max_value_t&lt;V&gt;, which is a struct defining type members least (smallest) and fast (&quot;easiest to manipulate&quot;).
"
73008559,migrate from webpack to vite with vuejs for chrome extension project,"I am working on a chrome extension using vuejs currently i have a ready project to start with but it is with webpack.
In the webpack I have multi-entry points some of which lead to generating HTML files and others with javascript only.
with webpack it is clear what is the inputs and how they will be as output in Vite i tried but there is a lot of plugins outdated that work with vuejs 3
this link contains the project
https://stackblitz.com/edit/vue-v83gga
my webpack file is :
const path = require(&quot;path&quot;);
const fs = require(&quot;fs&quot;);

// Generate pages object
const pages = {};

function getEntryFile(entryPath) {
  let files = fs.readdirSync(entryPath);
  return files;
}

const chromeName = getEntryFile(path.resolve(`src/entry`));

function getFileExtension(filename) {
  return /[.]/.exec(filename) ? /[^.]+$/.exec(filename)[0] : undefined;
}
chromeName.forEach((name) =&gt; {
  const fileExtension = getFileExtension(name);
  const fileName = name.replace(&quot;.&quot; + fileExtension, &quot;&quot;);
  pages[fileName] = {
    entry: `src/entry/${name}`,
    template: &quot;public/index.html&quot;,
    filename: `${fileName}.html`,
  };
});

const isDevMode = process.env.NODE_ENV === &quot;development&quot;;

module.exports = {
  pages,
  filenameHashing: false,
  chainWebpack: (config) =&gt; {
    config.plugin(&quot;copy&quot;).use(require(&quot;copy-webpack-plugin&quot;), [
      {
        patterns: [
          {
            from: path.resolve(`src/manifest.${process.env.NODE_ENV}.json`),
            to: `${path.resolve(&quot;dist&quot;)}/manifest.json`,
          },
          {
            from: path.resolve(`public/`),
            to: `${path.resolve(&quot;dist&quot;)}/`,
          },
        ],
      },
    ]);
  },
  configureWebpack: {
    output: {
      filename: `[name].js`,
      chunkFilename: `[name].js`,
    },
    devtool: isDevMode ? &quot;inline-source-map&quot; : false,
  },
  css: {
    extract: false, // Make sure the css is the same
  },
};

","javascript, vue.js, webpack, vite",1,73016386,"i finally find out a solution for it as a pre-build template by vitesse written with typescript
https://github.com/antfu/vitesse-webext
in short answer if you want to have multiple entries of HTML files you can add them to the original vite.config.js file
regarding the content.ts file, it needs a different vite.config.content.ts file and we have to call it when we build the project like this
vite build &amp;&amp; vite build --config vite.config.content.ts

regarding the vite.config.ts file, the code will be like this written in typescript
/// &lt;reference types=&quot;vitest&quot; /&gt;

import { dirname, relative } from 'path'
import type { UserConfig } from 'vite'
import { defineConfig } from 'vite'
import Vue from '@vitejs/plugin-vue'
import Icons from 'unplugin-icons/vite'
import IconsResolver from 'unplugin-icons/resolver'
import Components from 'unplugin-vue-components/vite'
import AutoImport from 'unplugin-auto-import/vite'
import WindiCSS from 'vite-plugin-windicss'
import windiConfig from './windi.config'
import { isDev, port, r } from './scripts/utils'

export const sharedConfig: UserConfig = {
  root: r('src'),
  resolve: {
    alias: {
      '~/': `${r('src')}/`,
    },
  },
  define: {
    __DEV__: isDev,
  },
  plugins: [
    Vue(),

    AutoImport({
      imports: [
        'vue',
        {
          'webextension-polyfill': [
            ['*', 'browser'],
          ],
        },
      ],
      dts: r('src/auto-imports.d.ts'),
    }),

    // https://github.com/antfu/unplugin-vue-components
    Components({
      dirs: [r('src/components')],
      // generate `components.d.ts` for ts support with Volar
      dts: r('src/components.d.ts'),
      resolvers: [
        // auto import icons
        IconsResolver({
          componentPrefix: '',
        }),
      ],
    }),

    // https://github.com/antfu/unplugin-icons
    Icons(),

    // rewrite assets to use relative path
    {
      name: 'assets-rewrite',
      enforce: 'post',
      apply: 'build',
      transformIndexHtml(html, { path }) {
        return html.replace(/&quot;\/assets\//g, `&quot;${relative(dirname(path), '/assets')}/`)
      },
    },
  ],
  optimizeDeps: {
    include: [
      'vue',
      '@vueuse/core',
      'webextension-polyfill',
    ],
    exclude: [
      'vue-demi',
    ],
  },
}

export default defineConfig(({ command }) =&gt; ({
  ...sharedConfig,
  base: command === 'serve' ? `http://localhost:${port}/` : '/dist/',
  server: {
    port,
    hmr: {
      host: 'localhost',
    },
  },
  build: {
    outDir: r('extension/dist'),
    emptyOutDir: false,
    sourcemap: isDev ? 'inline' : false,
    // https://developer.chrome.com/docs/webstore/program_policies/#:~:text=Code%20Readability%20Requirements
    terserOptions: {
      mangle: false,
    },
    rollupOptions: {
      input: {
        background: r('src/background/index.html'),
        options: r('src/options/index.html'),
        popup: r('src/popup/index.html'),
      },
    },
  },
  plugins: [
    ...sharedConfig.plugins!,

    // https://github.com/antfu/vite-plugin-windicss
    WindiCSS({
      config: windiConfig,
    }),
  ],
  test: {
    globals: true,
    environment: 'jsdom',
  },
}))

the important part of it is this
vite.config.ts
...
build: {
    outDir: r('extension/dist'),
    emptyOutDir: false,
    sourcemap: isDev ? 'inline' : false,
    // https://developer.chrome.com/docs/webstore/program_policies/#:~:text=Code%20Readability%20Requirements
    terserOptions: {
      mangle: false,
    },
    rollupOptions: {
      input: {
        background: r('src/background/index.html'),
        options: r('src/options/index.html'),
        popup: r('src/popup/index.html'),
      },
    },
  },
...

Thank you to anyone who tried to help and I hope this will be helpful to others
Regards
"
74328847,Detect shift + copy keystrokes in javascript,"i'd like to handle keystroke combination of shift + copy. what i am doing is checking if keystrokes shift + cmd + c are all keydown, which is effectively shift + copy.
  var keyPressed = {};
  window.addEventListener(&quot;keydown&quot;, function (e) {
    keyPressed[e.key] = true;
    const keyList = Object.keys(keyPressed);

    const isShiftCopy = [&quot;Meta&quot;, &quot;Shift&quot;, &quot;c&quot;].every((x) =&gt;
      keyList.includes(x)
    );

    if (isShiftCopy) {
      console.log(&quot;shift copy called&quot;);
      e.preventDefault();
    }
  });

this works but it listens to every keystroke though. is there a better way?
here's what i'm doing for basic copy keystrokes.
  window.addEventListener(&quot;copy&quot;, function (e) {
      console.log(&quot;copy called&quot;);

       // TODO can shift be detected at the same time as this copy event?
    });

it'd be great to avoid listening to all possible keystrokes to detect shift + copy.
can shift be detected from copy event listener? or is there another possible solution other than using keydown ?
","javascript, keyevent",0,74328894,"The copy event does not have any keystrokes that are carried along with the event. The only way to accomplish this is to simply filter the keystrokes, as you've done in your first example.
If you want to read more into the event object that copy has, it's a ClipboardEvent
However, if you want the copy event to get the current selection, you can use the Selection API to help you see what text / nodes are selected when the user copies things.
"
73218534,"When Django Model creates, can I define fields in __init__?","Are they typed in below same?
The first code which defines fields in class attribute section is recommended by django documents
class Musician(models.Model):
    first_name = models.CharField(max_length=50)
    last_name = models.CharField(max_length=50)
    instrument = models.CharField(max_length=100)

The second code which I want to use defines fields in init function.
class Musician(models.Model):
    def __init__(self, *args, **kwargs):
        first_name = models.CharField(max_length=50)
        last_name = models.CharField(max_length=50)
        instrument = models.CharField(max_length=100)
        super().__init__(*args, **kwargs)

I want to use second codes when I define classmethod in Model to define functions validateing fields like below.
class HyperLinks(model.Model):
    def __init__(self, *args, **kwargs):
        self.links = models.JSONField(default=[], validators=[self.validate_links])
        super().__init__(*args, **kwargs)

    @staticmethod
    def validate_links(data):
        &quot;&quot;&quot;
        example
        links = [(&quot;github&quot;, &quot;https://github.com/yeop-sang&quot;), (&quot;homepage&quot;, &quot;http://yeop.kr&quot;)]
        &quot;&quot;&quot;
        if type(data) is not list:
            raise ValidationError(
                'links should be list'
            )
        for datum in data:
            if type(datum) is not tuple:
                raise ValidationError(
                    'links should be list contained tuple'
                )
            if len(datum) is not 2:
                raise ValidationError(
                    'link should be contain type and link'
                )
            if not (type(datum[0]) is str or type(datum[1]) is str):
                raise ValidationError(
                    'link and type should be string'
                )

","python, django",-2,73230701,"The Second code in my question won't work.
I found similar questions, Storing Variables in Python Class, Attributes initialization/declaration in Python class: where to place them?
According to above questions, class attributes cannot be shared by __dict__ function.
class A(object):
    foo = None
class B(object):
   def __init__(self):
       self.foo = None

A.__dict__
# result
# mappingproxy({'__module__': '__main__', 'foo': None, '__dict__': &lt;attribute '__dict__' of 'A' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'A' objects&gt;, '__doc__': None})
B.__dict__
# result
# mappingproxy({'__module__': '__main__', '__init__': &lt;function B.__init__ at 0x110805790&gt;, '__dict__': &lt;attribute '__dict__' of 'B' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'B' objects&gt;, '__doc__': None})

There is differences which django library call models. Therefore, when we define models, we must avoid define attributes in __init__ functions. That makes unexpected errors.
Especially, in django Migration Section, the django cannot recognize fields, then it won't create columns or delete your columns. And in objects.create(), the column names.
Then, how about declare the function in front of assigning field attributes like below?
class HyperLinks(models.Model):
    @staticmethod
    def validate_links(data):
        &quot;&quot;&quot;
        example
        links = [(&quot;github&quot;, &quot;https://github.com/yeop-sang&quot;), (&quot;homepage&quot;, &quot;http://yeop.kr&quot;)]
        &quot;&quot;&quot;
        if type(data) is not list:
            raise ValidationError(
                'links should be list'
            )
        for datum in data:
            if type(datum) is not tuple:
                raise ValidationError(
                    'links should be list contained tuple'
                )
            if len(datum) is not 2:
                raise ValidationError(
                    'link should be contain type and link'
                )
            if not (type(datum[0]) is str and type(datum[1]) is str):
                raise ValidationError(
                    'link and type should be string'
                )

    links = models.JSONField(default=[], validators=[validate_links])

There is an Exception TypeError: 'staticmethod' object is not callable.
(Related link).
To fix it, I can change last line like links = models.JSONField(default=[], validators=[validate_links.__get__(object)])
Eventually, to validate fields, the best way is create the functions separated from Model class which recommended by django docs and @0sVoid.
"
74162662,"How to convert a List<Entity> where each element points to other Entities into Map<String, Entity> in Java","I am having a class as
public class Entity {
    private String id;
    private List&lt;Entity&gt; children;
    
    // getters, constructor, etc.
}

Now I need to convert this Entity class data into Map&lt;String, Entity&gt;
My Method accepts (List entity) as Input and that need to be converted to Map
I tried like:
public static Map&lt;String, Entity&gt; group(List&lt;Entity&gt; entities) {
    
    Map&lt;String, Entity&gt; map = new HashMap&lt;&gt;();
    for (Entity e : entities) {
        if (!map.containsKey(e.getId())) {
            map.put(e.getId(), ??? e.getChildren() ???); // my point of confusion
        }
    }
    return map;
}

My problem is that I don't know how to proceed at the point when I need to access children-entities via getChildren(). How it can be implemented to get the proper data?
Sample data format is as follows.
[
 {
    id: bos
    childs:[
        {
            id: manager1
            childs: [{id: worker11}, {id: worker12}]
        },
        {
            id: manager2
            childs: [{id: worker21}, {id: worker22}]
        }
    ]
 }
]

","java, list, algorithm, hashmap",1,74162853,"Basically, you have a disjointed Graph of Entities.
Therefore, you need to implement a graph traversal algorithm in order to the data of the Entities into the resulting Map.
One of the simplest algorithms commonly used for such purposes is the Depth first search.
The core idea behind this algorithm:

Maintain a Stack, containing the element that are being examined.
Search starts from the root element being pushed on the top of the stack.
Elements are being repeatedly removed from the top of the stack. And if the next element has children that haven't been yet seen, they are being pushed on the top of the stack.

Here's how the iterative implementation might look like:
public static Map&lt;String, Entity&gt; group(List&lt;Entity&gt; entities) {
    
    Map&lt;String, Entity&gt; result = new HashMap&lt;&gt;();
    Set&lt;String&gt; seen = new HashSet&lt;&gt;();
    
    for (Entity e : entities) {
        if (seen.add(e.getId())) { // entity was not previously encountered
            addAllChildren(result, seen, e);
        }
    }
    return result;
}

/**
 * Depth first search algorithm implementation
 */
public static void addAllChildren(Map&lt;String, Entity&gt; result,
                                  Set&lt;String&gt; seen,
                                  Entity root) {
    
    Deque&lt;Entity&gt; stack = new ArrayDeque&lt;&gt;();
    stack.push(root);
    
    while (!stack.isEmpty()) {
        Entity current = stack.pop();
        result.put(current.getId(), current);
        
        for (Entity child: current.getChildren()) {
            if (seen.add(child.getId())) {
                stack.push(child);
            }
        }
    }
}

"
73077152,Malformed Array Literal postgresql,"I would like to insert data in the form of a string in a column of type array (char[]) only my request returns the error &quot;Malformed Array Literal&quot;
here is my request:
async function insertTag(req, res) {
    return db.none('UPDATE user_account SET tag_property = $1 WHERE email = $2',
            [req.body.tag_id, req.body.email])
        .then(function () {
            res.status(200)
                .json({
                    status: 'success',
                    message: 'Updated user',
                });
        })
        .catch(error =&gt; {
            console.log(error)
        });
}

here is my data table 
tagIdInput: '',
InsertTagUserAccount(){
                fetch('http://192.168.1.51:3000/api/v1/tag_insertion', {
                    method: 'PUT',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        email : 'monemail@gmail.com',
                        tag_id : '{' + this.tagIdInput + '}',
                    }),
                })
                // Converting to JSON
                .then(response =&gt; response.json())
                // Displaying results to console
                .then(json =&gt; console.log(json));       
                },

How can I fix that ?
","javascript, node.js, postgresql",0,73080456,"
I don't now how to add a new tag_id instead of replacing the old one

See modifying arrays in the docs and use the array_append function for that:
UPDATE user_account
SET tag_property = array_append(tag_property, $1)
WHERE email = $2;

If your frontend code is actually sending an array of multiple items to add, you can use
UPDATE user_account
SET tag_property = tag_property || $1::text[]
WHERE email = $2;

"
73060562,Writing into someone else's s3 bucket but no one can read it,"I am writing into someone else's s3 bucket but no one can read it.
How do I make it so that the owner of the s3 bucket can read what im writing into the bucket? Is this something they would have to change on their end since they are the owner or is this something I can change on my end?
I dont see the Bucket on my Amazon S3 buckets list because I am not the owner. Therefore, I cannot change the permissions there (or can I change the settings on an invisible bucket?).
","amazon-web-services, amazon-s3",0,73060669,"When uploading to an Amazon S3 bucket that belongs to a different account, use ACL=bucket-owner-full-control. This will 'handover' ownership of the object to the other account.
This is a very strange behaviour of Amazon S3 that they have now corrected by offering the ability to  disable ACLs and enforce the Bucket owner. If the owner of the bucket configures this setting, then it will work as expected (without needing to specify the ACL on upload).
See: Controlling ownership of objects and disabling ACLs for your bucket - Amazon Simple Storage Service
"
74109047,how to map question options in my program,"i need to show my question options as a radio buttons in my popup module i have tried but i cant find one solutions
its my question module:
import questions from &quot;./Data&quot;;
const QuestionModel = () =&gt; {
  return (
    &lt;div className=&quot;modal-body&quot;&gt;
      &lt;div className=&quot;app&quot;&gt;
        {questions.map((item) =&gt; {
          return (
            &lt;&gt;
              &lt;h3&gt;{item.questionText}&lt;/h3&gt;
            &lt;/&gt;
          );
        })}
      &lt;/div&gt;
    &lt;/div&gt;
  );
};

and this is my sample data file:
const questions = [
    {
        questionText: 'What is the capital of France?',
        answerOptions: [
            { answerText: 'New York', isCorrect: false },
            { answerText: 'London', isCorrect: false },
            { answerText: 'Paris', isCorrect: true },
            { answerText: 'Dublin', isCorrect: false },
        ],
    },
    {
        questionText: 'Who is CEO of Tesla?',
        answerOptions: [
            { answerText: 'Jeff Bezos', isCorrect: false },
            { answerText: 'Elon Musk', isCorrect: true },
            { answerText: 'Bill Gates', isCorrect: false },
            { answerText: 'Tony Stark', isCorrect: false },
        ],
    },
    {
        questionText: 'The iPhone was created by which company?',
        answerOptions: [
            { answerText: 'Apple', isCorrect: true },
            { answerText: 'Intel', isCorrect: false },
            { answerText: 'Amazon', isCorrect: false },
            { answerText: 'Microsoft', isCorrect: false },
        ],
    },
    {
        questionText: 'How many Harry Potter books are there?',
        answerOptions: [
            { answerText: '1', isCorrect: false },
            { answerText: '4', isCorrect: false },
            { answerText: '6', isCorrect: false },
            { answerText: '7', isCorrect: true },
        ],
    },
];
export default questions;

i need to show answer text as my options in my module
","javascript, html, reactjs",0,74109327,"The answersOptions is an array with objects inside, so you need to map through this array and display the object.answerText.
Code:
{questions.map((item) =&gt; {
          return (
            &lt;&gt;
              &lt;h3&gt;{item.questionText}&lt;/h3&gt;
              &lt;div&gt;
                {item.answerOptions.map((ans) =&gt; {
                  return (
                    &lt;&gt;
                      &lt;input
                        type=&quot;radio&quot;
                        name={item.questionText}
                        id={item.questionText}
                      /&gt;
                      &lt;label htmlFor={item.questionText}&gt;
                        {ans.answerText}
                      &lt;/label&gt;
                    &lt;/&gt;
                  );
                })}
              &lt;/div&gt;
            &lt;/&gt;
          );
        })}

"
73772360,Is there a limit to number of redirect URIs that you can register with OAuth2 provider?,"As the title of the question, is there a limit to number of callback/redirect URIs that you can register with OAuth2 IDP provider like Okta, Google, etc?
I need to know this limit as I am building suite of web applications deployed on separate subdomains but need them to share the same session. My thought is to share the same client id and client secret with all these apps so that access_token and refresh_token can be reused.
","authentication, oauth-2.0, google-oauth",0,73774691,"The specification does not limit this. A client can have as many redirect URIs as it wishes. Concrete authorization server might have their own limits. You would have to check with each vendor separately to verify the limit of redirect URIs they allow.
Maybe a better solution would be to have one app that is responsible for obtaining the tokens and then it could establish a session with all the different applications. I think having one backend responsible for handling a session is better than relying on the lifespan of an access token. In fact, access tokens are not meant as a session-carrying mechanism. They are not related to user sessions, and you should rely on other tools for that. You can still use Google to verify the identity of a user, but you should handle the session separately.
"
72901581,Host identification in Docker container,"PROBLEM:
My application consists of one server and two clients which can be run on Windows, Linux, MAC operating systems. My goal is for the server to be able to determine if the clients are running on the same physical host or different ones. When clients work outside of a container, this can be done easily (for example, using a /etc/machine-id). The problem arises when containers come into play. The same /etc/machine-id is no longer unique across containers.
RESTRICTIONS:
The environment of docker containers cannot be changed (that is, it is not possible to use environment variables or volumes)
QUESTION:
Is there a way, maybe OS-specific or not, to identify a host that is independent of whether containerization is used or not?
",docker,2,72954175,"SOLUTION:
I used the host boot time to identify the host. Windows, Linux and MAC provide ways to get this information. These methods return the boot time of the host when called from a container. This is not a completely accurate solution to my problem, since there is some possibility that the hosts were running at the same time, but this probability is small enough to be neglected.
"
73319080,"Thymeleaf with springboot, error trying to check if list is empty now working","i'm trying to check if my list called listPersons is empty or not, but when i check i got an error like this:

Caused by: org.attoparser.ParseException: Exception evaluating
SpringEL expression: .... Caused by:
org.thymeleaf.exceptions.TemplateProcessingException: Exception
evaluating SpringEL expression: &quot;#lists.isEmpty(listPersons&quot;
(template: &quot;index&quot; - line 15, col 8)

I have tried this:
&lt;h2 th:if=&quot;${#lists.isEmpty(listPersons)}&quot;&gt;No hay personas&lt;/h2&gt;
&lt;div th:if=&quot;${#!lists.isEmpty(listPersons)}&quot;&gt;

and this:
 ${listPersons.isEmpty()}

But none of the options are working. I'm using thymeleaf-3.0.15 and springboot version 2.7.2
In my Java method i have this line:
model.addAttribute(&quot;listPersons&quot;, personaService.getAll());

","spring-boot, thymeleaf",0,73319289,"You are not using the conditional statements correctly, hence you are getting the SPEL error
&lt;div th:if=&quot;${#!lists.isEmpty(listPersons)}&quot;&gt;

Use the below for your condition
&lt;div th:if=&quot;${not #lists.isEmpty(listPersons)}&quot;&gt;

Refer https://www.thymeleaf.org/doc/tutorials/2.1/usingthymeleaf.html#conditional-evaluation
to get more insights.
"
73336387,Why does accessing a container in cosmos immediately exit with no exception?,"I started with a bog standard cosmos query example in C#.
When the code hits this line, it exits with no further information:
var currentResultSet = await queryResultSetIterator.ReadNextAsync();

To verify something was working, I created this snippet:
this.cosmosClient = new CosmosClient(EndpointUri, PrimaryKey);
this.container = cosmosClient.GetContainer(databaseId, containerId);

// This code worked and I verified results in data explorer
var deltest = this.cosmosClient.GetContainer(databaseId, &quot;deleteme&quot;);
deltest.DeleteContainerAsync().Wait();  

// this exits immediately, no exception
var a = await this.container.ReadContainerAsync();

The ReadContainerAsync left an important clue I did not see in the query code:
DocDBTrace Information: 0 : Azure Environment metadata information not available. A socket operation was attempted to an unreachable network. (169.254.169.254:80)

I have looked through the container setup, and I don't see anything.  Is there an option I need to enable to allow the container to be queryable?
EDIT 1
After playing with this for a bit.  I am encountering behavior I would not normally expect to see.  A bit of boring background:

I am doing TDD with a unit test project for a .NET 6 library
I am testing a class implementing an interface that hides the DB from the caller
Class has a constructor and a single async method

This TEST code in the constructor works:
var deltest = this.cosmosClient.GetContainer(databaseId, &quot;deletetesttwo&quot;);
deltest.DeleteContainerAsync().Wait();

This TEST code in the async method exits the unit test project debug mode instantly:
var deltest = this.cosmosClient.GetContainer(databaseId, &quot;deletetesttwo&quot;);
await deltest.DeleteContainerAsync();

I am recreating containers using data explorer between invocations.
","c#, azure, azure-cosmosdb-sqlapi",0,73337026,"FACEPALM
After looking at this: Cosmos DB call never returns with async call
Remember kids: A unit test project example test method isn't async when you first create the class.
Changing the test method to async and adding await fixed the issue.
"
73225767,Am I interpreting K-means results correctly?,"I have implemented k-means elbow plot to find the optimum K for my data (after doing PCA). I have gotten the elbow plot shown below. My question is: I think the optimum K is 3 in my case (this is where a sudden drop occurs/point of inflection)? But looking at my X_PCA_1 VS. X_PCA_2 plot, I think the data can be clustered into 2 clusters only? or am I mistaken?
Note: I am still a beginner.
K-elbow

","python, k-means, pca",2,73226505,"If you want to plot to see clearly the clusters, first you can use PCA with 3 components:
pca = PCA(3)
X_pca = pca.fit_transform(scaled_df)

Then, you can append each point to each dimension:
X = []
Y = []
Z = []
for i in X_pca:
    X.append(i[0])
    Y.append(i[1])
    Z.append(i[2])

From here you can choose a library to plot 3d graphs.
model = KMeans(n_clusters=3)
cluster_kmeans = model.fit_predict(scaled_df)

df_graph = pd.DataFrame({'X': X,
                         'Y': Y,
                         'Z': Z,
                         'labels': cluster_kmeans
                         })

fig = plt.figure(figsize=(20, 10))
ax = fig.add_subplot(111, projection='3d')

for s in df_graph.labels.unique():
    ax.scatter(df_graph.X[df_graph.labels==s],df_graph.Y[df_graph.labels==s],df_graph.Z[df_graph.labels==s],label=s)
    
ax.legend()
plt.show()

"
73676462,Spring Data JDBC aggregate ID in child objects,"I was playing with Spring-Data-JDBC and encountered 2 issues. I have following entities with 1:N relationship.
------

DROP TABLE IF EXISTS product;

CREATE TABLE product (
    product_id int AUTO_INCREMENT  PRIMARY KEY,
    name varchar(250) not null,
    description varchar(512) not null
);

DROP TABLE IF EXISTS product_line;

CREATE TABLE product_line (
    product_id int constraint fk_product_line_product references product(product_id),
    label varchar(250) not null
);

----------


@Data
@Builder
public class Product {

    @Id
    private Long productId;

    private String name;

    private String description;

    @Singular
    @MappedCollection(idColumn = &quot;product_id&quot;, keyColumn = &quot;product_id&quot;)
    private Set&lt;ProductLine&gt; lines;
}

@Data
@Builder
public class ProductLine {

    private Long productId;

    private String label;

}

Problem 1: Following test case fails because I was expecting to have the productId populated in the ProductLine object but it is not. Is this the expected behavior of Spring Data JDBC?
@SpringBootTest
class SpringDataJdbcApplicationTests {

    @Autowired
    private ProductRepository productRepository;

    @Test
    void saveTest() {

        Product product = Product.builder()
                .name(&quot;Product-1&quot;)
                .description(&quot;Description&quot;)
                .line(ProductLine
                        .builder()
                        .label(&quot;Line-label&quot;)
                        .build())
                .build();

        this.productRepository.save(product);

        assertThat(product.getProductId()).isNotNull();
        assertThat(product.getLines()).isNotNull().isNotEmpty().hasSize(1);
        assertThat(product.getLines().stream().findFirst()).isPresent();
        assertThat(product.getLines().stream().findFirst().get().getProductId()).isNotNull().isEqualTo(product.getProductId()); // -----&gt; Fails here. 

    }

}

Problem 2: If I change Set&lt;ProductLine&gt; to List&lt;ProductLine&gt;, it fails due to JdbcSQLIntegrityConstraintViolationException, which means the product id set to 0 as seen in the log snippet below.
2022-09-10 22:33:12.393 DEBUG 18460 --- [           main] o.s.jdbc.core.JdbcTemplate               : Executing prepared SQL statement [INSERT INTO &quot;PRODUCT_LINE&quot; (&quot;LABEL&quot;, &quot;PRODUCT_ID&quot;) VALUES (?, ?)]
2022-09-10 22:33:12.393 TRACE 18460 --- [           main] o.s.jdbc.core.StatementCreatorUtils      : Setting SQL statement parameter value: column index 1, parameter value [Line-label], value class [java.lang.String], SQL type 12
2022-09-10 22:33:12.393 TRACE 18460 --- [           main] o.s.jdbc.core.StatementCreatorUtils      : Setting SQL statement parameter value: column index 2, parameter value [0], value class [java.lang.Integer], SQL type 4

","spring-boot, spring-data-jdbc",0,73699045,"
Following test case fails because I was expecting to have the productId populated in the ProductLine object but it is not. Is this the expected behavior of Spring Data JDBC?

Yes, if you want a productId you have to (and can easily) populate it yourself using plain Java code.
But you really shouldn't need the productId in the first place since if you follow Domain Driven Design, you will access a ProductLine exclusively from a Product which already has the id at hand.
The article https://spring.io/blog/2021/09/22/spring-data-jdbc-how-do-i-make-bidirectional-relationships might be helpful.

If I change Set&lt;ProductLine&gt; to List&lt;ProductLine&gt;, it fails due to JdbcSQLIntegrityConstraintViolationException, which means the product id set to 0 as seen in the log snippet below.

You have two problems here:

You already have two sources for the product_id field: The relation from the aggregate root and the simple field, which may cause problems.

You mapped both the back reference to the aggregate root idColumn and the index of the list keyColumn to the same database column. Together with the simple field from above these are three values all mapped to the same column. Not good.
The value that seems to win is the list index, resulting in the exception.
In order to fix that, create an additional column in the product_line table and map the list index to it.


"
74286842,How to not return a key if its value is None in a recursive function,"I have return statement within a recursive function that looks like this:
def recursive_function(data):
....
return {f'uid': uid,'title': title, 'string': string,'create-time': create_time, 'edit-time': edit_time, 'children': children, 'refs': refs}

Sometimes some of these values can be None (ex: when the title has a value, the string's value will be None, and vice-versa). The application I'm using does not recognize keys with None values, how do I prevent those keys from returning when the values are None?
Thank you in advance.
","python, json, python-3.x",0,74286926,"You can achieve this using dictionary comprehension:
return {key:value for key,value in {f'uid': uid,'title': title, 'string': string,'create-time': create_time, 'edit-time': edit_time, 'children': children, 'refs': refs}.items() if value is not None }


"
74392033,EmbededPowerBI react component is not filtering report data,"I am using PowerBIEmbed component to display powerBI report, Power BI report is using telemetry query to filter data.
telemetry has columns like
name
CustomColumnJson {
Id,
Event
}
I want to apply filter over Id column, then I am applying filter like , but filter is not working.
       &lt;PowerBIEmbed
            embedConfig={{
                type: 'report', 
                id: '*********************',  //client_id
                embedUrl: &quot;&quot;, //embed url, if u dont knw refer powerbi api docs
                accessToken: this.state.accessToken,
                tokenType: models.TokenType.Aad,
filters: [{
                $schema: &quot;http://powerbi.com/product/schema#basic&quot;,
                target: {
                table: &quot;Event&quot;,
                column: &quot;CustomColumnJson.Id&quot;
                },
                operator: &quot;In&quot;,
                values: &quot;XYZ&quot;
            }],
                settings: {
                    panes: {
                        filters: {
                            expanded: false,
                            visible: true
                        }
                    },
                }
            }} eventHandlers={
                new Map([
                    ['loaded', function () { console.log('Report loaded'); }],
                    ['rendered', function () { console.log('Report rendered'); }],
                    ['error', function (event) { console.log(event.detail); }]
                ])
            }
            cssClassName={&quot;container&quot;}
            getEmbeddedComponent={(embeddedReport) =&gt; {
                window.report = embeddedReport;
            }}
        /&gt;

","reactjs, powerbi, powerbi-embedded, powerbi-custom-visuals",0,74398695,"Values in the filters should be of Array of (strings or boolean or numbers).
Try this code and LMK if this works.
filters: [{
                $schema: &quot;http://powerbi.com/product/schema#basic&quot;,
                target: {
                table: &quot;Event&quot;,
                column: &quot;CustomColumnJson.Id&quot;
                },
                operator: &quot;In&quot;,
                values: [&quot;XYZ&quot;]
            }],

Sample :
const filter = {
$schema: &quot;http://powerbi.com/product/schema#basic&quot;,
target: {
    table: &quot;Geo&quot;,
    column: &quot;Region&quot;
},
operator: &quot;In&quot;,
values: [&quot;West&quot;, &quot;Central&quot;]}; 
// Add the filter to the report's filters.
try {
await report.updateFilters(models.FiltersOperations.Add, [filter]);
console.log(&quot;Report filter was added.&quot;);}
catch (errors) {
console.log(errors);}

Here is my table and column name.

Filter section before applying filter

Filter section after applying filter

References:
https://learn.microsoft.com/javascript/api/overview/powerbi/control-report-filters
"
73413953,Search if jsonb array of string contains value,"I have arry of strings in a column like :  [&quot;196 2616&quot;, &quot;9503744&quot;, &quot;36.25260-6027&quot;, &quot;2 414 425&quot;, &quot;7 034 771 6&quot;, &quot;F709714&quot;, &quot;1088229&quot;, &quot;183144&quot;, &quot;505870338&quot;, &quot;105075&quot;]
I want to search if this array contains for example 2 414 425.
I tried something like this:
 SELECT * FROM  table_name t where t.numbers @&gt; '2 414 425'
But it doesnt return anything even when it should.
","sql, postgresql",-1,73414108,"The @&gt; operator needs a proper JSON object on the right hand side:
where t.numbers @&gt; '[&quot;2 414 425&quot;]'

This should work if numbers is defined as jsonb (which it should be). Otherwise cast it numbers::jsonb
Checking if at least one of multiple keys is contained in the JSON array can be done using the ?| operator:
where t.numbers ?| array['2 414 425', '13261999']

The ?&amp; operator will check if all those keys are contained in the JSON array.
"
74591448,"Why is my Either-returning method always returning Left, irrespective of what happened?","The use case here is that I have added a method to an Entity Framework DbContext that does some extra work before saving, and then returns an Either depending on the results. A very simplified version of this looks like this...
static async Task&lt;Either&lt;string, Unit&gt;&gt; SaveChangesAsyncEither(string userId) {
  // In reality, this would do some auditing, check for concurrency issues, and
  // attempt to save the changes. It would return unit if all went OK, 
  // or an error message if not. Simple check for demonstrating the issue...
  if (userId == &quot;jim&quot;) {
    return &quot;We don't like Jim&quot;;
  }
  return unit;
}

This method is used in many places in my solution, and wors fine.
In one minimal API project, I have a method that looks like this (again, highly simplified)...
static async Task&lt;Either&lt;DeviceApiResponseStates, DeviceApiResponseStates&gt;&gt; CreateDevice(string userId) {
  // In reality we would have more parameters, create a device, etc before
  // calling SaveChangesAsyncEither
  return (await SaveChangesAsyncEither(userId))
      .Match(() =&gt; Right&lt;DeviceApiResponseStates, DeviceApiResponseStates&gt;(DeviceApiResponseStates.OK),
        _ =&gt; Left(DeviceApiResponseStates.Nah));
}

...where DeviceApiResponseStates is an enum. For simplicity, you can imagine it looks like this...
enum DeviceApiResponseStates {
  OK,
  Nah
}

Those three code blocks are a complete sample of my problem.
I would expect that if I call CreateDevice(&quot;jim&quot;), then I would get a Left with a value of Nah, and if I call it with any other string value, I would get a Right with a value of OK.
However, when I try this...
Console.WriteLine((await CreateDevice(&quot;&quot;))
  .Match(_ =&gt; &quot;Yeah&quot;, ex =&gt; $&quot;Exception: {ex}&quot;));

... I get Nah, irrespective of the string value.
Anyone able to explain what I'm doing wrong?
","c#, functional-programming, language-ext",2,74633737,
73528506,Numpy Array non-sequentially divide the columns of the main array into n sub-arrays,"I've been trying to do something like a numpy.array_split(), but to split it like this instead:

So It would return an array (for example let's call it output[] ) with n 2D subarrays inside of it.
For example (for n = 3):

output[0] would return the (yellow) subarray with columns a1, a4, a7, a10,
output[1] would return the (red) subarray with columns a2, a5, a8,
output[2] would return the (blue) subarray with columns a3, a6, a9.

def split(arr, n):
    output= [[] for _ in range(n)]
    for v, help in zip(arr, cycle(out)):
        help.append(v)
    return output

I don't know how to combine rows into one 2D array, so I have many 1D arrays instead of one 2D.
","python, arrays, numpy, split",2,73528612,"Not sure if a native solution exists but you can use:
# get groups
group = np.arange(a.shape[1])%n
# groups sorting order
order = np.argsort(group)
# get counts of each group (in order as the output is sorted)
_, idx = np.unique(group, return_counts=True)
# split the reindexed array
out = np.split(a[:, order], np.cumsum(idx[:-1]), axis=1)

Output:
[array([[ 0,  3,  6,  9],
        [10, 13, 16, 19],
        [20, 23, 26, 29],
        [30, 33, 36, 39],
        [40, 43, 46, 49]]),
 array([[ 1,  4,  7],
        [11, 14, 17],
        [21, 24, 27],
        [31, 34, 37],
        [41, 44, 47]]),
 array([[ 2,  5,  8],
        [12, 15, 18],
        [22, 25, 28],
        [32, 35, 38],
        [42, 45, 48]])]

Used input:
array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],
       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],
       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],
       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],
       [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]])

"
73397834,"What is the unit of lower case ""m"" and ""k"" in the image below?","
Is there any documentation that describes this &quot;m&quot; and &quot;k&quot;. In the k8s documentation, I could see for &quot;Mi&quot;, &quot;Gi&quot; etc, but not this. Any help would be greatly appreciated.
","kubernetes, horizontalpodautoscaler",0,73439953,"After some research i got this :
Those are Kubernetes-style quantities, Instead of displaying things as a decimal, it will display with SI suffixes. For instance, 1.5 becomes 1500m. When Kubernetes displays a quantity, it will tend to use milli-units if there would be a decimal point, and plain units otherwise. So, if it had to display 500 on the dot, it would just display 500, but if it's 500.5, it would display 500500m. So m means divide by 1000, k means times 1000. There's no documentation really except this. Search for &quot;Kubernetes-style quantities&quot; if you want to see more examples.
1m/750m = (1/1000)/(750/1000) = 0.001/.75 = .1%/75%
refer this link also
"
73679367,Remove template text on regexp_replace in Oracle's SQL,"I am trying to remove template text like &amp;#x; or &amp;#xx; or &amp;#xxx; from long string
Note: x / xx / xxx - is number, The length of the number is unknown, The cell type is CLOB
for example:
SELECT 'H&amp;#39;ello wor&amp;#177;ld' FROM dual

A desirable result:
Hello world

I know that regexp_replace should be used, But how do you use this function to remove this text?
","sql, regex, oracle, regexp-replace",-1,73679820,"You can use
SELECT REGEXP_REPLACE(col,'&amp;&amp;#\d+;')       
  FROM t

where

&amp; is put twice to provide escaping for the substitution character
\d represents digits and the following + provides the multiple occurrences of them
ending the pattern with ;

or just use a single ampersand ('&amp;#\d+;') for the pattern as in the case of Demo , since an ampersand has a special meaning for Oracle, a usage is a bit problematic.
"
73541768,how can i access UIBezierPath that is drawn in draw(_ rect: CGRect)?,"I'm drawing lines with UIBezierPath in draw(_ rect: CGRect) method previously i did tried that with CAShapeLayer but i wasn't able to select particular path and move it so i'm trying this, but after drawing i'm not able to access that BezierPath from view's subviews or it's sublayers and not directly from UIView. How can i access that bezierpath drawn in drawRect method so i can change it's position according to touches.
private var bezierPaths: [MyBezierPath] = [MyBezierPath]()

    override func draw(_ rect: CGRect) {
    super.draw(rect)
    UIColor.orange.set()
    for path in bezierPaths {
        path.lineWidth = 4
        path.lineCapStyle = .round
        path.lineJoinStyle = .round
        path.stroke()
    }
}

    func drawingPath(_ path: [MyBezierPath]) {
    bezierPaths = path
}

like creating CAShapeLayer and setting layer.path = BezierPath like this :
        let shapeLayer = CAShapeLayer()
        shapeLayer.lineWidth = 1
        shapeLayer.strokeColor = UIColor.black.cgColor
        shapeLayer.fillColor = UIColor.clear.cgColor
        shapeLayer.lineCap = .round
        shapeLayer.lineJoin = .round
        shapeLayer.lineDashPattern = [10, 10]
        shapeLayer.name = &quot;ShapeLayer&quot;
        self.canvas.layer.addSublayer(shapeLayer)
override func touchesMoved(_ touches: Set&lt;UITouch&gt;, with event: UIEvent?) {

if canvas.layer.sublayers != nil &amp;&amp; canvas.layer.sublayers?.last?.name == &quot;ShapeLayer&quot; {
                guard let layer = canvas.layer.sublayers?.last as? CAShapeLayer else { return }
                layer.path = path.cgPath
            }
}

like this i can access layer.path but how can i do it for path drawn in draw(Rect:) method ?
","swift, uiview, core-graphics, calayer, uibezierpath",0,73545767,"Depending on what you're actually trying to do, overriding draw(_:) may not be the best approach.
For example, if you want to animate the drawn paths, it will be much easier if you are using CAShapeLayer as sublayers, or using subviews.
Also, shape layers are highly optimized ... if you write your own draw / animate functions you risk ending up with lesser-optimized code.
However, whichever approach you take, to &quot;find the path&quot; you want to use contains(_ point: CGPoint)
For example, if you have an array of UIBezierPath, with all paths relative to the top-left (0,0) of the view, on touch you could do:
// find a path that contains the touch point
if let touchedPath = bezierPaths.first(where: {$0.contains(point)}) {
    // do something with that path
}

If the paths are not relative to the top-left of the view - for example, if the path is relative to the layer position, or is part of a subview - you'd need to convert the touch point.
Here's a quick example that looks like this - on load, and then after dragging a few shapes around:
 
We'll start with a simple &quot;path&quot; struct, which contains the bezier path and the color to use. We could add various other properties, such as line width, dash pattern, etc:
struct MyPath {
    var color: UIColor = .white
    var path: UIBezierPath = UIBezierPath()
}

then we'll use this UIView subclass that will handle the drawing, as well as touches began/moved/ended:
class BezDrawView: UIView {
    
    var myPaths: [MyPath] = [] {
        didSet {
            setNeedsDisplay()
        }
    }
    
    // used to track path to move
    var activePath: MyPath?
    var startPoint: CGPoint = .zero
    
    override func draw(_ rect: CGRect) {
        super.draw(rect)
        
        if myPaths.count &gt; 0 {
            myPaths.forEach { p in
                p.color.set()
                p.path.stroke()
            }
        }
        
    }
    
    override func touchesBegan(_ touches: Set&lt;UITouch&gt;, with event: UIEvent?) {
        guard let t = touches.first else { return }
        let point = t.location(in: self)
        // find a path that contains the touch point
        if let touchedPath = myPaths.first(where: {$0.path.contains(point)}) {
            self.activePath = touchedPath
            self.startPoint = point
            return
        }
    }
    override func touchesMoved(_ touches: Set&lt;UITouch&gt;, with event: UIEvent?) {
        guard let ap = activePath, let t = touches.first else { return }
        let point = t.location(in: self)
        // move the path by the distance the touch moved
        let tr = CGAffineTransform(translationX: point.x - startPoint.x, y: point.y - startPoint.y)
        ap.path.apply(tr)
        startPoint = point
        // this triggers draw(_:)
        setNeedsDisplay()
    }
    override func touchesEnded(_ touches: Set&lt;UITouch&gt;, with event: UIEvent?) {
        // done dragging
        activePath = nil
    }
    
}

and an example controller which defines some sample shapes (paths):
class ViewController: UIViewController {
    
    override func viewDidLoad() {
        super.viewDidLoad()
        
        view.backgroundColor = .systemBackground
        
        let testBezDrawView = BezDrawView()
        testBezDrawView.backgroundColor = UIColor(white: 0.1, alpha: 1.0)
        testBezDrawView.translatesAutoresizingMaskIntoConstraints = false
        view.addSubview(testBezDrawView)
        
        let g = view.safeAreaLayoutGuide
        
        NSLayoutConstraint.activate([
            
            // constrain bez draw view to all 4 sides with 20-points &quot;padding&quot;
            testBezDrawView.topAnchor.constraint(equalTo: g.topAnchor, constant: 20.0),
            testBezDrawView.leadingAnchor.constraint(equalTo: g.leadingAnchor, constant: 20.0),
            testBezDrawView.trailingAnchor.constraint(equalTo: g.trailingAnchor, constant: -20.0),
            testBezDrawView.bottomAnchor.constraint(equalTo: g.bottomAnchor, constant: -20.0),
            
        ])
        
        // add some sample path shapes and colors
        let colors: [UIColor] = [
            .systemRed, .systemGreen, .systemBlue,
            .cyan, .magenta, .yellow, .orange, .green,
        ]
        let rects: [CGRect] = [
            CGRect(x: 20, y: 20, width: 60, height: 60),
            CGRect(x: 180, y: 20, width: 40, height: 60),
            CGRect(x: 20, y: 120, width: 60, height: 100),
            CGRect(x: 200, y: 140, width: 50, height: 90),
            CGRect(x: 90, y: 220, width: 100, height: 60),
            CGRect(x: 220, y: 260, width: 80, height: 160),
            CGRect(x: 50, y: 360, width: 200, height: 100),
            CGRect(x: 150, y: 480, width: 120, height: 80),
        ]
        var somePaths: [MyPath] = []
        var i: Int = 0
        for (c, r) in zip(colors, rects) {
            var b = UIBezierPath()
            switch i % 4 {
            case 1:     // oval
                b = UIBezierPath(ovalIn: r)
            case 2:     // triangle shape
                b = UIBezierPath()
                b.move(to: CGPoint(x: r.minX, y: r.maxY))
                b.addLine(to: CGPoint(x: r.midX, y: r.minY))
                b.addLine(to: CGPoint(x: r.maxX, y: r.maxY))
                b.close()
            case 3:     // diamond
                b = UIBezierPath()
                b.move(to: CGPoint(x: r.minX, y: r.midY))
                b.addLine(to: CGPoint(x: r.midX, y: r.minY))
                b.addLine(to: CGPoint(x: r.maxX, y: r.midY))
                b.addLine(to: CGPoint(x: r.midX, y: r.maxY))
                b.close()
            default:    // rect
                b = UIBezierPath(rect: r)
            }
            b.lineWidth = 4
            b.lineCapStyle = .round
            b.lineJoinStyle = .round
            b.setLineDash([5, 10], count: 2, phase: 0)
            let p = MyPath(color: c, path: b)
            somePaths.append(p)
            i += 1
        }
        testBezDrawView.myPaths = somePaths
    }
    
}

Here's a video of it in use (too big to convert to gif and embed here):
https://imgur.com/a/BmaHkKM

Edit in response to comment...
That needs very few changes to make it work with shape layers instead of draw(_:).
We can use the same Translation Transform to &quot;move&quot; the path, then update the .path property of that path's associated layer:
    let tr = CGAffineTransform(translationX: point.x - startPoint.x, y: point.y - startPoint.y)
    active.path.apply(tr)
    activeLayer.path = activeParh.path.cgPath

I strongly, strongly recommend that you try to convert that sample code to shape layers on your own - it would be a good learning exercise.
But, if you run into trouble, here's a modified version...
First, we're going to use the. array index of the MyPath object to match with the sublayer index, so we need to make our struct Equatable:
struct MyPath: Equatable {
    var color: UIColor = .white
    var path: UIBezierPath = UIBezierPath()
}

Then some minor changes to BezDrawView -- which we'll name BezLayerView:
class BezLayerView: UIView {
    
    var myPaths: [MyPath] = [] {
        didSet {
            // remove any existing layers
            if let subs = layer.sublayers {
                subs.forEach { lay in
                    lay.removeFromSuperlayer()
                }
            }
            // create layers for paths
            myPaths.forEach { p in
                let lay = CAShapeLayer()
                lay.lineWidth = 4
                lay.lineCap = .round
                lay.lineJoin = .round
                lay.lineDashPattern = [5, 10]
                lay.fillColor = UIColor.clear.cgColor
                lay.strokeColor = p.color.cgColor
                lay.path = p.path.cgPath
                layer.addSublayer(lay)
            }
        }
    }
    
    // used to track path to move
    var activeLayer: CAShapeLayer?
    var activePath: MyPath?
    var startPoint: CGPoint = .zero
    
    override func touchesBegan(_ touches: Set&lt;UITouch&gt;, with event: UIEvent?) {
        guard let t = touches.first, let subs = layer.sublayers else { return }
        let point = t.location(in: self)
        // find a path that contains the touch point
        if let touchedPath = myPaths.first(where: {$0.path.contains(point)}) {
            // find the layer associated with that path
            if let idx = myPaths.firstIndex(of: touchedPath) {
                if let lay = subs[idx] as? CAShapeLayer {
                    self.activePath = touchedPath
                    self.activeLayer = lay
                    self.startPoint = point
                }
            }
        }
    }
    override func touchesMoved(_ touches: Set&lt;UITouch&gt;, with event: UIEvent?) {
        guard let lay = activeLayer, let ap = activePath, let t = touches.first else { return }
        let point = t.location(in: self)
        // move the path by the distance the touch moved
        let tr = CGAffineTransform(translationX: point.x - startPoint.x, y: point.y - startPoint.y)
        ap.path.apply(tr)
        lay.path = ap.path.cgPath
        startPoint = point
    }
    override func touchesEnded(_ touches: Set&lt;UITouch&gt;, with event: UIEvent?) {
        // done dragging
        activeLayer = nil
        activePath = nil
    }
    
}

and an almost identical version of the controller:
class ViewController: UIViewController {
    
    override func viewDidLoad() {
        super.viewDidLoad()
        
        view.backgroundColor = .systemBackground
        
        let testBezLayerView = BezLayerView()
        testBezLayerView.backgroundColor = UIColor(white: 0.1, alpha: 1.0)
        testBezLayerView.translatesAutoresizingMaskIntoConstraints = false
        view.addSubview(testBezLayerView)
        
        let g = view.safeAreaLayoutGuide
        
        NSLayoutConstraint.activate([
            
            // constrain bez draw view to all 4 sides with 20-points &quot;padding&quot;
            testBezLayerView.topAnchor.constraint(equalTo: g.topAnchor, constant: 20.0),
            testBezLayerView.leadingAnchor.constraint(equalTo: g.leadingAnchor, constant: 20.0),
            testBezLayerView.trailingAnchor.constraint(equalTo: g.trailingAnchor, constant: -20.0),
            testBezLayerView.bottomAnchor.constraint(equalTo: g.bottomAnchor, constant: -20.0),
            
        ])
        
        // add some sample path shapes and colors
        let colors: [UIColor] = [
            .systemRed, .systemGreen, .systemBlue,
            .cyan, .magenta, .yellow, .orange, .green,
        ]
        let rects: [CGRect] = [
            CGRect(x: 20, y: 20, width: 60, height: 60),
            CGRect(x: 180, y: 20, width: 40, height: 60),
            CGRect(x: 20, y: 120, width: 60, height: 100),
            CGRect(x: 200, y: 140, width: 50, height: 90),
            CGRect(x: 90, y: 220, width: 100, height: 60),
            CGRect(x: 220, y: 260, width: 80, height: 160),
            CGRect(x: 50, y: 360, width: 200, height: 100),
            CGRect(x: 150, y: 480, width: 120, height: 80),
        ]
        var somePaths: [MyPath] = []
        var i: Int = 0
        for (c, r) in zip(colors, rects) {
            var b = UIBezierPath()
            switch i % 4 {
            case 1:     // oval
                b = UIBezierPath(ovalIn: r)
            case 2:     // triangle shape
                b = UIBezierPath()
                b.move(to: CGPoint(x: r.minX, y: r.maxY))
                b.addLine(to: CGPoint(x: r.midX, y: r.minY))
                b.addLine(to: CGPoint(x: r.maxX, y: r.maxY))
                b.close()
            case 3:     // diamond
                b = UIBezierPath()
                b.move(to: CGPoint(x: r.minX, y: r.midY))
                b.addLine(to: CGPoint(x: r.midX, y: r.minY))
                b.addLine(to: CGPoint(x: r.maxX, y: r.midY))
                b.addLine(to: CGPoint(x: r.midX, y: r.maxY))
                b.close()
            default:    // rect
                b = UIBezierPath(rect: r)
            }
            let p = MyPath(color: c, path: b)
            somePaths.append(p)
            i += 1
        }
        testBezLayerView.myPaths = somePaths
    }
    
}

The output and functionality should be indistinguishable from the BezDrawView implementation.
"
72938512,Cannot clear laravel migrations because of invalid database url config,"I accidentally added a wrong database url to my Laravel config now every time I try doing anything with artisan I get this error
 InvalidArgumentException 

  The database configuration URL is malformed.

I already removed that line but now I can't clear the cache for the config and every time I do anything with artisan I get the same error even when I just run php artisan help , something like an infinite loop where laravel has to clear the cache to get rid of the bug but I can't clear it because of the bug
","php, laravel, laravel-artisan",0,72938719,"Try
composer dump-autoload
php artisan config:cache

If it didn't work could you share the config file
"
74189852,GitHub Pages absolute_url discrepancy,"I changed my GH Pages Source setting from &quot;classic&quot;/&quot;hands off&quot; to &quot;GitHub Actions (Beta)&quot;, and after some tweaking, everything is working the same again, except for one thing: when hosted on my-subdomain.github.io the link to the home page goes to github.com.
The anchor tag comes from jekyll-theme-primer's default.html layout and looks like this:
&lt;a href=&quot;{{ &quot;/&quot; | absolute_url }}&quot;&gt;

On my local machine (in Docker), this is fine and links to localhost:3000 and previously on GH Pages it linked to my-subdomain.github.io (and I named the repository the same) which was fine, but after the switch it links to github.com which is bad.
My GHA workflow is a straight copy of the official starter workflow which runs this command:
bundle exec jekyll build --baseurl &quot;${{ steps.pages.outputs.base_path }}&quot;

And site.base_url is &quot;&quot; in all cases.
According to the Jekyll docs, absolute_url &quot;prepends url and base_url to the input&quot;. Why is url set to github.com now and what's the best way to fix it?
","jekyll, github-pages",0,74190383,"I fixed it by adding _config-gh.yml with url set to the correct github.io subdomain and adding --config _config.yml,_config-gh.yml to the workflow command.
"
73851725,Python While reach timeout,"I am running a Python script on a Windows machine that needs to exit from the while loop when timeout is reached or flag is True:
import time
start_time = time.time()
flag = False
timeout = 5

while time.time() &lt; timeout + start_time:
    # DO something
    flag = True
    break

if flag is False:
   print(f&quot;Timeout reached {timeout}&quot;)

With the current code, the timeout or the flag are not hit. Any hints of what it is wrong?
","python, while-loop, timeout",-1,73934278,"I am going to post the solution that I have found and worked for me as in the #DO SOMETHING section I had some blocks of code that were using some libraries that were in conflict with multithreading public library:
import time

MAX_TIMEOUT = 5

start_time = time.time()
while True:
    time_delta = time.time() - start_time
    while time_delta &lt;= MAX_TIMEOUT:
        # DO SOMETHING
        finished = True
        break
        if finished:
           break
        if time_delta &gt; MAX_TIMEOUT:
            print(&quot;Timeout reached.&quot;)
            break

"
73944185,Filling the model with sample images,"models.py
class Phrase(models.Model):
    image = models.ImageField(blank=True,
                              default=&quot;&quot;,
                              null=False,                              
 upload_to=UploadTo(folder=UPLOAD_TO.VOCABULARY_IMG_FOLDER).save_path)

Script
sample_img_dir = os.path.join(settings.BASE_DIR, 'doc', 'samples', 'img')
sample_images = os.listdir(sample_img_dir)
img = random.choice(sample_images)
f = open(os.path.join(sample_img_dir, img))
sample_img = File(f)

obj = Phrase(
        image=sample_img
    )
obj.save()

I have a model with an ImageField. I want to fill it with sample data. This is not  about testing. I just want to fill the database for development purposes. I saved some 50 jpg files and decided to add them programmatically.
I failed miserably. This code blows up with the exception:
  File &quot;/usr/lib/python3.8/codecs.py&quot;, line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
python-BaseException

Process finished with exit code 130 (interrupted by signal 2: SIGINT)

What can I try next?
",django,0,73945023,"f = open(os.path.join(sample_img_dir, img), &quot;rb&quot;)

should do the trick. If not you can try to add the encoding standard like
f = open(os.path.join(sample_img_dir, img), &quot;rb&quot;, encoding=&quot;utf-8&quot;)

But I'm not sure if this even works with bytes, it might only work for &quot;r&quot;.
You should give the file also a name:
sample_img = File(f, img)

If you already have the model created you can slo save the file afterwards with:
phrase = Phrase.objects.get(pk=1)
phrase.upload_to.save(img, content=sample_img))

small edit:
you can faster create a new entry with the following command:
phrase = Phrase.objects.create(
    image=sample_img
)

"
73669427,I can view httpOnly cookies in browser,"I thought that httpOnly cookies were only available to read in a http request. However, when I open up Firefox dev tools, I can see the cookies' value. Is this normal?
","javascript, reactjs, cookies, next.js, web-development-server",1,73669477,"Yes, thatâ€™s normal.you can access the cookies using the devtool.
"
74322206,How do I add different variables that are present in different classes using .map()/.filters(),"I have three different type of fee (cost, deliveryServiceFee and fee)  in different objects and I want to add them up and put them in a variable called &quot;totalDeliveryFee&quot;.
Here are the classes:
CartEntry.java
package core.aggreagte

public class CartEntry {
@NotNull
@Valid
private Fulfillment fulfillment;

@DecimalMin(&quot;0.0&quot;)
private BigDecimal totalDeliveryFee;
}

Fulfillment.java
package core.aggreagte

public class Fulfillment {
@Valid
private StoreDelivery storeDelivery;
}

StoreDelivery.java
package core.aggreagte

public class StoreDelivery {

@DecimalMin(&quot;0.0&quot;)
private BigDecimal cost;

@DecimalMin(&quot;0.0&quot;)
private BigDecimal deliveryServiceFee;

private DeliveryWindow deliveryWindow;
}

DeliveryWindow.java
package core.aggreagte

public class DeliveryWindow {
@DecimalMin(&quot;0.0&quot;)
private BigDecimal fee;
}

Summation of all three variables happens here in Calculator.java
Here is what I've got so far:
CartEntryTotalDeliveryFeeCalculator.java
package core.calculator.cartEntry.impl;

import core.aggregate.CartEntry;
import core.aggregate.Fullfillment;
import core.aggregate.StoreDelivery;
import core.calculator.cartEntry.CartEntryCalculator

public class CartEntryTotalDeliveryFeeCalculator implements CartEntryCalculator{
@Override
public void calculate(final CartEntry cartEntry {
          Optional.of(cartEntry).filter(fulfillment -&gt; Objects.nonNull(fulfillment.getFulfillment())).map(CartEntry::getFulfillment)
            .filter(storeDelivery -&gt; Objects.nonNull(storeDelivery.getStoreDelivery()))
            .map(Fulfillment::getStoreDelivery).filter(deliveryFee -&gt; Objects.nonNull(deliveryFee.getCost()))
            .filter(serviceFee -&gt; Objects.nonNull(serviceFee.getDeliveryServiceFee()))
            .map(StoreDelivery::getDeliveryWindow).filter(windowFee -&gt; Objects.nonNull(windowFee.getFee()));
}
}

","java, lambda, java-stream, option-type",2,74322620,"Since you cannot modify these classes, you will need to rely on each of the getter methods of these classes. And, since all of the needed values are components and subcomponents of the CartEntry class, all you need is create a stream of all the fulfillments and use the getter methods to accumulate the sum of each of these values.
List&lt;CartEntry&gt; entries = List.of(new CartEntry(), new CartEntry());
        
double total =
    entries.stream()
        .mapToDouble(entry -&gt; entry.getTotalDeliveryFee()
            .add(entry.getFulfillment().getStoreDelivery().getCost()
                .add(entry.getFulfillment().getStoreDelivery()
                        .getDeliveryServiceFee().add(entry.getFulfillment()
                        .getStoreDelivery().getDeliveryWindow().getFee())))
            .doubleValue())
        .sum();     

That gathers all the totals from components and subcomponents of the CartEntry class.
One last observation: Since the classes are using annotations to guarantee &quot;not null&quot; objects and for decimal values to have a minimum value of 0.0, my assumption is that the use of Optional is really not needed. All subcomponents of CartEntry appear to be automatically created with a value of 0.0. If that assumption is correct, the above function should work perfectly as is. If the assumption is incorrect, then it will be required to  use Optional.of() and then return 0.0 for null decimal values.
"
73543246,Can I use the service account of a GCP VM (xxx-compute@developer.gserviceaccount.com) instead of SA json file to make api calls using python?,"Currently, I am using some xxxx service account credential json file to make REST API Calls
from logging import exception
import requests
import ast
import json
import re
import sys
import subprocess
import os
from googleapiclient import discovery
from oauth2client.client import GoogleCredentials
from google.oauth2 import service_account
from datetime import datetime
from datetime import timedelta

main_list = []

# Get the credentials from service account
credentials = service_account.Credentials.from_service_account_file(&quot;path to the json file&quot;)
service = discovery.build('cloudresourcemanager', 'v1', credentials=credentials)

I do not want to use this json file anymore, instead i want to use Compute Engine service account (xxx-compute@developer.gserviceaccount.com) to call API's, Can someone tell me what change i have to do in python so that it uses VM's service account??
","python, google-cloud-platform",0,73545301,"I encourage you to use Application Default Credentials (ADC).
See this Python example.
ADCs means your code is unchanged whether you run it locally or on Google Cloud.
When you test your code off Google Cloud, you can export GOOGLE_APPLICATION_CREDENTIALS=/path/to/your/key.json and ADC will use the exported credentials.
When you deploy your code to Google Cloud, ADC obtains the credentials (for the resource that's running the code) from Google's Metadata service.
For example, when you run ADC code on Compute Engine, ADC will obtain the instance's (!) Service Account.
You should try to always use instance|role-specific Service Accounts but the default Compute Engine account is a Service Account too and will work.
Be aware that you'll need to ensure that whatever Service Account(s) is/are used have the correct IAM permissions to access other services.
"
72978467,Visual Studio Code: How to change repo & see current repo,"I'm pretty new into Visual Studio Code.
Does anyone know how I can find the current target repo.
I also asked my self how I can change the current repo.
","visual-studio-code, repository, repo",1,72978629,"If you mean, find the folder currently open in your workspace, simply hover over the filename of an open file to see the path to it.
If you mean, open up a new folder within the workspace, go to File &gt; Open Folder &gt; Then browse to desired folder.
"
74204364,Is it OK to use Django development server for single-user applications?,"I'm developing an application that controls some piece of complex hardware and exposes a front-end to the users using Django, mainly for cross-platform and remote access reasons. Currently using Django templates, but soon with a separate front-end through DRF calls. My main points of interest are:

user management. Admin users have more access
session management. Ideally, one cannot login from multiple IPs at the same time.
web-socket support for asynchronous notifications and real-time monitoring.
asynchronous background operations. e.g. with celery workers

Note that the users of these application are the hardware operators which are usually no more than 3-5 tops, and most of the times, only one of them is actively working on it so no real user concurrency, neither real need to scale.
So my question is: Is there a real reason I would want to distribute my application using a production server such as gunicorn instead of simply running manage.py runserver?
","python, django, django-rest-framework, gunicorn",1,74204538,"From django runserver documentation:

DO NOT USE THIS SERVER IN A PRODUCTION SETTING. It has not gone through security audits or performance tests. (And thatâ€™s how itâ€™s gonna stay. Weâ€™re in the business of making Web frameworks, not Web servers, so improving this server to be able to handle a production environment is outside the scope of Django.)

The development server is not intended for use in production. It is not designed to be particularly efficient, stable, or secure. It does not support all the possible features of an HTTP server.
In short, python manage.py runserver may work until it breaks!!
"
73573447,"Mapped typed within mapped type generic does work, except it doesnt","Here is the ts playground
I want to create a type, which creates an object out of the keys of a given object, with the values being another object created out of the union type of the given object.
// It works, but Typescript is unhappy
type makeSortOptions&lt;T extends Record&lt;&quot;albums&quot; | &quot;tracks&quot;, string&gt;&gt; = {
  [key in keyof T]: { [value in T[key]]: &quot;ascending&quot; | &quot;descending&quot; }
}

type SortOptions = makeSortOptions&lt;
  {
    albums: &quot;title&quot;
    tracks: &quot;title&quot; | &quot;artist&quot;
  }
&gt;

// SortOptions is of the expected type
// but why is Typescript unhappy with the utillity type?
const x: SortOptions = {
  albums: { title: &quot;descending&quot; },
  tracks: {
    artist: &quot;descending&quot;,
    title: &quot;ascending&quot;,
  },
}

// Does as expected not work
const y: SortOptions = {
  albums: { title: &quot;space and time&quot; }, 
  tracks: {
    artist: &quot;foo&quot;,
    bar: &quot;ascending&quot;,
  },
}

And that is the error I am getting:
Type 'T[key]' is not assignable to type 'string | number | symbol'.
  Type 'T[keyof T]' is not assignable to type 'string | number | symbol'.
    Type 'T[string] | T[number] | T[symbol]' is not assignable to type 'string | number | symbol'.
      Type 'T[string]' is not assignable to type 'string | number | symbol'.ts(2322)

","typescript, typescript-generics",-1,73573629,"TypeScript is not happy because T[key] could theoratically be a type which is not string, number or symbol.
Imagine this call:
type SortOptions = makeSortOptions&lt;
  {
    albums: &quot;title&quot;
    tracks: &quot;title&quot; | &quot;artist&quot;
    zzz: { a: 123 }
  }
&gt;

It is totally valid to call makeSortOptions with this object, but the zzz property contains an object which can not be used as a key.

I would put the valid Keys in an extra type.
type Keys = &quot;albums&quot; | &quot;tracks&quot;

type makeSortOptions&lt;T extends Record&lt;Keys, string&gt;&gt; = {
  [key in Keys]: { [value in T[key]]: &quot;ascending&quot; | &quot;descending&quot; }
}

Instead of mapping over keyof T (which could lead to non-keyable types), we map over Keys. And through the constraint T extends Record&lt;Keys, string&gt;, TypeScript knows that every key of Keys must lead to a string type.
Playground

You could also just intersect it with a string.
type makeSortOptions&lt;T extends Record&lt;&quot;albums&quot; | &quot;tracks&quot;, string&gt;&gt; = {
  [key in keyof T]: { [value in T[key] &amp; string]: &quot;ascending&quot; | &quot;descending&quot; }
}

Non-string types would then evaluate to never and would not show up in the type.
Playground
"
73387665,How to select subject from an auto complete option?,"Website link- https://demoqa.com/automation-practice-form/
I am trying to find xpath for an auto suggested option for Subject field

","selenium, xpath, autocomplete",0,73388318,"This is one way of interacting with that dropdown:
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import Select
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.common.keys import Keys

chrome_options = Options()
chrome_options.add_argument(&quot;--no-sandbox&quot;)
chrome_options.add_argument('disable-notifications')
chrome_options.add_argument(&quot;window-size=1280,720&quot;)

webdriver_service = Service(&quot;chromedriver/chromedriver&quot;) ## path to where you saved chromedriver binary
browser = webdriver.Chrome(service=webdriver_service, options=chrome_options)
actions = ActionChains(browser)

url = 'https://demoqa.com/automation-practice-form/'
browser.get(url) 

WebDriverWait(browser, 20).until(EC.element_to_be_clickable((By.ID, &quot;subjectsInput&quot;))).send_keys('m')

elusive_el = WebDriverWait(browser, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, &quot;.subjects-auto-complete__menu&quot;)))
print(elusive_el.get_attribute('outerHTML'))
maths_option = elusive_el.find_element(By.XPATH, &quot;//div[text()='Maths']&quot;)
maths_option.click()
print('selected maths')

This should select the Math option, and also print in terminal the html structure of that element, so you can inspect them, and eventually select other child elements as well - you will have to send another string into that input field, wait for the dropdown to initialize, select another option.
Selenium docs: https://www.selenium.dev/documentation/
"
73535528,unimplemented type 'list' in 'listgreater' error in R when using cast,"I'm trying to cast a simple dataframe using R.  It's been melted using melt(). Here's the structure of the melted dataframe:
&gt; str(pMaster)
'data.frame':   172 obs. of  7 variables:
 $ Year          : chr  &quot;1788&quot; &quot;1792&quot; &quot;1796&quot; &quot;1800&quot; ...
 $ TotalVotesCast: num  43782 28579 66840 67280 143028 ...
 $ result        : chr  &quot;RunnerUp&quot; &quot;RunnerUp&quot; &quot;RunnerUp&quot; &quot;RunnerUp&quot; ...
 $ candidate     : chr  &quot;No candidate&quot; &quot;No candidate&quot; &quot;Thomas Jefferson&quot; &quot;Aaron Burr&quot; ...
 $ party         : chr  NA NA &quot;D-R&quot; &quot;D-R&quot; ...
 $ PopPct        : num  0 0 46.5 38.6 27.2 ...
 $ PopVotes      : num  0 0 31115 25952 38919 ...

And here's what I get when I try to cast it:
&gt; cast(pMaster, Year ~ result, value = &quot;PopVotes&quot;, fun.aggregate = sum)
Error in order(Year = c(&quot;1788&quot;, &quot;1788&quot;, &quot;1792&quot;, &quot;1792&quot;, &quot;1796&quot;, &quot;1796&quot;,  : 
  unimplemented type 'list' in 'listgreater'

Nothing I try seems to solve the error I'm getting.  I am able to cast things if I use a variable other than Year, but I can't see anything about the data in the Year column that looks like it could be causing trouble.  I've done some searching here on SO and elsewhere, but was surprised to see there isn't that much on whatever &quot;listgreater&quot; is.   Any ideas, anyone?  Thanks for any help.
",r,0,73547648,"Can you do something similar with pivot_wider and pivot_longer from the tidyr package? I haven't used the case/melt framework in some time, and I'm wondering if the language has moved away from it.
"
73235410,How do server programs work on Docker when *only* the listening port is mapped to the Docker host?,"This is just a conceptual question that I have been thinking about recently.
Say I'm running an Nginx container on Docker on a host. Normally, for this to work, we have to map ports like 80 and 443 to host container. This is because these are listening ports, and connections from the outside world to port 80 should be forwarded to port 80 of the container. So far so good.
But also: port 80 is just the listening socket, right? The listening socket only accepts the connection; after this any communication done between a client and the Nginx server is supposedly done on a different socket with a random port number (on the server side). This is to allow multiple connections, and to keep the listening port free to establish more connections, etc. This is where my issue comes in.
Say I'm a client and I connect to this Nginx server. As far as I understand, I first send TCP packets to port 80 of the host that is hosting this Nginx Docker container. But during the establishment of the connection, the server changes their port to another number, say 45670. (Not sure how, but I am guessing the packets that are sent back suddenly mention this port, and our client will continue the rest of the exchange with this port number instead).
But now as I send packets (e.g. HTTP requests) to the host on port 45670, how will the Nginx docker container see those packets?
I am struggling to understand how server processes can run on Docker with only one port exposed / published for mapping.
Thanks!
","docker, sockets, nginx",-1,73235673,"
But also: port 80 is just the listening socket, right? The listening socket only accepts the connection; after this any communication done between a client and the Nginx server is supposedly done on a different socket with a random port number (on the server side).

Nope. When a connection is established, the client side is a random port number (usually) and the server side is the same port that the server listens on.
In TCP there aren't actually listening sockets - they're an operating system thing - and a connection is identified by the combination of both the port numbers and both the IP addresses. The client sends a SYN (&quot;new connection please&quot;) from its port 49621 (for example) to port 80 on the server; the server sends a SYN/ACK (&quot;okay&quot;) from its port 80 to port 49621 on the client.
"
74234235,How to do SQL Server date formatting,"I am preparing a query on sql server. But I'm stuck with the date format.
I want the date format to be at the bottom. If there are letters in it, I don't want it to appear. The ISDATE command only accepts the EN date format.
I want to write it as digit2/digit2/digit4 like alt.
SELECT TOP 4  * FROM A AS T WHERE 1 = 1 AND ISNUMERIC(T.Id) = 1


11111111111 FIRSTNAME LASTNAME 19.10.1965
11111111111 FIRSTNAME LASTNAME 15.8.1980
11111111111 FIRSTNAME LASTNAME 12.8.2015
11111111111 FIRSTNAME LASTNAME 3.3.1967

","sql, sql-server, regex, regexp-replace",0,74234513,"ISDATE is the wrong approach here because it only supports a narrow range of formats and relies on the regional/language settings of the caller, e.g.:
SELECT ISDATE('19.10.1965'), -- 0
       ISDATE('10.19.1965'); -- 1

SET LANGUAGE TÃ¼rkÃ§e;

SELECT ISDATE('19.10.1965'), -- 1
       ISDATE('10.19.1965'); -- 0

Trying to match a pattern like digit2/digit2/digit4 is also the wrong approach, since it will allow &quot;dates&quot; like 31/02/3456 and 99/99/0000.
Try:
SELECT TRY_CONVERT(date, '19.10.1965', 104);

As a filter:
... WHERE TRY_CONVERT(date, date_column, 104) IS NOT NULL;

Also I would stay away from PARSE/TRY_PARSE/FORMAT as the CLR overhead can be substantial.
"
74471297,Typescript Type Flatten Child nested objects,"i have been following this example  and here  to flatten a type invain.  Most of this flatten the object completely into  removing the nests. I would like to to maintain my structure, just removing some wrappers (in this case body) in the nested objected which can be anything and n deep.
I would like to transform my type from
type TestInterface {
  id: string
  body: {
    title: string 
    something: string 
    user: {
      id: string
      body: {
        firstname: string
        lastname: string
        age: number
      }
    }
    country: {
      id: string
      body: {
        code: string
        name: string
        region: {
          id: string
          body: {
            code: string
            name: string
            continent: {
              id: string
              body: {
               code: string
               name: string
              }
            }
          }
        }
      }
    }
  }
}

the required output is the same type structure above but with the body wrapper dropped.
type TestInterface {
  id: string
  title: string 
  something: string 
  user: {
    id: string
    firstname: string
    lastname: string
    age: number
  }
  country: {
    id: string
    code: string
    name: string
    region: {
      id: string
      code: string
      name: string
      continent: {
        id: string
        code: string
        name: string
      }
    }
  }
}

","typescript, typescript-typings, typescript-generics, flatten, infinite-recursion",0,74471502,"type Pure&lt;T&gt; = T extends object ? {[K in keyof T]: T[K]} : T
type Flatten&lt;T&gt; = Pure&lt;
| T extends {body: any} ? Flatten2&lt;Omit&lt;T, 'body'&gt; &amp; T['body']&gt; : Flatten2&lt;T&gt;
&gt;
type Flatten2&lt;T&gt; = T extends object ? {[K in keyof T]: Flatten&lt;T[K]&gt;} : T

type X = Flatten&lt;TestInterface&gt;

Playground
"
73616926,Reducing the number of ticks in the colorbar using Matplotlib,"How do I reduce the number of ticks on the colorbar and ensure that the values are equi-spaced? Basically, the 8 color bands have to be equally spaced between Amin=257 and Amax=454 i.e. the length of each colorband =(Amax-Amin)/8. I present the current and expected outputs.
import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
import numpy as np
from matplotlib.colors import Normalize
from matplotlib import cm
import math
from  numpy import nan

fig,aPe = plt.subplots(1)
n=3

N=2*n*(n-1)

J = np.array([[]])
Pe=np.array([[394.20560747663563, 408.7929050665396 , 419.132709901089  ,
        398.95097406721044, 403.81198021076113, 430.00914784982064,
        424.50127213826016, 453.54817733128607, 441.4651085668709 ,
        447.42507960635163, 413.8982415602072 , 390.3025816600353 ],
            
[394.20560747663563, 408.7929050665396 , 419.132709901089  ,
         398.95097406721044, 403.81198021076113, 430.00914784982064,
         424.50127213826016, 453.5481773312857 , 347.7309476270773 ,
         257.42585381716805, 413.8982415602072 , 390.3025816600353 ]])         
             
C1 = nan
for i in J[0]:
    Pe = np.insert(Pe, i, [C1], axis=1)
print(&quot;Pe =&quot;, [Pe])

for i in range(0,len(Pe)):
    Max=max(max(Pe[i]), max(Pe[i]))
    Min=min(min(Pe[i]), min(Pe[i]))
a=Min
b=Max
Amax= math.ceil(Max)
Amin= math.floor(Min)
print(Amax, Amin)

color = cm.get_cmap('Dark2')
norm = Normalize(vmin=Amin, vmax=Amax)
color_list = []
for i in range(len(Pe[0])):   
    color_list.append(color(((Pe[0,i])-Amin)/(Amax-Amin)))
    
id = 0
for j in range(0, n):
    for k in range(n-1):
        aPe.hlines(200+200*(n-j-1)+5*n, 200*(k+1)+5*n, 200*(k+2)+5*n, zorder=0, colors=color_list[id])
        id += 1

    for i in range(0, n):
        rect = mpl.patches.Rectangle((200+200*i, 200+200*j), 10*n, 10*n, linewidth=1, edgecolor='black', facecolor='black')
        aPe.add_patch(rect)
        if j &lt; n-1:
            aPe.vlines(200+200*i+5*n, 200*(n-1-j)+5*n, 200*(n-j)+5*n, zorder=0, colors=color_list[id])
            id += 1

cb = fig.colorbar(cm.ScalarMappable(cmap=color, norm=norm), ticks=np.arange(Amin, Amax+len(color.colors), len(color.colors)))
cb.set_label(&quot;Entry pressure (N/m$^{2}$)&quot;)
aPe.set_xlim(left = 0, right = 220*n)
aPe.set_ylim(bottom = 0, top = 220*n)
plt.axis('off')
plt.show()

The current output is

The expected output is

","python, matplotlib",0,73617187,"Once you have created the colorbar, add this line to set the ticks to the way shown in your pic.
cb.set_ticks(np.arange(Amin, Amax+1, (Amax-Amin)/8).astype(np.int64))

Plot

"
73574161,How do I change my default Qt Creator property window's Color picker?,"I'm just familiarizing myself with QT Creator, and so I may use incorrect terminology.  I've been trying to research this myself, but must not be choosing my keywords properly.
I'm trying to find the location of the setting or preference within the Creator 8.0.1 IDE that allows me to see different properties of a selected object's colors instead of the one's presented by default.
Instead of this:


I'm hoping for this:

Also, and likely related, when I click the &quot;Color&quot; in the current setup, the Color Select Dialog that appears looks like this:

Is it possible, and I think it may fix itself if the properties color options issue above is solved, to have the default selector be this one?

If I double-click on an object within the design window, I get that selector, but if I click on the color within the properties panel, then I get the previous one.
I'm happy to provide any other info you may need:

Qt Creator 8.0.1

QML imports:

import QtQuick 2.15
import QtQuick.Window 2.15
import QtQuick.Controls 2.15

","qt, ide, preferences",1,74139376,"The ColorEditor you're showing is the Qt Design Studio custom ColorEditor for the PropertyEditor. This was a change made in QtDS 2.2 release.
The first image is showing the integrated minimal color editor in the PropertyEditor, the second one is showing the old (pre QtDS 2.2) ColorEditor that needed a complete section. The decision was made that it needed a slimmer version of the ColorEditor and the full ColorEditor on demand. The third image is showing the new full ColorEditor of QtDS.
You can get the operation system ColorDialog in the new version of the QtDS ColorEditor by right-clicking on the ColorPicker in the full ColorEditor and choosing &quot;Open Color Dialog&quot; from the context menu.

"
74598647,Return entire row from table and columns from other tables,"I'm using postgresql 14 and trying to return an entire record from a table in addition to columns from different tables. The catch is, that I don't want to write all the titles in the record. I tried working with the guide lines here [1], but I'm getting different errors. Can anyone tell me what I'm doing wrong?
CREATE OR REPLACE FUNCTION public.get_license_by_id(license_id_ integer)
    RETURNS TABLE(rec tbl_licenses, template_name character varying, company_name character varying)
    LANGUAGE 'plpgsql'
    COST 100
    VOLATILE SECURITY DEFINER PARALLEL UNSAFE
    ROWS 1000

AS $BODY$
DECLARE
BEGIN 
    CREATE TEMPORARY TABLE tempTable AS (
        SELECT 
            (rec).*, B.company_name, C.template_name 
            -- Tried using A instead of (rec).* with error: column &quot;a&quot; has pseudo-type record
        FROM 
        (
            (SELECT * FROM tbl_licenses) A
            LEFT JOIN
            (SELECT * FROM tbl_customers) B on A.customer_id = B.customer_id
            LEFT JOIN
            (SELECT * FROM tbl_templates) C on A.template_id = C.template_id
        )
    );
    UPDATE tempTable
    SET license = '1'
    WHERE tempTable.license IS NOT NULL;
    RETURN QUERY ( 
        SELECT * FROM tempTable
    );
    
    DROP TABLE tempTable;
    RETURN;
END;
$BODY$;

I'm calling the function like SELECT rec FROM get_license_by_id(1);
but getting:

ERROR:  structure of query does not match function result type
DETAIL:  Returned type integer does not match expected type tbl_licenses in column 1.

","postgresql, postgresql-14",0,74598944,"You need to cast the A alias to the correct record type. However the nested derived tables are not necessary for the other tables. If you use a coalesce() for the license column in the SELECT, then you get get rid of the inefficient creation and update of the temp table as well.
CREATE OR REPLACE FUNCTION get_license_by_id(license_id_ integer)
  RETURNS TABLE(rec tbl_licenses, template_name character varying, company_name character varying)
  LANGUAGE sql
  STABLE
AS $BODY$
  SELECT a::tbl_licenses, -- this is important
         B.company_name, C.template_name 
  FROM (
    select license_id, customer_id, ... other columns ..., 
           coalesce(license, '1') as license -- makes the temp table unnecessary
    from tbl_licenses A
  ) a
    LEFT JOIN tbl_customers B on A.customer_id = B.customer_id
    LEFT JOIN tbl_templates C on A.template_id = C.template_id
  where a.license_id = license_id_;
$BODY$
;

"
74433987,python concurrent.futures.ProcessPoolExecutor crashing with full RAM,"Python concurrent.futures.ProcessPoolExecutor crashing with full RAM
Program description
Hi, I've got a computationally heavy function which I want to run in parallel. The function is a test that accepts as inputs:

a DataFrame to test on
parameters based on which the calculations will be ran.

The return value is a short list of calculation results.
I want to run the same function in a for loop with different parameters and the same input DataFrame, basically run a brute-force to find optimal parameters for my problem.
The code I've written
I currently am running the code concurrently with ProcessPoolExecutor from the module concurrent.futures.
import concurrent.futures
from itertools import repeat
import pandas as pd

from my_tests import func


parameters = [
    (arg1, arg2, arg3),
    (arg1, arg2, arg3),
    ...
]
large_df = pd.read_csv(csv_path)

with concurrent.futures.ProcessPoolExecutor() as executor:
    for future in executor.map(func, repeat(large_df.copy()), parameters):
        test_result = future.result()
        ...

The problem
The problem I face is that I need to run a large amount of iterations, but my program crashes almost instantly.
In on order for it not to crash, I need to limit it to max 4 workers, which is 1/4 of my CPU resources.
with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:
    ...

I figured out my program crashes due to a full RAM (16 GB). What I found weird is that when I was running it on more workers, it was gradually eating more and more RAM, which it never released, until it crashed.
Instead of passing a copy of the DataFrame, I tried to pass the file path, but apart of slowing down my program, it didn't change anything.
Do you have any idea of why that problem occurs and how to solve it?
","python, multiprocessing, concurrent.futures, process-pool",1,74450459,"See my comment on what map actually returns.
This answer is relevant according to how large your parameters list is, i.e. how many total tasks are being placed on the multiprocessing pool's task queue:
You are currently creating and passing a copy of your dataframe (with large_df.copy()) every time you are submitting a new task (one task for each element of parameters. One thing you can do is to initialize your pool processes once with a single copy per pool process that will be used by every task submitted and executed by the pool process.  The assumption is that the dataframe itself is not modified by my_tests.func. If it is modified and you need a copy of the original large_df for each new task, the function worker (see below) can make the copy. In this case you would need 2 * N copies (instead of just N copies) to exist simultaneously where N is the number of processes in the pool. This will save you memory if the length of parameters is greater than that since in your code a copy of the dataframe will exist either on the task queue or in a pool process's address space.
If you are running under a platform such as Linux that uses the fork method to create new processes, then each child process will inherit a copy automatcally as a global variable:
import concurrent.futures
import pandas as pd

from my_tests import func


parameters = [
    (arg1, arg2, arg3),
    (arg1, arg2, arg3),
    ...
]

large_df = pd.read_csv(csv_path) # will be inherited

def worker(parameter):
    return func(large_df, parameter)
    &quot;&quot;&quot;
    # or:
    return func(large_df.copy(), parameter)
    &quot;&quot;&quot;

with concurrent.futures.ProcessPoolExecutor() as executor:
    for result in executor.map(worker, parameters):
        ...

my_tests.func is expecting as its first argument a dataframe, but with the above change the dataframe is no longer being passed; the dataframe is now accessed as a global variable. So without modifying func, we need am adapter function, worker, that will pass to func what it is expecting. Of course, if you are able to modify func, then you can do without the adapter.
If you were running on a platform such as Windows that uses the spawn method to create new processes, then:
import concurrent.futures
import pandas as pd

from my_tests import func

def init_pool_processes(df):
    global large_df
    large_df = df


def worker(parameter):
    return func(large_df, parameter)
    &quot;&quot;&quot;
    # or:
    return func(large_df.copy(), parameter)
    &quot;&quot;&quot;

if __name__ == '__main__':
    
    parameters = [
        (arg1, arg2, arg3),
        (arg1, arg2, arg3),
        ...
    ]
    
    large_df = pd.read_csv(csv_path) # will be inherited
    
    with concurrent.futures.ProcessPoolExecutor(initializer=init_pool_processes, initargs=(large_df,)) as executor:
        for result in executor.map(worker, parameters):
            ...

"
73315006,Trying to separate bars in two overlayed bar charts in ggplot,"I am trying to create a single chart from two created bar charts to show the differences in their distribution. I have both charts merging together, and the axis labels are correct. However, I cannot figure out how to get the bars in each section to be next to each other for comparison instead of overlaying. Data for this chart are two variables within the same DF. I am relatively new to r and new to ggplot so even plotting what I have was a challenge. Please be kind and I apologize if this is a question that has been answered before.
Here is the code I am using:
Labeled &lt;- ggplot(NULL, aes(lab),position_dodge(.5)) + ggtitle(&quot;Figure 1. Comparison of Distribution of Age of Diagnosis and Age of Feeding Challenges&quot;)+
  geom_bar(aes(x=AgeFactor,fill = &quot;Age of Autism Diagnosis&quot;), data = Graph, alpha = 0.5,width = 0.6) +
  geom_bar(aes(x=FdgFactor,fill = &quot;Feeding Challenge Onset&quot;), data = Graph, alpha = 0.5,width=.6)+
  scale_x_discrete(limits=c(&quot;0-6months&quot;,&quot;7-12months&quot;,&quot;1-1.99&quot;,&quot;2-2.99&quot;,&quot;3-3.99&quot;,&quot;4-4.99&quot;,&quot;5-5.99&quot;,&quot;6-6.99&quot;,&quot;7-7.99&quot;,&quot;8-8.99&quot;,&quot;9-9.99&quot;,&quot;10-10.99&quot;))+
  xlab(&quot;Age&quot;)+
  ylab(&quot;&quot;)+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  scale_fill_discrete(name = &quot;&quot;)

and this is the graph it is creating for me:

I really appreciate any insight. This is my first time asking a question on stack too - so I am happy to edit/adjust info as needed.
","r, ggplot2",1,73316122,"The issue is that you plot from different columns of your dataset. To dodge your bars position_dodge requires a column to group the data by. To this end you could reshape your data to long format using e.g. tidyr::pivot_longer so that your two columns are stacked on top of each other and you get a new column containing the column or group names as categories.
Using some fake random example data. First I replicate your issue with this data and your code:
set.seed(123)

levels &lt;- c(&quot;0-6months&quot;, &quot;7-12months&quot;, &quot;1-1.99&quot;, &quot;2-2.99&quot;, &quot;3-3.99&quot;, &quot;4-4.99&quot;, &quot;5-5.99&quot;, &quot;6-6.99&quot;, &quot;7-7.99&quot;, &quot;8-8.99&quot;, &quot;9-9.99&quot;, &quot;10-10.99&quot;)

Graph &lt;- data.frame(
  AgeFactor = sample(levels, 100, replace = TRUE),
  FdgFactor = sample(levels, 100, replace = TRUE),
  lab = 1:100
)

library(ggplot2)

ggplot(NULL, aes(lab), position_dodge(.5)) +
  ggtitle(&quot;Figure 1. Comparison of Distribution of Age of Diagnosis and Age of Feeding Challenges&quot;) +
  geom_bar(aes(x = AgeFactor, fill = &quot;Age of Autism Diagnosis&quot;), data = Graph, alpha = 0.5, width = 0.6) +
  geom_bar(aes(x = FdgFactor, fill = &quot;Feeding Challenge Onset&quot;), data = Graph, alpha = 0.5, width = .6) +
  scale_x_discrete(limits = c(&quot;0-6months&quot;, &quot;7-12months&quot;, &quot;1-1.99&quot;, &quot;2-2.99&quot;, &quot;3-3.99&quot;, &quot;4-4.99&quot;, &quot;5-5.99&quot;, &quot;6-6.99&quot;, &quot;7-7.99&quot;, &quot;8-8.99&quot;, &quot;9-9.99&quot;, &quot;10-10.99&quot;)) +
  xlab(&quot;Age&quot;) +
  ylab(&quot;&quot;) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  scale_fill_discrete(name = &quot;&quot;)


And now the fix using reshaping. Additionally I simplified your code a bit:

library(tidyr)
library(dplyr)

Graph_long &lt;- Graph %&gt;%
  select(AgeFactor, FdgFactor) %&gt;%
  pivot_longer(c(AgeFactor, FdgFactor))
  
ggplot(Graph_long, aes(x = value, fill = name)) +
  geom_bar(alpha = 0.5, width = 0.6, position = position_dodge()) +
  scale_fill_discrete(labels = c(&quot;Age of Autism Diagnosis&quot;, &quot;Feeding Challenge Onset&quot;)) +
  scale_x_discrete(limits = levels) +
  labs(x = &quot;Age&quot;, y = NULL, fill = NULL, title = &quot;Figure 1. Comparison of Distribution of Age of Diagnosis and Age of Feeding Challenges&quot;) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))


"
74026877,terraform create billing budget on GCP,"When I try to create a billing budget for a project using terraform, I get the following error message:
Error: Error creating Budget: googleapi: Error 403: Your application has authenticated using end user credentials from the Google Cloud SDK or Google Cloud Shell which are not supported by the billingbudgets.googleapis.com. We recommend configuring the billing/quota_project setting in gcloud or using a service account through the auth/impersonate_service_account setting. For more information about service accounts and how to use them in your application, see https://cloud.google.com/docs/authentication/. If you are getting this error with curl or similar tools, you may need to specify 'X-Goog-User-Project' HTTP header for quota and billing purposes. For more information regarding 'X-Goog-User-Project' header, please check https://cloud.google.com/apis/docs/system-parameters.
Details:
[
  {
    &quot;@type&quot;: &quot;type.googleapis.com/google.rpc.ErrorInfo&quot;,
    &quot;domain&quot;: &quot;googleapis.com&quot;,
    &quot;metadata&quot;: {
      &quot;consumer&quot;: &quot;projects/543254326546&quot;,
      &quot;service&quot;: &quot;billingbudgets.googleapis.com&quot;
    },
    &quot;reason&quot;: &quot;SERVICE_DISABLED&quot;
  }
]

The project that I logged in to has the API service billingbudgets.googleapis.com enabled.
The following roles are assigned to my service account:
Actions Admin
Billing Account Usage Commitment Recommender Admin
Billing Account Usage Commitment Recommender Viewer
Project Billing Manager
Service Usage Admin
Service Usage Consumer
Billing Account Administrator

My terraform code:
resource &quot;google_billing_budget&quot; &quot;budget&quot; {
  billing_account = var.billing_account
  display_name    = var.name

  budget_filter {
    projects               = [var.projects]
  }

  amount {
    specified_amount {
      currency_code = &quot;USD&quot;
      units = var.budget_amount
    }
  }

  threshold_rules {
    threshold_percent = var.budget_threshold
  }
}

With the gcloud SDK, I'm able to create the budget and I don't get any errors.
Here is the command I run to create the budget:
gcloud billing budgets create --billing-account=0FFF0-FFFFF-CBFFFF --display-name=test-daniel --budget-amount=100USD --project=testproject

","google-cloud-platform, terraform-provider-gcp",0,74039346,"As per this git issue, Adding billing.admin role to the Terraform Service Account solves your issue.
And check this issue if the issue still continues after adding the role.
"
73185851,GNU memmem vs C strstr,"Is there any use case that can be solved by memmem but not by strstr?
I was thinking of able to parse a string raw bytes (needle) inside a bigger string of raw bytes(haystack). Like trying to find a particular raw byte pattern inside a blob of raw bytes read from C's read function.
",c,0,73186122,"There is the case you mention: raw binary data.
This is because raw binary data may contain zeroes, which are interpreted and string terminator by strstr, making it ignore the rest of the haystack or needle.
Additionally, if the raw binary data contains no zero bytes, and you don't have a valid (inside the same array or buffer allocation) extra zero after the binary data, then strstr will happily go beyond the data and cause Undefined Behavior via buffer overflow.

Or, to the point: strstr can't be used if the data is not strings. memmem doesn't have this limitation.
"
74328779,"Is there a way to get ""text"" or ""fg_color"" value from custom Tkinter button widget?","I have a customtkinter (CTk) button widget that, when pressed, sends an encoded message to a client depending on the button's &quot;text&quot; value; in this case, if the button's text is &quot;Off&quot;, it sends the message &quot;On&quot; and vice versa to the client.
import tkinter as tk
import traceback
import customtkinter as cust
import socket
from threading import Thread
from tkinter import messagebox

class GUI2(cust.CTk): #second window; not the root

    def __init__(self):

        super().__init__()

        self.PORT = 5000
        
        self.SERVER = socket.gethostbyname(socket.gethostname())
        
        self.ADDRESS = (self.SERVER, self.PORT)
       
        self.FORMAT = &quot;utf-8&quot;
        
        self.clients = [] #list to store all client connections
       
        self.server = socket.socket(socket.AF_INET,
                            socket.SOCK_STREAM)
        
        self.server.bind(self.ADDRESS)
        

        self.master2 = cust.CTkToplevel()
        
        self.ecdpower = cust.CTkButton(self.master2, text = &quot;Off&quot;, fg_color = &quot;Black&quot;, text_color = &quot;White&quot;, hover_color = &quot;Silver&quot;, command = lambda: Thread(target = self.startstream).start())
        self.ecdpower.grid(row = 0, column = 0) #button to send message to client connections
        
        self.thread = Thread(target = self.startChat)

        self.thread.start() #starts function to accept client connections
        
    def startChat(self): #function to accept client connections

        self.server.listen(30)

        try:

            while True:

                    self.conn, self.addr = self.server.accept()
                    
                    self.clients.append(self.conn) #stores all client connections

        except:

            pass 
            
    def startstream(self):

        
        try:

            if not self.clients: #checks if list is empty

                messagebox.showerror(&quot;No Connections!&quot;, &quot;No clients connected to host!&quot;)

            else:

                for x in self.clients:

                    if self.ecdpower[&quot;text&quot;] == &quot;Off&quot;: #ecdpower button widget acts like a &quot;power button&quot;

                        self.ecdpower.configure(text = &quot;On&quot;, fg_color = &quot;Green&quot;)

                        x.send((&quot;On&quot;).encode(self.FORMAT))

                    else:
                        
                        self.ecdpower.configure(text = &quot;Off&quot;, fg_color = &quot;Red&quot;)

                        x.send((&quot;Off&quot;).encode(self.FORMAT))

        except:

            print (traceback.format_exc())    

Error is as follows:
Traceback (most recent call last):
  File &quot;f:\project\mainmenu.py&quot;, line 390, in startstream
  File &quot;F:\Program Files (x86)\Python\lib\tkinter\__init__.py&quot;, line 1681, in cget
    return self.tk.call(self._w, 'cget', '-' + key)
_tkinter.TclError: unknown option &quot;-text&quot;

I have also tried if self.ecdpower.cget(&quot;text&quot;) == &quot;Off: and tried other values like fg_color; both result in the same error. When I removed the if condition, the message sending works correctly so the only problem is how to verify the button &quot;text&quot; value.
Any help to fix this or possible other alternatives is greatly appreciated.
","python, customtkinter",0,74336451,"Per @jasonharper's comment above, CTkButton is

not actually a Tkinter Button at all (it's made from a Frame containing a Canvas and a Label), so the normal Tkinter attribute-getting functions don't apply.

Instead of using self.ecdpower[&quot;text&quot;] or self.ecdpower.cget(&quot;text&quot;): I should use

self.ecdpower.text

to get the CTKbutton's text value.
The same can be applied with fg_color; use self.ecdpower.fg_color to get the value.
"
72969739,Extract Sample start value from Sampler result tab in JMeter,"I need to extract &quot;Sample start&quot; value means date &amp; time value from the Sampler result tab in JMeter.
Sample Start:2022-07-13 21:56:18 IST
Load time:1549
Connect Time:292

Is there any way to do that? Please suggest some solution.
","jmeter, jmeter-plugins, jmeter-5.0",0,72971859,"You can add a JSR223 PostProcessor as a child of the request which start time you want to &quot;extract&quot; and put the following code into &quot;Script&quot; area:
vars.put('start', new Date(prev.getStartTime()).format('yyyy-MM-dd HH:mm:ss zzz'))

it will store the parent Sampler start time into ${start} JMeter Variable
Demo:

More information on what do these prev and vars things mean: Top 8 JMeter Java Classes You Should Be Using with Groovy
"
74472565,Which data type to use for different configurations,"I have a 4 different configurations to be used and these configuration values are stored in a property file. The properties for all the configurations are same, but the values are different for each.
Ex:
The property file configurations I am using:
####Config1####
conf1.password=admin
conf1.username=admin
conf1.context=123
conf1.name=localhost

####config2####
conf2.username=app
conf2.password=app
conf2.context=com
conf2.name=localhost

####config3####
conf3.username=app
conf3.password=app
conf3.context=com
conf3.name=localhost

####config4####
conf4.username=app
conf4.password=app
conf4.context=com
conf4.name=localhost


I can get the properties from the property file. Is it possible to have a single variable to store these values based on configuration and access them in an optimised and readable way?
I tried using hash-map for every configuration separately and fetching it from that. But it is increasing my code redundancy as if I perform same steps for every configuration and if-elsed the configuration name to get the hashmap values.
Currently I am using the properties with hashmap like this:
HashMap&lt;String, String&gt; conf1 = new HashMap&lt;&gt;();
HashMap&lt;String, String&gt; conf2 = new HashMap&lt;&gt;();
HashMap&lt;String, String&gt; conf3 = new HashMap&lt;&gt;();
HashMap&lt;String, String&gt; conf4 = new HashMap&lt;&gt;();

conf1.put(&quot;UserName&quot;, prop.getProperty(â€œconf1.username&quot;));
conf1.put(&quot;Password&quot;,prop.getProperty(&quot;conf1.password&quot;));
conf1.put(â€œnameâ€,prop.getProperty(&quot;conf1.name&quot;));
conf1.put(&quot;contextâ€,â€conf1,contextâ€);

conf2.put(&quot;UserName&quot;, prop.getProperty(â€œconf2.username&quot;));
conf2.put(&quot;Password&quot;,prop.getProperty(&quot;conf2.password&quot;));
conf2.put(â€œnameâ€,prop.getProperty(&quot;conf2.name&quot;));
conf2.put(&quot;contextâ€,â€conf2,contextâ€);

conf3...
conf4...

if (Conf.equalsIgnoreCase(â€œconf1â€)) {
    GenerateTestFile(
          &quot;Name:â€œ + conf1.get(&quot;Name&quot;) + â€œ-UserName:â€ +
          conf1.get(&quot;UserName&quot;) + â€œ-Password:â€ + conf1.get(&quot;Password&quot;) + 
        &quot;-Context:â€ + conf1.get(â€œContextâ€) ,FileName);
} else if (Conf.equalsIgnoreCase(â€œconf2â€)) {
GenerateTestFile(
          &quot;Name:â€œ + conf2.get(&quot;Name&quot;) + â€œ-UserName:â€ +
          conf2.get(&quot;UserName&quot;) + â€œ-Password:â€ + conf2.get(&quot;Password&quot;) + 
        &quot;-Context:â€ + conf2.get(â€œContextâ€) ,FileName);
}
Else if(conf3){â€¦}
Else if(conf4){â€¦}


","java, properties-file",1,74475226,"You could use a Map&lt;String,Map&lt;String,String&gt;&gt; where the key is the name of the configuration, and the value (Map&lt;String,String&gt;) is the configuration parameters.
To load the file, you would do something like this:
private static Pattern RE = Pattern.compile(
        &quot;([A-Za-z0-9_-]+)\\.([A-Za-z0-9_-]+)&quot;);

private static Map&lt;String,Map&lt;String,String&gt;&gt; loadConfs(String name)
        throws IOException {
    Map&lt;String,Map&lt;String,String&gt;&gt; confs = new HashMap&lt;&gt;();
    Properties props = new Properties();
    ClassLoader cl = Thread.currentThread().getContextClassLoader();
    try (InputStream in = cl.getResourceAsStream(name)) {
        props.load(in);
    }
    for (String propName: props.stringPropertyNames()) {
        Matcher matcher = RE.matcher(propName);
        if (matcher.matches()) {
            String confName = matcher.group(1);
            String parmName = matcher.group(2);
            Map&lt;String,String&gt; conf = confs.get(confName);
            if (conf == null) {
                conf = new HashMap&lt;&gt;();
                confs.put(confName, conf);
            }
            conf.put(parmName, props.getProperty(propName));
        }
    }
    return confs;
}

You could then do something like this:
Map&lt;String,Map&lt;String,String&gt;&gt; confs = loadConfs(&quot;conf.properties&quot;);
...
Map&lt;String,String&gt; conf = confs.get(confName);
if (conf != null) {
    GenerateTestFile(
            &quot;Name:â€œ + conf.get(&quot;Name&quot;)
            + â€œ-UserName:â€ + conf.get(&quot;UserName&quot;)
            + â€œ-Password:â€ + conf.get(&quot;Password&quot;)
            + &quot;-Context:â€ + conf.get(â€œContextâ€),
            FileName);
}

"
74575521,Rename Azure Storage Table Column,"As the title says, is it possible to rename an Azure Storage Table column?
I tried using the portal and through storage explorer with no results
","azure, azure-table-storage",0,74576527,"Hmm.. Haven't had to do this before. But if I had to make a guess, it's that columns don't really exist in table storage. There is no schema anyway, you can include whatever fields in the objects. To rename a column, you'd probably have to go through all the objects and rename the field in them.
"
73102008,How to convert a dictionary with a tuple inside of a nested list?,"I'm trying to create a bigram from a dictionary with a specific condition. Below is the example of the dictionary:
dict_example = {'keywords1': ['africa',
  'basic service',
  'class',
  'develop country',
  'disadvantage',
  'economic resource',
  'social protection system']

The specific condition is that I want to create a bigram if the words in each element are more than 1. Below is the code that I have been working on so far:
keywords_bigram_temp = {}
keywords_bigram = {}
for k, v in dict_example.items():
    keywords_bigram_temp.update({k: [word_tokenize(w) for w in v]})
    for k2, v2 in keywords_bigram_temp.items():
        keywords_bigram.update({k2: [list(nltk.bigrams(v3)) for v3 in v2 if len(v3) &gt; 1]})

This code works, but instead of returning a normal tuple within a list (I think this is what bigram normally looked like), it returns a tuple within a nested list. Below is an example of the result:
'keywords1': [[('basic', 'service')],
  [('develop', 'country')],
  [('economic', 'resource')],
  [('social', 'protection'),
   ('social', 'system'),
   ('protection', 'system'),
   ('social', 'protection')]}

What I need is a normal bigram structure, a tuple within a list like so:
'keywords1': [('basic', 'service'),
  ('develop', 'country'),
  ('economic', 'resource'),
  ('social', 'protection'),
  ('protection', 'system')]}

","python, nltk",1,73102177,"Here's a way to do what your question asks using itertools.combinations():
from itertools import combinations
keywords_bigram = {'keywords1': [x for elem in dict_example['keywords1'] if ' ' in elem for x in combinations(elem.split(), 2)]}

Output:
{'keywords1': [('basic', 'service'), ('develop', 'country'), ('economic', 'resource'), ('social', 'protection'), ('social', 'system'), ('protection', 'system')]}

Explanation:

in the dict comprehension, use for elem in dict_example['keywords1'] if ' ' in elem to iterate over all items in the list associated with keywords1 that contain a ' ' character, meaning the words in the element number more than 1
use the nested loop for x in combinations(elem.split(), 2) to include every unique combination of 2 words within the multi-word item

UPDATE:
Based on OP's clarification that original question contained an extra entry,  and that what is required is &quot;in a 'a b c d' context, it will become ('a','b'),('b','c'),('c','d')&quot;, here are three alternative solutions.
Solution #1 using walrus operator := and dict comprehension:
keywords_bigram = {'keywords1': [x for elem in dict_example['keywords1'] if len(words := elem.split()) &gt; 1 for x in zip(words, words[1:])]}

Solution #2 using a long-hand for loop:
keywords_bigram = {'keywords1': []}
for elem in dict_example['keywords1']:
    words = elem.split()
    if len(words) &gt; 1:
        keywords_bigram['keywords1'].extend(zip(words, words[1:]))

Solution #3 without zip():
keywords_bigram = {'keywords1': []}
for elem in dict_example['keywords1']:
    words = elem.split()
    if len(words) &gt; 1:
        for i in range(len(words) - 1):
            keywords_bigram['keywords1'].append(tuple(words[i:i+2]))

All three solutions give identical output:
{'keywords1': [('basic', 'service'), ('develop', 'country'), ('economic', 'resource'), ('social', 'protection'), ('protection', 'system')]}

"
73268456,How to dynamically convert dataframe columns to map,"How to convert the data to map in PySpark, for dynamic columns?
Input dataframe:




key_column
Column_1
Column_2
.....
Column_N




1
Value_1
Value_2
.....
Value_N


1
Value_a
Value_2
......
Value_Z


2
Value_1
Value_2
.....
Value_N




Expected output dataframe:




key_column
Map_output




1
{&quot;Column_1&quot;:&quot;Value_1, Value_a&quot;, &quot;Column_2&quot;:&quot;Value_2&quot;, ......, &quot;Column_N&quot;:&quot;Value_N, Value_Z&quot;}


2
{&quot;Column_1&quot;:&quot;Value_1&quot;, &quot;Column_2&quot;:&quot;Value_2&quot;, ......, &quot;Column_N&quot;:&quot;Value_N&quot;}



","apache-spark, dictionary, pyspark, dynamic, multiple-columns",1,73273083,"We can use create_map function with reduce().
col_list = ['col1', 'col2', 'col3']  # can use sdf.columns for all columns in dataframe

spark.sparkContext.parallelize([('val01', 'val02', 'val03'), ('val11', 'val12', 'val13')]). \
    toDF(['col1', 'col2', 'col3']). \
    withColumn('allcol_map', 
               func.create_map(*reduce(lambda x, y: x + y, [[func.lit(k), func.col(k)] for k in col_list]))
               ). \
    show(truncate=False)

# +-----+-----+-----+---------------------------------------------+
# |col1 |col2 |col3 |allcol_map                                   |
# +-----+-----+-----+---------------------------------------------+
# |val01|val02|val03|{col1 -&gt; val01, col2 -&gt; val02, col3 -&gt; val03}|
# |val11|val12|val13|{col1 -&gt; val11, col2 -&gt; val12, col3 -&gt; val13}|
# +-----+-----+-----+---------------------------------------------+

# root
#  |-- col1: string (nullable = true)
#  |-- col2: string (nullable = true)
#  |-- col3: string (nullable = true)
#  |-- allcol_map: map (nullable = false)
#  |    |-- key: string
#  |    |-- value: string (valueContainsNull = true)


We can also use map_from_entries function that requires an array of structs. The struct fields will be converted into the maps. It will output the same result as aforementioned.
col_list = ['col1', 'col2', 'col3']  # can use sdf.columns for all columns in dataframe

spark.sparkContext.parallelize([('val01', 'val02', 'val03'), ('val11', 'val12', 'val13')]). \
    toDF(['col1', 'col2', 'col3']). \
    withColumn('allcol_map', 
               func.map_from_entries(func.array(*[func.struct(func.lit(k).alias('key'), func.col(k).alias('val')) for k in col_list]))
               ). \
    show(truncate=False)


Based on the updated situation, you'd like to group by some key columns. Looking at the new expected output, you can use concat_ws and collect_list / collect_set to club the all / unique column values.
col_list = ['col1', 'col2', 'col3']

spark.sparkContext.parallelize([('part0', 'val01', 'val02', 'val03'), ('part0', 'val11', 'val12', 'val13'), ('part1', 'val21', 'val22', 'val23')]). \
    toDF(['key_column', 'col1', 'col2', 'col3']). \
    groupBy('key_column'). \
    agg(*[func.concat_ws(',', func.collect_set(k)).alias(k) for k in col_list]). \
    withColumn('allcol_map', 
               func.map_from_entries(func.array(*[func.struct(func.lit(k).alias('key'), func.col(k).alias('val')) for k in col_list]))
               ). \
    show(truncate=False)

# +----------+-----------+-----------+-----------+---------------------------------------------------------------+
# |key_column|col1       |col2       |col3       |allcol_map                                                     |
# +----------+-----------+-----------+-----------+---------------------------------------------------------------+
# |part1     |val21      |val22      |val23      |{col1 -&gt; val21, col2 -&gt; val22, col3 -&gt; val23}                  |
# |part0     |val01,val11|val02,val12|val03,val13|{col1 -&gt; val01,val11, col2 -&gt; val02,val12, col3 -&gt; val03,val13}|
# +----------+-----------+-----------+-----------+---------------------------------------------------------------+

"
74591135,Grep log within a time range,"I want to grep log between 13:27:45 - 13:28:00,
I managed to grep log between 13:27 - 13:28 with the command grep '^13:2[7-8] logfilename, but how can I grep 13:27:45 - 13:28:00?
Would you recommend using sed or even awk for such operation?
","linux, unix, grep",0,74591253,"To match the format 13:27:45 - 13:28:00
grep &quot;^13:\(27:\(4[5-9]\|5[0-9]\)\|28:00\)&quot; file

Or
grep -E &quot;^13:(27:(4[5-9]|5[0-9])|28:00)&quot; file

Explanation

^ Start of string
13: Match literally
( Start a group for the alternatioms

27: Match literally
(4[5-9]|5[0-9]) Match 45 - 49 or 50 - 59
| Or
28:00 Match literally


) Close the group

"
74199920,pyspark: filter values in one dataframe based on array values in another dataframe,"I have a pypsark dataframe like this:
|                name|segment_list|rung_list  |
+--------------------+------------+-----------+
|   Campaign 1       | [1.0,  5.0]|  [L2,  L3]|
|   Campaign 1       |       [1.1]|       [L1]|
|   Campaign 2       |       [1.2]|       [L2]|
|   Campaign 2       |       [1.1]|  [L4,  L5]|
+--------------------+------------+-----------+

I have another pyspark dataframe that has segment and rung for every customer:
+-----------+---------------+---------+
|customer_id|     segment   |rung     |
+-----------+---------------+---------+
|  124001823|            1.0|       L2|
|  166001989|            5.0|       L2|
|  768002266|            1.1|       L1|
+-----------+---------------+---------+

What I want is a final output that figures out the customers based on the segment and rung list. The final output should be something like the following:
|                name|customer_id |   
+--------------------+------------+
|   Campaign 1       | 124001823  | 
|   Campaign 1       | 166001989  | 
|   Campaign 1       | 768002266  | 
+--------------------+------------+ 

I tried using udf but that approach didnt quite work. I would like to avoid using a for loop on a collect operation or going row by row. So I am primarily looking for a groupby operation on name column.
So I want a better way to do the following:
for row in x.collect():
    y = eligible.filter(eligible.segment.isin(row['segment_list'])).filter(eligible.rung.isin(row['rung_list']))

","apache-spark, pyspark, apache-spark-sql",-1,74211438,"you could try to use array_contains for the join conditions.
here's an example
data1_sdf. \
    join(data2_sdf, 
         func.expr('array_contains(segment_list, segment)') &amp; func.expr('array_contains(rung_list, rung)'), 
         'left'
         ). \
    select('name', 'customer_id'). \
    dropDuplicates(). \
    show(truncate=False)

# +----------+-----------+
# |name      |customer_id|
# +----------+-----------+
# |Campaign 1|166001989  |
# |Campaign 1|124001823  |
# |Campaign 1|768002266  |
# |Campaign 2|null       |
# +----------+-----------


pasting the query plan spark produced
== Parsed Logical Plan ==
Deduplicate [name#123, customer_id#129]
+- Project [name#123, customer_id#129]
   +- Join LeftOuter, (array_contains(segment_list#124, segment#130) AND array_contains(rung_list#125, rung#131))
      :- LogicalRDD [name#123, segment_list#124, rung_list#125], false
      +- LogicalRDD [customer_id#129, segment#130, rung#131], false

== Analyzed Logical Plan ==
name: string, customer_id: string
Deduplicate [name#123, customer_id#129]
+- Project [name#123, customer_id#129]
   +- Join LeftOuter, (array_contains(segment_list#124, segment#130) AND array_contains(rung_list#125, rung#131))
      :- LogicalRDD [name#123, segment_list#124, rung_list#125], false
      +- LogicalRDD [customer_id#129, segment#130, rung#131], false

== Optimized Logical Plan ==
Aggregate [name#123, customer_id#129], [name#123, customer_id#129]
+- Project [name#123, customer_id#129]
   +- Join LeftOuter, (array_contains(segment_list#124, segment#130) AND array_contains(rung_list#125, rung#131))
      :- LogicalRDD [name#123, segment_list#124, rung_list#125], false
      +- Filter (isnotnull(segment#130) AND isnotnull(rung#131))
         +- LogicalRDD [customer_id#129, segment#130, rung#131], false

== Physical Plan ==
*(4) HashAggregate(keys=[name#123, customer_id#129], functions=[], output=[name#123, customer_id#129])
+- Exchange hashpartitioning(name#123, customer_id#129, 200), ENSURE_REQUIREMENTS, [id=#267]
   +- *(3) HashAggregate(keys=[name#123, customer_id#129], functions=[], output=[name#123, customer_id#129])
      +- *(3) Project [name#123, customer_id#129]
         +- BroadcastNestedLoopJoin BuildRight, LeftOuter, (array_contains(segment_list#124, segment#130) AND array_contains(rung_list#125, rung#131))
            :- *(1) Scan ExistingRDD[name#123,segment_list#124,rung_list#125]
            +- BroadcastExchange IdentityBroadcastMode, [id=#261]
               +- *(2) Filter (isnotnull(segment#130) AND isnotnull(rung#131))
                  +- *(2) Scan ExistingRDD[customer_id#129,segment#130,rung#131]

seems it is not well optimized, I'm thinking there can be other optimized methods.
"
74350679,"Python mixins : how to deal with *args, **kwargs when calling super()?","In the following example I show some mixins that may or may not use *args or **kwargs:
class AMixin():
    def __init__(self, **kwargs):
        print(&quot;AMixin&quot;)
        self.a = 'a' + str(kwargs.get('a', ''))
        
class BMixin():
    def __init__(self, **kwargs):
        print(&quot;BMixin&quot;)        
        self.b = 'b' + str(kwargs.get('b', ''))
                
class ABMixin(AMixin, BMixin):
    def __init__(self, **kwargs):
        print(&quot;ABMixin&quot;)
        super().__init__(**kwargs)
    
class A(AMixin):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
    
class B(BMixin):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
    
class AB(ABMixin):
    def __init__(self, **kwargs):
        print(&quot;AB&quot;)
        super().__init__(**kwargs)
    
AB(a='a', b='b')

Here I encounter an issue because the last mixin is calling its parent which doesn't exist:
Cell In [4], line 9, in BMixin.__init__(self, *args, **kwargs)
      8 def __init__(self, *args, **kwargs):
----&gt; 9     super().__init__(*args, **kwargs)
     10     print(&quot;BMixin&quot;)
     11     self.b = 'b' + str(kwargs.get('b', ''))

TypeError: object.__init__() takes exactly one argument 
           (the instance to initialize)

How should I modify this example to allow any combination of mixins, and inherit mixins in any order?
One possible UGLY solution is to add a dummy end mixin:
class EndMixin:
    def __init__(self, **kwargs):
        ...
        
class AMixin(EndMixin):
    def __init__(self, **kwargs):
        print(&quot;AMixin&quot;)
        self.a = 'a' + str(kwargs.get('a', ''))
        
class BMixin(EndMixin):
    def __init__(self, **kwargs):
        print(&quot;BMixin&quot;)        
        self.b = 'b' + str(kwargs.get('b', ''))
               

","python, oop, traits, mixins",0,74350883,"You can make your mixins inherit from a base-class that stops the super call to object.
class BaseMixin:
    def __init__(self, *args, **kwargs):
        pass


class AMixin(BaseMixin):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        print(&quot;AMixin&quot;)
        self.a = 'a' + str(kwargs.get('a', ''))


class BMixin(BaseMixin):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        print(&quot;BMixin&quot;)
        self.b = 'b' + str(kwargs.get('b', ''))


class ABMixin(AMixin, BMixin):
    ...


class A(AMixin):
    ...


class B(BMixin):
    ...


class AB(ABMixin):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)


obj = AB(a='a', b='b')
print(obj.b)
print(obj.a)

"
73957101,Different colors text in a single cell,"Here i need to print var32 alone in a different color which is in red.
I tried with the below line but its not working, can someone pls guide in this.
Thanks in Advance
Range(&quot;BH&quot; &amp; kk).Value.ActiveCell.Characters(Start:=11, Length:=14).Font.ColorIndex = 3
For kk = 2 To RowsCount
If (Range(&quot;BI&quot; &amp; kk).Value = &quot;yes&quot; And Range(&quot;BJ&quot; &amp; kk).Value = &quot;yes&quot; And Range(&quot;BK&quot; &amp; kk).Value = &quot;yes&quot; And Range(&quot;BL&quot; &amp; kk).Value = &quot;yes&quot;) And (Range(&quot;BM&quot; &amp; kk).Value = &quot;yes&quot; And Range(&quot;BN&quot; &amp; kk).Value = &quot;yes&quot; And Range(&quot;BO&quot; &amp; kk).Value = &quot;yes&quot; And Range(&quot;BP&quot; &amp; kk).Value = &quot;yes&quot;) And (Range(&quot;BQ&quot; &amp; kk).Value = &quot;yes&quot; And Range(&quot;BR&quot; &amp; kk).Value = &quot;no&quot; And Range(&quot;BS&quot; &amp; kk).Value = &quot;yes&quot; And Range(&quot;BT&quot; &amp; kk).Value = &quot;yes&quot;) Then
   Range(&quot;BH&quot; &amp; kk).Value = var12 &amp; &quot;,&quot; &amp; var22 &amp; &quot;,&quot; &amp; var32
   Range(&quot;BH&quot; &amp; kk).Value.ActiveCell.Characters(Start:=11, Length:=14).Font.ColorIndex = 3
EndIf
Next kk

","excel, vba",-1,73960349,"Range(&quot;BH&quot; &amp; kk).Characters(Start:=11, Length:=14).Font.Color=vbRed

"
73987353,"In django-rest-framework, I want to output the childdb in the same parentdb by putting the parentdb name in the url parameter","There is a model that binds the user with a foreignkey. What I want to do is set the url parameter to
I'm writing an api that prints the items of children with the same parent when I put as_view/int:parentpk, but I can't implement it due to my lack of skills. Please help
Here is a model.py that accepts a user as a foreignkey
   class TestingTasks(models.Model): 
        Taskname = models.CharField(max_length=100, unique=True)    
        dateofuse = models.DateTimeField(auto_now_add=True)    
        Compressing = models.TextField()    
        Path = models.FileField(null=True)    
        parent_id = models.ForeignKey(User,related_name='users', on_delete=models.CASCADE,default=1)

And here is views.py
class TestingAPI(APIView):
permission_classes = [AllowAny]

def get(self, request, company_id):
    instance = TestingTasks.objects.filter(parent_id=id)
    serializer_class = TestingSerializer(instance)
    return Response(serializer_class.data)

Here is urls.py
path(&quot;Testing/&lt;int:company_id&gt;&quot;,views.TestingAPI.as_view())

I need to implement a total of three get, put, and delete, but I can't do the rest because I can't get.
I'd appreciate it if you could give me a direction on how to do it. Have a nice day.
","django, django-models, django-rest-framework, django-views, django-serializer",0,73988061,"just add the functions in class
class TestingAPI(APIView):
      permission_classes = [AllowAny]

      def get(self, request, company_id):
          instance = TestingTasks.objects.filter(parent_id=company_id)
          serializer_class = TestingSerializer(instance)
          return Response(serializer_class.data)

      def put(self, request, company_id):
          ...
      def delete(self, request, company_id):
          ...

"
74412442,Angular not showing value in input when using ngModel,"I'm using Angular 14, when I put this code, it works fine and the value is initialized.
&lt;input type=&quot;text&quot; name=&quot;name&quot; value=&quot;John&quot; &gt;

But when I add ngModel, the value is no longer initialized, and nothing is showed in the text box.
&lt;input type=&quot;text&quot; ngModel name=&quot;name&quot; value=&quot;John&quot; &gt;

How can I put a value in text box with ngModel ?
",angular,-1,74412485,"MyComponent.component.html
&lt;input type=&quot;text&quot; [(ngModel)]=&quot;name&quot; /&gt;

MyComponent.component.ts
...
class MyComponent {
  public name = &quot;Jhon&quot;;
}

And as you update the input, the variable name will be updated. If you dont want it updated just use [ngModel] instead of [(ngModel)]
"
73690166,Can you generate a scene graph after a plant has been finalized?,"I'm working on a project that requires me to add a model through Parser (which requires the plant to be of the same type as the array used) before Setting the position of the model in said plant and taking distance queries. These queries only work when the query object generated from the scene graph is of type float.
I've run into a problem where setting the position doesn't work due to the array being used being of type AutoDiff. A possible solution would then be converting the plant of type float to Autodiff with plant.ToAutoDiff(), but this only creates a copy of the plant without coupling it to the scene graph (and in turn the query object) from which the queries are derived. Taking queries with a query object generated from the original plant would then fail to reflect the new position passed to the AutoDiff copy.
Is there a way to create a new scene graph from the already finalized symbolic copy of the original plant, so that I can perform the queries with it?
",drake,0,73690443,"A couple of thoughts:

Don't just convert the plant to autodiff. Convert the whole diagram. That will give you a converted, connected network.
You're stuck with the current workflow. Presumably, your proximity geometries are specified in your parsed file (as &lt;collision&gt; tags). The parsing process is ephemeral. The declaration is consumed, passed through MultibodyPlant into SceneGraph. If there is no SceneGraph at parse time, all knowledge of the declared collision geometry is forgotten.

So, the typical workflow is:

Create a float-valued diagram.
Scalar convert it to an AutoDiff-valued diagram.
Keep both around to serve the different roles.

We don't have a tutorial that directly shows scalar converting an entire diagram, but it's akin to what is shown in this MultibodyPlant-specific tutorial. Just call ToScalarType() on the Diagram root.
"
73810279,Splunk Search query returns 'Unknown Search Command' error while trying to display search results using the Splunk Enterprise SDK for Java,"I am trying to access Splunk results using java.
I have followed the below link to achieve the same
https://dev.splunk.com/enterprise/docs/devtools/java/sdk-java/howtousesdkjava/howtodisplaysearchsdkjava/
I am trying to give the below search String but getting the below exception
source=&quot;/u/application/xxxx/yyy/zzzz/logs/access_log&quot; 
| eval server_type=mvindex(split('host', &quot;.&quot;),0), site=mvindex(split('host', &quot;.&quot;),1), country=mvindex(split('host', &quot;.&quot;),2), domain=mvindex(split('host', &quot;.&quot;),3), org=mvindex(split('host', &quot;.&quot;),4) 
| search country=&quot;XX&quot; serviceName=&quot;/services/*&quot; 
| chart count by serviceName

Setting the Search String in job
String mySearch = &quot;source=\&quot;/u/applic/wsadmin/WMSE/apache/logs/httpd_60402/access_log\&quot; | eval server_type=mvindex(split('host', \&quot;.\&quot;),0), site=mvindex(split('host', \&quot;.\&quot;),1), country=mvindex(split('host', \&quot;.\&quot;),2), domain=mvindex(split('host', \&quot;.\&quot;),3), org=mvindex(split('host', \&quot;.\&quot;),4) |search country=\&quot;us\&quot; serviceName=\&quot;/services/*\&quot; | chart count by serviceName&quot;;
    Job job = service.getJobs().create(mySearch);

Exception in thread &quot;main&quot; com.splunk.HttpException: HTTP 400 -- Unknown search command 'source'
But the same code works with the below simple search command
String mySearch = &quot;search * | head 5&quot;;
Job job = service.getJobs().create(mySearch);

Can someone help to understand the issue
","splunk, splunk-query, splunk-sdk",0,73810710,"Adding 'search' before the source should resolve it.
either 'search' or '|' should be the first command while creating search query via rest api.
"
73389055,"F# error: ""Either make the arguments to 'it' explicit or, if you do not intend for it to be generic, add a type annotation.""","In F# interactive shell dotnet fsi, I'm trying to test flip function as in Haskell,
flip :: (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c
&gt; let flip = fun f -&gt; fun a -&gt; fun b -&gt; f(b)(a);;
val flip: f: ('a -&gt; 'b -&gt; 'c) -&gt; a: 'b -&gt; b: 'a -&gt; 'c

then, investigating the built-in pipe-operator,
&gt; (|&gt;);;
val it: ('a -&gt; ('a -&gt; 'b) -&gt; 'b)

so far so good.
Now,
&gt; flip (|&gt;);;

  flip (|&gt;);;
  ^^^^^^^^^

/..... : error FS0030: Value restriction. The value 'it' has been inferred to have generic type
    val it: (('_a -&gt; '_b) -&gt; '_a -&gt; '_b)    
Either make the arguments to 'it' explicit or, if you do not intend for it to be generic, add a type annotation.

Can someone explain what's going on with this error in the F# type system?
To me,
val it: (('_a -&gt; '_b) -&gt; '_a -&gt; '_b) should be actually the expected result, and how can I sort this out? Thanks.
","haskell, functional-programming, f#, type-systems",2,73390341,"My previous answer explains what Value Restriction is and why it happens. But now your next question is: ok, so what do I do about it?
As the error message itself suggests, there are two possible ways: (1) give it explicit arguments or (2) if you don't want it to be generic, add a type annotation.
1. Explicit arguments
let flippedPipe x = flip (|&gt;) x

Even though logically this is the same as let flippedPipe = flip (|&gt;), syntactically this is now a function, not a value. And syntax is what matters for the Value Restriction.
2. A type annotation
let flippedPipe : (int -&gt; int) -&gt; int -&gt; int = flip (|&gt;)

This works because the function is no longer generic, so the Value Restriction does not apply. This is a desirable option in many circumstances, but judging by the kinds of functions you're working with here, I would assume this is not what you wanted in this case.
3. Explicit type parameters
The error message doesn't mention this, and in fairness, it can be considered a variation of option (2). The idea is that you can give your function explicit type parameters like this:
let flippedPipe&lt;'a, 'b&gt; = flip (|&gt;)

This makes the Value Restriction go away, because, even though it still technically applies, the fact that you added the type parameters presumably shows that you know what you're doing, so the compiler shuts up.
However, though this appears to work at first glance, it does so in the wrong way. If you look at the inferred type of this function, you'll see:
val flippedPipe : (obj -&gt; obj) -&gt; obj  -&gt; obj

This happens because, even though you added type parameters, you didn't specify exactly where they go. They may not be used at all (aka &quot;phantom types&quot;) for all the compiler knows.
So to make it work properly, this should be the definition:
let flippedPipe&lt;'a, 'b&gt; : ('a -&gt; 'b) -&gt; 'a -&gt; 'b = flip (|&gt;)

"
74002035,Is there a way to perpetually save photos to an Xcode app after refreshing?,"I'm working on a program that uploads images to a CollectionView by accessing the user's photo library. It's looking great so far, and the majority of it is running smoothly.
However, when I exit out of the app and refresh it, the once uploaded photos don't appear anymore.
I'm only a little familiar with Core Data and I've been trying to work it in, but all of my sources aren't that helpful.
Here's my code so far:


import UIKit
import PhotosUI
import Photos
import CoreData

class ViewController: UIViewController, PHPickerViewControllerDelegate {

    @IBOutlet var collectionView: UICollectionView!
    
                                
    override func viewDidLoad() {
        super.viewDidLoad()
        
        // set up collection
        navigationItem.rightBarButtonItem = UIBarButtonItem(barButtonSystemItem: .add, target: self, action: #selector(addPhotos))
        
        collectionView.register(ClosetCollectionViewCell.nib(), forCellWithReuseIdentifier: ""ClosetCollectionViewCell"")
        
        collectionView.delegate = self
        collectionView.dataSource = self
        
        let layout = UICollectionViewFlowLayout()
        layout.itemSize = CGSize(width: 125, height: 125)
        collectionView.collectionViewLayout = layout
        
        layout.minimumInteritemSpacing = 10
        layout.minimumLineSpacing = 10
    
        
    }
    
    
    // access photo library
    @objc private func addPhotos() {
        var config = PHPickerConfiguration()
        config.selectionLimit = 10
        config.filter = .images
        let vc = PHPickerViewController(configuration: config)
        vc.delegate = self
        present(vc, animated: true)
    }
    
    func picker(_ picker: PHPickerViewController, didFinishPicking results: [PHPickerResult]) {
        picker.dismiss(animated: true, completion: nil)
        let group = DispatchGroup()
        
        results.forEach { result in
            group.enter()
            result.itemProvider.loadObject(ofClass: UIImage.self) { reading, error in
                defer {
                    group.leave()
                }
                guard let image = reading as? UIImage, error == nil else {
                    return
                }
                // add to user's photo array
                print(image)
                imageArray.append(image)
                
            }
        }
        
        group.notify(queue: .main) {
            self.collectionView.reloadData()
        }
        
        
    }
    

}


// user images below
var imageArray = [UIImage]()


extension ViewController: UICollectionViewDelegate {
    func collectionView(_ collectionView: UICollectionView, didSelectItemAt indexPath: IndexPath) {
        collectionView.deselectItem(at: indexPath, animated: true)
        
        print(""you tapped me!"")
        // when cell is tapped...
    }
}

extension ViewController: UICollectionViewDataSource {
    func collectionView(_ collectionView: UICollectionView, numberOfItemsInSection section: Int) -&gt; Int {
        // how many cells are shown? based on number of items the user uploaded
        return imageArray.count
    }
    
    func collectionView(_ collectionView: UICollectionView, cellForItemAt indexPath: IndexPath) -&gt; UICollectionViewCell {
        // return cell for given item
        let cell = collectionView.dequeueReusableCell(withReuseIdentifier: ""ClosetCollectionViewCell"", for: indexPath) as! ClosetCollectionViewCell
        
        
        cell.imageView.image = imageArray[indexPath.row]
        
        return cell
    }
}

extension ViewController: UICollectionViewDelegateFlowLayout {
    // margin of padding between cells
    func collectionView(_ collectionView: UICollectionView, layout collectionViewLayout: UICollectionViewLayout, sizeForItemAt indexPath: IndexPath) -&gt; CGSize {
        return CGSize(width: 115, height: 115)
    }
    
}



I don't know where to start!
Any ideas?
","swift, xcode, swiftui, core-data, uiimage",0,74002169,"For your question, reason your app lost all photos everytime you refresh because it was temporary store but not save somewhere else ( internet or on local).
If you want to save it on you own server, create server side and do with api.
Come to local here, you have come to the right path finding a local which is Core Data to store. But the key point to need to know here is:

Saving image to local should use FileManager ( which means each app have the own documentary folder in your phone so save the not only image but document, files, everything else to here - It will lost only when your app is uninstalled) You just need to keep the name of the image ( you can create your own name to save image)

Code will be like this
func saveImage(imageName: String, image: UIImage) {
    // get documentary path to save image to
    guard let documentsDirectory = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first else { return }

    let fileName = imageName
    let fileURL = documentsDirectory.appendingPathComponent(fileName)
    guard let data = image.jpegData(compressionQuality: 1) else { return }

    //Checks if file exists, removes it if so.
    if FileManager.default.fileExists(atPath: fileURL.path) {
        do {
            try FileManager.default.removeItem(atPath: fileURL.path)
            print(&quot;Removed old image&quot;)
        } catch let removeError {
            print(&quot;couldn't remove file at path&quot;, removeError)
        }

    }
    
    do {
        try data.write(to: fileURL)
    } catch let error {
        print(&quot;error saving file with error&quot;, error)
    }
}

func loadImageFromDiskWith(fileName: String) -&gt; UIImage? {
  let documentDirectory = FileManager.SearchPathDirectory.documentDirectory

    let userDomainMask = FileManager.SearchPathDomainMask.userDomainMask
    let paths = NSSearchPathForDirectoriesInDomains(documentDirectory, userDomainMask, true)

    if let dirPath = paths.first {
        let imageUrl = URL(fileURLWithPath: dirPath).appendingPathComponent(fileName)
        let image = UIImage(contentsOfFile: imageUrl.path)
        return image

    }

    return nil
}

Next is the Core Data or UserDefaults is where you save the key connect to the list of name images you save before. So everytime you come into app, just take the list image name out from the key and appear it again
I will do with UserDefaults you can try to implement the same with CoreData. I save image as name is number so I save to UserDefault only the number of images. You can change to something like you want
Code will be like this
var imageArray = [UIImage]()
var countImage = 0

override func viewDidLoad() {
    super.viewDidLoad()
    
    // get number of image have been saved
    let countImage = UserDefaults.standard.integer(forKey: &quot;test&quot;)

    if countImage &lt; 1 {
        return
    }
    
    for i in 1...countImage {
        // get image from disk
        imageArray.append(self.loadImageFromDiskWith(fileName: String(i))!)
    }
    
    print(imageArray)
    self.collectionView.reloadData() // reload collection view
}

func picker(_ picker: PHPickerViewController, didFinishPicking results: [PHPickerResult]) {
    picker.dismiss(animated: true, completion: nil)
    let group = DispatchGroup()
    
    results.forEach { result in
        group.enter()
        result.itemProvider.loadObject(ofClass: UIImage.self) { reading, error in
            defer {
                group.leave()
            }
            guard let image = reading as? UIImage, error == nil else {
                return
            }
            // add to user's photo array
            print(image)
            self.imageArray.append(image)
            // append self.countImage to 1 and save number to  UserDefault and image to FileManager
            self.countImage += 1
            UserDefaults.standard.set(self.countImage, forKey: &quot;test&quot;)
            self.saveImage(imageName: String(self.countImage), image: image)
        }
    }
    
    group.notify(queue: .main) {
        self.collectionView.reloadData()
    }
}

"
74371499,Kotlin: Multiline function name (with backticks),"How can I escape a function name so that it can span multiple lines? For example
@Test
fun `This is a really long description of what should happen to this function when the IDs do not match up.`() {
  // test
}

What I would want is something like
@Test
fun `This is a really long description of what should happen to this \
     function when the IDs do not match up.`() { // test }

Is this possible?
","kotlin, junit",2,74371656,"It is not possible, function names convention allows spaces in test methods but not multiple lines : https://kotlinlang.org/docs/coding-conventions.html#names-for-test-methods

In tests (and only in tests), you can use method names with spaces enclosed in backticks.

A method with multiple lines in its name would not be callable even through reflection. (see https://stackoverflow.com/a/45750788/7346454)
"
74086321,How do i create a search link after user selects search criterias in webpage?,"I have created a search.html where users can select/enter search criteria and click the search button to search the database of 1000 records. I have done the HTML part but I don't know how to generate the action link.
&lt;form action=&quot;/bookings/search?&quot; method=&quot;POST&quot;&gt;
    &lt;div class=&quot;row mb-3&quot;&gt;
        &lt;label for=&quot;inputEmail3&quot; class=&quot;col-sm-2 col-form-label&quot;&gt;Email&lt;/label&gt;
        &lt;div class=&quot;col-sm-10&quot;&gt;
            &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;inputEmail3&quot; name=&quot;email&quot; placeholder=&quot;Email&quot; value=&quot;&quot;&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&quot;row mb-3&quot;&gt;
        &lt;label for=&quot;inputPassword3&quot; class=&quot;col-sm-2 col-form-label&quot;&gt;Number of Tickets&lt;/label&gt;
        &lt;div class=&quot;col-sm-10&quot;&gt;
            &lt;input type=&quot;number&quot; class=&quot;form-control&quot; id=&quot;inputPassword3&quot; name=&quot;numTickets&quot; min=1 max=4
                value=&quot;&quot;&gt;
        &lt;/div&gt;
    &lt;/div&gt;
   &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot;&gt;Search&lt;/button&gt;

So, when the user enters the email or number of Tickets, the submit button will direct the result to /bookings/search javascript that goes through the database (Mongo DB). The email supports partial matching.
I want to do is: say, the user enters 'atom' in email and 2 in number of Tickets, then the action query should look like /bookings/search?email=atom&amp;numTickets=2.
I believe it is related to javascript, but I am not sure how to do it.
My bookings/search looks like this:
bookings/search
","javascript, html, node.js, express",1,74086444,"Just changed the method to &quot;get&quot; instead of &quot;post&quot; and it works.
"
74381155,Missing commands in AWS CLI?,"Sorry if this is a dumb question - I'm just getting started with AWS - I've installed the AWS CLI utility on Windows, and configured it with my access key and secret. The command &quot;aws --version&quot; says &quot;aws-cli/2.8.10 Python/3.9.11 Windows/10 exe/AMD64 prompt/off&quot;.  I'm trying to run &quot;aws assume-impersonation-role&quot; as documented here:
https://docs.aws.amazon.com/cli/latest/reference/workmail/assume-impersonation-role.html

but I get the error &quot;invalid choice&quot;. The list of valid choices has nothing like what I'm looking for.  Is there some extension or add-on I need to install?
","amazon-web-services, aws-cli",0,74381192,"Just to check the obvious, are you doing:
aws assume-impersonation-role --organization-id â€¦ --impersonation-role-id â€¦

rather than the intended
aws workmail assume-impersonation-role --organization-id â€¦ --impersonation-role-id â€¦

?
"
73270959,React Semantic UI Search component only accepts one character at a time (which also eliminates the previous input),"I am using search component from Semantic UI. When I console.log what I typed in the search field, only a single character is printed ('abcd' will be printed as 'a', 'b', 'c', 'd') and the search field doesn't show any character as if it doesn't take any input. But If I used &lt;Input&gt; &lt;/Input&gt; instead, these problems are gone.
code sample is here
","javascript, reactjs, semantic-ui",0,73270981,"This works as intended. Did you forget to actually set state?
const handleSearchChange = useCallback((e, data) =&gt; {
    setValue(data.value);
    setLoading(!loading);
  }, []);

"
73442986,How to concatenate millions array records to a single string faster?,"I am trying to concatenate all values of a 2D array to a single String.
But performance is really impacted by size of the array (2800 X 1700).
I there a better way to do it ?
Thank you !
float[][] datas = obj.getMatrix();
String result = &quot;&quot;;
int[] shape = {2800,1700};
for(k=0; k&lt;shape[0]; k++){
   for(j=0; j&lt;shape[1]; j++){
      result += (datas[k][j] + &quot;&quot;).getBytes();
   }
}

UPDATE
I am using unidata netCDF java API to convert my data for ncML response.
My float[][] gives me some values that i want to add to a list.
Instead of doing a String result = &quot;10.0,15.1,45.6,25.4.....&quot; I want to convert each value to byte[]. My string will look like result = &quot;[B@xxxxxxxx[B@xxxxxxxx[B@xxxxxxxx[B@xxxxxxxx....&quot;
Then,  I can convert my result into Base64 using Base64.getEncoder().encode(result.getBytes())
It will look like :
float[][] datas = obj.getMatrix();
    StringBuffer result = new StringBuffer();
    int[] shape = {2800,1700};
    for(k=0; k&lt;shape[0]; k++){
       for(j=0; j&lt;shape[1]; j++){
          result.append((datas[k][j] + &quot;&quot;).getBytes());
       }
    }
byte[] encodedByte = Base64.getEcnoder().encode(result);
String encodedStr = new String(result);

Then, when user get the response, he will decode the result, obtain the &quot;[B@xxxxxxxx[B@xxxxxxxx[B@xxxxxxxx[B@xxxxxxxx....&quot; responseand can identify values
UPDATE 2
Thanks to all the comments, I understand what it cannot works.
Finally, I decided to just do : result.append(datas[k][j] + &quot;,&quot;);
","java, arrays, for-loop",0,73443108,"Use StringBuilder instead of string for result. This will reduce time to few secs.
as given below
StringBuilder result = new StringBuilder();
        int[] shape = {2800,1700};
        for(int k=0; k&lt;shape[0]; k++){
            for(int j=0; j&lt;shape[1]; j++){
                result.append ((datas[k][j] + &quot;&quot;).getBytes() );
            }
        }

"
73398477,How to use the next_rails gem for dual booting on heroku,"I am using the next_rails gem for dual booting and am ready to test on heroku, which I normally do by git push staging master. How do I test the next rails version on heroku?
","ruby-on-rails, heroku, next-rails",0,73398478,"In theory you should be able to set the BUNDLE_GEMFILE Heroku environment variable to Gemfile.next, and then just push it to staging e.g.
heroku config:set  BUNDLE_GEMFILE=Gemfile.next -r staging

git push staging master

Unfortunately there appears to be an issue with the Heroku ruby buildpack. My work around is as follows
a) use the next_rails gem as documented for development server and development tests
b) Once ready for testing deployment, create a new branch, with the only change is for the Gemfile to go from:
...
if next?
  gem 'rails', '~&gt; 7.0.3.1'
  gem &quot;sprockets-rails&quot;
else
  gem 'rails', '~&gt; 6.1.6.1'
end

to:
...
 gem 'rails', '~&gt; 7.0.3.1'

And deploy that branch to staging. This branch only needs to be merged with master when you want to test out staging.
If the issue is resolved, I will update this answer.
"
73717005,OSMNx: How to return OSM roads using graph_from_point even if its extreme end nodes are not within the distance,"I want to fetch the road network inside the blue circle. But i am not able to do so as its far end nodes are well beyond 100 meter from the point.

lng,lat=8.89458178871303, 41.657804855447374

road_filter =  '[&quot;highway&quot;~&quot;secondary&quot;]'
G=ox.graph_from_point((lat, lng),custom_filter=road_filter,dist=100)

","networkx, openstreetmap, osmnx",-1,73735254,"G=ox.graph_from_point((lat, lng),custom_filter=road_filter,dist=100,simplify=False,retain_all=True,truncate_by_edge=True)

simplify=False and truncate_by_edge=True did the trick.

"
73467227,How to convert string arraylist to model arraylist in flutter?,"List&lt;String&gt; langList = [English,  Gujarati,  Hindi,  Marathi,  Punjabi,  Urdu,  Spanish]

var selectedLanguagesList = &lt;LanguageDatum&gt;[].obs;

langList is a string type of list. and selectedLanguagesList is a model type of list.
How do I convert string list to model list in flutter ?
class LanguageDatum {
  LanguageDatum({
     this.id,
     this.name,
     this.status,
    this.createdAt,
    this.updatedAt,
    this.deletedAt,
  });

  int? id;
  String? name;
  int? status;
  DateTime? createdAt;
  DateTime? updatedAt;
  dynamic deletedAt;

  factory LanguageDatum.fromJson(Map&lt;String, dynamic&gt; json) =&gt; LanguageDatum(
    id: json[&quot;id&quot;]??0,
    name: json[&quot;name&quot;]??&quot;&quot;,
    status: json[&quot;status&quot;]??&quot;&quot;,
    createdAt: json[&quot;created_at&quot;] != null ? DateTime.parse(json[&quot;created_at&quot;]) : null,
    updatedAt: json[&quot;updated_at&quot;] != null ? DateTime.parse(json[&quot;updated_at&quot;]) : null,
    deletedAt: json[&quot;deleted_at&quot;],
  );

  Map&lt;String, dynamic&gt; toJson() =&gt; {
    &quot;id&quot;: id,
    &quot;name&quot;: name,
    &quot;status&quot;: status,
    &quot;created_at&quot;: createdAt,
    &quot;updated_at&quot;: updatedAt,
    &quot;deleted_at&quot;: deletedAt,
  };
}

So, Above is model class.
","flutter, dart, arraylist",1,73467355,"If I understand your question correctly, I guess it would be
// To convert String array to Model array
final listOfLanguageDatum =
    langList.map((e) =&gt; LanguageDatum(name: e)).toList();

List&lt;String&gt; langList = [
  'Tamil'
  'English',
  'Gujarati',
  'Hindi',
  'Marathi',
  'Punjabi',
  'Urdu',
  'Spanish'
];

class LanguageDatum extends GetxController {
  LanguageDatum({
    this.id,
    this.name,
    this.status,
    this.createdAt,
    this.updatedAt,
    this.deletedAt,
  });

  int? id;
  String? name;
  int? status;
  DateTime? createdAt;
  DateTime? updatedAt;
  dynamic deletedAt;

  factory LanguageDatum.fromJson(Map&lt;String, dynamic&gt; json) =&gt; LanguageDatum(
        id: json[&quot;id&quot;] ?? 0,
        name: json[&quot;name&quot;] ?? &quot;&quot;,
        status: json[&quot;status&quot;] ?? &quot;&quot;,
        createdAt: json[&quot;created_at&quot;] != null
            ? DateTime.parse(json[&quot;created_at&quot;])
            : null,
        updatedAt: json[&quot;updated_at&quot;] != null
            ? DateTime.parse(json[&quot;updated_at&quot;])
            : null,
        deletedAt: json[&quot;deleted_at&quot;],
      );

  Map&lt;String, dynamic&gt; toJson() =&gt; {
        &quot;id&quot;: id,
        &quot;name&quot;: name,
        &quot;status&quot;: status,
        &quot;created_at&quot;: createdAt,
        &quot;updated_at&quot;: updatedAt,
        &quot;deleted_at&quot;: deletedAt,
      };

  @override
  String toString() {
    return 'LanguageDatum(id: $id, name: $name, status: $status, createdAt: $createdAt, updateAt: $updatedAt, deletedAt: $deletedAt)';
  }
}


"
73585351,Python Dataframe extract quarterly data and export to a quarterly folder,"I have a summary dataframe. I want to extract quarterly data and export it to the quarterly folders created already.
My code:
ad = pd.DataFrame({&quot;sensor_value&quot;:[10,20]},index=['2019-01-01 05:00:00','2019-06-01 05:00:00'])
ad = 
                     sensor_value
2019-01-01 05:00:00            10
2019-06-01 05:00:00            20

ad.index = pd.to_datetime(ad.index,format = '%Y-%m-%d %H:%M:%S')
# create quarter column
ad['quarter'] = ad.index.to_period('Q')
ad =
                     sensor_value quarter
2019-01-01 05:00:00            10  2019Q1
2019-06-01 05:00:00            20  2019Q2

# quarters list
qt_list = ad['quarter'].unique()

# extract data for quarter and store it in the corresponding folder that already exist
fold_location = 'C\\Data\\'
for i in qt_list:
    auxdf = ad[ad['quarter']=='%s'%(i)]
    save_loc = fold_location+'\\'+str(i)
    auxdf.to_csv(save_loc+'\\'+'Sensor_1minData_%s.csv'%(i))

Is there a better way of doing it?
Thanks
","python, pandas, dataframe, numpy, datetime",0,73585539,"You can use groupby with something like:
for quarter, df in ad.groupby('quarter'):
    df.to_csv(f&quot;C\\Data\\{quarter}\\Sensor_1minData_{quarter}.csv&quot;)

"
73879329,Strange behavior in terminal output using snowflake-connector together with simple-ddl-parser,"does anybody have an idea what is happening? I'm not so advanced in coding to understand the reason behind the following behavior:
I have a short python script connecting to Snowflake and getting a DDL definition from some table. Having the DDL I want to parse it using simple-ddl-parser.
import snowflake.connector
from simple_ddl_parser import DDLParser

ctx = snowflake.connector.connect(
    user='xxx',
    account='xxx', 
    warehouse='xxx', 
    database='xxx',       
    schema ='xxx',
    role = 'xxx',
    authenticator=&quot;externalbrowser&quot;)        

cs = ctx.cursor()

try:
    cs.execute(&quot;select get_ddl('table', 'xxx');&quot;)
    ddl = cs.fetchone()
    # print(ddl[0])
    result = DDLParser(ddl[0]).run()
finally:
    cs.close()
    
ctx.close()

When I'm commenting out the line result = DDLParser(ddl[0]).run() and simply printing out the ddl on the screen everything is working fine. In terminal I'm getting the information that my browser will open etc. (because of externalbrowser authentication) and I can see the DDL.
However when I'm starting to use the DDLParser to parse the DDL I'm getting a lot of information from snowflake-connector. It looks like some debug info or all the details about connection etc.:
Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...
connection.py: 557:closed
telemetry.py: 151:Closing telemetry client.
telemetry.py: 116:Sending 1 logs to telemetry. Data is {'logs': [{'message': {'type': 'client_time_consume_first_result', 'source': 'PythonConnector', 'query_id': '01a7449c-0c03-a272-0000-ce55d70a2ffe', 'value': 493}, 'timestamp': '1664357536706'}]}.
network.py:1147:Session status for SessionPool 'xxx', SessionPool 1/1 active sessions
network.py: 827:remaining request timeout: 5, retry cnt: 1
network.py: 808:Request guid: 8524f554-bc67-4209-af13-d87249a7fae6
network.py:1006:socket timeout: 60
connectionpool.py: 456:https://xxx:443 &quot;POST /telemetry/send?request_guid=8524f554-bc67-4209-af13-d87249a7fae6 HTTP/1.1&quot; 200 86
network.py:1032:SUCCESS
network.py:1152:Session status for SessionPool 'xxx', SessionPool 0/1 active sessions
network.py: 715:ret[code] = None, after post request
telemetry.py: 140:Successfully uploading metrics to telemetry.
connection.py: 560:No async queries seem to be running, deleting session
network.py:1147:Session status for SessionPool 'xxx', SessionPool 1/1 active sessions
network.py: 827:remaining request timeout: 5, retry cnt: 1
network.py: 808:Request guid: 33d96b5f-f8db-4fbc-b88f-54a5c330615c
network.py:1006:socket timeout: 60
connectionpool.py: 456:https://xxx:443 &quot;POST /session?delete=true&amp;request_guid=33d96b5f-f8db-4fbc-b88f-54a5c330615c HTTP/1.1&quot; 200 76
network.py:1032:SUCCESS
network.py:1152:Session status for SessionPool 'xxx', SessionPool 0/1 active sessions
network.py: 715:ret[code] = None, after post request
connection.py: 571:Session is closed
connection.py: 548:Rest object has been destroyed, cannot close session
   _api.py: 172:Attempting to acquire lock 1617266024480 on C:\Users\xxx\AppData\Local\Snowflake\Caches\ocsp_cache.lock
   _api.py: 176:Lock 1617266024480 acquired on C:\Users\xxx\AppData\Local\Snowflake\Caches\ocsp_cache.lock
   _api.py: 209:Attempting to release lock 1617266024480 on C:\Users\xxx\AppData\Local\Snowflake\Caches\ocsp_cache.lock
   _api.py: 212:Lock 1617266024480 released on C:\Users\xxx\AppData\Local\Snowflake\Caches\ocsp_cache.lock

I'm getting my DDL successfully parsed but why I'm getting all this additional information displayed on the screen?
Is snowflake-connector and simple-ddl-parser somehow interfering with each other? Is it possible that some variables or functions are named the same or something in the simple-ddl-parser code is switching on some debug info from snowflake-connector? I have no idea... but I don't want to see this &quot;debug&quot; info on my screen but want to use simple-ddl-parser.
I will be happy to get any feedback! Thx!
","python, snowflake-cloud-data-platform, ddl",1,73879877,"The DDLParser has default log level set to DEBUG as I can see here.
You can set the DDLParser logging to CRITICAL and these messages won't appear on the screen anymore.
So, in your existing script add:
import logging
...
result = DDLParser(ddl[0], log_level=logging.CRITICAL).run()

See more information here.
"
73025557,c# MathNet Gamma distribution sampling not matching,"I am trying to implement an event time sampling for different distributions using the MathNet library. I have them working for exponential, normal and weibull but the same process is not working for Gamma anyone know what I am doing wrong?
Testing Example to get mean.
    using System;
    using MathNet.Numerics.Distributions;

    public class Program
    {
        public static void Main()
        {
            double sum = 0.0;
            var dist = new Gamma(0.5,50);
            int runs = 1000000;
            for (int i=0; i&lt;runs; i++)
            {
                sum += dist.Sample();
            }
            Console.WriteLine((sum/runs).ToString());
        }
    }

Returns: ~0.01
Using online calculator https://keisan.casio.com/exec/system/1180573218 I get 11.37 for the mean. (CD 0.5, shape 0.5 scale 50)
","c#, mathnet-numerics",0,73029006,"There are two things to keep in mind:

Math.Net is using shape and rate (or inverse scale) definition of gamma distribution, while most online calculators are using shape and scale.
The lower (or upper) CDF is not equal the expectation value of the distribution: if you do the integral to calculate the expected value, you get E[X] = shape/rate, that is quite close to the result you get from your code

"
74083779,Problem with value arguments in const fn with basic numeric generics,"I'm trying to translate some of my C++ code into Rust and came across the following problem. The code is simplified to a (hopefully) minimal not-working example. In the end it is supposed to work with all unsigned integer types, but for this example it just needs to implement the PartialOrd trait.
#![allow(incomplete_features)]  
#![feature(generic_const_exprs)]
#![feature(const_trait_impl)]   


const fn foo&lt;T&gt;(n: T, k: T) -&gt; T                                       
where                                                                   
    T: Sized,                                                           
    T: Copy,
    T: ~const core::marker::Destruct,
    T: ~const std::cmp::PartialOrd,                            
{                                                                       
    if n &lt; k {                                                          
        n
    } else {
        k
    }
}                                                                       

Fails to compile with the following error message:
error[E0658]: cannot borrow here, since the borrowed element may contain interior mutability
 13 |     if n &lt; k {                                                          
    |        ^

If I replace the arguments n and k with references, it compiles. Turns out, the functions in the PartialOrd are also implemented using references. So from my understanding, the expression 2 &lt; 4 will call the le function with references. For performance reasons, I doubt that's what's happening, though.
It's actually two questions that I'm asking:

Can I solve the error without using references?
Why is PartialOrd using references while Ord uses values (at least for min and max, but not for cmp)?

",rust,0,74084051,"
Adding #![feature(const_refs_to_cell)] makes it compile.
min and max take Self because they return one of the two arguments as Self. Other methods in Ord and PartialOrd else returns a bool or an Ordering so they can take by reference. if min and max they took by reference the signature would be fn max&lt;'a&gt;(&amp;'a self, other: &amp;'a Self) -&gt; &amp;'a Self which you &quot;get for free&quot; because there is a impl&lt;A&gt; Ord for &amp;A where A: Ord.

"
74512385,"Flutter - ""Invalid constant value"" inside OnChange - Flutter","Im trying to do a very basic Log in app in Flutter. I'm trying to get the email and password from a TextField Widget with OnChange, but it gives me this error &quot;Invalid constant value&quot;, inside of the function of OnChange. What can I do?. Here is the code:
import 'package:flutter/material.dart';

String email = '';
String password = '';

class Login extends StatelessWidget {
  const Login({super.key});

  @override
  Widget build(BuildContext context) {
    return Container(
      margin: const EdgeInsets.all(20.0),
      padding: const EdgeInsets.all(10.0),
      child: Center(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: const &lt;Widget&gt;[
            Padding(
              padding: EdgeInsets.all(30.0),
              child: Text(
                'Welcome to the log in'
              ),
            ),
            Padding(
              padding: EdgeInsets.all(10.0),
              child: TextField(
                obscureText: true,
                decoration: InputDecoration(
                  border: OutlineInputBorder(),
                  labelText: 'email',
                ),
                onChanged: (text) {
                  email = text; //Error here
                },
              ),
            ),
            Padding(
              padding: EdgeInsets.all(10.0),
              child: TextField(
                obscureText: true,
                decoration: InputDecoration(
                  border: OutlineInputBorder(),
                  labelText: 'password',
                ),
              ),
            )
          ],
        ),
      ),
    );
  }
}

The I tried to elimanate the const label from Column, but gives me the warning &quot;Prefer const with constant constructors&quot;.
","flutter, dart",1,74512430,"This const needs to be removed:
children: const &lt;Widget&gt;[

Then you can add const in other places. I'd guess that the IDE helps you out there. It could be used e.g. here padding: EdgeInsets.all(10.0), so the result will be:
padding: const EdgeInsets.all(10.0),

and so forth...
"
73537413,Adding createdAt and updatedAt in pymongo,"I want to add auto generated field created_at and updated_at in mongodb in python using pymongo.
This functionality is provided in Javascript when creating mongo schema using
var yourSchema = new Schema({..}, { timestamps: { createdAt: 'created_at', updatedAt: 'updated_at'} });

How exactly can this be done in pymongo?
","python-3.x, mongodb, pymongo",0,73537452,"This is a mongoose feature, not to be confused with javascript or MongoDB.
pymongo does not offer such capabilities.
You will just have to manually specify them in your operations, for example:
from datetime import datetime

db.collection.updateOne({
   &quot;key&quot;: 5
},
{
  &quot;$set&quot;: { &quot;updated_at&quot;: datetime.now() },
  &quot;$setOnInsert&quot;: { &quot;created_at&quot;: datetime.now() }
}, upsert=True)

"
73151371,How can I extract the start and end of multiple ranges from a column?,"I have a database where a column called StatusMotor is so:
+++++++++++++++++++++++++++++++
+ Date-time      + MotorStatus+
+++++++++++++++++++++++++++++++
+ 03-02-20 18:35 + Start      +  
+ 03-02-20 18:35 + Start      +
+ 03-02-20 18:36 + Start      +
+ 03-02-20 18:35 + Start      +
+ 03-02-20 18:36 + Start      +
+ 03-02-20 18:36 + Start      +
+ 03-02-20 18:36 + Stop       +
+ 03-02-20 18:36 + Stop       +
+ 03-02-20 18:36 + Stop       +
+ 03-02-20 18:36 + Standby    + 
+ 03-02-20 18:37 + Standby    +
+ 03-02-20 18:37 + Start      +
+ ...            + .... 


I have three status (START, STOP, STAND BY) and i would extract moments when Motor works:
the date-time when i have 1st Start or Start after a Stop and Standby,
and when I have last start before a Stop or Standby.
select DateTime, MotorStatus
from TableName 
Where MotorStatus like 'Start' and...

I don't know what condition i put to have this range.
How i could to do?
","mysql, conditional-statements, range, key-value, record",1,73151529,"This is a gaps and islands problem, and on MySQL 8+ we can use the difference in row numbers method here:
WITH cte AS (
    SELECT *, ROW_NUMBER() OVER (ORDER BY DateTime) rn1,
              ROW_NUMBER() OVER (PARTITION BY MotorStatus ORDER BY DateTime) rn2
    FROM yourTable
)

SELECT MIN(DateTime) AS start, MAX(DateTime) AS `end`
FROM cte
WHERE MotorStatus = 'Start'
GROUP BY rn1 - rn2
ORDER BY start;


Demo
"
74509701,How to get minimum LocalDateTime from array in Java,"I have an array:
LocalDateTime[] onTimes
I would like to find an efficient way (without iteration) of finding the minimum LocalDateTime.
Is there a quick way to do this?
","java, arrays, minimum",0,74509728,"You could, conceivably, use recursion; but I would not recommend that for performance. The best way I can think of is using the streams api like
LocalDateTime min = Arrays.stream(onTimes).min(Comparator.naturalOrder())
        .orElseThrow();

Note: This still iterates all elements internally to find the minimum.
For completeness sake; to do this without iteration, as I said, might be done recursively.
public static LocalDateTime getMinimum(LocalDateTime[] onTimes) {
    return getMinimum(onTimes, 0);
}

private static LocalDateTime getMinimum(LocalDateTime[] onTimes, int i) {
    if (i + 1 &lt; onTimes.length) {
        return min(onTimes[i], getMinimum(onTimes, i + 1));
    } else {
        return onTimes[i];
    }
}

private static LocalDateTime min(LocalDateTime a, LocalDateTime b) {
    if (a.compareTo(b) &lt;= 0) {
        return a;
    }
    return b;
}

"
73709225,React Javascript Multiple Arrays to an Object of Arrays,"I have a set of arrays that have multiple bits of data that I want to arrange into a new array of data.
This is what I have:
const dateArray = [&quot;9/13/2022&quot;, &quot;9/13/2022&quot;, &quot;9/13/2022&quot;, &quot;9/13/2022&quot;,&quot;9/13/2022&quot;]
const timeArray = [&quot;00:00&quot;, &quot;00:01&quot;, &quot;00:02&quot;, &quot;00:03&quot;, &quot;00:04&quot;]
const integerArray = [1,2,3,4,5]

This is what I want:
{
    row0: [&quot;9/13/2022&quot;, &quot;00:00&quot;, 1],
    row1: [&quot;9/13/2022&quot;, &quot;00:01&quot;, 2],
    row2: [&quot;9/13/2022&quot;, &quot;00:02&quot;, 3],
    row3: [&quot;9/13/2022&quot;, &quot;00:03&quot;, 4],
    row4: [&quot;9/13/2022&quot;, &quot;00:04&quot;, 5]
}

Thanks for any info you could provide, I've tried to do map, reduce and group but I haven't had exactly what I want to come back and I'm losing my mind keeping track of what I've tried.
","javascript, reactjs, arrays, object, data-manipulation",1,73709243,"Using Array#reduce:


const dateArray = [""9/13/2022"", ""9/13/2022"", ""9/13/2022"", ""9/13/2022"",""9/13/2022""]
const timeArray = [""00:00"", ""00:01"", ""00:02"", ""00:03"", ""00:04""]
const integerArray = [1,2,3,4,5]

const res = dateArray.reduce((acc, _, i, dates) =&gt; ({
  ...acc, [`row${i}`]: [dates[i], timeArray[i], integerArray[i]]
}), {});

console.log(res);



"
73660116,Enabling SMTP Basic Authentication on Office365-Tenant after 1st Oct 2022,"I understand that SMTP Basic Authentication on Office365-Tenants will be automatically disabled from the 1st October 2022 on. As SMPT Oauth 2.0 Client Credential Flow has not been implement yet by Microsoft we can't move our product implementation (non-interactive) away from Basic Authentication.
We therefore need our customers to be able to keep SMTP Basic Authentication enabled after the 1st. October.
Question:

Will existing Office365-Tenants be able to keep SMTP with Basic Authentication enabled until Oauth 2.0 Client Credential Flow will be available for SMTP?
Is the same also true for new Tenants that are created in future?Â 

Thanks!
","azure, smtp, office365",0,73684145,"SMTP basic auth is not going away yet ðŸ˜‰
https://learn.microsoft.com/en-us/exchange/clients-and-mobile-in-exchange-online/deprecation-of-basic-authentication-exchange-online#pop-imap-and-smtp-auth (last paragraph of this section)
https://techcommunity.microsoft.com/t5/exchange-team-blog/basic-authentication-and-exchange-online-september-2021-update/ba-p/2772210 (Bolded line after the first paragraph)
"
74440532,Flutter - im having a problem calling a Api List,"Im having a problem using an Api which i have a List in. When i try to show, it shows like
[Instance of 'Source'] on screen
i had a problem like that with others data, but i was able to use a second source of call, like
finalApi![widget.index].aspect.name
but this one i can use only sources finalApi![widget.index].sources.toString()
i will show my api right below
import 'dart:convert';

List&lt;FinalApi&gt; finalApiFromMap(String str) =&gt;
    List&lt;FinalApi&gt;.from(json.decode(str).map((x) =&gt; FinalApi.fromMap(x)));

String finalApiToMap(List&lt;FinalApi&gt; data) =&gt;
    json.encode(List&lt;dynamic&gt;.from(data.map((x) =&gt; x.toMap())));

class FinalApi {
  FinalApi({
    required this.id,
    required this.name,
    required this.description,
    required this.tooltip,
    required this.order,
    required this.rank,
    required this.patch,
    required this.owned,
    required this.icon,
    required this.type,
    required this.aspect,
    required this.sources,
  });

  int id;
  String name;
  String description;
  String tooltip;
  int order;
  int rank;
  String patch;
  String owned;
  String icon;
  Aspect type;
  Aspect aspect;
  List&lt;Source&gt; sources;

  factory FinalApi.fromMap(Map&lt;String, dynamic&gt; json) =&gt; FinalApi(
        id: json[&quot;id&quot;],
        name: json[&quot;name&quot;],
        description: json[&quot;description&quot;],
        tooltip: json[&quot;tooltip&quot;],
        order: json[&quot;order&quot;],
        rank: json[&quot;rank&quot;],
        patch: json[&quot;patch&quot;],
        owned: json[&quot;owned&quot;],
        icon: json[&quot;icon&quot;],
        type: Aspect.fromMap(json[&quot;type&quot;]),
        aspect: Aspect.fromMap(json[&quot;aspect&quot;]),
        sources:
            List&lt;Source&gt;.from(json[&quot;sources&quot;].map((x) =&gt; Source.fromMap(x))),
      );

  Map&lt;String, dynamic&gt; toMap() =&gt; {
        &quot;id&quot;: id,
        &quot;name&quot;: name,
        &quot;description&quot;: description,
        &quot;tooltip&quot;: tooltip,
        &quot;order&quot;: order,
        &quot;rank&quot;: rank,
        &quot;patch&quot;: patch,
        &quot;owned&quot;: owned,
        &quot;icon&quot;: icon,
        &quot;type&quot;: type.toMap(),
        &quot;aspect&quot;: aspect.toMap(),
        &quot;sources&quot;: List&lt;dynamic&gt;.from(sources.map((x) =&gt; x.toMap())),
      };
}

class Aspect {
  Aspect({
    required this.id,
    required this.name,
  });

  int id;
  Name? name;

  factory Aspect.fromMap(Map&lt;String, dynamic&gt; json) =&gt; Aspect(
        id: json[&quot;id&quot;],
        name: nameValues.map[json[&quot;name&quot;]],
      );

  Map&lt;String, dynamic&gt; toMap() =&gt; {
        &quot;id&quot;: id,
        &quot;name&quot;: nameValues.reverse[name],
      };
}

enum Name {
  WATER,
  FIRE,
  BLUNT,
  PIERCING,
  LIGHTNING,
  NONE,
  EARTH,
  SLASHING,
  ICE,
  WIND,
  PIERCING_FIRE,
  BLUNT_EARTH,
  MAGIC,
  PHYSICAL
}

final nameValues = EnumValues({
  &quot;Blunt&quot;: Name.BLUNT,
  &quot;Blunt/Earth&quot;: Name.BLUNT_EARTH,
  &quot;Earth&quot;: Name.EARTH,
  &quot;Fire&quot;: Name.FIRE,
  &quot;Ice&quot;: Name.ICE,
  &quot;Lightning&quot;: Name.LIGHTNING,
  &quot;Magic&quot;: Name.MAGIC,
  &quot;None&quot;: Name.NONE,
  &quot;Physical&quot;: Name.PHYSICAL,
  &quot;Piercing&quot;: Name.PIERCING,
  &quot;Piercing/Fire&quot;: Name.PIERCING_FIRE,
  &quot;Slashing&quot;: Name.SLASHING,
  &quot;Water&quot;: Name.WATER,
  &quot;Wind&quot;: Name.WIND
});

class Source {
  Source({
    required this.type,
    required this.text,
    required this.relatedType,
    required this.relatedId,
  });

  Type? type;
  String text;
  dynamic relatedType;
  dynamic relatedId;

  factory Source.fromMap(Map&lt;String, dynamic&gt; json) =&gt; Source(
        type: typeValues.map[json[&quot;type&quot;]],
        text: json[&quot;text&quot;],
        relatedType: json[&quot;related_type&quot;],
        relatedId: json[&quot;related_id&quot;],
      );

  Map&lt;String, dynamic&gt; toMap() =&gt; {
        &quot;type&quot;: typeValues.reverse[type],
        &quot;text&quot;: text,
        &quot;related_type&quot;: relatedType,
        &quot;related_id&quot;: relatedId,
      };
}

enum Type { OTHER, DUNGEON }

final typeValues = EnumValues({&quot;Dungeon&quot;: Type.DUNGEON, &quot;Other&quot;: Type.OTHER});

class EnumValues&lt;T&gt; {
  Map&lt;String, T&gt; map;
  Map&lt;T, String&gt;? reverseMap;

  EnumValues(this.map);

  Map&lt;T, String&gt; get reverse {
    if (reverseMap == null) {
      reverseMap = map.map((k, v) =&gt; new MapEntry(v, k));
    }
    return reverseMap!;
  }
}

i dont understand much about Api and Json, but should be some information inside.
how i tried:
ListView.builder(
   shrinkWrap: true,
   itemCount: finalApi![widget.index].sources.length,
   itemBuilder: (context, index) {
   return Text(finalApi![widget.index].sources.toString());
  },
 ),

","flutter, dart, flutter-layout",1,74441131,"your listview is on sources, so if you want to show sources you need use its index on it. try this:
ListView.builder(
   shrinkWrap: true,
   itemCount: finalApi![widget.index].sources.length,
   itemBuilder: (context, index) {
      return Text(finalApi![widget.index].sources[index].text);//&lt;--- change this
  },
 ),

"
74587419,I can't get the description part in NestJs,"
Hello everyone. In the trainings I watch, this explanation comes out of everyone, but it does not come out to me. I tried all the plugins but couldn't make it. How can I handle this. Thanks in advance.
Hello everyone. In the trainings I watch, this explanation comes out of everyone, but it does not come out to me. I tried all the plugins but couldn't make it. How can I handle this. Thanks in advance.
PS
I use vscode. I've tried all the plugins related to NestJs. In all tutorials, this comes out when they move the mouse cursor between the e.g. Controller ( | ).
","javascript, typescript, visual-studio-code, nestjs, jsdoc",0,74587545,"This is JSDocs and is coming from the node_modules/@nestjs/common/decorators/core/controller.decorator.d.ts
If you Ctrl + Click on @Controller (Go to Definition) you should get:
/**
 * Decorator that marks a class as a Nest controller that can receive inbound
 * requests and produce responses.
 *
 * An HTTP Controller responds to inbound HTTP Requests and produces HTTP Responses.
 * It defines a class that provides the context for one or more related route
 * handlers that correspond to HTTP request methods and associated routes
 * for example `GET /api/profile`, `POST /users/resume`.
 *
 * A Microservice Controller responds to requests as well as events, running over
 * a variety of transports [(read more here)](https://docs.nestjs.com/microservices/basics).
 * It defines a class that provides a context for one or more message or event
 * handlers.
 *
 * @see [Controllers](https://docs.nestjs.com/controllers)
 * @see [Microservices](https://docs.nestjs.com/microservices/basics#request-response)
 *
 * @publicApi
 */
export declare function Controller(): ClassDecorator;

This means that you have @nestjs/common package installed in your local repository.
Ensure you have no conflicting VS Code Extensions/Snippets/Plugins installed.
"
74187884,TextField mui component autoFocus end of text,"Right now, autoFocus applies to the beginning of the input but I'd like to get focused on the end of the text.
export default function BasicTextFields() {
  const [value, setValue] = React.useState(
    &quot;hello world. hello world. hello world&quot;
  );

  return (
    &lt;Box
      component=&quot;form&quot;
      sx={{
        &quot;&amp; &gt; :not(style)&quot;: { m: 1, width: &quot;25ch&quot; }
      }}
      noValidate
      autoComplete=&quot;off&quot;
    &gt;
      &lt;TextField
        id=&quot;outlined-basic&quot;
        variant=&quot;outlined&quot;
        value={value}
        onChange={(e) =&gt; setValue(e.target.value)}
        multiline
        autoFocus
      /&gt;
    &lt;/Box&gt;
  );
}

Is this possible?
I tried this from this link : https://github.com/mui/material-ui/issues/12779
But this didn't work for my case.
&lt;TextField
    variant=&quot;outlined&quot;
    type=&quot;text&quot;
    id=&quot;field-comment&quot;
    name=&quot;comment&quot;
    label=&quot;Label&quot;
    placeholder=&quot;Placeholder&quot;
    onChange={(event) =&gt; setValue(event.target.value)}
    inputRef={(input) =&gt; input &amp;&amp; input.focus()}
    onFocus={(e) =&gt;
        e.currentTarget.setSelectionRange(
        e.currentTarget.value.length,
        e.currentTarget.value.length
    )}
    multiline
    rows={4}
    value={value}
    className={classes.sCommentTextField}
/&gt;

I also tried this.
&lt;TextField
  inputRef={input =&gt; input &amp;&amp; input.focus()}
/&gt;

but it also didn't work.
Are there any ways that I can do this?
","reactjs, material-ui, autofocus",2,74195479,"This works!
&lt;TextField
    variant=&quot;outlined&quot;
    type=&quot;text&quot;
    id=&quot;field-comment&quot;
    name=&quot;comment&quot;
    label=&quot;Label&quot;
    placeholder=&quot;Placeholder&quot;
    onChange={(event) =&gt; setValue(event.target.value)}
    inputRef={(input) =&gt; input &amp;&amp; input.focus()}
    onFocus={(e) =&gt;
        e.currentTarget.setSelectionRange(
        e.currentTarget.value.length,
        e.currentTarget.value.length
    )}
    multiline
    rows={4}
    value={value}
    className={classes.sCommentTextField}
/&gt;

Remove autoFocus and add inputRef and onFocus
"
74343850,jolt spec to remove 0 byte files,"I am trying to find only file names having valid size &gt;0 using jolt.
{
  &quot;objectName&quot;: &quot;data&quot;,
  &quot;path&quot;: &quot;/user/testuser/test_project/processing&quot;,
  &quot;type&quot;: &quot;directory&quot;,
  &quot;owner&quot;: &quot;testuser&quot;,
  &quot;group&quot;: &quot;testuser&quot;,
  &quot;length&quot;: &quot;2733&quot;,
  &quot;countFiles&quot;: &quot;7&quot;,
  &quot;countDirs&quot;: &quot;1&quot;,
  &quot;content&quot;: [
    {
      &quot;objectName&quot;: &quot;part-00000-f56d8bfa-2a3d-438c-89a5-d9a2460e6c66-c000.json&quot;,
      &quot;path&quot;: &quot;/user/testuser/test_project/processing/data&quot;,
      &quot;type&quot;: &quot;file&quot;,
      &quot;owner&quot;: &quot;testuser&quot;,
      &quot;group&quot;: &quot;testuser&quot;,
      &quot;length&quot;: &quot;0&quot;
    },
    {
      &quot;objectName&quot;: &quot;part-00043-f56d8bfa-2a3d-438c-89a5-d9a2460e6c66-c000.json&quot;,
      &quot;path&quot;: &quot;/user/testuser/test_project/processing/data&quot;,
      &quot;type&quot;: &quot;file&quot;,
      &quot;owner&quot;: &quot;testuser&quot;,
      &quot;group&quot;: &quot;testuser&quot;,
      &quot;length&quot;: &quot;782&quot;
    }
  ]
}

Below is my jolt spec
[
  {
    &quot;operation&quot;: &quot;shift&quot;,
    &quot;spec&quot;: {
      &quot;content&quot;: {
        &quot;*&quot;: {
          &quot;type&quot;: {
            &quot;file&quot;: {
              &quot;@2&quot;: &quot;files[]&quot;
            }
          }
        }
      }
    }
  },
  {
    &quot;operation&quot;: &quot;shift&quot;,
    &quot;spec&quot;: {
      &quot;files&quot;: {
        &quot;*&quot;: {
          &quot;objectName&quot;: {
            &quot;*&quot;: {
              &quot;@2&quot;: &quot;files[]&quot;
            }
          }
        }
      }
    }
  },
  {
    &quot;operation&quot;: &quot;shift&quot;,
    &quot;spec&quot;: {
      &quot;files&quot;: {
        &quot;*&quot;: {
          &quot;objectName&quot;: &quot;files.[&amp;1].filename&quot;,
          &quot;path&quot;: &quot;files.[&amp;1].filepath&quot;,
          &quot;length&quot;: &quot;files.[&amp;1].filesize&quot;
        }
      }
    }
  }
]

In the output i want only the files having size greater than 0
currently it gives
{
  &quot;files&quot;: [
    {
      &quot;filename&quot;: &quot;part-00000-f56d8bfa-2a3d-438c-89a5-d9a2460e6c66-c000.json&quot;,
      &quot;filepath&quot;: &quot;/user/testuser/test_project/processing/data&quot;,
      &quot;filesize&quot;: &quot;0&quot;
    },
    {
      &quot;filename&quot;: &quot;part-00043-f56d8bfa-2a3d-438c-89a5-d9a2460e6c66-c000.json&quot;,
      &quot;filepath&quot;: &quot;/user/testuser/test_project/processing/data&quot;,
      &quot;filesize&quot;: &quot;782&quot;
    }
  ]
}

I Tried using remove jolt spech but i can only find examples of removing null values , not sure how to remove numbers or using a filter like length &gt; 0 .
Also tried using shift operator with &quot;0&quot; and &quot;*&quot; on length attribute, but it doesn't remove the tag.
","json, specifications, jolt",1,74345789,"You can use successive shift transformations along with a conditional logic to separate the case when length = 0 or !=0, and lastly use a remove transformation to drop the unnecessary attribute such as
[
  {
    &quot;operation&quot;: &quot;shift&quot;,
    &quot;spec&quot;: {
      &quot;*&quot;: &quot;&amp;&quot;, // elements other than &quot;content&quot; array
      &quot;content&quot;: {
        &quot;*&quot;: {
          &quot;length&quot;: {
            &quot;0&quot;: &quot;AttributeToRemove&quot;, // case when length  = 0
            &quot;*&quot;: { // case when length != 0
              &quot;@(2,objectName)&quot;: &quot;files.&amp;3.filename&quot;,
              &quot;@(2,path)&quot;: &quot;files.&amp;3.filepath&quot;,
              &quot;@1&quot;: &quot;files.&amp;3.filesize&quot;
            }
          }
        }
      }
    }
  },
  {
    &quot;operation&quot;: &quot;shift&quot;,
    &quot;spec&quot;: {
      &quot;*&quot;: &quot;&amp;&quot;,
      &quot;fi*&quot;: {
        &quot;*&quot;: {
          &quot;@&quot;: &quot;&amp;2[]&quot; // go 2 levels up the tree to grab the literal `files` to replicate by using &amp;2
        }
      }
    }
  },
  {
    // get rid of redundantly generated attribute due to length  = 0 case
    &quot;operation&quot;: &quot;remove&quot;,
    &quot;spec&quot;: {
      &quot;AttributeToRemove&quot;: &quot;&quot;
    }
  }
]

the demo on the site http://jolt-demo.appspot.com/ is

"
74118094,how to get the subscription status with stripe.subscriptions,"I am trying to get a customer's subscription status. I already have their customer id. I am trying to determine from their status if they have paid or have cancelled, unpaid, ended, etc. I am in php.
this is how i get their customer id
 $customersResponse = $stripe-&gt;customers-&gt;all(['email' =&gt; $_SESSION['userid']]);     
 $custid1 = $customersResponse-&gt;data[0]-&gt;id;  

Now I want to get their status so I use
$subscriptionsResponse = $stripe-&gt;subscriptions-&gt;all(['customer' =&gt; $custid1]
$status=$subscriptionsResponse-&gt;data[0] -&gt; status;   but status is always null                      

In my testing I am using a customer who has currently cancelled. I am finding this data[0] to be terribly hard to debug. How can I get the $status set correctly?
",stripe-payments,0,74118261,"Stripe's API reference doc shows how to get subscription list and filter by status.
Stripe won't return 'canceled' subscriptions unless you specify 'status' =&gt; 'canceled' or 'status' =&gt; 'all' in the request. If status is omitted from the request, the response will only include non-canceled subscriptions.
You also need to pass a value for the customer parameter if you want to list a specific customer's subscription(s) only.
In short, you need to pass status and customer query parameters in your request to receive all subscriptions of specific customer.
"
73591819,"How to show the week before posts from ""You may have missed"" post section in WP blog with PHP","I am working on my WordPress blog and in the footer area I have a slider that consists of 4 posts. That slider is called &quot;You may have missed&quot; and currently it is showing the latest posts. With 'rand' arg I managed to sort that it shows random posts but my concern is that it can go months backward. I want to exclude current week posts and only show the week before posts so I can have a valid you &quot;You may have missed&quot; in my blog. For example, if current week is 34, show posts only from week 33, if it is week 45 show posts only from week 44 etc. I want to solve it through arrays.
This is what I currently have
            $footer_post_type = array(
            'posts_per_page' =&gt; 4,
            'post__not_in' =&gt; get_option('sticky_posts'),
            'year' =&gt; date( 'Y' ),
            'week' =&gt; strftime( '%U' ),
            'orderby' =&gt; 'rand',
            'post_type' =&gt; array(
                'post'
            ),

","php, arrays, wordpress, footer, posts",0,73594579,"Should be pretty straightforward. Just have to subtract 1 from your current week.
You can shorten this code a bit but included everything for demo purposes:
$week = date( 'W' ); // Get current week of the year
$year = date( 'Y' ); // Get current year

$last_week = $week - 1; // Subtract 1 to get previous week number


// Create your query args

$args = array(
 'posts_per_page' =&gt; 4,
 'post__not_in' =&gt; get_option('sticky_posts'),
 'date_query' =&gt; array(
        array(
            'year' =&gt; $year, // Year here
            'week' =&gt; $last_week, // Week here
        ),
    ),
 'orderby' =&gt; 'rand',
 'post_type' =&gt; 'post'
            
);

$query = new WP_Query( $args );

"
73651301,"Volume Mounts for main directories of containers like /mnt, /dev, /var to volumes","Can we mount directly the main dirs of containers to volumes as part of kubernetes podspec.
For ex:

/mnt
/dev
/var

All files and subdir of /mnt, /dev, /var should be mounted to volumes as part of podspec.
How can we do this?
","kubernetes, kubernetes-pod",1,73719132,"For development purposes, you can create a hostPath Persistent Volume, but if you want to implement this for production, I strongly recommend you to use some NFS.
Here you have an example on how to use a NFS in a Pod definition:
kind: Pod
apiVersion: v1
metadata:
  name: nfs-in-a-pod
spec:
  containers:
    - name: app
      image: alpine
      volumeMounts:
        - name: nfs-volume
          mountPath: /var/nfs # change the destination you like the share to be mounted to
  volumes:
    - name: nfs-volume
      nfs:
        server: nfs.example.com # change this to your NFS server
        path: /share1 # change this to the relevant share

And here an example of a hostPath Persistent Volume:
apiVersion: v1
kind: PersistentVolume
metadata:
  name: task-pv-volume
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: &quot;/mnt/data&quot;
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: task-pv-claim
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 3Gi
---
apiVersion: v1
kind: Pod
metadata:
  name: task-pv-pod
spec:
  volumes:
    - name: task-pv-storage
      persistentVolumeClaim:
        claimName: task-pv-claim
  containers:
    - name: task-pv-container
      image: nginx
      ports:
        - containerPort: 80
          name: &quot;http-server&quot;
      volumeMounts:
        - mountPath: &quot;/usr/share/nginx/html&quot;
          name: task-pv-storage

In the hostPath example, all files inside /mnt/data will be mounted as /usr/share/nginx/html in the Pod.
"
73017844,HTML to PDF using jspdf in ionic,"I want to convert html to pdf using jspdf but i want to generate the pdf without showing the html content to users. The technology im using is ionic.
Please help on this issue
","angular, ionic-framework, mobile-development",-1,73022952,"  public downloadPDF() {
    const doc = new jsPDF();

    const specialElementHandlers = {
      '#editor': function (element, renderer) {
        return true;
      }
    };

    const content = this.content.nativeElement;

    doc.fromHTML(content.innerHTML, 15, 15, {
      width: 190,
      'elementHandlers': specialElementHandlers
    });

    doc.save('test.pdf');
  }

Example: https://stackblitz.com/edit/angular-html-to-pdf-example
"
72863142,Git fetch does not fetch the latest commits from the remote,"I have a two-machine (Mac and Win) setup where I need to transfer changes from the Windows machine to the Mac. So I make my changes on the Win machine, commit and push them to GitHub. So far, so good. (I have confirmed that the new commits are indeed on GitHub.)
But I have recently started having a problem on the Mac that git fetch origin does not fetch the new commits from GitHub. Therefore git pull (with the branch in question checked out) tells me it is already up to date.
This repository is a submodule. I looked at the config files for the submodule on both machines, which have identical settings for remotes and for the branch. They look as follows (with account and branch names changed to generic ones).
[remote &quot;origin&quot;]
    url = git@github.com:upstream/myrepo.git
    fetch = +refs/heads/*:refs/remotes/origin/*
    pushurl = git@github.com:personal/myrepo.git
[remote &quot;upstream&quot;]
    url = git@github.com:upstream/myrepo.git
    fetch = +refs/heads/*:refs/remotes/upstream/*

[branch &quot;mybranch-name&quot;]
    remote = origin
    merge = refs/heads/mybranch-name

My question is, does anyone know why git fetch origin from the Mac is ignoring the new commits in the remote repository? Is there a way to force it to fetch from the actual remote repository on GitHub? (Since clearly this is not currently happening.)
Currently I have partial write access to the upstream remote, which allows me to work around this problem by pushing my branch there, then pulling it into the local branch on the Mac (then pushing to origin from the Mac). But I will soon be losing write access to upstream.
If it matters, I normally use SourceTree to manage git, but in this case I have been  doing the git commands directly from the command line with no difference in behavior. I have several other submodules that are not having this problem, nor is the main repository.
","git, github",0,72863222,"The separate url and pushurl here are suspicious:

[remote &quot;origin&quot;]
    url = git@github.com:upstream/myrepo.git
    fetch = +refs/heads/*:refs/remotes/origin/*
    pushurl = git@github.com:personal/myrepo.git


As the git remote documentation says:

Note that the push URL and the fetch URL, even though they can be set differently, must still refer to the same place. What you pushed to the push URL should be what you would see if you immediately fetched from the fetch URL. If you are trying to fetch from one place (e.g. your upstream) and push to another (e.g. your publishing repository), use two separate remotes.

This caveat is, unfortunately, apparently only found in the git remote documentation; it probably should be in git fetch, git push, and git config documentation as well.
(As you've confirmed in the comments, this seems to be the basic problem, and apparently SourceTree did this for some reason known only to SourceTree.)
"
